{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'custom.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b224c104e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# custom librarys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcustom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;31m# 저장된 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'custom.model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import visdom\n",
    "import copy\n",
    "import torch.nn.utils.prune as prune\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "# custom librarys\n",
    "import custom.model as cm # 저장된 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(55)\n",
    "#torch.cuda.manual_seed_all(55)\n",
    "#torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 1\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visdom setting\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")\n",
    "\n",
    "# make plot\n",
    "vis_plt = vis.line(X=torch.Tensor(1).zero_(), Y=torch.Tensor(1).zero_(), \n",
    "                    opts=dict(title = 'LeNet300_Accuracy_Tracker',\n",
    "                              legend=['100'],\n",
    "                             showlegend=True,\n",
    "                              xtickmin = 0,\n",
    "                              xtickmax = 20000,\n",
    "                              ytickmin = 0.95,\n",
    "                              ytickmax = 0.99\n",
    "                             )\n",
    "                   )\n",
    "\n",
    "def visdom_plot(loss_plot, loss_value, num, name):\n",
    "    vis.line(X = num,\n",
    "            Y = loss_value,\n",
    "            win = loss_plot,\n",
    "            name = name,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "lr = 0.0012\n",
    "#epochs = 50\n",
    "#epochs = 20\n",
    "epochs = 30\n",
    "batch_size = 60\n",
    "weight_decay = 1.2e-3\n",
    "iteration = 0\n",
    "remaining_weight = 1\n",
    "prune_per = 0.2\n",
    "# number of iteration\n",
    "noi = 11\n",
    "\n",
    "switch = 0\n",
    "best_accu = []\n",
    "# 마지막 layer의 Pruning rate는 기존의 1/2\n",
    "# prune_per_ll = prune_per/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_train = dsets.MNIST(root='../MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms,\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root='../MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms,\n",
    "                        download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, cp_mask, switch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    EPS = 1e-6\n",
    "    for data, label in dataloader:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "\n",
    "        if switch == 1:\n",
    "            # 0-weight 학습 방지 code\n",
    "            i = 0\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    p.grad.data *= cp_mask[i]\n",
    "                    i += 1\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss / len(dataloader)\n",
    "    return running_loss\n",
    "\n",
    "def test(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            predicted = torch.argmax(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            accuracy = (correct/total)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# prune function\n",
    "# pruning mask 생성 -> mask 복사 -> init값 복사 -> prune 진행\n",
    "def weight_init(model1, model2, rate):\n",
    "    # prune mask 생성\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # bottle neck 방지\n",
    "            if name == 'fc3':\n",
    "                prune.l1_unstructured(module, name = 'weight', amount = (rate/2))\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name = 'weight', amount = rate)\n",
    "                        \n",
    "    # mask 복사\n",
    "    cp_mask = []\n",
    "    for name, mask in model1.named_buffers():\n",
    "        cp_mask.append(mask)\n",
    "    # init 값 복사\n",
    "    \n",
    "    for name, p in model1.named_parameters():\n",
    "        if 'weight_orig' in name:\n",
    "            for name2, p2 in model2.named_parameters():\n",
    "                if name[0:len(name) - 5] in name2:\n",
    "                    p.data = copy.deepcopy(p2.data)\n",
    "                    break\n",
    "        if 'bias_orig' in name:\n",
    "            for name2, p2 in model2.named_parameters():\n",
    "                if name[0:len(name) - 5] in name2:\n",
    "                    p.data = copy.deepcopy(p2.data)\n",
    "                    break\n",
    "                    \n",
    "    # prune 진행\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.remove(module, name = 'weight')\n",
    "            \n",
    "    return cp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cm.LeNet300().to(device)\n",
    "model_init = copy.deepcopy(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "#optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = 1.2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPS = 1e-6\n",
    "# number of weight\n",
    "a = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "#b = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "b = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "\n",
    "now = (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_now(model):\n",
    "    fc1_1 = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "    fc1_0 = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    fc1 = fc1_1 + fc1_0\n",
    "    fc1_p = fc1_0 / fc1_1\n",
    "    fc2_1 = ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "    fc2_0 = ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    fc2 = fc2_1 + fc2_0\n",
    "    fc3_1 = ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "    fc3_0 = ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    fc3 = fc3_1 + fc3_0\n",
    "    #print(fc1, fc2, fc3, fc1+fc2+fc3, fc1_1 + fc2_1 + fc3_1 ,fc1_0 + fc2_0 + fc3_0)\n",
    "    print('%d' % (fc1+fc2+fc3),\n",
    "         '(%d |' % (fc1_1+fc2_1+fc3_1),\n",
    "         '%d)' % (fc1_0+fc2_0+fc3_0)\n",
    "         )\n",
    "    print('%d' % fc1,\n",
    "         '(%d |' % fc1_1,\n",
    "         '%d)' % fc1_0\n",
    "         )\n",
    "    print('%d' % fc2,\n",
    "         '(%d |' % fc2_1,\n",
    "         '%d)' % fc2_0\n",
    "         )\n",
    "    print('%d' % fc3,\n",
    "         '(%d |' % fc3_1,\n",
    "         '%d)' % fc3_0\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_init(model, model_init, 1 - weight_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_init(model, model_init, 1 - weight_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model.fc3.weight_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.l1_unstructured(module, name = 'weight', amount = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # init 값 복사\n",
    "for name, p in model.named_parameters():\n",
    "     if 'weight_orig' in name:\n",
    "        for name2, p2 in model_init.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break\n",
    "    if 'bias_orig' in name:\n",
    "        for name2, p2 in modelinit.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.remove(module, name = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model.fc3.weight[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model_init.fc3.weight[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(noi):\n",
    "    best_accu.append(0)\n",
    "    best_accu[i] = [0, 0, 0]\n",
    "    cp_mask = []\n",
    "    if i != 0:\n",
    "        remaining_weight = remaining_weight * (1-prune_per)\n",
    "        cp_mask = weight_init(model, model_init, 1 - remaining_weight)\n",
    "        switch = 1\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "    print(\"Learning start(remaining weight : %d%%)\" % round(remaining_weight * 100, 1))\n",
    "    start_time = timeit.default_timer()\n",
    "    pw = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    print('pruned weight (All | Pruned) %d |' % now,'%d' % pw)\n",
    "    #print(model.fc3.weight[0][0])\n",
    "    #print(model_init.fc3.weight[0][0])\n",
    "    calc_now(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        if epoch == 0:\n",
    "            accuracy = test(model, test_loader, criterion)\n",
    "            visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([0]), str(round(remaining_weight*100, 1)))\n",
    "            print('[epoch : %d]' % (epoch),\n",
    "             '(loss: x.xxxxx)',\n",
    "             '(accu: %.4f)' % (accuracy)\n",
    "             )\n",
    "        running_loss = train(model, train_loader, optimizer, criterion, cp_mask, switch)\n",
    "        accuracy = test(model, test_loader, criterion)\n",
    "        visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([(epoch+1) * 1000]), str(round(remaining_weight*100, 1)))\n",
    "        \n",
    "        # best accuracy list (weight_remain, epoch, accuracy)\n",
    "        if best_accu[i][2] <= accuracy:\n",
    "            best_accu[i] = [remaining_weight, epoch, accuracy]\n",
    "        \n",
    "        print('[epoch : %d]' % (epoch+1),\n",
    "             '(loss: %.5f)' % (running_loss),\n",
    "             '(accu: %.4f)' % (accuracy)\n",
    "             )\n",
    "    stop_time = timeit.default_timer()\n",
    "    #print(model.fc3.weight[0][0])\n",
    "    #print(model_init.fc3.weight[0][0])\n",
    "    print(\"Finish!\",\n",
    "          \"(Best accu: %.4f)\" % best_accu[i][2],\n",
    "          \"(Time taken(sec) : %.2f)\" % (stop_time - start_time),\n",
    "          \"\\n\")\n",
    "    calc_now(model)\n",
    "    print(\"\\n\\n\\n\\n\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy per weight remaining\")\n",
    "for i in range(len(best_accu)):\n",
    "    print(\"Remaining weight %.1f %% \" % (best_accu[i][0] * 100),\n",
    "         \"Epoch %d\" % best_accu[i][1],\n",
    "         \"Accu %.4f %%\" % best_accu[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, p in model.named_parameters():\n",
    "    EPS = 1e-6\n",
    "    if 'weight' in name:\n",
    "        tensor = p.data.cpu().numpy()\n",
    "        grad_tensor = p.grad.data.cpu().numpy()\n",
    "        grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "        p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        print(p.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 숫자 60000\n",
    "배치 길이 60\n",
    "배치 개수 1000\n",
    "epoch = 50\n",
    "\n",
    "이터레이션 횟수 50000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
