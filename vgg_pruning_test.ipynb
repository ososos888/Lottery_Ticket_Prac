{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import visdom\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# visdom setting\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")\n",
    "\n",
    "# make plot\n",
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),\n",
    "                    opts=dict(title = 'VGG_Loss_Tracker',\n",
    "                              legend=['T_loss', 'V_loss'],\n",
    "                             showlegend=True\n",
    "                             )\n",
    "                   )\n",
    "\n",
    "def loss_tracker(loss_plot, loss_value, num, name):\n",
    "    vis.line(X = num,\n",
    "            Y = loss_value,\n",
    "            win = loss_plot,\n",
    "            name = name,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "torch.manual_seed(555)\n",
    "torch.cuda.manual_seed_all(555)\n",
    "np.random.seed(555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정된 학습용 기기 : cuda:1\n"
     ]
    }
   ],
   "source": [
    "# CUDA 설정\n",
    "\n",
    "GPU_NUM = 1\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#device = torch.device('cuda')\n",
    "print(\"설정된 학습용 기기 :\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "lr = 0.1\n",
    "epochs = 3\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 전처리\n",
    "transform = transforms.Compose([transforms.ToTensor()]\n",
    "                              )\n",
    "# Data load\n",
    "trainset = dsets.CIFAR10('../CIFAR10/',\n",
    "                         train=True,\n",
    "                         transform = transform,\n",
    "                         download=False)\n",
    "\n",
    "# transforms.Normalize\n",
    "train_data_mean = trainset.data.mean( axis=(0,1,2) )\n",
    "train_data_std = trainset.data.std( axis=(0,1,2) )\n",
    "\n",
    "# 각 pixel은 0~255값을 가지므로 이를 나누어 정규화한다.\n",
    "train_data_mean /= 255\n",
    "train_data_std /= 255\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize(40),\n",
    "                                     transforms.RandomCrop(32),\n",
    "                                    transforms.ToTensor(),\n",
    "                               transforms.Normalize(train_data_mean, train_data_std)\n",
    "                               ])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(train_data_mean, train_data_std)\n",
    "                               ])\n",
    "\n",
    "# Normalize 된 dataset으로 reload\n",
    "trainset = dsets.CIFAR10('../CIFAR10/',\n",
    "                         train=True,\n",
    "                         transform = transform_test,\n",
    "                         download=False)\n",
    "\n",
    "valset = dsets.CIFAR10('../CIFAR10/',\n",
    "                         train=True,\n",
    "                         transform = transform,\n",
    "                         download=False)\n",
    "\n",
    "testset = dsets.CIFAR10('../CIFAR10/',\n",
    "                         train=False,\n",
    "                         transform = transform,\n",
    "                         download=False)\n",
    "\n",
    "# validation set 분류\n",
    "validation_ratio = 0.15\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "# 설정한 비율만큼 분할 시의 data 갯수\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "# shuffle\n",
    "np.random.shuffle(indices)\n",
    "# data 분할\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = trainset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          sampler = train_sampler,\n",
    "                                          drop_last = True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset = valset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          sampler = val_sampler,\n",
    "                                          drop_last = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = testset,\n",
    "                                          batch_size = 4,\n",
    "                                          shuffle = False,\n",
    "                                          drop_last = True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog',\n",
    "           'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=4096, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model output channel 수를 맞춰준다\n",
    "model = models.vgg16()\n",
    "model.fc = nn.Linear(4096, 10)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.prune_iterations\n",
    "args.prune_type\n",
    "args.prune_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na = torch.Tensor(1,3,32,32).to(device)\\nout = model(a)\\nprint(out)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's output channel check\n",
    "'''\n",
    "a = torch.Tensor(1,3,32,32).to(device)\n",
    "out = model(a)\n",
    "print(out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 훈련 함수\n",
    "def train(model, optimizer, criterion, DataLoader, total_batch):\n",
    "    model.train()    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(DataLoader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss / total_batch\n",
    "    return running_loss \n",
    "    \n",
    "# validation loss 함수\n",
    "def loss_eval(model, criterion, DataLoader, total_batch):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(DataLoader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) \n",
    "            running_loss += loss / total_batch\n",
    "        return running_loss    \n",
    "        \n",
    "# accuracy 계산 함수\n",
    "def accu_eval(DataLoader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(DataLoader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "# 특정 가중치값이 커질수록 오버피팅이 발생할 가능성이 높아지므로\n",
    "# 이를 해소하기 위해 특정값을 손실함수에 더해주는 것 (가중치 업데이트 쏠림 방지)\n",
    "optimizer = optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=3e-4)\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=13, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinhyuk/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 1] (T_loss: 2.06267)  (V_loss: 1.584349)  (Val Accuract : 41 %)\n",
      "[epoch : 2] (T_loss: 1.51753)  (V_loss: 1.387423)  (Val Accuract : 49 %)\n",
      "[epoch : 3] (T_loss: 1.33654)  (V_loss: 1.316104)  (Val Accuract : 52 %)\n",
      "[epoch : 4] (T_loss: 1.17735)  (V_loss: 1.215312)  (Val Accuract : 57 %)\n",
      "[epoch : 5] (T_loss: 1.07808)  (V_loss: 1.204826)  (Val Accuract : 57 %)\n",
      "[epoch : 6] (T_loss: 0.99805)  (V_loss: 1.020895)  (Val Accuract : 63 %)\n",
      "[epoch : 7] (T_loss: 0.92629)  (V_loss: 1.098331)  (Val Accuract : 62 %)\n",
      "[epoch : 8] (T_loss: 0.88024)  (V_loss: 0.951883)  (Val Accuract : 66 %)\n",
      "[epoch : 9] (T_loss: 0.83776)  (V_loss: 0.944779)  (Val Accuract : 67 %)\n",
      "[epoch : 10] (T_loss: 0.80634)  (V_loss: 0.866553)  (Val Accuract : 68 %)\n",
      "[epoch : 11] (T_loss: 0.76882)  (V_loss: 0.996573)  (Val Accuract : 66 %)\n",
      "[epoch : 12] (T_loss: 0.74905)  (V_loss: 1.041671)  (Val Accuract : 64 %)\n",
      "[epoch : 13] (T_loss: 0.60526)  (V_loss: 0.835952)  (Val Accuract : 71 %)\n",
      "[epoch : 14] (T_loss: 0.57611)  (V_loss: 0.767144)  (Val Accuract : 73 %)\n",
      "[epoch : 15] (T_loss: 0.55795)  (V_loss: 0.892238)  (Val Accuract : 70 %)\n",
      "[epoch : 16] (T_loss: 0.54986)  (V_loss: 0.926891)  (Val Accuract : 70 %)\n",
      "[epoch : 17] (T_loss: 0.53632)  (V_loss: 0.829581)  (Val Accuract : 72 %)\n",
      "[epoch : 18] (T_loss: 0.52945)  (V_loss: 0.868075)  (Val Accuract : 71 %)\n",
      "[epoch : 19] (T_loss: 0.51908)  (V_loss: 0.806102)  (Val Accuract : 72 %)\n",
      "[epoch : 20] (T_loss: 0.50232)  (V_loss: 0.903919)  (Val Accuract : 71 %)\n",
      "[epoch : 21] (T_loss: 0.50297)  (V_loss: 0.883303)  (Val Accuract : 71 %)\n",
      "[epoch : 22] (T_loss: 0.49109)  (V_loss: 0.848715)  (Val Accuract : 71 %)\n",
      "[epoch : 23] (T_loss: 0.48407)  (V_loss: 0.864583)  (Val Accuract : 72 %)\n",
      "[epoch : 24] (T_loss: 0.47579)  (V_loss: 0.957419)  (Val Accuract : 70 %)\n",
      "[epoch : 25] (T_loss: 0.46871)  (V_loss: 0.857897)  (Val Accuract : 72 %)\n",
      "[epoch : 26] (T_loss: 0.35402)  (V_loss: 0.781780)  (Val Accuract : 75 %)\n",
      "[epoch : 27] (T_loss: 0.31671)  (V_loss: 0.851861)  (Val Accuract : 74 %)\n",
      "[epoch : 28] (T_loss: 0.30656)  (V_loss: 0.774933)  (Val Accuract : 75 %)\n",
      "[epoch : 29] (T_loss: 0.29792)  (V_loss: 0.798228)  (Val Accuract : 75 %)\n",
      "[epoch : 30] (T_loss: 0.30172)  (V_loss: 0.859265)  (Val Accuract : 73 %)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "t_batch = len(train_loader)\n",
    "v_batch = len(val_loader)\n",
    "print('Learning Start!')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lr_sche.step()\n",
    "    # model training\n",
    "    t_running_loss = train(model, optimizer, criterion, train_loader, t_batch)\n",
    "\n",
    "    # validation loss\n",
    "    v_running_loss = loss_eval(model, criterion, val_loader, v_batch)\n",
    "\n",
    "    # validation accuracy\n",
    "    correct, total = accu_eval(val_loader)\n",
    "\n",
    "    # Plot & print\n",
    "    loss_tracker(loss_plt, torch.Tensor([t_running_loss]), torch.Tensor([epoch]), 'T_loss')\n",
    "    loss_tracker(loss_plt, torch.Tensor([v_running_loss]), torch.Tensor([epoch]), 'V_loss')\n",
    "\n",
    "    print('[epoch : %d] (T_loss: %.5f) ' % (epoch + 1, t_running_loss),\n",
    "          '(V_loss: %5f) ' % (v_running_loss),\n",
    "          '(Val Accuract : %d %%)' % (100 * correct / total)\n",
    "         )\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (testset) : 73.440 %\n"
     ]
    }
   ],
   "source": [
    "# model test\n",
    "correct, total = accu_eval(test_loader)\n",
    "print('Accuracy (testset) : %.3f %%' % (100*correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
