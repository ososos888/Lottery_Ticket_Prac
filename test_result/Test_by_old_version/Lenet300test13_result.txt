model_type: Lenet_300_100
lr: 0.0012
epochs: 30
batch_size: 60
weight_decay: 0.0001
prune_per_c: 1
prune_per_f: 0.2
prune_per_o: 0.1
test_iter: 5
prune_iter: 21
trainset: Dataset MNIST
    Number of datapoints: 60000
    Root location: ../MNIST_data/
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=(0.1307,), std=(0.3081,))
           )
valset: empty
testset: Dataset MNIST
    Number of datapoints: 10000
    Root location: ../MNIST_data/
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=(0.1307,), std=(0.3081,))
           )
train_loader: <torch.utils.data.dataloader.DataLoader object at 0x7fbfb2c24710>
val_loader: <torch.utils.data.dataloader.DataLoader object at 0x7fbfb2c24310>
test_loader: <torch.utils.data.dataloader.DataLoader object at 0x7fbfb2c24750>
validation_ratio: 0.08333333333333333 


Model structure
 Lenet_300_100(
  (fc1): Linear(in_features=784, out_features=300, bias=True)
  (fc2): Linear(in_features=300, out_features=100, bias=True)
  (fcout): Linear(in_features=100, out_features=10, bias=True)
)
===================================================================== 

Test_Iter (1/5)
------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :        266200 (266200 | 0)          100.00
fc1.weight   :        235200 (235200 | 0)          100.00
fc2.weight   :         30000 (30000 | 0)           100.00
fcout.weight :          1000 (1000 | 0)            100.00
------------------------------------------------------------
Learning start! [Prune_iter : (1/21), Remaining weight : 100.0 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69095) (accu: 0.0912)
[epoch : 1] (l_loss: 0.20703) (t_loss: 0.10734) (accu: 0.9647)
[epoch : 2] (l_loss: 0.09460) (t_loss: 0.08345) (accu: 0.9734)
[epoch : 3] (l_loss: 0.06441) (t_loss: 0.07871) (accu: 0.9783)
[epoch : 4] (l_loss: 0.05240) (t_loss: 0.07665) (accu: 0.9771)
[epoch : 5] (l_loss: 0.04386) (t_loss: 0.08792) (accu: 0.9748)
[epoch : 6] (l_loss: 0.03771) (t_loss: 0.09970) (accu: 0.9737)
[epoch : 7] (l_loss: 0.03193) (t_loss: 0.09356) (accu: 0.9767)
[epoch : 8] (l_loss: 0.02845) (t_loss: 0.08600) (accu: 0.9794)
[epoch : 9] (l_loss: 0.02430) (t_loss: 0.08547) (accu: 0.9804)
[epoch : 10] (l_loss: 0.02504) (t_loss: 0.09564) (accu: 0.9784)
[epoch : 11] (l_loss: 0.02349) (t_loss: 0.10338) (accu: 0.9760)
[epoch : 12] (l_loss: 0.01927) (t_loss: 0.11592) (accu: 0.9771)
[epoch : 13] (l_loss: 0.01987) (t_loss: 0.11009) (accu: 0.9792)
[epoch : 14] (l_loss: 0.02019) (t_loss: 0.13994) (accu: 0.9734)
[epoch : 15] (l_loss: 0.01986) (t_loss: 0.09686) (accu: 0.9788)
[epoch : 16] (l_loss: 0.01579) (t_loss: 0.14099) (accu: 0.9752)
[epoch : 17] (l_loss: 0.01571) (t_loss: 0.12299) (accu: 0.9780)
[epoch : 18] (l_loss: 0.01667) (t_loss: 0.11609) (accu: 0.9797)
[epoch : 19] (l_loss: 0.01461) (t_loss: 0.14303) (accu: 0.9772)
[epoch : 20] (l_loss: 0.01518) (t_loss: 0.13612) (accu: 0.9812)
[epoch : 21] (l_loss: 0.01608) (t_loss: 0.12633) (accu: 0.9789)
[epoch : 22] (l_loss: 0.01350) (t_loss: 0.13404) (accu: 0.9791)
[epoch : 23] (l_loss: 0.01226) (t_loss: 0.12610) (accu: 0.9816)
[epoch : 24] (l_loss: 0.01202) (t_loss: 0.14508) (accu: 0.9781)
[epoch : 25] (l_loss: 0.01513) (t_loss: 0.12706) (accu: 0.9812)
[epoch : 26] (l_loss: 0.01194) (t_loss: 0.15616) (accu: 0.9774)
[epoch : 27] (l_loss: 0.01102) (t_loss: 0.17349) (accu: 0.9772)
[epoch : 28] (l_loss: 0.01365) (t_loss: 0.15012) (accu: 0.9794)
[epoch : 29] (l_loss: 0.01215) (t_loss: 0.14856) (accu: 0.9796)
[epoch : 30] (l_loss: 0.00903) (t_loss: 0.16488) (accu: 0.9794)
Finish! (Best accu: 0.9816) (Time taken(sec) : 318.06) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (213060 | 53140)         80.04
fc1.weight   :      235200 (188160 | 47040)         80.00
fc2.weight   :        30000 (24000 | 6000)          80.00
fcout.weight :          1000 (900 | 100)            90.00
------------------------------------------------------------
Learning start! [Prune_iter : (2/21), Remaining weight : 80.04 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.22558) (accu: 0.1582)
[epoch : 1] (l_loss: 0.18931) (t_loss: 0.09938) (accu: 0.9710)
[epoch : 2] (l_loss: 0.08242) (t_loss: 0.08871) (accu: 0.9734)
[epoch : 3] (l_loss: 0.05604) (t_loss: 0.07539) (accu: 0.9775)
[epoch : 4] (l_loss: 0.04164) (t_loss: 0.08008) (accu: 0.9780)
[epoch : 5] (l_loss: 0.03570) (t_loss: 0.08371) (accu: 0.9782)
[epoch : 6] (l_loss: 0.03198) (t_loss: 0.09433) (accu: 0.9749)
[epoch : 7] (l_loss: 0.02838) (t_loss: 0.09246) (accu: 0.9752)
[epoch : 8] (l_loss: 0.02486) (t_loss: 0.08997) (accu: 0.9790)
[epoch : 9] (l_loss: 0.02108) (t_loss: 0.10955) (accu: 0.9772)
[epoch : 10] (l_loss: 0.02099) (t_loss: 0.09352) (accu: 0.9787)
[epoch : 11] (l_loss: 0.02108) (t_loss: 0.09563) (accu: 0.9804)
[epoch : 12] (l_loss: 0.01583) (t_loss: 0.09613) (accu: 0.9796)
[epoch : 13] (l_loss: 0.01686) (t_loss: 0.11316) (accu: 0.9793)
[epoch : 14] (l_loss: 0.01609) (t_loss: 0.12089) (accu: 0.9783)
[epoch : 15] (l_loss: 0.01383) (t_loss: 0.13267) (accu: 0.9774)
[epoch : 16] (l_loss: 0.01551) (t_loss: 0.10947) (accu: 0.9802)
[epoch : 17] (l_loss: 0.01361) (t_loss: 0.13574) (accu: 0.9782)
[epoch : 18] (l_loss: 0.01506) (t_loss: 0.10470) (accu: 0.9815)
[epoch : 19] (l_loss: 0.01019) (t_loss: 0.13363) (accu: 0.9790)
[epoch : 20] (l_loss: 0.01483) (t_loss: 0.11689) (accu: 0.9794)
[epoch : 21] (l_loss: 0.01302) (t_loss: 0.15426) (accu: 0.9752)
[epoch : 22] (l_loss: 0.01101) (t_loss: 0.12693) (accu: 0.9822)
[epoch : 23] (l_loss: 0.01228) (t_loss: 0.14849) (accu: 0.9788)
[epoch : 24] (l_loss: 0.00956) (t_loss: 0.12425) (accu: 0.9821)
[epoch : 25] (l_loss: 0.01086) (t_loss: 0.13658) (accu: 0.9801)
[epoch : 26] (l_loss: 0.00900) (t_loss: 0.14401) (accu: 0.9782)
[epoch : 27] (l_loss: 0.01238) (t_loss: 0.13058) (accu: 0.9817)
[epoch : 28] (l_loss: 0.00986) (t_loss: 0.15760) (accu: 0.9793)
[epoch : 29] (l_loss: 0.01126) (t_loss: 0.16635) (accu: 0.9794)
[epoch : 30] (l_loss: 0.00855) (t_loss: 0.15204) (accu: 0.9801)
Finish! (Best accu: 0.9822) (Time taken(sec) : 325.72) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (170538 | 95662)         64.06
fc1.weight   :      235200 (150528 | 84672)         64.00
fc2.weight   :       30000 (19200 | 10800)          64.00
fcout.weight :          1000 (810 | 190)            81.00
------------------------------------------------------------
Learning start! [Prune_iter : (3/21), Remaining weight : 64.06 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.11260) (accu: 0.2369)
[epoch : 1] (l_loss: 0.17314) (t_loss: 0.09779) (accu: 0.9686)
[epoch : 2] (l_loss: 0.07005) (t_loss: 0.09985) (accu: 0.9700)
[epoch : 3] (l_loss: 0.04683) (t_loss: 0.09347) (accu: 0.9711)
[epoch : 4] (l_loss: 0.03532) (t_loss: 0.07728) (accu: 0.9787)
[epoch : 5] (l_loss: 0.02987) (t_loss: 0.08020) (accu: 0.9785)
[epoch : 6] (l_loss: 0.02504) (t_loss: 0.10360) (accu: 0.9740)
[epoch : 7] (l_loss: 0.01943) (t_loss: 0.09682) (accu: 0.9740)
[epoch : 8] (l_loss: 0.02133) (t_loss: 0.09120) (accu: 0.9794)
[epoch : 9] (l_loss: 0.01970) (t_loss: 0.10142) (accu: 0.9787)
[epoch : 10] (l_loss: 0.01453) (t_loss: 0.10565) (accu: 0.9774)
[epoch : 11] (l_loss: 0.01514) (t_loss: 0.09274) (accu: 0.9804)
[epoch : 12] (l_loss: 0.01558) (t_loss: 0.11057) (accu: 0.9808)
[epoch : 13] (l_loss: 0.01295) (t_loss: 0.11021) (accu: 0.9816)
[epoch : 14] (l_loss: 0.01269) (t_loss: 0.11342) (accu: 0.9792)
[epoch : 15] (l_loss: 0.01147) (t_loss: 0.13347) (accu: 0.9779)
[epoch : 16] (l_loss: 0.01279) (t_loss: 0.16113) (accu: 0.9751)
[epoch : 17] (l_loss: 0.00887) (t_loss: 0.11086) (accu: 0.9822)
[epoch : 18] (l_loss: 0.01037) (t_loss: 0.13256) (accu: 0.9800)
[epoch : 19] (l_loss: 0.01092) (t_loss: 0.13553) (accu: 0.9780)
[epoch : 20] (l_loss: 0.01419) (t_loss: 0.14134) (accu: 0.9766)
[epoch : 21] (l_loss: 0.00859) (t_loss: 0.15525) (accu: 0.9762)
[epoch : 22] (l_loss: 0.01036) (t_loss: 0.12236) (accu: 0.9822)
[epoch : 23] (l_loss: 0.00818) (t_loss: 0.14784) (accu: 0.9787)
[epoch : 24] (l_loss: 0.01348) (t_loss: 0.13218) (accu: 0.9812)
[epoch : 25] (l_loss: 0.00901) (t_loss: 0.13319) (accu: 0.9813)
[epoch : 26] (l_loss: 0.00544) (t_loss: 0.14778) (accu: 0.9807)
[epoch : 27] (l_loss: 0.01093) (t_loss: 0.15174) (accu: 0.9806)
[epoch : 28] (l_loss: 0.00956) (t_loss: 0.15623) (accu: 0.9811)
[epoch : 29] (l_loss: 0.00841) (t_loss: 0.15445) (accu: 0.9777)
[epoch : 30] (l_loss: 0.00757) (t_loss: 0.17937) (accu: 0.9791)
Finish! (Best accu: 0.9822) (Time taken(sec) : 328.48) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (136511 | 129689)        51.28
fc1.weight   :      235200 (120422 | 114778)        51.20
fc2.weight   :       30000 (15360 | 14640)          51.20
fcout.weight :          1000 (729 | 271)            72.90
------------------------------------------------------------
Learning start! [Prune_iter : (4/21), Remaining weight : 51.28 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.10959) (accu: 0.2115)
[epoch : 1] (l_loss: 0.16734) (t_loss: 0.07648) (accu: 0.9742)
[epoch : 2] (l_loss: 0.05985) (t_loss: 0.07309) (accu: 0.9769)
[epoch : 3] (l_loss: 0.03899) (t_loss: 0.06706) (accu: 0.9801)
[epoch : 4] (l_loss: 0.02945) (t_loss: 0.07305) (accu: 0.9790)
[epoch : 5] (l_loss: 0.02436) (t_loss: 0.07702) (accu: 0.9790)
[epoch : 6] (l_loss: 0.01944) (t_loss: 0.09056) (accu: 0.9776)
[epoch : 7] (l_loss: 0.01773) (t_loss: 0.09138) (accu: 0.9763)
[epoch : 8] (l_loss: 0.01621) (t_loss: 0.08563) (accu: 0.9808)
[epoch : 9] (l_loss: 0.01509) (t_loss: 0.10235) (accu: 0.9778)
[epoch : 10] (l_loss: 0.01428) (t_loss: 0.09325) (accu: 0.9808)
[epoch : 11] (l_loss: 0.01183) (t_loss: 0.09870) (accu: 0.9809)
[epoch : 12] (l_loss: 0.01316) (t_loss: 0.10211) (accu: 0.9791)
[epoch : 13] (l_loss: 0.01258) (t_loss: 0.10262) (accu: 0.9792)
[epoch : 14] (l_loss: 0.01132) (t_loss: 0.10616) (accu: 0.9803)
[epoch : 15] (l_loss: 0.00887) (t_loss: 0.13220) (accu: 0.9770)
[epoch : 16] (l_loss: 0.00704) (t_loss: 0.11945) (accu: 0.9787)
[epoch : 17] (l_loss: 0.01352) (t_loss: 0.12160) (accu: 0.9779)
[epoch : 18] (l_loss: 0.00927) (t_loss: 0.10912) (accu: 0.9819)
[epoch : 19] (l_loss: 0.00663) (t_loss: 0.10944) (accu: 0.9827)
[epoch : 20] (l_loss: 0.00975) (t_loss: 0.11657) (accu: 0.9799)
[epoch : 21] (l_loss: 0.01038) (t_loss: 0.13038) (accu: 0.9822)
[epoch : 22] (l_loss: 0.00781) (t_loss: 0.15600) (accu: 0.9772)
[epoch : 23] (l_loss: 0.00750) (t_loss: 0.13147) (accu: 0.9831)
[epoch : 24] (l_loss: 0.00888) (t_loss: 0.15403) (accu: 0.9780)
[epoch : 25] (l_loss: 0.00992) (t_loss: 0.15158) (accu: 0.9783)
[epoch : 26] (l_loss: 0.00722) (t_loss: 0.13910) (accu: 0.9816)
[epoch : 27] (l_loss: 0.00696) (t_loss: 0.15110) (accu: 0.9817)
[epoch : 28] (l_loss: 0.00885) (t_loss: 0.12663) (accu: 0.9836)
[epoch : 29] (l_loss: 0.00559) (t_loss: 0.15031) (accu: 0.9802)
[epoch : 30] (l_loss: 0.00686) (t_loss: 0.14468) (accu: 0.9808)
Finish! (Best accu: 0.9836) (Time taken(sec) : 333.64) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (109282 | 156918)        41.05
fc1.weight   :      235200 (96338 | 138862)         40.96
fc2.weight   :       30000 (12288 | 17712)          40.96
fcout.weight :          1000 (656 | 344)            65.60
------------------------------------------------------------
Learning start! [Prune_iter : (5/21), Remaining weight : 41.05 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.10386) (accu: 0.1989)
[epoch : 1] (l_loss: 0.15620) (t_loss: 0.07477) (accu: 0.9772)
[epoch : 2] (l_loss: 0.05101) (t_loss: 0.07442) (accu: 0.9759)
[epoch : 3] (l_loss: 0.03360) (t_loss: 0.07112) (accu: 0.9795)
[epoch : 4] (l_loss: 0.02256) (t_loss: 0.06755) (accu: 0.9817)
[epoch : 5] (l_loss: 0.02000) (t_loss: 0.07417) (accu: 0.9819)
[epoch : 6] (l_loss: 0.01551) (t_loss: 0.06880) (accu: 0.9815)
[epoch : 7] (l_loss: 0.01396) (t_loss: 0.09193) (accu: 0.9788)
[epoch : 8] (l_loss: 0.01292) (t_loss: 0.08197) (accu: 0.9809)
[epoch : 9] (l_loss: 0.01071) (t_loss: 0.09863) (accu: 0.9786)
[epoch : 10] (l_loss: 0.01119) (t_loss: 0.09392) (accu: 0.9809)
[epoch : 11] (l_loss: 0.01028) (t_loss: 0.09620) (accu: 0.9812)
[epoch : 12] (l_loss: 0.01024) (t_loss: 0.11174) (accu: 0.9786)
[epoch : 13] (l_loss: 0.00878) (t_loss: 0.09620) (accu: 0.9817)
[epoch : 14] (l_loss: 0.00554) (t_loss: 0.09653) (accu: 0.9815)
[epoch : 15] (l_loss: 0.00873) (t_loss: 0.12576) (accu: 0.9772)
[epoch : 16] (l_loss: 0.01008) (t_loss: 0.10735) (accu: 0.9806)
[epoch : 17] (l_loss: 0.00640) (t_loss: 0.13060) (accu: 0.9795)
[epoch : 18] (l_loss: 0.01150) (t_loss: 0.13064) (accu: 0.9798)
[epoch : 19] (l_loss: 0.00722) (t_loss: 0.10887) (accu: 0.9808)
[epoch : 20] (l_loss: 0.00512) (t_loss: 0.10312) (accu: 0.9840)
[epoch : 21] (l_loss: 0.00511) (t_loss: 0.12508) (accu: 0.9814)
[epoch : 22] (l_loss: 0.01025) (t_loss: 0.13195) (accu: 0.9820)
[epoch : 23] (l_loss: 0.00692) (t_loss: 0.13048) (accu: 0.9830)
[epoch : 24] (l_loss: 0.00466) (t_loss: 0.12911) (accu: 0.9814)
[epoch : 25] (l_loss: 0.00608) (t_loss: 0.13398) (accu: 0.9812)
[epoch : 26] (l_loss: 0.00692) (t_loss: 0.13355) (accu: 0.9826)
[epoch : 27] (l_loss: 0.00531) (t_loss: 0.11412) (accu: 0.9825)
[epoch : 28] (l_loss: 0.00414) (t_loss: 0.12171) (accu: 0.9821)
[epoch : 29] (l_loss: 0.00908) (t_loss: 0.13289) (accu: 0.9823)
[epoch : 30] (l_loss: 0.00385) (t_loss: 0.16067) (accu: 0.9826)
Finish! (Best accu: 0.9840) (Time taken(sec) : 343.39) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (87490 | 178710)         32.87
fc1.weight   :      235200 (77070 | 158130)         32.77
fc2.weight   :        30000 (9830 | 20170)          32.77
fcout.weight :          1000 (590 | 410)            59.00
------------------------------------------------------------
Learning start! [Prune_iter : (6/21), Remaining weight : 32.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.08666) (accu: 0.2304)
[epoch : 1] (l_loss: 0.14567) (t_loss: 0.07785) (accu: 0.9763)
[epoch : 2] (l_loss: 0.04625) (t_loss: 0.07427) (accu: 0.9779)
[epoch : 3] (l_loss: 0.02584) (t_loss: 0.05797) (accu: 0.9841)
[epoch : 4] (l_loss: 0.01871) (t_loss: 0.07234) (accu: 0.9799)
[epoch : 5] (l_loss: 0.01358) (t_loss: 0.07151) (accu: 0.9817)
[epoch : 6] (l_loss: 0.01339) (t_loss: 0.08123) (accu: 0.9824)
[epoch : 7] (l_loss: 0.01077) (t_loss: 0.07256) (accu: 0.9830)
[epoch : 8] (l_loss: 0.00881) (t_loss: 0.07501) (accu: 0.9835)
[epoch : 9] (l_loss: 0.00804) (t_loss: 0.08514) (accu: 0.9832)
[epoch : 10] (l_loss: 0.00942) (t_loss: 0.09056) (accu: 0.9820)
[epoch : 11] (l_loss: 0.00696) (t_loss: 0.09294) (accu: 0.9829)
[epoch : 12] (l_loss: 0.00777) (t_loss: 0.10224) (accu: 0.9817)
[epoch : 13] (l_loss: 0.00919) (t_loss: 0.09701) (accu: 0.9827)
[epoch : 14] (l_loss: 0.00629) (t_loss: 0.11168) (accu: 0.9799)
[epoch : 15] (l_loss: 0.00758) (t_loss: 0.11624) (accu: 0.9780)
[epoch : 16] (l_loss: 0.00499) (t_loss: 0.10823) (accu: 0.9818)
[epoch : 17] (l_loss: 0.00907) (t_loss: 0.11223) (accu: 0.9815)
[epoch : 18] (l_loss: 0.00375) (t_loss: 0.10799) (accu: 0.9829)
[epoch : 19] (l_loss: 0.00715) (t_loss: 0.11295) (accu: 0.9810)
[epoch : 20] (l_loss: 0.00596) (t_loss: 0.10492) (accu: 0.9830)
[epoch : 21] (l_loss: 0.00296) (t_loss: 0.13056) (accu: 0.9812)
[epoch : 22] (l_loss: 0.00734) (t_loss: 0.13228) (accu: 0.9799)
[epoch : 23] (l_loss: 0.00627) (t_loss: 0.14427) (accu: 0.9810)
[epoch : 24] (l_loss: 0.00529) (t_loss: 0.13765) (accu: 0.9815)
[epoch : 25] (l_loss: 0.00402) (t_loss: 0.13578) (accu: 0.9799)
[epoch : 26] (l_loss: 0.00487) (t_loss: 0.14226) (accu: 0.9809)
[epoch : 27] (l_loss: 0.00474) (t_loss: 0.13316) (accu: 0.9826)
[epoch : 28] (l_loss: 0.00432) (t_loss: 0.14417) (accu: 0.9810)
[epoch : 29] (l_loss: 0.00448) (t_loss: 0.12909) (accu: 0.9824)
[epoch : 30] (l_loss: 0.00421) (t_loss: 0.13326) (accu: 0.9815)
Finish! (Best accu: 0.9841) (Time taken(sec) : 341.74) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (70051 | 196149)         26.32
fc1.weight   :      235200 (61656 | 173544)         26.21
fc2.weight   :        30000 (7864 | 22136)          26.21
fcout.weight :          1000 (531 | 469)            53.10
------------------------------------------------------------
Learning start! [Prune_iter : (7/21), Remaining weight : 26.32 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.05288) (accu: 0.2494)
[epoch : 1] (l_loss: 0.14016) (t_loss: 0.07129) (accu: 0.9771)
[epoch : 2] (l_loss: 0.03786) (t_loss: 0.05842) (accu: 0.9814)
[epoch : 3] (l_loss: 0.02163) (t_loss: 0.06441) (accu: 0.9812)
[epoch : 4] (l_loss: 0.01449) (t_loss: 0.07747) (accu: 0.9795)
[epoch : 5] (l_loss: 0.01140) (t_loss: 0.07553) (accu: 0.9796)
[epoch : 6] (l_loss: 0.01167) (t_loss: 0.07901) (accu: 0.9811)
[epoch : 7] (l_loss: 0.00802) (t_loss: 0.07907) (accu: 0.9821)
[epoch : 8] (l_loss: 0.00804) (t_loss: 0.08100) (accu: 0.9831)
[epoch : 9] (l_loss: 0.00699) (t_loss: 0.09085) (accu: 0.9795)
[epoch : 10] (l_loss: 0.00672) (t_loss: 0.09820) (accu: 0.9819)
[epoch : 11] (l_loss: 0.00593) (t_loss: 0.09342) (accu: 0.9829)
[epoch : 12] (l_loss: 0.00447) (t_loss: 0.12683) (accu: 0.9804)
[epoch : 13] (l_loss: 0.00746) (t_loss: 0.09605) (accu: 0.9832)
[epoch : 14] (l_loss: 0.00566) (t_loss: 0.09971) (accu: 0.9840)
[epoch : 15] (l_loss: 0.00329) (t_loss: 0.11347) (accu: 0.9808)
[epoch : 16] (l_loss: 0.00694) (t_loss: 0.14112) (accu: 0.9801)
[epoch : 17] (l_loss: 0.00362) (t_loss: 0.10450) (accu: 0.9843)
[epoch : 18] (l_loss: 0.00167) (t_loss: 0.11581) (accu: 0.9836)
[epoch : 19] (l_loss: 0.01027) (t_loss: 0.12133) (accu: 0.9816)
[epoch : 20] (l_loss: 0.00343) (t_loss: 0.13638) (accu: 0.9810)
[epoch : 21] (l_loss: 0.00189) (t_loss: 0.11850) (accu: 0.9833)
[epoch : 22] (l_loss: 0.00518) (t_loss: 0.15942) (accu: 0.9786)
[epoch : 23] (l_loss: 0.00743) (t_loss: 0.12308) (accu: 0.9820)
[epoch : 24] (l_loss: 0.00342) (t_loss: 0.15379) (accu: 0.9801)
[epoch : 25] (l_loss: 0.00612) (t_loss: 0.14092) (accu: 0.9814)
[epoch : 26] (l_loss: 0.00224) (t_loss: 0.14143) (accu: 0.9809)
[epoch : 27] (l_loss: 0.00368) (t_loss: 0.12051) (accu: 0.9840)
[epoch : 28] (l_loss: 0.00424) (t_loss: 0.14083) (accu: 0.9834)
[epoch : 29] (l_loss: 0.00421) (t_loss: 0.14640) (accu: 0.9812)
[epoch : 30] (l_loss: 0.00437) (t_loss: 0.15019) (accu: 0.9825)
Finish! (Best accu: 0.9843) (Time taken(sec) : 345.79) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (56094 | 210106)         21.07
fc1.weight   :      235200 (49325 | 185875)         20.97
fc2.weight   :        30000 (6291 | 23709)          20.97
fcout.weight :          1000 (478 | 522)            47.80
------------------------------------------------------------
Learning start! [Prune_iter : (8/21), Remaining weight : 21.07 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.04141) (accu: 0.2703)
[epoch : 1] (l_loss: 0.13783) (t_loss: 0.06544) (accu: 0.9811)
[epoch : 2] (l_loss: 0.03456) (t_loss: 0.06090) (accu: 0.9814)
[epoch : 3] (l_loss: 0.01723) (t_loss: 0.06511) (accu: 0.9806)
[epoch : 4] (l_loss: 0.01181) (t_loss: 0.06231) (accu: 0.9818)
[epoch : 5] (l_loss: 0.00913) (t_loss: 0.07029) (accu: 0.9821)
[epoch : 6] (l_loss: 0.00888) (t_loss: 0.07165) (accu: 0.9826)
[epoch : 7] (l_loss: 0.00746) (t_loss: 0.08134) (accu: 0.9816)
[epoch : 8] (l_loss: 0.00706) (t_loss: 0.08898) (accu: 0.9804)
[epoch : 9] (l_loss: 0.00496) (t_loss: 0.08748) (accu: 0.9826)
[epoch : 10] (l_loss: 0.00388) (t_loss: 0.08908) (accu: 0.9825)
[epoch : 11] (l_loss: 0.00441) (t_loss: 0.08720) (accu: 0.9838)
[epoch : 12] (l_loss: 0.00725) (t_loss: 0.11249) (accu: 0.9802)
[epoch : 13] (l_loss: 0.00433) (t_loss: 0.09830) (accu: 0.9825)
[epoch : 14] (l_loss: 0.00215) (t_loss: 0.10715) (accu: 0.9831)
[epoch : 15] (l_loss: 0.00609) (t_loss: 0.11286) (accu: 0.9808)
[epoch : 16] (l_loss: 0.00399) (t_loss: 0.11317) (accu: 0.9815)
[epoch : 17] (l_loss: 0.00339) (t_loss: 0.12329) (accu: 0.9809)
[epoch : 18] (l_loss: 0.00575) (t_loss: 0.12500) (accu: 0.9808)
[epoch : 19] (l_loss: 0.00270) (t_loss: 0.13603) (accu: 0.9797)
[epoch : 20] (l_loss: 0.00576) (t_loss: 0.11790) (accu: 0.9831)
[epoch : 21] (l_loss: 0.00197) (t_loss: 0.12430) (accu: 0.9820)
[epoch : 22] (l_loss: 0.00313) (t_loss: 0.14511) (accu: 0.9820)
[epoch : 23] (l_loss: 0.00406) (t_loss: 0.13038) (accu: 0.9817)
[epoch : 24] (l_loss: 0.00289) (t_loss: 0.12111) (accu: 0.9836)
[epoch : 25] (l_loss: 0.00097) (t_loss: 0.11868) (accu: 0.9842)
[epoch : 26] (l_loss: 0.00414) (t_loss: 0.14112) (accu: 0.9814)
[epoch : 27] (l_loss: 0.00470) (t_loss: 0.12495) (accu: 0.9826)
[epoch : 28] (l_loss: 0.00252) (t_loss: 0.13696) (accu: 0.9826)
[epoch : 29] (l_loss: 0.00298) (t_loss: 0.13354) (accu: 0.9832)
[epoch : 30] (l_loss: 0.00352) (t_loss: 0.13436) (accu: 0.9834)
Finish! (Best accu: 0.9842) (Time taken(sec) : 346.71) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (44923 | 221277)         16.88
fc1.weight   :      235200 (39460 | 195740)         16.78
fc2.weight   :        30000 (5033 | 24967)          16.78
fcout.weight :          1000 (430 | 570)            43.00
------------------------------------------------------------
Learning start! [Prune_iter : (9/21), Remaining weight : 16.88 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.00483) (accu: 0.3024)
[epoch : 1] (l_loss: 0.13314) (t_loss: 0.06608) (accu: 0.9788)
[epoch : 2] (l_loss: 0.03188) (t_loss: 0.05423) (accu: 0.9829)
[epoch : 3] (l_loss: 0.01587) (t_loss: 0.06225) (accu: 0.9828)
[epoch : 4] (l_loss: 0.00926) (t_loss: 0.06521) (accu: 0.9821)
[epoch : 5] (l_loss: 0.00578) (t_loss: 0.06209) (accu: 0.9837)
[epoch : 6] (l_loss: 0.00731) (t_loss: 0.08405) (accu: 0.9801)
[epoch : 7] (l_loss: 0.00523) (t_loss: 0.08046) (accu: 0.9813)
[epoch : 8] (l_loss: 0.00480) (t_loss: 0.11730) (accu: 0.9749)
[epoch : 9] (l_loss: 0.00514) (t_loss: 0.08200) (accu: 0.9834)
[epoch : 10] (l_loss: 0.00344) (t_loss: 0.09400) (accu: 0.9822)
[epoch : 11] (l_loss: 0.00607) (t_loss: 0.11458) (accu: 0.9791)
[epoch : 12] (l_loss: 0.00390) (t_loss: 0.09747) (accu: 0.9823)
[epoch : 13] (l_loss: 0.00070) (t_loss: 0.09646) (accu: 0.9838)
[epoch : 14] (l_loss: 0.00016) (t_loss: 0.09363) (accu: 0.9847)
[epoch : 15] (l_loss: 0.00005) (t_loss: 0.09521) (accu: 0.9852)
[epoch : 16] (l_loss: 0.00003) (t_loss: 0.09684) (accu: 0.9853)
[epoch : 17] (l_loss: 0.00002) (t_loss: 0.09849) (accu: 0.9855)
[epoch : 18] (l_loss: 0.00002) (t_loss: 0.10059) (accu: 0.9854)
[epoch : 19] (l_loss: 0.00001) (t_loss: 0.10254) (accu: 0.9853)
[epoch : 20] (l_loss: 0.01535) (t_loss: 0.10792) (accu: 0.9813)
[epoch : 21] (l_loss: 0.00377) (t_loss: 0.11073) (accu: 0.9821)
[epoch : 22] (l_loss: 0.00169) (t_loss: 0.10360) (accu: 0.9836)
[epoch : 23] (l_loss: 0.00020) (t_loss: 0.10327) (accu: 0.9846)
[epoch : 24] (l_loss: 0.00005) (t_loss: 0.10133) (accu: 0.9846)
[epoch : 25] (l_loss: 0.00003) (t_loss: 0.10251) (accu: 0.9849)
[epoch : 26] (l_loss: 0.00002) (t_loss: 0.10411) (accu: 0.9851)
[epoch : 27] (l_loss: 0.00002) (t_loss: 0.10560) (accu: 0.9850)
[epoch : 28] (l_loss: 0.00001) (t_loss: 0.10785) (accu: 0.9847)
[epoch : 29] (l_loss: 0.00001) (t_loss: 0.10977) (accu: 0.9850)
[epoch : 30] (l_loss: 0.00001) (t_loss: 0.11176) (accu: 0.9848)
Finish! (Best accu: 0.9855) (Time taken(sec) : 355.35) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (35982 | 230218)         13.52
fc1.weight   :      235200 (31568 | 203632)         13.42
fc2.weight   :        30000 (4027 | 25973)          13.42
fcout.weight :          1000 (387 | 613)            38.70
------------------------------------------------------------
Learning start! [Prune_iter : (10/21), Remaining weight : 13.52 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 1.92273) (accu: 0.4277)
[epoch : 1] (l_loss: 0.13112) (t_loss: 0.06451) (accu: 0.9807)
[epoch : 2] (l_loss: 0.02946) (t_loss: 0.05559) (accu: 0.9819)
[epoch : 3] (l_loss: 0.01429) (t_loss: 0.05774) (accu: 0.9823)
[epoch : 4] (l_loss: 0.00799) (t_loss: 0.05636) (accu: 0.9840)
[epoch : 5] (l_loss: 0.00462) (t_loss: 0.06796) (accu: 0.9825)
[epoch : 6] (l_loss: 0.00441) (t_loss: 0.07169) (accu: 0.9820)
[epoch : 7] (l_loss: 0.00673) (t_loss: 0.07797) (accu: 0.9829)
[epoch : 8] (l_loss: 0.00404) (t_loss: 0.08658) (accu: 0.9813)
[epoch : 9] (l_loss: 0.00241) (t_loss: 0.08321) (accu: 0.9837)
[epoch : 10] (l_loss: 0.00064) (t_loss: 0.07803) (accu: 0.9837)
[epoch : 11] (l_loss: 0.00753) (t_loss: 0.10490) (accu: 0.9802)
[epoch : 12] (l_loss: 0.00222) (t_loss: 0.08355) (accu: 0.9827)
[epoch : 13] (l_loss: 0.00113) (t_loss: 0.08615) (accu: 0.9845)
[epoch : 14] (l_loss: 0.00281) (t_loss: 0.11513) (accu: 0.9809)
[epoch : 15] (l_loss: 0.00443) (t_loss: 0.11159) (accu: 0.9809)
[epoch : 16] (l_loss: 0.00441) (t_loss: 0.11367) (accu: 0.9812)
[epoch : 17] (l_loss: 0.00141) (t_loss: 0.10038) (accu: 0.9838)
[epoch : 18] (l_loss: 0.00104) (t_loss: 0.10711) (accu: 0.9828)
[epoch : 19] (l_loss: 0.00317) (t_loss: 0.11181) (accu: 0.9826)
[epoch : 20] (l_loss: 0.00337) (t_loss: 0.11119) (accu: 0.9835)
[epoch : 21] (l_loss: 0.00311) (t_loss: 0.11536) (accu: 0.9824)
[epoch : 22] (l_loss: 0.00142) (t_loss: 0.10905) (accu: 0.9839)
[epoch : 23] (l_loss: 0.00016) (t_loss: 0.10144) (accu: 0.9840)
[epoch : 24] (l_loss: 0.00454) (t_loss: 0.12731) (accu: 0.9812)
[epoch : 25] (l_loss: 0.00298) (t_loss: 0.13079) (accu: 0.9806)
[epoch : 26] (l_loss: 0.00185) (t_loss: 0.12764) (accu: 0.9823)
[epoch : 27] (l_loss: 0.00024) (t_loss: 0.11189) (accu: 0.9842)
[epoch : 28] (l_loss: 0.00004) (t_loss: 0.11442) (accu: 0.9838)
[epoch : 29] (l_loss: 0.00001) (t_loss: 0.11487) (accu: 0.9839)
[epoch : 30] (l_loss: 0.00001) (t_loss: 0.11578) (accu: 0.9843)
Finish! (Best accu: 0.9845) (Time taken(sec) : 364.43) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (28824 | 237376)         10.83
fc1.weight   :      235200 (25254 | 209946)         10.74
fc2.weight   :        30000 (3221 | 26779)          10.74
fcout.weight :          1000 (349 | 651)            34.90
------------------------------------------------------------
Learning start! [Prune_iter : (11/21), Remaining weight : 10.83 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 1.92359) (accu: 0.4285)
[epoch : 1] (l_loss: 0.13720) (t_loss: 0.06116) (accu: 0.9804)
[epoch : 2] (l_loss: 0.02875) (t_loss: 0.05824) (accu: 0.9825)
[epoch : 3] (l_loss: 0.01316) (t_loss: 0.05400) (accu: 0.9841)
[epoch : 4] (l_loss: 0.00755) (t_loss: 0.06151) (accu: 0.9832)
[epoch : 5] (l_loss: 0.00420) (t_loss: 0.06753) (accu: 0.9822)
[epoch : 6] (l_loss: 0.00445) (t_loss: 0.06769) (accu: 0.9836)
[epoch : 7] (l_loss: 0.00484) (t_loss: 0.07450) (accu: 0.9823)
[epoch : 8] (l_loss: 0.00154) (t_loss: 0.07569) (accu: 0.9834)
[epoch : 9] (l_loss: 0.00242) (t_loss: 0.09230) (accu: 0.9807)
[epoch : 10] (l_loss: 0.00426) (t_loss: 0.08645) (accu: 0.9825)
[epoch : 11] (l_loss: 0.00112) (t_loss: 0.09639) (accu: 0.9829)
[epoch : 12] (l_loss: 0.00044) (t_loss: 0.09960) (accu: 0.9830)
[epoch : 13] (l_loss: 0.00573) (t_loss: 0.10260) (accu: 0.9826)
[epoch : 14] (l_loss: 0.00262) (t_loss: 0.10192) (accu: 0.9831)
[epoch : 15] (l_loss: 0.00149) (t_loss: 0.10670) (accu: 0.9826)
[epoch : 16] (l_loss: 0.00255) (t_loss: 0.11762) (accu: 0.9820)
[epoch : 17] (l_loss: 0.00216) (t_loss: 0.11793) (accu: 0.9813)
[epoch : 18] (l_loss: 0.00201) (t_loss: 0.11522) (accu: 0.9823)
[epoch : 19] (l_loss: 0.00227) (t_loss: 0.11790) (accu: 0.9830)
[epoch : 20] (l_loss: 0.00143) (t_loss: 0.11662) (accu: 0.9827)
[epoch : 21] (l_loss: 0.00109) (t_loss: 0.11590) (accu: 0.9834)
[epoch : 22] (l_loss: 0.00213) (t_loss: 0.15411) (accu: 0.9786)
[epoch : 23] (l_loss: 0.00403) (t_loss: 0.12561) (accu: 0.9833)
[epoch : 24] (l_loss: 0.00106) (t_loss: 0.13041) (accu: 0.9833)
[epoch : 25] (l_loss: 0.00178) (t_loss: 0.13032) (accu: 0.9834)
[epoch : 26] (l_loss: 0.00149) (t_loss: 0.14066) (accu: 0.9805)
[epoch : 27] (l_loss: 0.00307) (t_loss: 0.12859) (accu: 0.9833)
[epoch : 28] (l_loss: 0.00201) (t_loss: 0.13629) (accu: 0.9822)
[epoch : 29] (l_loss: 0.00065) (t_loss: 0.14821) (accu: 0.9811)
[epoch : 30] (l_loss: 0.00223) (t_loss: 0.12998) (accu: 0.9824)
Finish! (Best accu: 0.9841) (Time taken(sec) : 357.97) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (23095 | 243105)          8.68
fc1.weight   :      235200 (20204 | 214996)          8.59
fc2.weight   :        30000 (2577 | 27423)           8.59
fcout.weight :          1000 (314 | 686)            31.40
------------------------------------------------------------
Learning start! [Prune_iter : (12/21), Remaining weight : 8.68 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 1.96191) (accu: 0.5385)
[epoch : 1] (l_loss: 0.15142) (t_loss: 0.06256) (accu: 0.9806)
[epoch : 2] (l_loss: 0.03085) (t_loss: 0.05287) (accu: 0.9840)
[epoch : 3] (l_loss: 0.01442) (t_loss: 0.05363) (accu: 0.9826)
[epoch : 4] (l_loss: 0.00718) (t_loss: 0.05546) (accu: 0.9837)
[epoch : 5] (l_loss: 0.00517) (t_loss: 0.06164) (accu: 0.9829)
[epoch : 6] (l_loss: 0.00271) (t_loss: 0.06495) (accu: 0.9834)
[epoch : 7] (l_loss: 0.00276) (t_loss: 0.07415) (accu: 0.9824)
[epoch : 8] (l_loss: 0.00287) (t_loss: 0.07391) (accu: 0.9828)
[epoch : 9] (l_loss: 0.00322) (t_loss: 0.08446) (accu: 0.9824)
[epoch : 10] (l_loss: 0.00233) (t_loss: 0.09134) (accu: 0.9817)
[epoch : 11] (l_loss: 0.00188) (t_loss: 0.09441) (accu: 0.9833)
[epoch : 12] (l_loss: 0.00100) (t_loss: 0.09163) (accu: 0.9826)
[epoch : 13] (l_loss: 0.00301) (t_loss: 0.10565) (accu: 0.9815)
[epoch : 14] (l_loss: 0.00137) (t_loss: 0.10232) (accu: 0.9810)
[epoch : 15] (l_loss: 0.00033) (t_loss: 0.09758) (accu: 0.9834)
[epoch : 16] (l_loss: 0.00008) (t_loss: 0.09731) (accu: 0.9834)
[epoch : 17] (l_loss: 0.00004) (t_loss: 0.09755) (accu: 0.9844)
[epoch : 18] (l_loss: 0.00003) (t_loss: 0.09911) (accu: 0.9839)
[epoch : 19] (l_loss: 0.00002) (t_loss: 0.10117) (accu: 0.9837)
[epoch : 20] (l_loss: 0.00002) (t_loss: 0.10334) (accu: 0.9830)
[epoch : 21] (l_loss: 0.00001) (t_loss: 0.10585) (accu: 0.9831)
[epoch : 22] (l_loss: 0.00978) (t_loss: 0.10944) (accu: 0.9829)
[epoch : 23] (l_loss: 0.00110) (t_loss: 0.10498) (accu: 0.9843)
[epoch : 24] (l_loss: 0.00020) (t_loss: 0.10416) (accu: 0.9840)
[epoch : 25] (l_loss: 0.00007) (t_loss: 0.10411) (accu: 0.9845)
[epoch : 26] (l_loss: 0.00003) (t_loss: 0.10498) (accu: 0.9841)
[epoch : 27] (l_loss: 0.00002) (t_loss: 0.10616) (accu: 0.9840)
[epoch : 28] (l_loss: 0.00002) (t_loss: 0.10781) (accu: 0.9842)
[epoch : 29] (l_loss: 0.00001) (t_loss: 0.10866) (accu: 0.9843)
[epoch : 30] (l_loss: 0.00001) (t_loss: 0.11068) (accu: 0.9840)
Finish! (Best accu: 0.9845) (Time taken(sec) : 364.52) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (18507 | 247693)          6.95
fc1.weight   :      235200 (16163 | 219037)          6.87
fc2.weight   :        30000 (2062 | 27938)           6.87
fcout.weight :          1000 (282 | 718)            28.20
------------------------------------------------------------
Learning start! [Prune_iter : (13/21), Remaining weight : 6.95 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 1.96180) (accu: 0.5292)
[epoch : 1] (l_loss: 0.16735) (t_loss: 0.06600) (accu: 0.9806)
[epoch : 2] (l_loss: 0.03329) (t_loss: 0.05077) (accu: 0.9848)
[epoch : 3] (l_loss: 0.01603) (t_loss: 0.05535) (accu: 0.9831)
[epoch : 4] (l_loss: 0.00835) (t_loss: 0.05854) (accu: 0.9836)
[epoch : 5] (l_loss: 0.00457) (t_loss: 0.06132) (accu: 0.9826)
[epoch : 6] (l_loss: 0.00309) (t_loss: 0.07250) (accu: 0.9821)
[epoch : 7] (l_loss: 0.00327) (t_loss: 0.07187) (accu: 0.9835)
[epoch : 8] (l_loss: 0.00148) (t_loss: 0.07675) (accu: 0.9838)
[epoch : 9] (l_loss: 0.00188) (t_loss: 0.08481) (accu: 0.9820)
[epoch : 10] (l_loss: 0.00401) (t_loss: 0.08513) (accu: 0.9824)
[epoch : 11] (l_loss: 0.00114) (t_loss: 0.08475) (accu: 0.9834)
[epoch : 12] (l_loss: 0.00023) (t_loss: 0.08318) (accu: 0.9840)
[epoch : 13] (l_loss: 0.00013) (t_loss: 0.08576) (accu: 0.9841)
[epoch : 14] (l_loss: 0.00009) (t_loss: 0.08758) (accu: 0.9839)
[epoch : 15] (l_loss: 0.00007) (t_loss: 0.09042) (accu: 0.9842)
[epoch : 16] (l_loss: 0.00030) (t_loss: 0.12627) (accu: 0.9802)
[epoch : 17] (l_loss: 0.00790) (t_loss: 0.10172) (accu: 0.9822)
[epoch : 18] (l_loss: 0.00083) (t_loss: 0.10458) (accu: 0.9824)
[epoch : 19] (l_loss: 0.00033) (t_loss: 0.10218) (accu: 0.9834)
[epoch : 20] (l_loss: 0.00009) (t_loss: 0.10093) (accu: 0.9843)
[epoch : 21] (l_loss: 0.00004) (t_loss: 0.10067) (accu: 0.9842)
[epoch : 22] (l_loss: 0.00003) (t_loss: 0.10272) (accu: 0.9843)
[epoch : 23] (l_loss: 0.00002) (t_loss: 0.10359) (accu: 0.9841)
[epoch : 24] (l_loss: 0.00002) (t_loss: 0.10568) (accu: 0.9838)
[epoch : 25] (l_loss: 0.00001) (t_loss: 0.10654) (accu: 0.9837)
[epoch : 26] (l_loss: 0.00001) (t_loss: 0.10955) (accu: 0.9835)
[epoch : 27] (l_loss: 0.00001) (t_loss: 0.11228) (accu: 0.9841)
[epoch : 28] (l_loss: 0.00001) (t_loss: 0.11575) (accu: 0.9831)
[epoch : 29] (l_loss: 0.00714) (t_loss: 0.14771) (accu: 0.9808)
[epoch : 30] (l_loss: 0.00167) (t_loss: 0.12238) (accu: 0.9828)
Finish! (Best accu: 0.9848) (Time taken(sec) : 365.93) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (14833 | 251367)          5.57
fc1.weight   :      235200 (12930 | 222270)          5.50
fc2.weight   :        30000 (1649 | 28351)           5.50
fcout.weight :          1000 (254 | 746)            25.40
------------------------------------------------------------
Learning start! [Prune_iter : (14/21), Remaining weight : 5.57 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.00568) (accu: 0.5222)
[epoch : 1] (l_loss: 0.19037) (t_loss: 0.06863) (accu: 0.9793)
[epoch : 2] (l_loss: 0.03744) (t_loss: 0.05504) (accu: 0.9836)
[epoch : 3] (l_loss: 0.01896) (t_loss: 0.05407) (accu: 0.9835)
[epoch : 4] (l_loss: 0.01060) (t_loss: 0.05626) (accu: 0.9826)
[epoch : 5] (l_loss: 0.00648) (t_loss: 0.05966) (accu: 0.9833)
[epoch : 6] (l_loss: 0.00385) (t_loss: 0.06514) (accu: 0.9829)
[epoch : 7] (l_loss: 0.00262) (t_loss: 0.07457) (accu: 0.9827)
[epoch : 8] (l_loss: 0.00178) (t_loss: 0.06704) (accu: 0.9840)
[epoch : 9] (l_loss: 0.00312) (t_loss: 0.07425) (accu: 0.9827)
[epoch : 10] (l_loss: 0.00144) (t_loss: 0.07849) (accu: 0.9833)
[epoch : 11] (l_loss: 0.00044) (t_loss: 0.07764) (accu: 0.9838)
[epoch : 12] (l_loss: 0.00022) (t_loss: 0.07899) (accu: 0.9839)
[epoch : 13] (l_loss: 0.00336) (t_loss: 0.08896) (accu: 0.9830)
[epoch : 14] (l_loss: 0.00053) (t_loss: 0.08729) (accu: 0.9840)
[epoch : 15] (l_loss: 0.00016) (t_loss: 0.08702) (accu: 0.9843)
[epoch : 16] (l_loss: 0.00009) (t_loss: 0.08753) (accu: 0.9846)
[epoch : 17] (l_loss: 0.00006) (t_loss: 0.08902) (accu: 0.9844)
[epoch : 18] (l_loss: 0.00005) (t_loss: 0.09179) (accu: 0.9841)
[epoch : 19] (l_loss: 0.00004) (t_loss: 0.09381) (accu: 0.9840)
[epoch : 20] (l_loss: 0.00216) (t_loss: 0.13590) (accu: 0.9784)
[epoch : 21] (l_loss: 0.00661) (t_loss: 0.10736) (accu: 0.9825)
[epoch : 22] (l_loss: 0.00058) (t_loss: 0.10329) (accu: 0.9829)
[epoch : 23] (l_loss: 0.00010) (t_loss: 0.10187) (accu: 0.9836)
[epoch : 24] (l_loss: 0.00005) (t_loss: 0.10190) (accu: 0.9834)
[epoch : 25] (l_loss: 0.00004) (t_loss: 0.10243) (accu: 0.9845)
[epoch : 26] (l_loss: 0.00003) (t_loss: 0.10274) (accu: 0.9842)
[epoch : 27] (l_loss: 0.00002) (t_loss: 0.10347) (accu: 0.9838)
[epoch : 28] (l_loss: 0.00002) (t_loss: 0.10556) (accu: 0.9842)
[epoch : 29] (l_loss: 0.00001) (t_loss: 0.10715) (accu: 0.9839)
[epoch : 30] (l_loss: 0.00001) (t_loss: 0.11023) (accu: 0.9844)
Finish! (Best accu: 0.9846) (Time taken(sec) : 358.46) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (11892 | 254308)          4.47
fc1.weight   :      235200 (10344 | 224856)          4.40
fc2.weight   :        30000 (1319 | 28681)           4.40
fcout.weight :          1000 (229 | 771)            22.90
------------------------------------------------------------
Learning start! [Prune_iter : (15/21), Remaining weight : 4.47 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.08247) (accu: 0.3379)
[epoch : 1] (l_loss: 0.21795) (t_loss: 0.07454) (accu: 0.9755)
[epoch : 2] (l_loss: 0.04306) (t_loss: 0.05479) (accu: 0.9821)
[epoch : 3] (l_loss: 0.02362) (t_loss: 0.05117) (accu: 0.9838)
[epoch : 4] (l_loss: 0.01365) (t_loss: 0.05471) (accu: 0.9832)
[epoch : 5] (l_loss: 0.00828) (t_loss: 0.05488) (accu: 0.9836)
[epoch : 6] (l_loss: 0.00515) (t_loss: 0.06217) (accu: 0.9827)
[epoch : 7] (l_loss: 0.00328) (t_loss: 0.06143) (accu: 0.9827)
[epoch : 8] (l_loss: 0.00246) (t_loss: 0.07452) (accu: 0.9819)
[epoch : 9] (l_loss: 0.00276) (t_loss: 0.07098) (accu: 0.9843)
[epoch : 10] (l_loss: 0.00123) (t_loss: 0.07439) (accu: 0.9832)
[epoch : 11] (l_loss: 0.00076) (t_loss: 0.07425) (accu: 0.9839)
[epoch : 12] (l_loss: 0.00034) (t_loss: 0.07600) (accu: 0.9841)
[epoch : 13] (l_loss: 0.00023) (t_loss: 0.08398) (accu: 0.9831)
[epoch : 14] (l_loss: 0.00502) (t_loss: 0.09390) (accu: 0.9821)
[epoch : 15] (l_loss: 0.00092) (t_loss: 0.08697) (accu: 0.9821)
[epoch : 16] (l_loss: 0.00020) (t_loss: 0.08833) (accu: 0.9834)
[epoch : 17] (l_loss: 0.00012) (t_loss: 0.08856) (accu: 0.9827)
[epoch : 18] (l_loss: 0.00009) (t_loss: 0.08981) (accu: 0.9829)
[epoch : 19] (l_loss: 0.00008) (t_loss: 0.09196) (accu: 0.9829)
[epoch : 20] (l_loss: 0.00006) (t_loss: 0.09378) (accu: 0.9835)
[epoch : 21] (l_loss: 0.00529) (t_loss: 0.11271) (accu: 0.9818)
[epoch : 22] (l_loss: 0.00077) (t_loss: 0.10988) (accu: 0.9827)
[epoch : 23] (l_loss: 0.00015) (t_loss: 0.10446) (accu: 0.9832)
[epoch : 24] (l_loss: 0.00007) (t_loss: 0.10493) (accu: 0.9830)
[epoch : 25] (l_loss: 0.00005) (t_loss: 0.10470) (accu: 0.9833)
[epoch : 26] (l_loss: 0.00004) (t_loss: 0.10535) (accu: 0.9832)
[epoch : 27] (l_loss: 0.00003) (t_loss: 0.10694) (accu: 0.9833)
[epoch : 28] (l_loss: 0.00002) (t_loss: 0.10800) (accu: 0.9833)
[epoch : 29] (l_loss: 0.00002) (t_loss: 0.11174) (accu: 0.9833)
[epoch : 30] (l_loss: 0.00001) (t_loss: 0.11377) (accu: 0.9834)
Finish! (Best accu: 0.9843) (Time taken(sec) : 360.16) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (9537 | 256663)          3.58
fc1.weight   :       235200 (8275 | 226925)          3.52
fc2.weight   :        30000 (1056 | 28944)           3.52
fcout.weight :          1000 (206 | 794)            20.60
------------------------------------------------------------
Learning start! [Prune_iter : (16/21), Remaining weight : 3.58 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.11295) (accu: 0.2961)
[epoch : 1] (l_loss: 0.24698) (t_loss: 0.07763) (accu: 0.9767)
[epoch : 2] (l_loss: 0.04849) (t_loss: 0.05667) (accu: 0.9827)
[epoch : 3] (l_loss: 0.02758) (t_loss: 0.05480) (accu: 0.9814)
[epoch : 4] (l_loss: 0.01718) (t_loss: 0.05320) (accu: 0.9835)
[epoch : 5] (l_loss: 0.01091) (t_loss: 0.05519) (accu: 0.9834)
[epoch : 6] (l_loss: 0.00718) (t_loss: 0.06402) (accu: 0.9824)
[epoch : 7] (l_loss: 0.00489) (t_loss: 0.06457) (accu: 0.9824)
[epoch : 8] (l_loss: 0.00321) (t_loss: 0.06644) (accu: 0.9824)
[epoch : 9] (l_loss: 0.00229) (t_loss: 0.07020) (accu: 0.9826)
[epoch : 10] (l_loss: 0.00174) (t_loss: 0.07823) (accu: 0.9815)
[epoch : 11] (l_loss: 0.00259) (t_loss: 0.08546) (accu: 0.9812)
[epoch : 12] (l_loss: 0.00138) (t_loss: 0.08100) (accu: 0.9824)
[epoch : 13] (l_loss: 0.00061) (t_loss: 0.08089) (accu: 0.9830)
[epoch : 14] (l_loss: 0.00034) (t_loss: 0.08404) (accu: 0.9829)
[epoch : 15] (l_loss: 0.00038) (t_loss: 0.10233) (accu: 0.9812)
[epoch : 16] (l_loss: 0.00477) (t_loss: 0.09540) (accu: 0.9829)
[epoch : 17] (l_loss: 0.00052) (t_loss: 0.09707) (accu: 0.9834)
[epoch : 18] (l_loss: 0.00019) (t_loss: 0.09601) (accu: 0.9837)
[epoch : 19] (l_loss: 0.00013) (t_loss: 0.09634) (accu: 0.9837)
[epoch : 20] (l_loss: 0.00010) (t_loss: 0.09718) (accu: 0.9839)
[epoch : 21] (l_loss: 0.00008) (t_loss: 0.09974) (accu: 0.9838)
[epoch : 22] (l_loss: 0.00006) (t_loss: 0.10413) (accu: 0.9836)
[epoch : 23] (l_loss: 0.00387) (t_loss: 0.11089) (accu: 0.9830)
[epoch : 24] (l_loss: 0.00081) (t_loss: 0.10559) (accu: 0.9836)
[epoch : 25] (l_loss: 0.00020) (t_loss: 0.10615) (accu: 0.9839)
[epoch : 26] (l_loss: 0.00008) (t_loss: 0.10603) (accu: 0.9838)
[epoch : 27] (l_loss: 0.00006) (t_loss: 0.10629) (accu: 0.9843)
[epoch : 28] (l_loss: 0.00004) (t_loss: 0.10634) (accu: 0.9837)
[epoch : 29] (l_loss: 0.00003) (t_loss: 0.10851) (accu: 0.9840)
[epoch : 30] (l_loss: 0.00003) (t_loss: 0.10892) (accu: 0.9842)
Finish! (Best accu: 0.9843) (Time taken(sec) : 362.54) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (7649 | 258551)          2.87
fc1.weight   :       235200 (6620 | 228580)          2.81
fc2.weight   :        30000 (844 | 29156)            2.81
fcout.weight :          1000 (185 | 815)            18.50
------------------------------------------------------------
Learning start! [Prune_iter : (17/21), Remaining weight : 2.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.16070) (accu: 0.2389)
[epoch : 1] (l_loss: 0.28548) (t_loss: 0.08518) (accu: 0.9743)
[epoch : 2] (l_loss: 0.05750) (t_loss: 0.06218) (accu: 0.9805)
[epoch : 3] (l_loss: 0.03482) (t_loss: 0.05540) (accu: 0.9832)
[epoch : 4] (l_loss: 0.02269) (t_loss: 0.05291) (accu: 0.9829)
[epoch : 5] (l_loss: 0.01595) (t_loss: 0.05420) (accu: 0.9826)
[epoch : 6] (l_loss: 0.01122) (t_loss: 0.05527) (accu: 0.9834)
[epoch : 7] (l_loss: 0.00811) (t_loss: 0.05852) (accu: 0.9844)
[epoch : 8] (l_loss: 0.00586) (t_loss: 0.06300) (accu: 0.9831)
[epoch : 9] (l_loss: 0.00414) (t_loss: 0.06742) (accu: 0.9827)
[epoch : 10] (l_loss: 0.00303) (t_loss: 0.07371) (accu: 0.9829)
[epoch : 11] (l_loss: 0.00231) (t_loss: 0.07452) (accu: 0.9821)
[epoch : 12] (l_loss: 0.00186) (t_loss: 0.07756) (accu: 0.9838)
[epoch : 13] (l_loss: 0.00181) (t_loss: 0.08035) (accu: 0.9834)
[epoch : 14] (l_loss: 0.00117) (t_loss: 0.08383) (accu: 0.9841)
[epoch : 15] (l_loss: 0.00067) (t_loss: 0.08462) (accu: 0.9841)
[epoch : 16] (l_loss: 0.00044) (t_loss: 0.08979) (accu: 0.9828)
[epoch : 17] (l_loss: 0.00172) (t_loss: 0.10386) (accu: 0.9815)
[epoch : 18] (l_loss: 0.00302) (t_loss: 0.10162) (accu: 0.9824)
[epoch : 19] (l_loss: 0.00044) (t_loss: 0.09619) (accu: 0.9838)
[epoch : 20] (l_loss: 0.00023) (t_loss: 0.09727) (accu: 0.9835)
[epoch : 21] (l_loss: 0.00016) (t_loss: 0.09825) (accu: 0.9837)
[epoch : 22] (l_loss: 0.00013) (t_loss: 0.10050) (accu: 0.9836)
[epoch : 23] (l_loss: 0.00012) (t_loss: 0.10251) (accu: 0.9837)
[epoch : 24] (l_loss: 0.00341) (t_loss: 0.11796) (accu: 0.9821)
[epoch : 25] (l_loss: 0.00113) (t_loss: 0.11307) (accu: 0.9828)
[epoch : 26] (l_loss: 0.00028) (t_loss: 0.11414) (accu: 0.9836)
[epoch : 27] (l_loss: 0.00011) (t_loss: 0.11190) (accu: 0.9835)
[epoch : 28] (l_loss: 0.00008) (t_loss: 0.11186) (accu: 0.9842)
[epoch : 29] (l_loss: 0.00006) (t_loss: 0.11253) (accu: 0.9841)
[epoch : 30] (l_loss: 0.00005) (t_loss: 0.11365) (accu: 0.9847)
Finish! (Best accu: 0.9847) (Time taken(sec) : 365.97) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (6139 | 260061)          2.31
fc1.weight   :       235200 (5296 | 229904)          2.25
fc2.weight   :        30000 (676 | 29324)            2.25
fcout.weight :          1000 (167 | 833)            16.70
------------------------------------------------------------
Learning start! [Prune_iter : (18/21), Remaining weight : 2.31 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.19914) (accu: 0.1266)
[epoch : 1] (l_loss: 0.33442) (t_loss: 0.10281) (accu: 0.9690)
[epoch : 2] (l_loss: 0.06877) (t_loss: 0.07069) (accu: 0.9774)
[epoch : 3] (l_loss: 0.04240) (t_loss: 0.05984) (accu: 0.9803)
[epoch : 4] (l_loss: 0.02945) (t_loss: 0.05975) (accu: 0.9812)
[epoch : 5] (l_loss: 0.02180) (t_loss: 0.06040) (accu: 0.9812)
[epoch : 6] (l_loss: 0.01595) (t_loss: 0.06153) (accu: 0.9815)
[epoch : 7] (l_loss: 0.01209) (t_loss: 0.06686) (accu: 0.9819)
[epoch : 8] (l_loss: 0.00940) (t_loss: 0.06751) (accu: 0.9816)
[epoch : 9] (l_loss: 0.00698) (t_loss: 0.07165) (accu: 0.9819)
[epoch : 10] (l_loss: 0.00535) (t_loss: 0.07286) (accu: 0.9828)
[epoch : 11] (l_loss: 0.00427) (t_loss: 0.07902) (accu: 0.9817)
[epoch : 12] (l_loss: 0.00320) (t_loss: 0.08125) (accu: 0.9812)
[epoch : 13] (l_loss: 0.00300) (t_loss: 0.08550) (accu: 0.9815)
[epoch : 14] (l_loss: 0.00233) (t_loss: 0.09004) (accu: 0.9811)
[epoch : 15] (l_loss: 0.00199) (t_loss: 0.09376) (accu: 0.9815)
[epoch : 16] (l_loss: 0.00128) (t_loss: 0.09637) (accu: 0.9818)
[epoch : 17] (l_loss: 0.00165) (t_loss: 0.10344) (accu: 0.9818)
[epoch : 18] (l_loss: 0.00120) (t_loss: 0.10110) (accu: 0.9828)
[epoch : 19] (l_loss: 0.00091) (t_loss: 0.10912) (accu: 0.9816)
[epoch : 20] (l_loss: 0.00221) (t_loss: 0.11225) (accu: 0.9808)
[epoch : 21] (l_loss: 0.00062) (t_loss: 0.11030) (accu: 0.9817)
[epoch : 22] (l_loss: 0.00031) (t_loss: 0.11027) (accu: 0.9822)
[epoch : 23] (l_loss: 0.00024) (t_loss: 0.11134) (accu: 0.9821)
[epoch : 24] (l_loss: 0.00022) (t_loss: 0.11673) (accu: 0.9820)
[epoch : 25] (l_loss: 0.00371) (t_loss: 0.13076) (accu: 0.9803)
[epoch : 26] (l_loss: 0.00121) (t_loss: 0.12420) (accu: 0.9812)
[epoch : 27] (l_loss: 0.00023) (t_loss: 0.12326) (accu: 0.9821)
[epoch : 28] (l_loss: 0.00016) (t_loss: 0.12370) (accu: 0.9819)
[epoch : 29] (l_loss: 0.00012) (t_loss: 0.12532) (accu: 0.9821)
[epoch : 30] (l_loss: 0.00065) (t_loss: 0.14636) (accu: 0.9796)
Finish! (Best accu: 0.9828) (Time taken(sec) : 367.70) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (4927 | 261273)          1.85
fc1.weight   :       235200 (4237 | 230963)          1.80
fc2.weight   :        30000 (540 | 29460)            1.80
fcout.weight :          1000 (150 | 850)            15.00
------------------------------------------------------------
Learning start! [Prune_iter : (19/21), Remaining weight : 1.85 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.23701) (accu: 0.0952)
[epoch : 1] (l_loss: 0.38561) (t_loss: 0.11004) (accu: 0.9679)
[epoch : 2] (l_loss: 0.07863) (t_loss: 0.07927) (accu: 0.9762)
[epoch : 3] (l_loss: 0.05194) (t_loss: 0.07111) (accu: 0.9775)
[epoch : 4] (l_loss: 0.03850) (t_loss: 0.06483) (accu: 0.9793)
[epoch : 5] (l_loss: 0.02998) (t_loss: 0.06413) (accu: 0.9794)
[epoch : 6] (l_loss: 0.02432) (t_loss: 0.06802) (accu: 0.9801)
[epoch : 7] (l_loss: 0.01991) (t_loss: 0.07094) (accu: 0.9789)
[epoch : 8] (l_loss: 0.01654) (t_loss: 0.07085) (accu: 0.9798)
[epoch : 9] (l_loss: 0.01380) (t_loss: 0.07573) (accu: 0.9797)
[epoch : 10] (l_loss: 0.01170) (t_loss: 0.07819) (accu: 0.9790)
[epoch : 11] (l_loss: 0.00997) (t_loss: 0.08234) (accu: 0.9796)
[epoch : 12] (l_loss: 0.00852) (t_loss: 0.08822) (accu: 0.9788)
[epoch : 13] (l_loss: 0.00723) (t_loss: 0.09014) (accu: 0.9789)
[epoch : 14] (l_loss: 0.00637) (t_loss: 0.09435) (accu: 0.9785)
[epoch : 15] (l_loss: 0.00519) (t_loss: 0.10076) (accu: 0.9777)
[epoch : 16] (l_loss: 0.00483) (t_loss: 0.10128) (accu: 0.9785)
[epoch : 17] (l_loss: 0.00420) (t_loss: 0.10811) (accu: 0.9778)
[epoch : 18] (l_loss: 0.00335) (t_loss: 0.10529) (accu: 0.9790)
[epoch : 19] (l_loss: 0.00326) (t_loss: 0.11252) (accu: 0.9792)
[epoch : 20] (l_loss: 0.00294) (t_loss: 0.11493) (accu: 0.9783)
[epoch : 21] (l_loss: 0.00255) (t_loss: 0.11922) (accu: 0.9771)
[epoch : 22] (l_loss: 0.00229) (t_loss: 0.12316) (accu: 0.9778)
[epoch : 23] (l_loss: 0.00228) (t_loss: 0.12474) (accu: 0.9788)
[epoch : 24] (l_loss: 0.00202) (t_loss: 0.12556) (accu: 0.9779)
[epoch : 25] (l_loss: 0.00151) (t_loss: 0.13201) (accu: 0.9779)
[epoch : 26] (l_loss: 0.00118) (t_loss: 0.13466) (accu: 0.9779)
[epoch : 27] (l_loss: 0.00243) (t_loss: 0.14455) (accu: 0.9780)
[epoch : 28] (l_loss: 0.00160) (t_loss: 0.13853) (accu: 0.9785)
[epoch : 29] (l_loss: 0.00087) (t_loss: 0.14387) (accu: 0.9777)
[epoch : 30] (l_loss: 0.00058) (t_loss: 0.14384) (accu: 0.9781)
Finish! (Best accu: 0.9801) (Time taken(sec) : 370.19) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3957 | 262243)          1.49
fc1.weight   :       235200 (3390 | 231810)          1.44
fc2.weight   :        30000 (432 | 29568)            1.44
fcout.weight :          1000 (135 | 865)            13.50
------------------------------------------------------------
Learning start! [Prune_iter : (20/21), Remaining weight : 1.49 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.25426) (accu: 0.0892)
[epoch : 1] (l_loss: 0.43349) (t_loss: 0.12791) (accu: 0.9630)
[epoch : 2] (l_loss: 0.09178) (t_loss: 0.08889) (accu: 0.9734)
[epoch : 3] (l_loss: 0.06331) (t_loss: 0.07723) (accu: 0.9763)
[epoch : 4] (l_loss: 0.04911) (t_loss: 0.07213) (accu: 0.9781)
[epoch : 5] (l_loss: 0.04017) (t_loss: 0.06925) (accu: 0.9792)
[epoch : 6] (l_loss: 0.03327) (t_loss: 0.07184) (accu: 0.9783)
[epoch : 7] (l_loss: 0.02873) (t_loss: 0.07064) (accu: 0.9789)
[epoch : 8] (l_loss: 0.02477) (t_loss: 0.07049) (accu: 0.9792)
[epoch : 9] (l_loss: 0.02142) (t_loss: 0.07456) (accu: 0.9786)
[epoch : 10] (l_loss: 0.01913) (t_loss: 0.07576) (accu: 0.9783)
[epoch : 11] (l_loss: 0.01682) (t_loss: 0.07878) (accu: 0.9778)
[epoch : 12] (l_loss: 0.01491) (t_loss: 0.08219) (accu: 0.9779)
[epoch : 13] (l_loss: 0.01338) (t_loss: 0.08529) (accu: 0.9774)
[epoch : 14] (l_loss: 0.01180) (t_loss: 0.08810) (accu: 0.9779)
[epoch : 15] (l_loss: 0.01062) (t_loss: 0.09082) (accu: 0.9780)
[epoch : 16] (l_loss: 0.00951) (t_loss: 0.09339) (accu: 0.9783)
[epoch : 17] (l_loss: 0.00847) (t_loss: 0.09951) (accu: 0.9768)
[epoch : 18] (l_loss: 0.00780) (t_loss: 0.09701) (accu: 0.9769)
[epoch : 19] (l_loss: 0.00702) (t_loss: 0.10094) (accu: 0.9776)
[epoch : 20] (l_loss: 0.00632) (t_loss: 0.10404) (accu: 0.9776)
[epoch : 21] (l_loss: 0.00571) (t_loss: 0.10956) (accu: 0.9770)
[epoch : 22] (l_loss: 0.00537) (t_loss: 0.11258) (accu: 0.9765)
[epoch : 23] (l_loss: 0.00465) (t_loss: 0.11534) (accu: 0.9775)
[epoch : 24] (l_loss: 0.00420) (t_loss: 0.11827) (accu: 0.9771)
[epoch : 25] (l_loss: 0.00459) (t_loss: 0.12218) (accu: 0.9765)
[epoch : 26] (l_loss: 0.00329) (t_loss: 0.12604) (accu: 0.9773)
[epoch : 27] (l_loss: 0.00365) (t_loss: 0.12991) (accu: 0.9769)
[epoch : 28] (l_loss: 0.00306) (t_loss: 0.12950) (accu: 0.9771)
[epoch : 29] (l_loss: 0.00275) (t_loss: 0.13469) (accu: 0.9765)
[epoch : 30] (l_loss: 0.00270) (t_loss: 0.13908) (accu: 0.9767)
Finish! (Best accu: 0.9792) (Time taken(sec) : 367.94) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3180 | 263020)          1.19
fc1.weight   :       235200 (2712 | 232488)          1.15
fc2.weight   :        30000 (346 | 29654)            1.15
fcout.weight :          1000 (122 | 878)            12.20
------------------------------------------------------------
Learning start! [Prune_iter : (21/21), Remaining weight : 1.19 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.26775) (accu: 0.0892)
[epoch : 1] (l_loss: 0.49578) (t_loss: 0.15072) (accu: 0.9559)
[epoch : 2] (l_loss: 0.11661) (t_loss: 0.10438) (accu: 0.9684)
[epoch : 3] (l_loss: 0.08288) (t_loss: 0.08986) (accu: 0.9728)
[epoch : 4] (l_loss: 0.06611) (t_loss: 0.08390) (accu: 0.9742)
[epoch : 5] (l_loss: 0.05560) (t_loss: 0.07956) (accu: 0.9746)
[epoch : 6] (l_loss: 0.04844) (t_loss: 0.07849) (accu: 0.9762)
[epoch : 7] (l_loss: 0.04317) (t_loss: 0.07823) (accu: 0.9763)
[epoch : 8] (l_loss: 0.03874) (t_loss: 0.07831) (accu: 0.9756)
[epoch : 9] (l_loss: 0.03540) (t_loss: 0.07904) (accu: 0.9766)
[epoch : 10] (l_loss: 0.03280) (t_loss: 0.08179) (accu: 0.9757)
[epoch : 11] (l_loss: 0.03055) (t_loss: 0.08016) (accu: 0.9759)
[epoch : 12] (l_loss: 0.02830) (t_loss: 0.08060) (accu: 0.9770)
[epoch : 13] (l_loss: 0.02682) (t_loss: 0.08265) (accu: 0.9780)
[epoch : 14] (l_loss: 0.02514) (t_loss: 0.08612) (accu: 0.9764)
[epoch : 15] (l_loss: 0.02396) (t_loss: 0.08432) (accu: 0.9770)
[epoch : 16] (l_loss: 0.02247) (t_loss: 0.08740) (accu: 0.9772)
[epoch : 17] (l_loss: 0.02153) (t_loss: 0.08707) (accu: 0.9776)
[epoch : 18] (l_loss: 0.02082) (t_loss: 0.09061) (accu: 0.9775)
[epoch : 19] (l_loss: 0.01992) (t_loss: 0.09214) (accu: 0.9773)
[epoch : 20] (l_loss: 0.01891) (t_loss: 0.09426) (accu: 0.9774)
[epoch : 21] (l_loss: 0.01811) (t_loss: 0.09649) (accu: 0.9766)
[epoch : 22] (l_loss: 0.01760) (t_loss: 0.09892) (accu: 0.9769)
[epoch : 23] (l_loss: 0.01695) (t_loss: 0.09976) (accu: 0.9781)
[epoch : 24] (l_loss: 0.01660) (t_loss: 0.10160) (accu: 0.9765)
[epoch : 25] (l_loss: 0.01528) (t_loss: 0.10915) (accu: 0.9756)
[epoch : 26] (l_loss: 0.01511) (t_loss: 0.10306) (accu: 0.9776)
[epoch : 27] (l_loss: 0.01456) (t_loss: 0.10730) (accu: 0.9760)
[epoch : 28] (l_loss: 0.01421) (t_loss: 0.10954) (accu: 0.9769)
[epoch : 29] (l_loss: 0.01368) (t_loss: 0.11297) (accu: 0.9767)
[epoch : 30] (l_loss: 0.01288) (t_loss: 0.11385) (accu: 0.9774)
Finish! (Best accu: 0.9781) (Time taken(sec) : 371.02) 


Maximum accuracy per weight remaining
Remaining weight 100.0 %  Epoch 22 Accu 0.9816
Remaining weight 80.04 %  Epoch 21 Accu 0.9822
Remaining weight 64.06 %  Epoch 21 Accu 0.9822
Remaining weight 51.28 %  Epoch 27 Accu 0.9836
Remaining weight 41.05 %  Epoch 19 Accu 0.9840
Remaining weight 32.87 %  Epoch 2 Accu 0.9841
Remaining weight 26.32 %  Epoch 16 Accu 0.9843
Remaining weight 21.07 %  Epoch 24 Accu 0.9842
Remaining weight 16.88 %  Epoch 16 Accu 0.9855
Remaining weight 13.52 %  Epoch 12 Accu 0.9845
Remaining weight 10.83 %  Epoch 2 Accu 0.9841
Remaining weight 8.68 %  Epoch 24 Accu 0.9845
Remaining weight 6.95 %  Epoch 1 Accu 0.9848
Remaining weight 5.57 %  Epoch 15 Accu 0.9846
Remaining weight 4.47 %  Epoch 8 Accu 0.9843
Remaining weight 3.58 %  Epoch 26 Accu 0.9843
Remaining weight 2.87 %  Epoch 29 Accu 0.9847
Remaining weight 2.31 %  Epoch 17 Accu 0.9828
Remaining weight 1.85 %  Epoch 5 Accu 0.9801
Remaining weight 1.49 %  Epoch 7 Accu 0.9792
Remaining weight 1.19 %  Epoch 22 Accu 0.9781
===================================================================== 

Test_Iter (2/5)
------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :        266200 (266200 | 0)          100.00
fc1.weight   :        235200 (235200 | 0)          100.00
fc2.weight   :         30000 (30000 | 0)           100.00
fcout.weight :          1000 (1000 | 0)            100.00
------------------------------------------------------------
Learning start! [Prune_iter : (1/21), Remaining weight : 100.0 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69095) (accu: 0.0912)
[epoch : 1] (l_loss: 0.69297) (t_loss: 0.26186) (accu: 0.9212)
[epoch : 2] (l_loss: 0.21794) (t_loss: 0.17202) (accu: 0.9465)
[epoch : 3] (l_loss: 0.15944) (t_loss: 0.14455) (accu: 0.9558)
[epoch : 4] (l_loss: 0.13272) (t_loss: 0.12926) (accu: 0.9598)
[epoch : 5] (l_loss: 0.11588) (t_loss: 0.12306) (accu: 0.9626)
[epoch : 6] (l_loss: 0.10361) (t_loss: 0.11539) (accu: 0.9653)
[epoch : 7] (l_loss: 0.09406) (t_loss: 0.11112) (accu: 0.9664)
[epoch : 8] (l_loss: 0.08623) (t_loss: 0.11034) (accu: 0.9686)
[epoch : 9] (l_loss: 0.08036) (t_loss: 0.10836) (accu: 0.9690)
[epoch : 10] (l_loss: 0.07551) (t_loss: 0.10625) (accu: 0.9685)
[epoch : 11] (l_loss: 0.07115) (t_loss: 0.10492) (accu: 0.9684)
[epoch : 12] (l_loss: 0.06751) (t_loss: 0.10493) (accu: 0.9689)
[epoch : 13] (l_loss: 0.06410) (t_loss: 0.10501) (accu: 0.9690)
[epoch : 14] (l_loss: 0.06099) (t_loss: 0.10841) (accu: 0.9663)
[epoch : 15] (l_loss: 0.05909) (t_loss: 0.10490) (accu: 0.9693)
[epoch : 16] (l_loss: 0.05647) (t_loss: 0.10927) (accu: 0.9671)
[epoch : 17] (l_loss: 0.05437) (t_loss: 0.10598) (accu: 0.9680)
[epoch : 18] (l_loss: 0.05239) (t_loss: 0.10722) (accu: 0.9693)
[epoch : 19] (l_loss: 0.05053) (t_loss: 0.10581) (accu: 0.9704)
[epoch : 20] (l_loss: 0.04885) (t_loss: 0.10799) (accu: 0.9687)
[epoch : 21] (l_loss: 0.04757) (t_loss: 0.10645) (accu: 0.9700)
[epoch : 22] (l_loss: 0.04583) (t_loss: 0.10776) (accu: 0.9700)
[epoch : 23] (l_loss: 0.04453) (t_loss: 0.10803) (accu: 0.9704)
[epoch : 24] (l_loss: 0.04302) (t_loss: 0.11145) (accu: 0.9705)
[epoch : 25] (l_loss: 0.04192) (t_loss: 0.11277) (accu: 0.9704)
[epoch : 26] (l_loss: 0.04060) (t_loss: 0.11130) (accu: 0.9709)
[epoch : 27] (l_loss: 0.03983) (t_loss: 0.11178) (accu: 0.9709)
[epoch : 28] (l_loss: 0.03851) (t_loss: 0.11326) (accu: 0.9702)
[epoch : 29] (l_loss: 0.03768) (t_loss: 0.11718) (accu: 0.9702)
[epoch : 30] (l_loss: 0.03705) (t_loss: 0.11718) (accu: 0.9700)
Finish! (Best accu: 0.9709) (Time taken(sec) : 377.90) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (213060 | 53140)         80.04
fc1.weight   :      235200 (188160 | 47040)         80.00
fc2.weight   :        30000 (24000 | 6000)          80.00
fcout.weight :          1000 (900 | 100)            90.00
------------------------------------------------------------
Learning start! [Prune_iter : (2/21), Remaining weight : 80.04 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69448) (accu: 0.0907)
[epoch : 1] (l_loss: 0.70132) (t_loss: 0.26210) (accu: 0.9208)
[epoch : 2] (l_loss: 0.21742) (t_loss: 0.17129) (accu: 0.9481)
[epoch : 3] (l_loss: 0.15805) (t_loss: 0.14211) (accu: 0.9579)
[epoch : 4] (l_loss: 0.13124) (t_loss: 0.12704) (accu: 0.9618)
[epoch : 5] (l_loss: 0.11481) (t_loss: 0.11814) (accu: 0.9639)
[epoch : 6] (l_loss: 0.10301) (t_loss: 0.11514) (accu: 0.9645)
[epoch : 7] (l_loss: 0.09361) (t_loss: 0.11053) (accu: 0.9669)
[epoch : 8] (l_loss: 0.08592) (t_loss: 0.10996) (accu: 0.9664)
[epoch : 9] (l_loss: 0.07971) (t_loss: 0.10818) (accu: 0.9678)
[epoch : 10] (l_loss: 0.07523) (t_loss: 0.10595) (accu: 0.9674)
[epoch : 11] (l_loss: 0.07060) (t_loss: 0.10607) (accu: 0.9687)
[epoch : 12] (l_loss: 0.06672) (t_loss: 0.10294) (accu: 0.9697)
[epoch : 13] (l_loss: 0.06360) (t_loss: 0.10430) (accu: 0.9699)
[epoch : 14] (l_loss: 0.06028) (t_loss: 0.10453) (accu: 0.9692)
[epoch : 15] (l_loss: 0.05790) (t_loss: 0.10572) (accu: 0.9690)
[epoch : 16] (l_loss: 0.05530) (t_loss: 0.10674) (accu: 0.9689)
[epoch : 17] (l_loss: 0.05350) (t_loss: 0.10351) (accu: 0.9705)
[epoch : 18] (l_loss: 0.05151) (t_loss: 0.10756) (accu: 0.9695)
[epoch : 19] (l_loss: 0.04971) (t_loss: 0.10431) (accu: 0.9705)
[epoch : 20] (l_loss: 0.04786) (t_loss: 0.10927) (accu: 0.9697)
[epoch : 21] (l_loss: 0.04658) (t_loss: 0.10708) (accu: 0.9711)
[epoch : 22] (l_loss: 0.04500) (t_loss: 0.10923) (accu: 0.9701)
[epoch : 23] (l_loss: 0.04387) (t_loss: 0.10743) (accu: 0.9706)
[epoch : 24] (l_loss: 0.04247) (t_loss: 0.10883) (accu: 0.9700)
[epoch : 25] (l_loss: 0.04138) (t_loss: 0.11050) (accu: 0.9703)
[epoch : 26] (l_loss: 0.04060) (t_loss: 0.11031) (accu: 0.9702)
[epoch : 27] (l_loss: 0.03935) (t_loss: 0.11346) (accu: 0.9698)
[epoch : 28] (l_loss: 0.03828) (t_loss: 0.11263) (accu: 0.9701)
[epoch : 29] (l_loss: 0.03732) (t_loss: 0.11325) (accu: 0.9705)
[epoch : 30] (l_loss: 0.03650) (t_loss: 0.11324) (accu: 0.9699)
Finish! (Best accu: 0.9711) (Time taken(sec) : 376.47) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (170538 | 95662)         64.06
fc1.weight   :      235200 (150528 | 84672)         64.00
fc2.weight   :       30000 (19200 | 10800)          64.00
fcout.weight :          1000 (810 | 190)            81.00
------------------------------------------------------------
Learning start! [Prune_iter : (3/21), Remaining weight : 64.06 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.65744) (accu: 0.0968)
[epoch : 1] (l_loss: 0.70020) (t_loss: 0.26260) (accu: 0.9235)
[epoch : 2] (l_loss: 0.21964) (t_loss: 0.17673) (accu: 0.9478)
[epoch : 3] (l_loss: 0.16023) (t_loss: 0.14439) (accu: 0.9575)
[epoch : 4] (l_loss: 0.13214) (t_loss: 0.12734) (accu: 0.9615)
[epoch : 5] (l_loss: 0.11520) (t_loss: 0.11761) (accu: 0.9635)
[epoch : 6] (l_loss: 0.10284) (t_loss: 0.11355) (accu: 0.9641)
[epoch : 7] (l_loss: 0.09360) (t_loss: 0.10835) (accu: 0.9680)
[epoch : 8] (l_loss: 0.08642) (t_loss: 0.10644) (accu: 0.9689)
[epoch : 9] (l_loss: 0.08037) (t_loss: 0.10455) (accu: 0.9689)
[epoch : 10] (l_loss: 0.07601) (t_loss: 0.10457) (accu: 0.9685)
[epoch : 11] (l_loss: 0.07198) (t_loss: 0.10426) (accu: 0.9686)
[epoch : 12] (l_loss: 0.06824) (t_loss: 0.10493) (accu: 0.9685)
[epoch : 13] (l_loss: 0.06552) (t_loss: 0.10457) (accu: 0.9686)
[epoch : 14] (l_loss: 0.06249) (t_loss: 0.10617) (accu: 0.9676)
[epoch : 15] (l_loss: 0.06061) (t_loss: 0.10628) (accu: 0.9692)
[epoch : 16] (l_loss: 0.05810) (t_loss: 0.10606) (accu: 0.9680)
[epoch : 17] (l_loss: 0.05615) (t_loss: 0.10434) (accu: 0.9699)
[epoch : 18] (l_loss: 0.05421) (t_loss: 0.10786) (accu: 0.9685)
[epoch : 19] (l_loss: 0.05294) (t_loss: 0.10501) (accu: 0.9699)
[epoch : 20] (l_loss: 0.05097) (t_loss: 0.10671) (accu: 0.9706)
[epoch : 21] (l_loss: 0.04969) (t_loss: 0.10753) (accu: 0.9699)
[epoch : 22] (l_loss: 0.04794) (t_loss: 0.10889) (accu: 0.9697)
[epoch : 23] (l_loss: 0.04665) (t_loss: 0.11304) (accu: 0.9687)
[epoch : 24] (l_loss: 0.04558) (t_loss: 0.10908) (accu: 0.9701)
[epoch : 25] (l_loss: 0.04443) (t_loss: 0.11043) (accu: 0.9704)
[epoch : 26] (l_loss: 0.04338) (t_loss: 0.11048) (accu: 0.9700)
[epoch : 27] (l_loss: 0.04212) (t_loss: 0.10991) (accu: 0.9706)
[epoch : 28] (l_loss: 0.04079) (t_loss: 0.11389) (accu: 0.9706)
[epoch : 29] (l_loss: 0.04040) (t_loss: 0.11999) (accu: 0.9699)
[epoch : 30] (l_loss: 0.03918) (t_loss: 0.11802) (accu: 0.9694)
Finish! (Best accu: 0.9706) (Time taken(sec) : 373.63) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (136511 | 129689)        51.28
fc1.weight   :      235200 (120422 | 114778)        51.20
fc2.weight   :       30000 (15360 | 14640)          51.20
fcout.weight :          1000 (729 | 271)            72.90
------------------------------------------------------------
Learning start! [Prune_iter : (4/21), Remaining weight : 51.28 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.56458) (accu: 0.0960)
[epoch : 1] (l_loss: 0.68428) (t_loss: 0.26576) (accu: 0.9209)
[epoch : 2] (l_loss: 0.21823) (t_loss: 0.18319) (accu: 0.9452)
[epoch : 3] (l_loss: 0.15895) (t_loss: 0.15176) (accu: 0.9542)
[epoch : 4] (l_loss: 0.13126) (t_loss: 0.13330) (accu: 0.9584)
[epoch : 5] (l_loss: 0.11426) (t_loss: 0.12419) (accu: 0.9611)
[epoch : 6] (l_loss: 0.10269) (t_loss: 0.11829) (accu: 0.9639)
[epoch : 7] (l_loss: 0.09367) (t_loss: 0.11387) (accu: 0.9647)
[epoch : 8] (l_loss: 0.08696) (t_loss: 0.11050) (accu: 0.9682)
[epoch : 9] (l_loss: 0.08173) (t_loss: 0.11366) (accu: 0.9667)
[epoch : 10] (l_loss: 0.07691) (t_loss: 0.11175) (accu: 0.9676)
[epoch : 11] (l_loss: 0.07324) (t_loss: 0.10662) (accu: 0.9690)
[epoch : 12] (l_loss: 0.07014) (t_loss: 0.11141) (accu: 0.9685)
[epoch : 13] (l_loss: 0.06722) (t_loss: 0.10818) (accu: 0.9698)
[epoch : 14] (l_loss: 0.06464) (t_loss: 0.10913) (accu: 0.9692)
[epoch : 15] (l_loss: 0.06212) (t_loss: 0.10789) (accu: 0.9693)
[epoch : 16] (l_loss: 0.05998) (t_loss: 0.10990) (accu: 0.9697)
[epoch : 17] (l_loss: 0.05800) (t_loss: 0.10897) (accu: 0.9696)
[epoch : 18] (l_loss: 0.05630) (t_loss: 0.10774) (accu: 0.9700)
[epoch : 19] (l_loss: 0.05425) (t_loss: 0.10950) (accu: 0.9702)
[epoch : 20] (l_loss: 0.05291) (t_loss: 0.11015) (accu: 0.9700)
[epoch : 21] (l_loss: 0.05110) (t_loss: 0.11157) (accu: 0.9694)
[epoch : 22] (l_loss: 0.04972) (t_loss: 0.10920) (accu: 0.9705)
[epoch : 23] (l_loss: 0.04815) (t_loss: 0.11276) (accu: 0.9703)
[epoch : 24] (l_loss: 0.04723) (t_loss: 0.11337) (accu: 0.9705)
[epoch : 25] (l_loss: 0.04579) (t_loss: 0.10941) (accu: 0.9713)
[epoch : 26] (l_loss: 0.04482) (t_loss: 0.11425) (accu: 0.9709)
[epoch : 27] (l_loss: 0.04359) (t_loss: 0.11315) (accu: 0.9709)
[epoch : 28] (l_loss: 0.04312) (t_loss: 0.11168) (accu: 0.9715)
[epoch : 29] (l_loss: 0.04199) (t_loss: 0.11542) (accu: 0.9712)
[epoch : 30] (l_loss: 0.04087) (t_loss: 0.11301) (accu: 0.9712)
Finish! (Best accu: 0.9715) (Time taken(sec) : 382.81) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (109282 | 156918)        41.05
fc1.weight   :      235200 (96338 | 138862)         40.96
fc2.weight   :       30000 (12288 | 17712)          40.96
fcout.weight :          1000 (656 | 344)            65.60
------------------------------------------------------------
Learning start! [Prune_iter : (5/21), Remaining weight : 41.05 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.54587) (accu: 0.1034)
[epoch : 1] (l_loss: 0.68331) (t_loss: 0.25505) (accu: 0.9230)
[epoch : 2] (l_loss: 0.20827) (t_loss: 0.17205) (accu: 0.9478)
[epoch : 3] (l_loss: 0.15147) (t_loss: 0.14588) (accu: 0.9546)
[epoch : 4] (l_loss: 0.12610) (t_loss: 0.13369) (accu: 0.9606)
[epoch : 5] (l_loss: 0.11115) (t_loss: 0.12361) (accu: 0.9621)
[epoch : 6] (l_loss: 0.10057) (t_loss: 0.11943) (accu: 0.9648)
[epoch : 7] (l_loss: 0.09293) (t_loss: 0.11554) (accu: 0.9659)
[epoch : 8] (l_loss: 0.08636) (t_loss: 0.11220) (accu: 0.9649)
[epoch : 9] (l_loss: 0.08156) (t_loss: 0.10918) (accu: 0.9667)
[epoch : 10] (l_loss: 0.07747) (t_loss: 0.10887) (accu: 0.9679)
[epoch : 11] (l_loss: 0.07404) (t_loss: 0.10829) (accu: 0.9674)
[epoch : 12] (l_loss: 0.07080) (t_loss: 0.10680) (accu: 0.9682)
[epoch : 13] (l_loss: 0.06832) (t_loss: 0.10695) (accu: 0.9688)
[epoch : 14] (l_loss: 0.06564) (t_loss: 0.10660) (accu: 0.9690)
[epoch : 15] (l_loss: 0.06334) (t_loss: 0.10584) (accu: 0.9695)
[epoch : 16] (l_loss: 0.06103) (t_loss: 0.10988) (accu: 0.9673)
[epoch : 17] (l_loss: 0.05950) (t_loss: 0.10791) (accu: 0.9702)
[epoch : 18] (l_loss: 0.05716) (t_loss: 0.10878) (accu: 0.9699)
[epoch : 19] (l_loss: 0.05619) (t_loss: 0.10753) (accu: 0.9695)
[epoch : 20] (l_loss: 0.05427) (t_loss: 0.10838) (accu: 0.9692)
[epoch : 21] (l_loss: 0.05303) (t_loss: 0.10897) (accu: 0.9704)
[epoch : 22] (l_loss: 0.05153) (t_loss: 0.11079) (accu: 0.9700)
[epoch : 23] (l_loss: 0.05063) (t_loss: 0.10995) (accu: 0.9696)
[epoch : 24] (l_loss: 0.04902) (t_loss: 0.11301) (accu: 0.9684)
[epoch : 25] (l_loss: 0.04826) (t_loss: 0.11054) (accu: 0.9702)
[epoch : 26] (l_loss: 0.04678) (t_loss: 0.11235) (accu: 0.9705)
[epoch : 27] (l_loss: 0.04598) (t_loss: 0.11412) (accu: 0.9691)
[epoch : 28] (l_loss: 0.04510) (t_loss: 0.11274) (accu: 0.9706)
[epoch : 29] (l_loss: 0.04403) (t_loss: 0.11519) (accu: 0.9683)
[epoch : 30] (l_loss: 0.04292) (t_loss: 0.11411) (accu: 0.9696)
Finish! (Best accu: 0.9706) (Time taken(sec) : 373.86) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (87490 | 178710)         32.87
fc1.weight   :      235200 (77070 | 158130)         32.77
fc2.weight   :        30000 (9830 | 20170)          32.77
fcout.weight :          1000 (590 | 410)            59.00
------------------------------------------------------------
Learning start! [Prune_iter : (6/21), Remaining weight : 32.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.49433) (accu: 0.0908)
[epoch : 1] (l_loss: 0.69266) (t_loss: 0.25045) (accu: 0.9292)
[epoch : 2] (l_loss: 0.20187) (t_loss: 0.16663) (accu: 0.9506)
[epoch : 3] (l_loss: 0.14804) (t_loss: 0.14167) (accu: 0.9566)
[epoch : 4] (l_loss: 0.12398) (t_loss: 0.12799) (accu: 0.9624)
[epoch : 5] (l_loss: 0.10888) (t_loss: 0.12154) (accu: 0.9651)
[epoch : 6] (l_loss: 0.09865) (t_loss: 0.11636) (accu: 0.9657)
[epoch : 7] (l_loss: 0.09096) (t_loss: 0.11214) (accu: 0.9672)
[epoch : 8] (l_loss: 0.08470) (t_loss: 0.11086) (accu: 0.9662)
[epoch : 9] (l_loss: 0.07988) (t_loss: 0.10893) (accu: 0.9680)
[epoch : 10] (l_loss: 0.07514) (t_loss: 0.10963) (accu: 0.9678)
[epoch : 11] (l_loss: 0.07188) (t_loss: 0.10672) (accu: 0.9698)
[epoch : 12] (l_loss: 0.06860) (t_loss: 0.10675) (accu: 0.9694)
[epoch : 13] (l_loss: 0.06588) (t_loss: 0.10621) (accu: 0.9688)
[epoch : 14] (l_loss: 0.06325) (t_loss: 0.10729) (accu: 0.9682)
[epoch : 15] (l_loss: 0.06108) (t_loss: 0.10596) (accu: 0.9695)
[epoch : 16] (l_loss: 0.05904) (t_loss: 0.10721) (accu: 0.9689)
[epoch : 17] (l_loss: 0.05737) (t_loss: 0.10702) (accu: 0.9696)
[epoch : 18] (l_loss: 0.05556) (t_loss: 0.10787) (accu: 0.9696)
[epoch : 19] (l_loss: 0.05424) (t_loss: 0.10900) (accu: 0.9695)
[epoch : 20] (l_loss: 0.05261) (t_loss: 0.10787) (accu: 0.9705)
[epoch : 21] (l_loss: 0.05161) (t_loss: 0.10708) (accu: 0.9701)
[epoch : 22] (l_loss: 0.05018) (t_loss: 0.11107) (accu: 0.9708)
[epoch : 23] (l_loss: 0.04917) (t_loss: 0.11042) (accu: 0.9696)
[epoch : 24] (l_loss: 0.04809) (t_loss: 0.11034) (accu: 0.9710)
[epoch : 25] (l_loss: 0.04708) (t_loss: 0.11044) (accu: 0.9715)
[epoch : 26] (l_loss: 0.04599) (t_loss: 0.11270) (accu: 0.9710)
[epoch : 27] (l_loss: 0.04519) (t_loss: 0.11232) (accu: 0.9706)
[epoch : 28] (l_loss: 0.04396) (t_loss: 0.11328) (accu: 0.9707)
[epoch : 29] (l_loss: 0.04297) (t_loss: 0.11188) (accu: 0.9716)
[epoch : 30] (l_loss: 0.04249) (t_loss: 0.11368) (accu: 0.9720)
Finish! (Best accu: 0.9720) (Time taken(sec) : 380.69) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (70051 | 196149)         26.32
fc1.weight   :      235200 (61656 | 173544)         26.21
fc2.weight   :        30000 (7864 | 22136)          26.21
fcout.weight :          1000 (531 | 469)            53.10
------------------------------------------------------------
Learning start! [Prune_iter : (7/21), Remaining weight : 26.32 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.42693) (accu: 0.1025)
[epoch : 1] (l_loss: 0.69898) (t_loss: 0.24343) (accu: 0.9292)
[epoch : 2] (l_loss: 0.19844) (t_loss: 0.16546) (accu: 0.9514)
[epoch : 3] (l_loss: 0.14784) (t_loss: 0.14193) (accu: 0.9565)
[epoch : 4] (l_loss: 0.12556) (t_loss: 0.12988) (accu: 0.9599)
[epoch : 5] (l_loss: 0.11117) (t_loss: 0.12305) (accu: 0.9622)
[epoch : 6] (l_loss: 0.10101) (t_loss: 0.11784) (accu: 0.9637)
[epoch : 7] (l_loss: 0.09344) (t_loss: 0.11779) (accu: 0.9628)
[epoch : 8] (l_loss: 0.08714) (t_loss: 0.11269) (accu: 0.9667)
[epoch : 9] (l_loss: 0.08184) (t_loss: 0.11362) (accu: 0.9654)
[epoch : 10] (l_loss: 0.07769) (t_loss: 0.11171) (accu: 0.9649)
[epoch : 11] (l_loss: 0.07417) (t_loss: 0.10994) (accu: 0.9676)
[epoch : 12] (l_loss: 0.07091) (t_loss: 0.10854) (accu: 0.9675)
[epoch : 13] (l_loss: 0.06830) (t_loss: 0.11004) (accu: 0.9689)
[epoch : 14] (l_loss: 0.06579) (t_loss: 0.10961) (accu: 0.9675)
[epoch : 15] (l_loss: 0.06383) (t_loss: 0.10842) (accu: 0.9691)
[epoch : 16] (l_loss: 0.06185) (t_loss: 0.10827) (accu: 0.9694)
[epoch : 17] (l_loss: 0.06010) (t_loss: 0.11139) (accu: 0.9682)
[epoch : 18] (l_loss: 0.05849) (t_loss: 0.11040) (accu: 0.9692)
[epoch : 19] (l_loss: 0.05713) (t_loss: 0.11013) (accu: 0.9693)
[epoch : 20] (l_loss: 0.05526) (t_loss: 0.11148) (accu: 0.9699)
[epoch : 21] (l_loss: 0.05449) (t_loss: 0.11334) (accu: 0.9696)
[epoch : 22] (l_loss: 0.05290) (t_loss: 0.10995) (accu: 0.9699)
[epoch : 23] (l_loss: 0.05177) (t_loss: 0.11236) (accu: 0.9690)
[epoch : 24] (l_loss: 0.05106) (t_loss: 0.11307) (accu: 0.9701)
[epoch : 25] (l_loss: 0.04992) (t_loss: 0.11398) (accu: 0.9704)
[epoch : 26] (l_loss: 0.04926) (t_loss: 0.11578) (accu: 0.9699)
[epoch : 27] (l_loss: 0.04850) (t_loss: 0.11314) (accu: 0.9701)
[epoch : 28] (l_loss: 0.04775) (t_loss: 0.11550) (accu: 0.9697)
[epoch : 29] (l_loss: 0.04680) (t_loss: 0.11625) (accu: 0.9714)
[epoch : 30] (l_loss: 0.04602) (t_loss: 0.11622) (accu: 0.9701)
Finish! (Best accu: 0.9714) (Time taken(sec) : 381.58) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (56094 | 210106)         21.07
fc1.weight   :      235200 (49325 | 185875)         20.97
fc2.weight   :        30000 (6291 | 23709)          20.97
fcout.weight :          1000 (478 | 522)            47.80
------------------------------------------------------------
Learning start! [Prune_iter : (8/21), Remaining weight : 21.07 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.41897) (accu: 0.1049)
[epoch : 1] (l_loss: 0.68110) (t_loss: 0.24615) (accu: 0.9289)
[epoch : 2] (l_loss: 0.20211) (t_loss: 0.17511) (accu: 0.9476)
[epoch : 3] (l_loss: 0.15323) (t_loss: 0.15100) (accu: 0.9545)
[epoch : 4] (l_loss: 0.12961) (t_loss: 0.13872) (accu: 0.9571)
[epoch : 5] (l_loss: 0.11463) (t_loss: 0.13315) (accu: 0.9580)
[epoch : 6] (l_loss: 0.10397) (t_loss: 0.12603) (accu: 0.9624)
[epoch : 7] (l_loss: 0.09630) (t_loss: 0.12314) (accu: 0.9631)
[epoch : 8] (l_loss: 0.09033) (t_loss: 0.12103) (accu: 0.9637)
[epoch : 9] (l_loss: 0.08553) (t_loss: 0.11821) (accu: 0.9647)
[epoch : 10] (l_loss: 0.08161) (t_loss: 0.12058) (accu: 0.9649)
[epoch : 11] (l_loss: 0.07786) (t_loss: 0.11540) (accu: 0.9665)
[epoch : 12] (l_loss: 0.07509) (t_loss: 0.11458) (accu: 0.9673)
[epoch : 13] (l_loss: 0.07255) (t_loss: 0.11631) (accu: 0.9668)
[epoch : 14] (l_loss: 0.07011) (t_loss: 0.11365) (accu: 0.9674)
[epoch : 15] (l_loss: 0.06796) (t_loss: 0.11360) (accu: 0.9685)
[epoch : 16] (l_loss: 0.06625) (t_loss: 0.11180) (accu: 0.9687)
[epoch : 17] (l_loss: 0.06466) (t_loss: 0.11131) (accu: 0.9696)
[epoch : 18] (l_loss: 0.06289) (t_loss: 0.11551) (accu: 0.9681)
[epoch : 19] (l_loss: 0.06170) (t_loss: 0.11325) (accu: 0.9674)
[epoch : 20] (l_loss: 0.06007) (t_loss: 0.11236) (accu: 0.9686)
[epoch : 21] (l_loss: 0.05880) (t_loss: 0.11123) (accu: 0.9704)
[epoch : 22] (l_loss: 0.05780) (t_loss: 0.11081) (accu: 0.9690)
[epoch : 23] (l_loss: 0.05622) (t_loss: 0.11136) (accu: 0.9698)
[epoch : 24] (l_loss: 0.05528) (t_loss: 0.11571) (accu: 0.9682)
[epoch : 25] (l_loss: 0.05433) (t_loss: 0.11035) (accu: 0.9707)
[epoch : 26] (l_loss: 0.05309) (t_loss: 0.11144) (accu: 0.9700)
[epoch : 27] (l_loss: 0.05244) (t_loss: 0.11333) (accu: 0.9707)
[epoch : 28] (l_loss: 0.05162) (t_loss: 0.11319) (accu: 0.9717)
[epoch : 29] (l_loss: 0.05071) (t_loss: 0.10918) (accu: 0.9715)
[epoch : 30] (l_loss: 0.04970) (t_loss: 0.11087) (accu: 0.9717)
Finish! (Best accu: 0.9717) (Time taken(sec) : 381.81) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (44923 | 221277)         16.88
fc1.weight   :      235200 (39460 | 195740)         16.78
fc2.weight   :        30000 (5033 | 24967)          16.78
fcout.weight :          1000 (430 | 570)            43.00
------------------------------------------------------------
Learning start! [Prune_iter : (9/21), Remaining weight : 16.88 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.35948) (accu: 0.0930)
[epoch : 1] (l_loss: 0.68780) (t_loss: 0.24891) (accu: 0.9273)
[epoch : 2] (l_loss: 0.20608) (t_loss: 0.17728) (accu: 0.9470)
[epoch : 3] (l_loss: 0.15577) (t_loss: 0.15167) (accu: 0.9547)
[epoch : 4] (l_loss: 0.13094) (t_loss: 0.13683) (accu: 0.9602)
[epoch : 5] (l_loss: 0.11548) (t_loss: 0.13064) (accu: 0.9626)
[epoch : 6] (l_loss: 0.10472) (t_loss: 0.12282) (accu: 0.9647)
[epoch : 7] (l_loss: 0.09706) (t_loss: 0.12108) (accu: 0.9638)
[epoch : 8] (l_loss: 0.09064) (t_loss: 0.11891) (accu: 0.9657)
[epoch : 9] (l_loss: 0.08570) (t_loss: 0.11716) (accu: 0.9643)
[epoch : 10] (l_loss: 0.08166) (t_loss: 0.11505) (accu: 0.9668)
[epoch : 11] (l_loss: 0.07837) (t_loss: 0.11561) (accu: 0.9666)
[epoch : 12] (l_loss: 0.07520) (t_loss: 0.11488) (accu: 0.9666)
[epoch : 13] (l_loss: 0.07270) (t_loss: 0.11432) (accu: 0.9673)
[epoch : 14] (l_loss: 0.07056) (t_loss: 0.11310) (accu: 0.9683)
[epoch : 15] (l_loss: 0.06863) (t_loss: 0.11499) (accu: 0.9668)
[epoch : 16] (l_loss: 0.06675) (t_loss: 0.11571) (accu: 0.9667)
[epoch : 17] (l_loss: 0.06500) (t_loss: 0.11289) (accu: 0.9693)
[epoch : 18] (l_loss: 0.06368) (t_loss: 0.11402) (accu: 0.9686)
[epoch : 19] (l_loss: 0.06216) (t_loss: 0.11493) (accu: 0.9685)
[epoch : 20] (l_loss: 0.06107) (t_loss: 0.11402) (accu: 0.9689)
[epoch : 21] (l_loss: 0.05984) (t_loss: 0.11648) (accu: 0.9680)
[epoch : 22] (l_loss: 0.05874) (t_loss: 0.11439) (accu: 0.9683)
[epoch : 23] (l_loss: 0.05764) (t_loss: 0.11636) (accu: 0.9694)
[epoch : 24] (l_loss: 0.05711) (t_loss: 0.11709) (accu: 0.9681)
[epoch : 25] (l_loss: 0.05607) (t_loss: 0.11729) (accu: 0.9678)
[epoch : 26] (l_loss: 0.05525) (t_loss: 0.11803) (accu: 0.9670)
[epoch : 27] (l_loss: 0.05467) (t_loss: 0.11802) (accu: 0.9689)
[epoch : 28] (l_loss: 0.05391) (t_loss: 0.11616) (accu: 0.9692)
[epoch : 29] (l_loss: 0.05300) (t_loss: 0.12144) (accu: 0.9690)
[epoch : 30] (l_loss: 0.05238) (t_loss: 0.11919) (accu: 0.9690)
Finish! (Best accu: 0.9694) (Time taken(sec) : 388.38) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (35982 | 230218)         13.52
fc1.weight   :      235200 (31568 | 203632)         13.42
fc2.weight   :        30000 (4027 | 25973)          13.42
fcout.weight :          1000 (387 | 613)            38.70
------------------------------------------------------------
Learning start! [Prune_iter : (10/21), Remaining weight : 13.52 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32851) (accu: 0.1044)
[epoch : 1] (l_loss: 0.67324) (t_loss: 0.23717) (accu: 0.9299)
[epoch : 2] (l_loss: 0.19615) (t_loss: 0.17269) (accu: 0.9475)
[epoch : 3] (l_loss: 0.15100) (t_loss: 0.15145) (accu: 0.9549)
[epoch : 4] (l_loss: 0.12864) (t_loss: 0.13731) (accu: 0.9592)
[epoch : 5] (l_loss: 0.11456) (t_loss: 0.12950) (accu: 0.9610)
[epoch : 6] (l_loss: 0.10438) (t_loss: 0.12324) (accu: 0.9645)
[epoch : 7] (l_loss: 0.09676) (t_loss: 0.12111) (accu: 0.9649)
[epoch : 8] (l_loss: 0.09039) (t_loss: 0.11852) (accu: 0.9657)
[epoch : 9] (l_loss: 0.08565) (t_loss: 0.11673) (accu: 0.9665)
[epoch : 10] (l_loss: 0.08175) (t_loss: 0.11579) (accu: 0.9684)
[epoch : 11] (l_loss: 0.07812) (t_loss: 0.11510) (accu: 0.9675)
[epoch : 12] (l_loss: 0.07534) (t_loss: 0.11651) (accu: 0.9676)
[epoch : 13] (l_loss: 0.07308) (t_loss: 0.11522) (accu: 0.9669)
[epoch : 14] (l_loss: 0.07091) (t_loss: 0.11678) (accu: 0.9674)
[epoch : 15] (l_loss: 0.06904) (t_loss: 0.11454) (accu: 0.9671)
[epoch : 16] (l_loss: 0.06734) (t_loss: 0.11555) (accu: 0.9682)
[epoch : 17] (l_loss: 0.06602) (t_loss: 0.11355) (accu: 0.9675)
[epoch : 18] (l_loss: 0.06441) (t_loss: 0.11371) (accu: 0.9683)
[epoch : 19] (l_loss: 0.06351) (t_loss: 0.11502) (accu: 0.9678)
[epoch : 20] (l_loss: 0.06233) (t_loss: 0.11428) (accu: 0.9687)
[epoch : 21] (l_loss: 0.06146) (t_loss: 0.11474) (accu: 0.9686)
[epoch : 22] (l_loss: 0.06016) (t_loss: 0.11518) (accu: 0.9692)
[epoch : 23] (l_loss: 0.05946) (t_loss: 0.11574) (accu: 0.9680)
[epoch : 24] (l_loss: 0.05874) (t_loss: 0.11486) (accu: 0.9695)
[epoch : 25] (l_loss: 0.05779) (t_loss: 0.11545) (accu: 0.9683)
[epoch : 26] (l_loss: 0.05722) (t_loss: 0.11750) (accu: 0.9687)
[epoch : 27] (l_loss: 0.05637) (t_loss: 0.11836) (accu: 0.9692)
[epoch : 28] (l_loss: 0.05588) (t_loss: 0.11680) (accu: 0.9685)
[epoch : 29] (l_loss: 0.05528) (t_loss: 0.11871) (accu: 0.9684)
[epoch : 30] (l_loss: 0.05472) (t_loss: 0.11895) (accu: 0.9692)
Finish! (Best accu: 0.9695) (Time taken(sec) : 388.96) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (28824 | 237376)         10.83
fc1.weight   :      235200 (25254 | 209946)         10.74
fc2.weight   :        30000 (3221 | 26779)          10.74
fcout.weight :          1000 (349 | 651)            34.90
------------------------------------------------------------
Learning start! [Prune_iter : (11/21), Remaining weight : 10.83 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30953) (accu: 0.1122)
[epoch : 1] (l_loss: 0.71657) (t_loss: 0.24935) (accu: 0.9281)
[epoch : 2] (l_loss: 0.20513) (t_loss: 0.17498) (accu: 0.9476)
[epoch : 3] (l_loss: 0.15483) (t_loss: 0.14830) (accu: 0.9550)
[epoch : 4] (l_loss: 0.13080) (t_loss: 0.13429) (accu: 0.9582)
[epoch : 5] (l_loss: 0.11566) (t_loss: 0.12428) (accu: 0.9604)
[epoch : 6] (l_loss: 0.10543) (t_loss: 0.11978) (accu: 0.9617)
[epoch : 7] (l_loss: 0.09772) (t_loss: 0.11683) (accu: 0.9636)
[epoch : 8] (l_loss: 0.09219) (t_loss: 0.11565) (accu: 0.9629)
[epoch : 9] (l_loss: 0.08748) (t_loss: 0.11280) (accu: 0.9641)
[epoch : 10] (l_loss: 0.08433) (t_loss: 0.11490) (accu: 0.9638)
[epoch : 11] (l_loss: 0.08150) (t_loss: 0.11251) (accu: 0.9651)
[epoch : 12] (l_loss: 0.07894) (t_loss: 0.11245) (accu: 0.9650)
[epoch : 13] (l_loss: 0.07719) (t_loss: 0.11287) (accu: 0.9644)
[epoch : 14] (l_loss: 0.07534) (t_loss: 0.11187) (accu: 0.9662)
[epoch : 15] (l_loss: 0.07332) (t_loss: 0.11504) (accu: 0.9647)
[epoch : 16] (l_loss: 0.07222) (t_loss: 0.11194) (accu: 0.9661)
[epoch : 17] (l_loss: 0.07070) (t_loss: 0.11120) (accu: 0.9672)
[epoch : 18] (l_loss: 0.06977) (t_loss: 0.11160) (accu: 0.9677)
[epoch : 19] (l_loss: 0.06823) (t_loss: 0.11093) (accu: 0.9667)
[epoch : 20] (l_loss: 0.06744) (t_loss: 0.11117) (accu: 0.9671)
[epoch : 21] (l_loss: 0.06656) (t_loss: 0.11317) (accu: 0.9673)
[epoch : 22] (l_loss: 0.06578) (t_loss: 0.11502) (accu: 0.9667)
[epoch : 23] (l_loss: 0.06485) (t_loss: 0.11351) (accu: 0.9670)
[epoch : 24] (l_loss: 0.06413) (t_loss: 0.11538) (accu: 0.9663)
[epoch : 25] (l_loss: 0.06324) (t_loss: 0.11536) (accu: 0.9675)
[epoch : 26] (l_loss: 0.06294) (t_loss: 0.11370) (accu: 0.9671)
[epoch : 27] (l_loss: 0.06178) (t_loss: 0.11418) (accu: 0.9678)
[epoch : 28] (l_loss: 0.06126) (t_loss: 0.11355) (accu: 0.9675)
[epoch : 29] (l_loss: 0.06113) (t_loss: 0.11561) (accu: 0.9675)
[epoch : 30] (l_loss: 0.06029) (t_loss: 0.11484) (accu: 0.9681)
Finish! (Best accu: 0.9681) (Time taken(sec) : 386.86) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (23095 | 243105)          8.68
fc1.weight   :      235200 (20204 | 214996)          8.59
fc2.weight   :        30000 (2577 | 27423)           8.59
fcout.weight :          1000 (314 | 686)            31.40
------------------------------------------------------------
Learning start! [Prune_iter : (12/21), Remaining weight : 8.68 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.31280) (accu: 0.1037)
[epoch : 1] (l_loss: 0.71607) (t_loss: 0.23917) (accu: 0.9318)
[epoch : 2] (l_loss: 0.19777) (t_loss: 0.16560) (accu: 0.9513)
[epoch : 3] (l_loss: 0.15121) (t_loss: 0.14388) (accu: 0.9583)
[epoch : 4] (l_loss: 0.12921) (t_loss: 0.13336) (accu: 0.9601)
[epoch : 5] (l_loss: 0.11565) (t_loss: 0.12341) (accu: 0.9625)
[epoch : 6] (l_loss: 0.10582) (t_loss: 0.12022) (accu: 0.9640)
[epoch : 7] (l_loss: 0.09887) (t_loss: 0.11551) (accu: 0.9653)
[epoch : 8] (l_loss: 0.09372) (t_loss: 0.11363) (accu: 0.9667)
[epoch : 9] (l_loss: 0.08916) (t_loss: 0.11198) (accu: 0.9669)
[epoch : 10] (l_loss: 0.08568) (t_loss: 0.10958) (accu: 0.9669)
[epoch : 11] (l_loss: 0.08264) (t_loss: 0.10898) (accu: 0.9679)
[epoch : 12] (l_loss: 0.08004) (t_loss: 0.10952) (accu: 0.9680)
[epoch : 13] (l_loss: 0.07777) (t_loss: 0.10774) (accu: 0.9691)
[epoch : 14] (l_loss: 0.07581) (t_loss: 0.10991) (accu: 0.9676)
[epoch : 15] (l_loss: 0.07415) (t_loss: 0.10811) (accu: 0.9679)
[epoch : 16] (l_loss: 0.07247) (t_loss: 0.10832) (accu: 0.9675)
[epoch : 17] (l_loss: 0.07109) (t_loss: 0.10770) (accu: 0.9690)
[epoch : 18] (l_loss: 0.06982) (t_loss: 0.10821) (accu: 0.9686)
[epoch : 19] (l_loss: 0.06846) (t_loss: 0.10950) (accu: 0.9675)
[epoch : 20] (l_loss: 0.06761) (t_loss: 0.10888) (accu: 0.9683)
[epoch : 21] (l_loss: 0.06676) (t_loss: 0.10816) (accu: 0.9675)
[epoch : 22] (l_loss: 0.06543) (t_loss: 0.11033) (accu: 0.9684)
[epoch : 23] (l_loss: 0.06459) (t_loss: 0.11030) (accu: 0.9679)
[epoch : 24] (l_loss: 0.06394) (t_loss: 0.10933) (accu: 0.9684)
[epoch : 25] (l_loss: 0.06317) (t_loss: 0.10966) (accu: 0.9677)
[epoch : 26] (l_loss: 0.06248) (t_loss: 0.10977) (accu: 0.9687)
[epoch : 27] (l_loss: 0.06157) (t_loss: 0.11029) (accu: 0.9683)
[epoch : 28] (l_loss: 0.06124) (t_loss: 0.11110) (accu: 0.9683)
[epoch : 29] (l_loss: 0.06050) (t_loss: 0.11120) (accu: 0.9683)
[epoch : 30] (l_loss: 0.06023) (t_loss: 0.10930) (accu: 0.9679)
Finish! (Best accu: 0.9691) (Time taken(sec) : 387.75) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (18507 | 247693)          6.95
fc1.weight   :      235200 (16163 | 219037)          6.87
fc2.weight   :        30000 (2062 | 27938)           6.87
fcout.weight :          1000 (282 | 718)            28.20
------------------------------------------------------------
Learning start! [Prune_iter : (13/21), Remaining weight : 6.95 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.27865) (accu: 0.1199)
[epoch : 1] (l_loss: 0.72353) (t_loss: 0.25091) (accu: 0.9251)
[epoch : 2] (l_loss: 0.21157) (t_loss: 0.18099) (accu: 0.9443)
[epoch : 3] (l_loss: 0.16539) (t_loss: 0.15433) (accu: 0.9523)
[epoch : 4] (l_loss: 0.14381) (t_loss: 0.14313) (accu: 0.9558)
[epoch : 5] (l_loss: 0.12989) (t_loss: 0.13662) (accu: 0.9574)
[epoch : 6] (l_loss: 0.11929) (t_loss: 0.12880) (accu: 0.9600)
[epoch : 7] (l_loss: 0.11151) (t_loss: 0.12654) (accu: 0.9612)
[epoch : 8] (l_loss: 0.10510) (t_loss: 0.12285) (accu: 0.9609)
[epoch : 9] (l_loss: 0.09998) (t_loss: 0.11992) (accu: 0.9626)
[epoch : 10] (l_loss: 0.09601) (t_loss: 0.11837) (accu: 0.9629)
[epoch : 11] (l_loss: 0.09268) (t_loss: 0.11631) (accu: 0.9642)
[epoch : 12] (l_loss: 0.08975) (t_loss: 0.11619) (accu: 0.9649)
[epoch : 13] (l_loss: 0.08736) (t_loss: 0.11551) (accu: 0.9657)
[epoch : 14] (l_loss: 0.08531) (t_loss: 0.11410) (accu: 0.9658)
[epoch : 15] (l_loss: 0.08349) (t_loss: 0.11407) (accu: 0.9657)
[epoch : 16] (l_loss: 0.08189) (t_loss: 0.11480) (accu: 0.9661)
[epoch : 17] (l_loss: 0.08041) (t_loss: 0.11418) (accu: 0.9657)
[epoch : 18] (l_loss: 0.07914) (t_loss: 0.11511) (accu: 0.9652)
[epoch : 19] (l_loss: 0.07792) (t_loss: 0.11356) (accu: 0.9654)
[epoch : 20] (l_loss: 0.07717) (t_loss: 0.11312) (accu: 0.9674)
[epoch : 21] (l_loss: 0.07560) (t_loss: 0.11265) (accu: 0.9669)
[epoch : 22] (l_loss: 0.07497) (t_loss: 0.11588) (accu: 0.9655)
[epoch : 23] (l_loss: 0.07405) (t_loss: 0.11426) (accu: 0.9663)
[epoch : 24] (l_loss: 0.07326) (t_loss: 0.11436) (accu: 0.9671)
[epoch : 25] (l_loss: 0.07241) (t_loss: 0.11355) (accu: 0.9673)
[epoch : 26] (l_loss: 0.07161) (t_loss: 0.11299) (accu: 0.9679)
[epoch : 27] (l_loss: 0.07129) (t_loss: 0.11477) (accu: 0.9666)
[epoch : 28] (l_loss: 0.07027) (t_loss: 0.11374) (accu: 0.9680)
[epoch : 29] (l_loss: 0.06958) (t_loss: 0.11351) (accu: 0.9665)
[epoch : 30] (l_loss: 0.06949) (t_loss: 0.11342) (accu: 0.9670)
Finish! (Best accu: 0.9680) (Time taken(sec) : 388.57) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (14833 | 251367)          5.57
fc1.weight   :      235200 (12930 | 222270)          5.50
fc2.weight   :        30000 (1649 | 28351)           5.50
fcout.weight :          1000 (254 | 746)            25.40
------------------------------------------------------------
Learning start! [Prune_iter : (14/21), Remaining weight : 5.57 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30115) (accu: 0.0906)
[epoch : 1] (l_loss: 0.75096) (t_loss: 0.26440) (accu: 0.9223)
[epoch : 2] (l_loss: 0.22532) (t_loss: 0.19200) (accu: 0.9444)
[epoch : 3] (l_loss: 0.17525) (t_loss: 0.16522) (accu: 0.9509)
[epoch : 4] (l_loss: 0.14987) (t_loss: 0.14791) (accu: 0.9563)
[epoch : 5] (l_loss: 0.13405) (t_loss: 0.13849) (accu: 0.9593)
[epoch : 6] (l_loss: 0.12257) (t_loss: 0.13285) (accu: 0.9589)
[epoch : 7] (l_loss: 0.11488) (t_loss: 0.13087) (accu: 0.9593)
[epoch : 8] (l_loss: 0.10868) (t_loss: 0.12720) (accu: 0.9604)
[epoch : 9] (l_loss: 0.10379) (t_loss: 0.12503) (accu: 0.9605)
[epoch : 10] (l_loss: 0.09989) (t_loss: 0.12466) (accu: 0.9617)
[epoch : 11] (l_loss: 0.09684) (t_loss: 0.12365) (accu: 0.9628)
[epoch : 12] (l_loss: 0.09418) (t_loss: 0.12320) (accu: 0.9627)
[epoch : 13] (l_loss: 0.09179) (t_loss: 0.12214) (accu: 0.9634)
[epoch : 14] (l_loss: 0.09020) (t_loss: 0.12077) (accu: 0.9637)
[epoch : 15] (l_loss: 0.08804) (t_loss: 0.12115) (accu: 0.9640)
[epoch : 16] (l_loss: 0.08623) (t_loss: 0.12377) (accu: 0.9631)
[epoch : 17] (l_loss: 0.08504) (t_loss: 0.12100) (accu: 0.9636)
[epoch : 18] (l_loss: 0.08342) (t_loss: 0.12336) (accu: 0.9636)
[epoch : 19] (l_loss: 0.08216) (t_loss: 0.12099) (accu: 0.9644)
[epoch : 20] (l_loss: 0.08136) (t_loss: 0.12165) (accu: 0.9650)
[epoch : 21] (l_loss: 0.07999) (t_loss: 0.12365) (accu: 0.9635)
[epoch : 22] (l_loss: 0.07925) (t_loss: 0.12224) (accu: 0.9632)
[epoch : 23] (l_loss: 0.07853) (t_loss: 0.12093) (accu: 0.9650)
[epoch : 24] (l_loss: 0.07749) (t_loss: 0.12280) (accu: 0.9634)
[epoch : 25] (l_loss: 0.07678) (t_loss: 0.12290) (accu: 0.9648)
[epoch : 26] (l_loss: 0.07615) (t_loss: 0.12290) (accu: 0.9637)
[epoch : 27] (l_loss: 0.07562) (t_loss: 0.12207) (accu: 0.9640)
[epoch : 28] (l_loss: 0.07497) (t_loss: 0.12460) (accu: 0.9640)
[epoch : 29] (l_loss: 0.07424) (t_loss: 0.12399) (accu: 0.9651)
[epoch : 30] (l_loss: 0.07388) (t_loss: 0.12784) (accu: 0.9620)
Finish! (Best accu: 0.9651) (Time taken(sec) : 393.22) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (11892 | 254308)          4.47
fc1.weight   :      235200 (10344 | 224856)          4.40
fc2.weight   :        30000 (1319 | 28681)           4.40
fcout.weight :          1000 (229 | 771)            22.90
------------------------------------------------------------
Learning start! [Prune_iter : (15/21), Remaining weight : 4.47 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29343) (accu: 0.0904)
[epoch : 1] (l_loss: 0.73916) (t_loss: 0.25323) (accu: 0.9276)
[epoch : 2] (l_loss: 0.21342) (t_loss: 0.18285) (accu: 0.9434)
[epoch : 3] (l_loss: 0.16526) (t_loss: 0.15945) (accu: 0.9514)
[epoch : 4] (l_loss: 0.14306) (t_loss: 0.14791) (accu: 0.9542)
[epoch : 5] (l_loss: 0.13008) (t_loss: 0.14086) (accu: 0.9554)
[epoch : 6] (l_loss: 0.12159) (t_loss: 0.13684) (accu: 0.9569)
[epoch : 7] (l_loss: 0.11498) (t_loss: 0.13619) (accu: 0.9590)
[epoch : 8] (l_loss: 0.11051) (t_loss: 0.13334) (accu: 0.9597)
[epoch : 9] (l_loss: 0.10662) (t_loss: 0.13118) (accu: 0.9596)
[epoch : 10] (l_loss: 0.10353) (t_loss: 0.13171) (accu: 0.9605)
[epoch : 11] (l_loss: 0.10106) (t_loss: 0.12998) (accu: 0.9599)
[epoch : 12] (l_loss: 0.09866) (t_loss: 0.12916) (accu: 0.9605)
[epoch : 13] (l_loss: 0.09684) (t_loss: 0.13028) (accu: 0.9603)
[epoch : 14] (l_loss: 0.09512) (t_loss: 0.13189) (accu: 0.9605)
[epoch : 15] (l_loss: 0.09363) (t_loss: 0.12848) (accu: 0.9612)
[epoch : 16] (l_loss: 0.09215) (t_loss: 0.12813) (accu: 0.9614)
[epoch : 17] (l_loss: 0.09095) (t_loss: 0.12903) (accu: 0.9611)
[epoch : 18] (l_loss: 0.08993) (t_loss: 0.12775) (accu: 0.9618)
[epoch : 19] (l_loss: 0.08879) (t_loss: 0.12711) (accu: 0.9614)
[epoch : 20] (l_loss: 0.08814) (t_loss: 0.12831) (accu: 0.9612)
[epoch : 21] (l_loss: 0.08675) (t_loss: 0.12910) (accu: 0.9612)
[epoch : 22] (l_loss: 0.08643) (t_loss: 0.12975) (accu: 0.9618)
[epoch : 23] (l_loss: 0.08551) (t_loss: 0.12709) (accu: 0.9619)
[epoch : 24] (l_loss: 0.08490) (t_loss: 0.12712) (accu: 0.9628)
[epoch : 25] (l_loss: 0.08388) (t_loss: 0.12725) (accu: 0.9624)
[epoch : 26] (l_loss: 0.08327) (t_loss: 0.12651) (accu: 0.9634)
[epoch : 27] (l_loss: 0.08285) (t_loss: 0.12833) (accu: 0.9630)
[epoch : 28] (l_loss: 0.08209) (t_loss: 0.12911) (accu: 0.9629)
[epoch : 29] (l_loss: 0.08136) (t_loss: 0.12722) (accu: 0.9629)
[epoch : 30] (l_loss: 0.08095) (t_loss: 0.12762) (accu: 0.9624)
Finish! (Best accu: 0.9634) (Time taken(sec) : 398.67) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (9537 | 256663)          3.58
fc1.weight   :       235200 (8275 | 226925)          3.52
fc2.weight   :        30000 (1056 | 28944)           3.52
fcout.weight :          1000 (206 | 794)            20.60
------------------------------------------------------------
Learning start! [Prune_iter : (16/21), Remaining weight : 3.58 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29244) (accu: 0.0929)
[epoch : 1] (l_loss: 0.75056) (t_loss: 0.25479) (accu: 0.9253)
[epoch : 2] (l_loss: 0.21587) (t_loss: 0.18487) (accu: 0.9453)
[epoch : 3] (l_loss: 0.17018) (t_loss: 0.16302) (accu: 0.9512)
[epoch : 4] (l_loss: 0.14903) (t_loss: 0.15229) (accu: 0.9545)
[epoch : 5] (l_loss: 0.13647) (t_loss: 0.14498) (accu: 0.9573)
[epoch : 6] (l_loss: 0.12799) (t_loss: 0.14096) (accu: 0.9583)
[epoch : 7] (l_loss: 0.12172) (t_loss: 0.13941) (accu: 0.9591)
[epoch : 8] (l_loss: 0.11670) (t_loss: 0.13896) (accu: 0.9582)
[epoch : 9] (l_loss: 0.11275) (t_loss: 0.13410) (accu: 0.9594)
[epoch : 10] (l_loss: 0.10961) (t_loss: 0.13439) (accu: 0.9592)
[epoch : 11] (l_loss: 0.10733) (t_loss: 0.13233) (accu: 0.9609)
[epoch : 12] (l_loss: 0.10442) (t_loss: 0.13173) (accu: 0.9609)
[epoch : 13] (l_loss: 0.10277) (t_loss: 0.13227) (accu: 0.9606)
[epoch : 14] (l_loss: 0.10085) (t_loss: 0.13245) (accu: 0.9610)
[epoch : 15] (l_loss: 0.09954) (t_loss: 0.13076) (accu: 0.9616)
[epoch : 16] (l_loss: 0.09768) (t_loss: 0.13030) (accu: 0.9610)
[epoch : 17] (l_loss: 0.09666) (t_loss: 0.12922) (accu: 0.9613)
[epoch : 18] (l_loss: 0.09582) (t_loss: 0.12994) (accu: 0.9627)
[epoch : 19] (l_loss: 0.09453) (t_loss: 0.13007) (accu: 0.9607)
[epoch : 20] (l_loss: 0.09367) (t_loss: 0.13004) (accu: 0.9626)
[epoch : 21] (l_loss: 0.09312) (t_loss: 0.12926) (accu: 0.9613)
[epoch : 22] (l_loss: 0.09206) (t_loss: 0.12895) (accu: 0.9618)
[epoch : 23] (l_loss: 0.09136) (t_loss: 0.12906) (accu: 0.9616)
[epoch : 24] (l_loss: 0.09094) (t_loss: 0.12670) (accu: 0.9623)
[epoch : 25] (l_loss: 0.08995) (t_loss: 0.13063) (accu: 0.9622)
[epoch : 26] (l_loss: 0.08905) (t_loss: 0.13042) (accu: 0.9623)
[epoch : 27] (l_loss: 0.08878) (t_loss: 0.12925) (accu: 0.9620)
[epoch : 28] (l_loss: 0.08847) (t_loss: 0.12845) (accu: 0.9626)
[epoch : 29] (l_loss: 0.08757) (t_loss: 0.12789) (accu: 0.9619)
[epoch : 30] (l_loss: 0.08698) (t_loss: 0.12944) (accu: 0.9618)
Finish! (Best accu: 0.9627) (Time taken(sec) : 391.53) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (7649 | 258551)          2.87
fc1.weight   :       235200 (6620 | 228580)          2.81
fc2.weight   :        30000 (844 | 29156)            2.81
fcout.weight :          1000 (185 | 815)            18.50
------------------------------------------------------------
Learning start! [Prune_iter : (17/21), Remaining weight : 2.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30557) (accu: 0.0929)
[epoch : 1] (l_loss: 0.76367) (t_loss: 0.24456) (accu: 0.9293)
[epoch : 2] (l_loss: 0.21120) (t_loss: 0.18358) (accu: 0.9450)
[epoch : 3] (l_loss: 0.16883) (t_loss: 0.16432) (accu: 0.9508)
[epoch : 4] (l_loss: 0.14987) (t_loss: 0.15210) (accu: 0.9540)
[epoch : 5] (l_loss: 0.13816) (t_loss: 0.14651) (accu: 0.9562)
[epoch : 6] (l_loss: 0.13017) (t_loss: 0.14046) (accu: 0.9570)
[epoch : 7] (l_loss: 0.12445) (t_loss: 0.13873) (accu: 0.9575)
[epoch : 8] (l_loss: 0.11952) (t_loss: 0.13682) (accu: 0.9576)
[epoch : 9] (l_loss: 0.11635) (t_loss: 0.13584) (accu: 0.9588)
[epoch : 10] (l_loss: 0.11337) (t_loss: 0.13426) (accu: 0.9585)
[epoch : 11] (l_loss: 0.11094) (t_loss: 0.13388) (accu: 0.9586)
[epoch : 12] (l_loss: 0.10860) (t_loss: 0.13085) (accu: 0.9593)
[epoch : 13] (l_loss: 0.10670) (t_loss: 0.12995) (accu: 0.9603)
[epoch : 14] (l_loss: 0.10500) (t_loss: 0.13097) (accu: 0.9598)
[epoch : 15] (l_loss: 0.10353) (t_loss: 0.12911) (accu: 0.9597)
[epoch : 16] (l_loss: 0.10208) (t_loss: 0.12864) (accu: 0.9602)
[epoch : 17] (l_loss: 0.10100) (t_loss: 0.12949) (accu: 0.9594)
[epoch : 18] (l_loss: 0.09953) (t_loss: 0.12985) (accu: 0.9600)
[epoch : 19] (l_loss: 0.09861) (t_loss: 0.12772) (accu: 0.9605)
[epoch : 20] (l_loss: 0.09799) (t_loss: 0.12863) (accu: 0.9601)
[epoch : 21] (l_loss: 0.09692) (t_loss: 0.13028) (accu: 0.9585)
[epoch : 22] (l_loss: 0.09629) (t_loss: 0.12894) (accu: 0.9602)
[epoch : 23] (l_loss: 0.09523) (t_loss: 0.12737) (accu: 0.9602)
[epoch : 24] (l_loss: 0.09454) (t_loss: 0.12817) (accu: 0.9601)
[epoch : 25] (l_loss: 0.09423) (t_loss: 0.12713) (accu: 0.9612)
[epoch : 26] (l_loss: 0.09351) (t_loss: 0.12935) (accu: 0.9610)
[epoch : 27] (l_loss: 0.09277) (t_loss: 0.12843) (accu: 0.9598)
[epoch : 28] (l_loss: 0.09261) (t_loss: 0.12696) (accu: 0.9610)
[epoch : 29] (l_loss: 0.09201) (t_loss: 0.12810) (accu: 0.9604)
[epoch : 30] (l_loss: 0.09135) (t_loss: 0.12903) (accu: 0.9592)
Finish! (Best accu: 0.9612) (Time taken(sec) : 388.33) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (6139 | 260061)          2.31
fc1.weight   :       235200 (5296 | 229904)          2.25
fc2.weight   :        30000 (676 | 29324)            2.25
fcout.weight :          1000 (167 | 833)            16.70
------------------------------------------------------------
Learning start! [Prune_iter : (18/21), Remaining weight : 2.31 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29385) (accu: 0.0902)
[epoch : 1] (l_loss: 0.75450) (t_loss: 0.24527) (accu: 0.9306)
[epoch : 2] (l_loss: 0.21463) (t_loss: 0.18126) (accu: 0.9466)
[epoch : 3] (l_loss: 0.17117) (t_loss: 0.16203) (accu: 0.9516)
[epoch : 4] (l_loss: 0.15162) (t_loss: 0.15056) (accu: 0.9543)
[epoch : 5] (l_loss: 0.14028) (t_loss: 0.14799) (accu: 0.9544)
[epoch : 6] (l_loss: 0.13302) (t_loss: 0.14337) (accu: 0.9563)
[epoch : 7] (l_loss: 0.12708) (t_loss: 0.14250) (accu: 0.9565)
[epoch : 8] (l_loss: 0.12264) (t_loss: 0.14217) (accu: 0.9573)
[epoch : 9] (l_loss: 0.11922) (t_loss: 0.14081) (accu: 0.9578)
[epoch : 10] (l_loss: 0.11664) (t_loss: 0.13735) (accu: 0.9583)
[epoch : 11] (l_loss: 0.11397) (t_loss: 0.13757) (accu: 0.9591)
[epoch : 12] (l_loss: 0.11199) (t_loss: 0.13770) (accu: 0.9583)
[epoch : 13] (l_loss: 0.11016) (t_loss: 0.13643) (accu: 0.9596)
[epoch : 14] (l_loss: 0.10866) (t_loss: 0.13790) (accu: 0.9595)
[epoch : 15] (l_loss: 0.10748) (t_loss: 0.13779) (accu: 0.9579)
[epoch : 16] (l_loss: 0.10620) (t_loss: 0.13619) (accu: 0.9581)
[epoch : 17] (l_loss: 0.10494) (t_loss: 0.13569) (accu: 0.9589)
[epoch : 18] (l_loss: 0.10401) (t_loss: 0.13831) (accu: 0.9596)
[epoch : 19] (l_loss: 0.10283) (t_loss: 0.13900) (accu: 0.9593)
[epoch : 20] (l_loss: 0.10208) (t_loss: 0.13722) (accu: 0.9594)
[epoch : 21] (l_loss: 0.10129) (t_loss: 0.13734) (accu: 0.9591)
[epoch : 22] (l_loss: 0.10078) (t_loss: 0.13577) (accu: 0.9597)
[epoch : 23] (l_loss: 0.09962) (t_loss: 0.13780) (accu: 0.9583)
[epoch : 24] (l_loss: 0.09933) (t_loss: 0.13636) (accu: 0.9597)
[epoch : 25] (l_loss: 0.09862) (t_loss: 0.13711) (accu: 0.9604)
[epoch : 26] (l_loss: 0.09814) (t_loss: 0.13524) (accu: 0.9600)
[epoch : 27] (l_loss: 0.09796) (t_loss: 0.13414) (accu: 0.9592)
[epoch : 28] (l_loss: 0.09712) (t_loss: 0.13561) (accu: 0.9586)
[epoch : 29] (l_loss: 0.09680) (t_loss: 0.13756) (accu: 0.9585)
[epoch : 30] (l_loss: 0.09632) (t_loss: 0.13817) (accu: 0.9592)
Finish! (Best accu: 0.9604) (Time taken(sec) : 393.38) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (4927 | 261273)          1.85
fc1.weight   :       235200 (4237 | 230963)          1.80
fc2.weight   :        30000 (540 | 29460)            1.80
fcout.weight :          1000 (150 | 850)            15.00
------------------------------------------------------------
Learning start! [Prune_iter : (19/21), Remaining weight : 1.85 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.28838) (accu: 0.0947)
[epoch : 1] (l_loss: 0.75943) (t_loss: 0.25151) (accu: 0.9267)
[epoch : 2] (l_loss: 0.21964) (t_loss: 0.18811) (accu: 0.9440)
[epoch : 3] (l_loss: 0.17803) (t_loss: 0.16974) (accu: 0.9497)
[epoch : 4] (l_loss: 0.15840) (t_loss: 0.15758) (accu: 0.9527)
[epoch : 5] (l_loss: 0.14701) (t_loss: 0.15078) (accu: 0.9530)
[epoch : 6] (l_loss: 0.13904) (t_loss: 0.14689) (accu: 0.9555)
[epoch : 7] (l_loss: 0.13369) (t_loss: 0.14562) (accu: 0.9549)
[epoch : 8] (l_loss: 0.12989) (t_loss: 0.14266) (accu: 0.9571)
[epoch : 9] (l_loss: 0.12590) (t_loss: 0.14355) (accu: 0.9570)
[epoch : 10] (l_loss: 0.12344) (t_loss: 0.14069) (accu: 0.9578)
[epoch : 11] (l_loss: 0.12106) (t_loss: 0.14009) (accu: 0.9579)
[epoch : 12] (l_loss: 0.11889) (t_loss: 0.13879) (accu: 0.9578)
[epoch : 13] (l_loss: 0.11708) (t_loss: 0.13757) (accu: 0.9592)
[epoch : 14] (l_loss: 0.11558) (t_loss: 0.13766) (accu: 0.9577)
[epoch : 15] (l_loss: 0.11407) (t_loss: 0.13816) (accu: 0.9599)
[epoch : 16] (l_loss: 0.11319) (t_loss: 0.13757) (accu: 0.9588)
[epoch : 17] (l_loss: 0.11210) (t_loss: 0.13939) (accu: 0.9572)
[epoch : 18] (l_loss: 0.11125) (t_loss: 0.13596) (accu: 0.9594)
[epoch : 19] (l_loss: 0.10996) (t_loss: 0.13582) (accu: 0.9599)
[epoch : 20] (l_loss: 0.10906) (t_loss: 0.13544) (accu: 0.9601)
[epoch : 21] (l_loss: 0.10857) (t_loss: 0.13575) (accu: 0.9586)
[epoch : 22] (l_loss: 0.10779) (t_loss: 0.13710) (accu: 0.9576)
[epoch : 23] (l_loss: 0.10713) (t_loss: 0.13634) (accu: 0.9581)
[epoch : 24] (l_loss: 0.10677) (t_loss: 0.13546) (accu: 0.9589)
[epoch : 25] (l_loss: 0.10649) (t_loss: 0.13527) (accu: 0.9576)
[epoch : 26] (l_loss: 0.10554) (t_loss: 0.13353) (accu: 0.9588)
[epoch : 27] (l_loss: 0.10509) (t_loss: 0.13514) (accu: 0.9598)
[epoch : 28] (l_loss: 0.10465) (t_loss: 0.13472) (accu: 0.9588)
[epoch : 29] (l_loss: 0.10432) (t_loss: 0.13454) (accu: 0.9596)
[epoch : 30] (l_loss: 0.10386) (t_loss: 0.13960) (accu: 0.9570)
Finish! (Best accu: 0.9601) (Time taken(sec) : 391.87) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3957 | 262243)          1.49
fc1.weight   :       235200 (3390 | 231810)          1.44
fc2.weight   :        30000 (432 | 29568)            1.44
fcout.weight :          1000 (135 | 865)            13.50
------------------------------------------------------------
Learning start! [Prune_iter : (20/21), Remaining weight : 1.49 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.28753) (accu: 0.1486)
[epoch : 1] (l_loss: 0.78603) (t_loss: 0.26037) (accu: 0.9250)
[epoch : 2] (l_loss: 0.22325) (t_loss: 0.19135) (accu: 0.9437)
[epoch : 3] (l_loss: 0.17958) (t_loss: 0.17287) (accu: 0.9471)
[epoch : 4] (l_loss: 0.16134) (t_loss: 0.16127) (accu: 0.9522)
[epoch : 5] (l_loss: 0.15047) (t_loss: 0.15523) (accu: 0.9524)
[epoch : 6] (l_loss: 0.14336) (t_loss: 0.15201) (accu: 0.9535)
[epoch : 7] (l_loss: 0.13783) (t_loss: 0.14853) (accu: 0.9530)
[epoch : 8] (l_loss: 0.13365) (t_loss: 0.14828) (accu: 0.9532)
[epoch : 9] (l_loss: 0.13028) (t_loss: 0.15037) (accu: 0.9544)
[epoch : 10] (l_loss: 0.12782) (t_loss: 0.14607) (accu: 0.9551)
[epoch : 11] (l_loss: 0.12575) (t_loss: 0.14535) (accu: 0.9557)
[epoch : 12] (l_loss: 0.12373) (t_loss: 0.14660) (accu: 0.9556)
[epoch : 13] (l_loss: 0.12256) (t_loss: 0.14653) (accu: 0.9550)
[epoch : 14] (l_loss: 0.12118) (t_loss: 0.14482) (accu: 0.9561)
[epoch : 15] (l_loss: 0.12012) (t_loss: 0.14292) (accu: 0.9559)
[epoch : 16] (l_loss: 0.11876) (t_loss: 0.14494) (accu: 0.9565)
[epoch : 17] (l_loss: 0.11791) (t_loss: 0.14255) (accu: 0.9570)
[epoch : 18] (l_loss: 0.11678) (t_loss: 0.14271) (accu: 0.9564)
[epoch : 19] (l_loss: 0.11632) (t_loss: 0.14343) (accu: 0.9565)
[epoch : 20] (l_loss: 0.11517) (t_loss: 0.14375) (accu: 0.9574)
[epoch : 21] (l_loss: 0.11475) (t_loss: 0.14441) (accu: 0.9572)
[epoch : 22] (l_loss: 0.11418) (t_loss: 0.14475) (accu: 0.9573)
[epoch : 23] (l_loss: 0.11340) (t_loss: 0.14220) (accu: 0.9580)
[epoch : 24] (l_loss: 0.11267) (t_loss: 0.14212) (accu: 0.9573)
[epoch : 25] (l_loss: 0.11221) (t_loss: 0.14308) (accu: 0.9556)
[epoch : 26] (l_loss: 0.11177) (t_loss: 0.14286) (accu: 0.9575)
[epoch : 27] (l_loss: 0.11121) (t_loss: 0.14062) (accu: 0.9579)
[epoch : 28] (l_loss: 0.11089) (t_loss: 0.14365) (accu: 0.9561)
[epoch : 29] (l_loss: 0.11064) (t_loss: 0.14075) (accu: 0.9576)
[epoch : 30] (l_loss: 0.11017) (t_loss: 0.14185) (accu: 0.9570)
Finish! (Best accu: 0.9580) (Time taken(sec) : 380.37) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3180 | 263020)          1.19
fc1.weight   :       235200 (2712 | 232488)          1.15
fc2.weight   :        30000 (346 | 29654)            1.15
fcout.weight :          1000 (122 | 878)            12.20
------------------------------------------------------------
Learning start! [Prune_iter : (21/21), Remaining weight : 1.19 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29301) (accu: 0.1377)
[epoch : 1] (l_loss: 0.81091) (t_loss: 0.28221) (accu: 0.9165)
[epoch : 2] (l_loss: 0.24412) (t_loss: 0.21275) (accu: 0.9341)
[epoch : 3] (l_loss: 0.19779) (t_loss: 0.18706) (accu: 0.9433)
[epoch : 4] (l_loss: 0.17640) (t_loss: 0.17508) (accu: 0.9453)
[epoch : 5] (l_loss: 0.16409) (t_loss: 0.16932) (accu: 0.9490)
[epoch : 6] (l_loss: 0.15611) (t_loss: 0.16221) (accu: 0.9501)
[epoch : 7] (l_loss: 0.15044) (t_loss: 0.16165) (accu: 0.9501)
[epoch : 8] (l_loss: 0.14646) (t_loss: 0.16082) (accu: 0.9515)
[epoch : 9] (l_loss: 0.14329) (t_loss: 0.15906) (accu: 0.9511)
[epoch : 10] (l_loss: 0.14068) (t_loss: 0.15792) (accu: 0.9520)
[epoch : 11] (l_loss: 0.13829) (t_loss: 0.15814) (accu: 0.9525)
[epoch : 12] (l_loss: 0.13637) (t_loss: 0.15433) (accu: 0.9532)
[epoch : 13] (l_loss: 0.13484) (t_loss: 0.15655) (accu: 0.9517)
[epoch : 14] (l_loss: 0.13320) (t_loss: 0.15405) (accu: 0.9543)
[epoch : 15] (l_loss: 0.13246) (t_loss: 0.15624) (accu: 0.9533)
[epoch : 16] (l_loss: 0.13108) (t_loss: 0.15591) (accu: 0.9520)
[epoch : 17] (l_loss: 0.13001) (t_loss: 0.15652) (accu: 0.9532)
[epoch : 18] (l_loss: 0.12944) (t_loss: 0.15585) (accu: 0.9533)
[epoch : 19] (l_loss: 0.12866) (t_loss: 0.15407) (accu: 0.9541)
[epoch : 20] (l_loss: 0.12772) (t_loss: 0.15471) (accu: 0.9526)
[epoch : 21] (l_loss: 0.12734) (t_loss: 0.15508) (accu: 0.9538)
[epoch : 22] (l_loss: 0.12657) (t_loss: 0.15446) (accu: 0.9542)
[epoch : 23] (l_loss: 0.12610) (t_loss: 0.15463) (accu: 0.9538)
[epoch : 24] (l_loss: 0.12575) (t_loss: 0.15432) (accu: 0.9536)
[epoch : 25] (l_loss: 0.12511) (t_loss: 0.15538) (accu: 0.9541)
[epoch : 26] (l_loss: 0.12468) (t_loss: 0.15573) (accu: 0.9533)
[epoch : 27] (l_loss: 0.12422) (t_loss: 0.15351) (accu: 0.9539)
[epoch : 28] (l_loss: 0.12354) (t_loss: 0.15414) (accu: 0.9532)
[epoch : 29] (l_loss: 0.12328) (t_loss: 0.15312) (accu: 0.9544)
[epoch : 30] (l_loss: 0.12317) (t_loss: 0.15462) (accu: 0.9534)
Finish! (Best accu: 0.9544) (Time taken(sec) : 403.65) 


Maximum accuracy per weight remaining
Remaining weight 100.0 %  Epoch 26 Accu 0.9709
Remaining weight 80.04 %  Epoch 20 Accu 0.9711
Remaining weight 64.06 %  Epoch 27 Accu 0.9706
Remaining weight 51.28 %  Epoch 27 Accu 0.9715
Remaining weight 41.05 %  Epoch 27 Accu 0.9706
Remaining weight 32.87 %  Epoch 29 Accu 0.9720
Remaining weight 26.32 %  Epoch 28 Accu 0.9714
Remaining weight 21.07 %  Epoch 29 Accu 0.9717
Remaining weight 16.88 %  Epoch 22 Accu 0.9694
Remaining weight 13.52 %  Epoch 23 Accu 0.9695
Remaining weight 10.83 %  Epoch 29 Accu 0.9681
Remaining weight 8.68 %  Epoch 12 Accu 0.9691
Remaining weight 6.95 %  Epoch 27 Accu 0.9680
Remaining weight 5.57 %  Epoch 28 Accu 0.9651
Remaining weight 4.47 %  Epoch 25 Accu 0.9634
Remaining weight 3.58 %  Epoch 17 Accu 0.9627
Remaining weight 2.87 %  Epoch 24 Accu 0.9612
Remaining weight 2.31 %  Epoch 24 Accu 0.9604
Remaining weight 1.85 %  Epoch 19 Accu 0.9601
Remaining weight 1.49 %  Epoch 22 Accu 0.9580
Remaining weight 1.19 %  Epoch 28 Accu 0.9544
===================================================================== 

Test_Iter (3/5)
------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :        266200 (266200 | 0)          100.00
fc1.weight   :        235200 (235200 | 0)          100.00
fc2.weight   :         30000 (30000 | 0)           100.00
fcout.weight :          1000 (1000 | 0)            100.00
------------------------------------------------------------
Learning start! [Prune_iter : (1/21), Remaining weight : 100.0 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69095) (accu: 0.0912)
[epoch : 1] (l_loss: 0.98184) (t_loss: 0.37944) (accu: 0.8840)
[epoch : 2] (l_loss: 0.32348) (t_loss: 0.24479) (accu: 0.9250)
[epoch : 3] (l_loss: 0.23797) (t_loss: 0.20418) (accu: 0.9374)
[epoch : 4] (l_loss: 0.20223) (t_loss: 0.18542) (accu: 0.9438)
[epoch : 5] (l_loss: 0.18131) (t_loss: 0.17528) (accu: 0.9458)
[epoch : 6] (l_loss: 0.16789) (t_loss: 0.16901) (accu: 0.9479)
[epoch : 7] (l_loss: 0.15816) (t_loss: 0.16501) (accu: 0.9486)
[epoch : 8] (l_loss: 0.15126) (t_loss: 0.16012) (accu: 0.9519)
[epoch : 9] (l_loss: 0.14593) (t_loss: 0.15886) (accu: 0.9519)
[epoch : 10] (l_loss: 0.14122) (t_loss: 0.15761) (accu: 0.9536)
[epoch : 11] (l_loss: 0.13762) (t_loss: 0.15547) (accu: 0.9539)
[epoch : 12] (l_loss: 0.13410) (t_loss: 0.15485) (accu: 0.9548)
[epoch : 13] (l_loss: 0.13094) (t_loss: 0.15347) (accu: 0.9560)
[epoch : 14] (l_loss: 0.12854) (t_loss: 0.15314) (accu: 0.9561)
[epoch : 15] (l_loss: 0.12615) (t_loss: 0.15137) (accu: 0.9577)
[epoch : 16] (l_loss: 0.12419) (t_loss: 0.15154) (accu: 0.9562)
[epoch : 17] (l_loss: 0.12237) (t_loss: 0.15123) (accu: 0.9576)
[epoch : 18] (l_loss: 0.12118) (t_loss: 0.15098) (accu: 0.9587)
[epoch : 19] (l_loss: 0.11947) (t_loss: 0.14978) (accu: 0.9581)
[epoch : 20] (l_loss: 0.11839) (t_loss: 0.14782) (accu: 0.9582)
[epoch : 21] (l_loss: 0.11696) (t_loss: 0.14886) (accu: 0.9584)
[epoch : 22] (l_loss: 0.11606) (t_loss: 0.14838) (accu: 0.9575)
[epoch : 23] (l_loss: 0.11492) (t_loss: 0.14780) (accu: 0.9580)
[epoch : 24] (l_loss: 0.11395) (t_loss: 0.14783) (accu: 0.9588)
[epoch : 25] (l_loss: 0.11281) (t_loss: 0.14835) (accu: 0.9578)
[epoch : 26] (l_loss: 0.11227) (t_loss: 0.14785) (accu: 0.9589)
[epoch : 27] (l_loss: 0.11116) (t_loss: 0.14791) (accu: 0.9586)
[epoch : 28] (l_loss: 0.11038) (t_loss: 0.14609) (accu: 0.9597)
[epoch : 29] (l_loss: 0.10990) (t_loss: 0.14674) (accu: 0.9589)
[epoch : 30] (l_loss: 0.10926) (t_loss: 0.14650) (accu: 0.9591)
Finish! (Best accu: 0.9597) (Time taken(sec) : 398.98) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (213060 | 53140)         80.04
fc1.weight   :      235200 (188160 | 47040)         80.00
fc2.weight   :        30000 (24000 | 6000)          80.00
fcout.weight :          1000 (900 | 100)            90.00
------------------------------------------------------------
Learning start! [Prune_iter : (2/21), Remaining weight : 80.04 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69645) (accu: 0.0900)
[epoch : 1] (l_loss: 0.99386) (t_loss: 0.38324) (accu: 0.8845)
[epoch : 2] (l_loss: 0.32266) (t_loss: 0.24553) (accu: 0.9254)
[epoch : 3] (l_loss: 0.23761) (t_loss: 0.20688) (accu: 0.9360)
[epoch : 4] (l_loss: 0.20253) (t_loss: 0.18738) (accu: 0.9416)
[epoch : 5] (l_loss: 0.18247) (t_loss: 0.17702) (accu: 0.9456)
[epoch : 6] (l_loss: 0.16934) (t_loss: 0.17156) (accu: 0.9486)
[epoch : 7] (l_loss: 0.15992) (t_loss: 0.16583) (accu: 0.9503)
[epoch : 8] (l_loss: 0.15241) (t_loss: 0.16269) (accu: 0.9518)
[epoch : 9] (l_loss: 0.14635) (t_loss: 0.15991) (accu: 0.9524)
[epoch : 10] (l_loss: 0.14184) (t_loss: 0.15891) (accu: 0.9538)
[epoch : 11] (l_loss: 0.13757) (t_loss: 0.15616) (accu: 0.9554)
[epoch : 12] (l_loss: 0.13445) (t_loss: 0.15479) (accu: 0.9559)
[epoch : 13] (l_loss: 0.13125) (t_loss: 0.15437) (accu: 0.9560)
[epoch : 14] (l_loss: 0.12871) (t_loss: 0.15725) (accu: 0.9554)
[epoch : 15] (l_loss: 0.12663) (t_loss: 0.15235) (accu: 0.9558)
[epoch : 16] (l_loss: 0.12442) (t_loss: 0.15109) (accu: 0.9579)
[epoch : 17] (l_loss: 0.12268) (t_loss: 0.15117) (accu: 0.9579)
[epoch : 18] (l_loss: 0.12120) (t_loss: 0.14961) (accu: 0.9575)
[epoch : 19] (l_loss: 0.11948) (t_loss: 0.14869) (accu: 0.9582)
[epoch : 20] (l_loss: 0.11853) (t_loss: 0.14845) (accu: 0.9573)
[epoch : 21] (l_loss: 0.11717) (t_loss: 0.14761) (accu: 0.9581)
[epoch : 22] (l_loss: 0.11610) (t_loss: 0.14883) (accu: 0.9589)
[epoch : 23] (l_loss: 0.11526) (t_loss: 0.14903) (accu: 0.9598)
[epoch : 24] (l_loss: 0.11432) (t_loss: 0.14742) (accu: 0.9590)
[epoch : 25] (l_loss: 0.11339) (t_loss: 0.14769) (accu: 0.9586)
[epoch : 26] (l_loss: 0.11246) (t_loss: 0.14706) (accu: 0.9586)
[epoch : 27] (l_loss: 0.11176) (t_loss: 0.14687) (accu: 0.9585)
[epoch : 28] (l_loss: 0.11086) (t_loss: 0.14711) (accu: 0.9595)
[epoch : 29] (l_loss: 0.11029) (t_loss: 0.14787) (accu: 0.9584)
[epoch : 30] (l_loss: 0.10947) (t_loss: 0.14638) (accu: 0.9592)
Finish! (Best accu: 0.9598) (Time taken(sec) : 406.43) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (170538 | 95662)         64.06
fc1.weight   :      235200 (150528 | 84672)         64.00
fc2.weight   :       30000 (19200 | 10800)          64.00
fcout.weight :          1000 (810 | 190)            81.00
------------------------------------------------------------
Learning start! [Prune_iter : (3/21), Remaining weight : 64.06 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.66787) (accu: 0.1002)
[epoch : 1] (l_loss: 0.98942) (t_loss: 0.38413) (accu: 0.8843)
[epoch : 2] (l_loss: 0.32012) (t_loss: 0.24783) (accu: 0.9256)
[epoch : 3] (l_loss: 0.23636) (t_loss: 0.20823) (accu: 0.9370)
[epoch : 4] (l_loss: 0.20075) (t_loss: 0.18882) (accu: 0.9427)
[epoch : 5] (l_loss: 0.18047) (t_loss: 0.17668) (accu: 0.9466)
[epoch : 6] (l_loss: 0.16673) (t_loss: 0.16955) (accu: 0.9496)
[epoch : 7] (l_loss: 0.15704) (t_loss: 0.16284) (accu: 0.9501)
[epoch : 8] (l_loss: 0.15014) (t_loss: 0.16046) (accu: 0.9518)
[epoch : 9] (l_loss: 0.14450) (t_loss: 0.15779) (accu: 0.9529)
[epoch : 10] (l_loss: 0.13956) (t_loss: 0.15844) (accu: 0.9536)
[epoch : 11] (l_loss: 0.13617) (t_loss: 0.15289) (accu: 0.9558)
[epoch : 12] (l_loss: 0.13262) (t_loss: 0.15171) (accu: 0.9555)
[epoch : 13] (l_loss: 0.12968) (t_loss: 0.15311) (accu: 0.9558)
[epoch : 14] (l_loss: 0.12720) (t_loss: 0.14998) (accu: 0.9553)
[epoch : 15] (l_loss: 0.12516) (t_loss: 0.14881) (accu: 0.9572)
[epoch : 16] (l_loss: 0.12323) (t_loss: 0.14797) (accu: 0.9573)
[epoch : 17] (l_loss: 0.12144) (t_loss: 0.14742) (accu: 0.9577)
[epoch : 18] (l_loss: 0.11959) (t_loss: 0.14828) (accu: 0.9574)
[epoch : 19] (l_loss: 0.11848) (t_loss: 0.14842) (accu: 0.9582)
[epoch : 20] (l_loss: 0.11693) (t_loss: 0.14740) (accu: 0.9578)
[epoch : 21] (l_loss: 0.11571) (t_loss: 0.14747) (accu: 0.9576)
[epoch : 22] (l_loss: 0.11461) (t_loss: 0.14546) (accu: 0.9583)
[epoch : 23] (l_loss: 0.11364) (t_loss: 0.14738) (accu: 0.9575)
[epoch : 24] (l_loss: 0.11251) (t_loss: 0.14673) (accu: 0.9576)
[epoch : 25] (l_loss: 0.11175) (t_loss: 0.14673) (accu: 0.9585)
[epoch : 26] (l_loss: 0.11069) (t_loss: 0.14498) (accu: 0.9589)
[epoch : 27] (l_loss: 0.10982) (t_loss: 0.14657) (accu: 0.9583)
[epoch : 28] (l_loss: 0.10906) (t_loss: 0.14586) (accu: 0.9585)
[epoch : 29] (l_loss: 0.10869) (t_loss: 0.14463) (accu: 0.9590)
[epoch : 30] (l_loss: 0.10763) (t_loss: 0.14370) (accu: 0.9593)
Finish! (Best accu: 0.9593) (Time taken(sec) : 401.74) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (136511 | 129689)        51.28
fc1.weight   :      235200 (120422 | 114778)        51.20
fc2.weight   :       30000 (15360 | 14640)          51.20
fcout.weight :          1000 (729 | 271)            72.90
------------------------------------------------------------
Learning start! [Prune_iter : (4/21), Remaining weight : 51.28 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.58317) (accu: 0.0974)
[epoch : 1] (l_loss: 0.95670) (t_loss: 0.37571) (accu: 0.8828)
[epoch : 2] (l_loss: 0.31069) (t_loss: 0.24284) (accu: 0.9251)
[epoch : 3] (l_loss: 0.22937) (t_loss: 0.20476) (accu: 0.9362)
[epoch : 4] (l_loss: 0.19669) (t_loss: 0.18666) (accu: 0.9422)
[epoch : 5] (l_loss: 0.17822) (t_loss: 0.17718) (accu: 0.9455)
[epoch : 6] (l_loss: 0.16611) (t_loss: 0.16956) (accu: 0.9481)
[epoch : 7] (l_loss: 0.15777) (t_loss: 0.16683) (accu: 0.9481)
[epoch : 8] (l_loss: 0.15135) (t_loss: 0.16218) (accu: 0.9503)
[epoch : 9] (l_loss: 0.14602) (t_loss: 0.15965) (accu: 0.9513)
[epoch : 10] (l_loss: 0.14189) (t_loss: 0.15668) (accu: 0.9523)
[epoch : 11] (l_loss: 0.13792) (t_loss: 0.15688) (accu: 0.9532)
[epoch : 12] (l_loss: 0.13455) (t_loss: 0.15536) (accu: 0.9541)
[epoch : 13] (l_loss: 0.13213) (t_loss: 0.15363) (accu: 0.9552)
[epoch : 14] (l_loss: 0.12953) (t_loss: 0.15317) (accu: 0.9547)
[epoch : 15] (l_loss: 0.12738) (t_loss: 0.15278) (accu: 0.9554)
[epoch : 16] (l_loss: 0.12559) (t_loss: 0.15222) (accu: 0.9544)
[epoch : 17] (l_loss: 0.12373) (t_loss: 0.15151) (accu: 0.9557)
[epoch : 18] (l_loss: 0.12218) (t_loss: 0.15040) (accu: 0.9558)
[epoch : 19] (l_loss: 0.12082) (t_loss: 0.15149) (accu: 0.9556)
[epoch : 20] (l_loss: 0.11957) (t_loss: 0.15053) (accu: 0.9568)
[epoch : 21] (l_loss: 0.11836) (t_loss: 0.15137) (accu: 0.9565)
[epoch : 22] (l_loss: 0.11740) (t_loss: 0.14957) (accu: 0.9564)
[epoch : 23] (l_loss: 0.11619) (t_loss: 0.15142) (accu: 0.9561)
[epoch : 24] (l_loss: 0.11535) (t_loss: 0.14931) (accu: 0.9581)
[epoch : 25] (l_loss: 0.11427) (t_loss: 0.14997) (accu: 0.9581)
[epoch : 26] (l_loss: 0.11374) (t_loss: 0.14934) (accu: 0.9576)
[epoch : 27] (l_loss: 0.11281) (t_loss: 0.15027) (accu: 0.9580)
[epoch : 28] (l_loss: 0.11205) (t_loss: 0.15054) (accu: 0.9583)
[epoch : 29] (l_loss: 0.11110) (t_loss: 0.14905) (accu: 0.9581)
[epoch : 30] (l_loss: 0.11051) (t_loss: 0.14806) (accu: 0.9585)
Finish! (Best accu: 0.9585) (Time taken(sec) : 409.04) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (109282 | 156918)        41.05
fc1.weight   :      235200 (96338 | 138862)         40.96
fc2.weight   :       30000 (12288 | 17712)          40.96
fcout.weight :          1000 (656 | 344)            65.60
------------------------------------------------------------
Learning start! [Prune_iter : (5/21), Remaining weight : 41.05 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.58430) (accu: 0.1081)
[epoch : 1] (l_loss: 0.94975) (t_loss: 0.35959) (accu: 0.8947)
[epoch : 2] (l_loss: 0.29668) (t_loss: 0.23604) (accu: 0.9266)
[epoch : 3] (l_loss: 0.22077) (t_loss: 0.20007) (accu: 0.9390)
[epoch : 4] (l_loss: 0.18970) (t_loss: 0.18322) (accu: 0.9431)
[epoch : 5] (l_loss: 0.17223) (t_loss: 0.17406) (accu: 0.9457)
[epoch : 6] (l_loss: 0.16071) (t_loss: 0.17000) (accu: 0.9480)
[epoch : 7] (l_loss: 0.15287) (t_loss: 0.16334) (accu: 0.9495)
[epoch : 8] (l_loss: 0.14627) (t_loss: 0.16123) (accu: 0.9504)
[epoch : 9] (l_loss: 0.14152) (t_loss: 0.15724) (accu: 0.9507)
[epoch : 10] (l_loss: 0.13748) (t_loss: 0.15600) (accu: 0.9529)
[epoch : 11] (l_loss: 0.13433) (t_loss: 0.15378) (accu: 0.9544)
[epoch : 12] (l_loss: 0.13128) (t_loss: 0.15379) (accu: 0.9534)
[epoch : 13] (l_loss: 0.12911) (t_loss: 0.15328) (accu: 0.9545)
[epoch : 14] (l_loss: 0.12654) (t_loss: 0.15292) (accu: 0.9543)
[epoch : 15] (l_loss: 0.12506) (t_loss: 0.15181) (accu: 0.9545)
[epoch : 16] (l_loss: 0.12293) (t_loss: 0.15045) (accu: 0.9554)
[epoch : 17] (l_loss: 0.12162) (t_loss: 0.15222) (accu: 0.9554)
[epoch : 18] (l_loss: 0.12021) (t_loss: 0.14975) (accu: 0.9560)
[epoch : 19] (l_loss: 0.11905) (t_loss: 0.14946) (accu: 0.9557)
[epoch : 20] (l_loss: 0.11783) (t_loss: 0.15062) (accu: 0.9562)
[epoch : 21] (l_loss: 0.11670) (t_loss: 0.14752) (accu: 0.9566)
[epoch : 22] (l_loss: 0.11552) (t_loss: 0.14714) (accu: 0.9572)
[epoch : 23] (l_loss: 0.11470) (t_loss: 0.14793) (accu: 0.9571)
[epoch : 24] (l_loss: 0.11371) (t_loss: 0.14901) (accu: 0.9573)
[epoch : 25] (l_loss: 0.11290) (t_loss: 0.14592) (accu: 0.9585)
[epoch : 26] (l_loss: 0.11195) (t_loss: 0.14536) (accu: 0.9587)
[epoch : 27] (l_loss: 0.11168) (t_loss: 0.14598) (accu: 0.9587)
[epoch : 28] (l_loss: 0.11065) (t_loss: 0.14564) (accu: 0.9597)
[epoch : 29] (l_loss: 0.11003) (t_loss: 0.14702) (accu: 0.9590)
[epoch : 30] (l_loss: 0.10929) (t_loss: 0.14499) (accu: 0.9596)
Finish! (Best accu: 0.9597) (Time taken(sec) : 400.30) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (87490 | 178710)         32.87
fc1.weight   :      235200 (77070 | 158130)         32.77
fc2.weight   :        30000 (9830 | 20170)          32.77
fcout.weight :          1000 (590 | 410)            59.00
------------------------------------------------------------
Learning start! [Prune_iter : (6/21), Remaining weight : 32.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.56786) (accu: 0.0966)
[epoch : 1] (l_loss: 0.95259) (t_loss: 0.35242) (accu: 0.8942)
[epoch : 2] (l_loss: 0.29027) (t_loss: 0.22850) (accu: 0.9312)
[epoch : 3] (l_loss: 0.21769) (t_loss: 0.19613) (accu: 0.9409)
[epoch : 4] (l_loss: 0.18877) (t_loss: 0.18005) (accu: 0.9456)
[epoch : 5] (l_loss: 0.17256) (t_loss: 0.16957) (accu: 0.9492)
[epoch : 6] (l_loss: 0.16209) (t_loss: 0.16562) (accu: 0.9503)
[epoch : 7] (l_loss: 0.15451) (t_loss: 0.15998) (accu: 0.9503)
[epoch : 8] (l_loss: 0.14872) (t_loss: 0.15682) (accu: 0.9528)
[epoch : 9] (l_loss: 0.14412) (t_loss: 0.15390) (accu: 0.9527)
[epoch : 10] (l_loss: 0.14065) (t_loss: 0.15388) (accu: 0.9533)
[epoch : 11] (l_loss: 0.13745) (t_loss: 0.15059) (accu: 0.9533)
[epoch : 12] (l_loss: 0.13456) (t_loss: 0.15001) (accu: 0.9546)
[epoch : 13] (l_loss: 0.13214) (t_loss: 0.14842) (accu: 0.9569)
[epoch : 14] (l_loss: 0.12972) (t_loss: 0.14750) (accu: 0.9563)
[epoch : 15] (l_loss: 0.12753) (t_loss: 0.14422) (accu: 0.9570)
[epoch : 16] (l_loss: 0.12532) (t_loss: 0.14559) (accu: 0.9569)
[epoch : 17] (l_loss: 0.12319) (t_loss: 0.14471) (accu: 0.9569)
[epoch : 18] (l_loss: 0.12180) (t_loss: 0.14442) (accu: 0.9570)
[epoch : 19] (l_loss: 0.12011) (t_loss: 0.14449) (accu: 0.9576)
[epoch : 20] (l_loss: 0.11858) (t_loss: 0.14266) (accu: 0.9578)
[epoch : 21] (l_loss: 0.11738) (t_loss: 0.14273) (accu: 0.9585)
[epoch : 22] (l_loss: 0.11607) (t_loss: 0.14055) (accu: 0.9580)
[epoch : 23] (l_loss: 0.11528) (t_loss: 0.14101) (accu: 0.9583)
[epoch : 24] (l_loss: 0.11385) (t_loss: 0.14178) (accu: 0.9576)
[epoch : 25] (l_loss: 0.11280) (t_loss: 0.14094) (accu: 0.9594)
[epoch : 26] (l_loss: 0.11183) (t_loss: 0.13970) (accu: 0.9595)
[epoch : 27] (l_loss: 0.11154) (t_loss: 0.14074) (accu: 0.9593)
[epoch : 28] (l_loss: 0.11047) (t_loss: 0.13807) (accu: 0.9586)
[epoch : 29] (l_loss: 0.11007) (t_loss: 0.13848) (accu: 0.9594)
[epoch : 30] (l_loss: 0.10963) (t_loss: 0.13931) (accu: 0.9593)
Finish! (Best accu: 0.9595) (Time taken(sec) : 393.23) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (70051 | 196149)         26.32
fc1.weight   :      235200 (61656 | 173544)         26.21
fc2.weight   :        30000 (7864 | 22136)          26.21
fcout.weight :          1000 (531 | 469)            53.10
------------------------------------------------------------
Learning start! [Prune_iter : (7/21), Remaining weight : 26.32 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.46351) (accu: 0.1062)
[epoch : 1] (l_loss: 0.95369) (t_loss: 0.35306) (accu: 0.8953)
[epoch : 2] (l_loss: 0.28827) (t_loss: 0.23173) (accu: 0.9304)
[epoch : 3] (l_loss: 0.21722) (t_loss: 0.19697) (accu: 0.9393)
[epoch : 4] (l_loss: 0.18940) (t_loss: 0.18061) (accu: 0.9450)
[epoch : 5] (l_loss: 0.17333) (t_loss: 0.17217) (accu: 0.9464)
[epoch : 6] (l_loss: 0.16255) (t_loss: 0.16505) (accu: 0.9484)
[epoch : 7] (l_loss: 0.15480) (t_loss: 0.16103) (accu: 0.9502)
[epoch : 8] (l_loss: 0.14882) (t_loss: 0.15820) (accu: 0.9513)
[epoch : 9] (l_loss: 0.14375) (t_loss: 0.15554) (accu: 0.9507)
[epoch : 10] (l_loss: 0.13990) (t_loss: 0.15271) (accu: 0.9516)
[epoch : 11] (l_loss: 0.13641) (t_loss: 0.15311) (accu: 0.9512)
[epoch : 12] (l_loss: 0.13345) (t_loss: 0.15045) (accu: 0.9545)
[epoch : 13] (l_loss: 0.13106) (t_loss: 0.14971) (accu: 0.9541)
[epoch : 14] (l_loss: 0.12868) (t_loss: 0.14939) (accu: 0.9544)
[epoch : 15] (l_loss: 0.12692) (t_loss: 0.14925) (accu: 0.9543)
[epoch : 16] (l_loss: 0.12516) (t_loss: 0.15041) (accu: 0.9538)
[epoch : 17] (l_loss: 0.12358) (t_loss: 0.14715) (accu: 0.9553)
[epoch : 18] (l_loss: 0.12253) (t_loss: 0.14573) (accu: 0.9553)
[epoch : 19] (l_loss: 0.12110) (t_loss: 0.14582) (accu: 0.9563)
[epoch : 20] (l_loss: 0.11995) (t_loss: 0.14633) (accu: 0.9567)
[epoch : 21] (l_loss: 0.11876) (t_loss: 0.14484) (accu: 0.9569)
[epoch : 22] (l_loss: 0.11788) (t_loss: 0.14720) (accu: 0.9559)
[epoch : 23] (l_loss: 0.11709) (t_loss: 0.14374) (accu: 0.9569)
[epoch : 24] (l_loss: 0.11636) (t_loss: 0.14440) (accu: 0.9564)
[epoch : 25] (l_loss: 0.11550) (t_loss: 0.14438) (accu: 0.9569)
[epoch : 26] (l_loss: 0.11494) (t_loss: 0.14504) (accu: 0.9571)
[epoch : 27] (l_loss: 0.11401) (t_loss: 0.14477) (accu: 0.9568)
[epoch : 28] (l_loss: 0.11340) (t_loss: 0.14348) (accu: 0.9569)
[epoch : 29] (l_loss: 0.11272) (t_loss: 0.14379) (accu: 0.9581)
[epoch : 30] (l_loss: 0.11215) (t_loss: 0.14484) (accu: 0.9574)
Finish! (Best accu: 0.9581) (Time taken(sec) : 390.02) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (56094 | 210106)         21.07
fc1.weight   :      235200 (49325 | 185875)         20.97
fc2.weight   :        30000 (6291 | 23709)          20.97
fcout.weight :          1000 (478 | 522)            47.80
------------------------------------------------------------
Learning start! [Prune_iter : (8/21), Remaining weight : 21.07 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.47368) (accu: 0.0995)
[epoch : 1] (l_loss: 0.94506) (t_loss: 0.33980) (accu: 0.8998)
[epoch : 2] (l_loss: 0.28379) (t_loss: 0.22521) (accu: 0.9274)
[epoch : 3] (l_loss: 0.21484) (t_loss: 0.19243) (accu: 0.9392)
[epoch : 4] (l_loss: 0.18709) (t_loss: 0.17691) (accu: 0.9445)
[epoch : 5] (l_loss: 0.17132) (t_loss: 0.16758) (accu: 0.9480)
[epoch : 6] (l_loss: 0.16083) (t_loss: 0.16339) (accu: 0.9483)
[epoch : 7] (l_loss: 0.15345) (t_loss: 0.16014) (accu: 0.9501)
[epoch : 8] (l_loss: 0.14773) (t_loss: 0.15728) (accu: 0.9515)
[epoch : 9] (l_loss: 0.14351) (t_loss: 0.15376) (accu: 0.9535)
[epoch : 10] (l_loss: 0.14012) (t_loss: 0.15347) (accu: 0.9527)
[epoch : 11] (l_loss: 0.13709) (t_loss: 0.15156) (accu: 0.9536)
[epoch : 12] (l_loss: 0.13458) (t_loss: 0.15122) (accu: 0.9538)
[epoch : 13] (l_loss: 0.13228) (t_loss: 0.14991) (accu: 0.9552)
[epoch : 14] (l_loss: 0.13029) (t_loss: 0.14939) (accu: 0.9551)
[epoch : 15] (l_loss: 0.12843) (t_loss: 0.14827) (accu: 0.9553)
[epoch : 16] (l_loss: 0.12715) (t_loss: 0.14929) (accu: 0.9557)
[epoch : 17] (l_loss: 0.12531) (t_loss: 0.14841) (accu: 0.9554)
[epoch : 18] (l_loss: 0.12371) (t_loss: 0.14619) (accu: 0.9565)
[epoch : 19] (l_loss: 0.12276) (t_loss: 0.14954) (accu: 0.9550)
[epoch : 20] (l_loss: 0.12167) (t_loss: 0.14543) (accu: 0.9566)
[epoch : 21] (l_loss: 0.12018) (t_loss: 0.14775) (accu: 0.9564)
[epoch : 22] (l_loss: 0.11925) (t_loss: 0.14747) (accu: 0.9563)
[epoch : 23] (l_loss: 0.11848) (t_loss: 0.14591) (accu: 0.9568)
[epoch : 24] (l_loss: 0.11769) (t_loss: 0.14690) (accu: 0.9573)
[epoch : 25] (l_loss: 0.11649) (t_loss: 0.14427) (accu: 0.9579)
[epoch : 26] (l_loss: 0.11621) (t_loss: 0.14567) (accu: 0.9587)
[epoch : 27] (l_loss: 0.11529) (t_loss: 0.14524) (accu: 0.9589)
[epoch : 28] (l_loss: 0.11467) (t_loss: 0.14540) (accu: 0.9589)
[epoch : 29] (l_loss: 0.11399) (t_loss: 0.14424) (accu: 0.9582)
[epoch : 30] (l_loss: 0.11342) (t_loss: 0.14498) (accu: 0.9582)
Finish! (Best accu: 0.9589) (Time taken(sec) : 399.88) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (44923 | 221277)         16.88
fc1.weight   :      235200 (39460 | 195740)         16.78
fc2.weight   :        30000 (5033 | 24967)          16.78
fcout.weight :          1000 (430 | 570)            43.00
------------------------------------------------------------
Learning start! [Prune_iter : (9/21), Remaining weight : 16.88 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.42451) (accu: 0.0944)
[epoch : 1] (l_loss: 0.90804) (t_loss: 0.33978) (accu: 0.9002)
[epoch : 2] (l_loss: 0.28636) (t_loss: 0.23822) (accu: 0.9283)
[epoch : 3] (l_loss: 0.22699) (t_loss: 0.20785) (accu: 0.9366)
[epoch : 4] (l_loss: 0.20041) (t_loss: 0.19113) (accu: 0.9425)
[epoch : 5] (l_loss: 0.18403) (t_loss: 0.18275) (accu: 0.9451)
[epoch : 6] (l_loss: 0.17282) (t_loss: 0.17513) (accu: 0.9480)
[epoch : 7] (l_loss: 0.16437) (t_loss: 0.17163) (accu: 0.9489)
[epoch : 8] (l_loss: 0.15823) (t_loss: 0.16655) (accu: 0.9502)
[epoch : 9] (l_loss: 0.15293) (t_loss: 0.16340) (accu: 0.9511)
[epoch : 10] (l_loss: 0.14923) (t_loss: 0.16260) (accu: 0.9515)
[epoch : 11] (l_loss: 0.14572) (t_loss: 0.16125) (accu: 0.9523)
[epoch : 12] (l_loss: 0.14275) (t_loss: 0.15796) (accu: 0.9532)
[epoch : 13] (l_loss: 0.14025) (t_loss: 0.15691) (accu: 0.9538)
[epoch : 14] (l_loss: 0.13783) (t_loss: 0.15630) (accu: 0.9533)
[epoch : 15] (l_loss: 0.13585) (t_loss: 0.15471) (accu: 0.9542)
[epoch : 16] (l_loss: 0.13391) (t_loss: 0.15347) (accu: 0.9548)
[epoch : 17] (l_loss: 0.13212) (t_loss: 0.15222) (accu: 0.9552)
[epoch : 18] (l_loss: 0.13078) (t_loss: 0.15315) (accu: 0.9550)
[epoch : 19] (l_loss: 0.12946) (t_loss: 0.15243) (accu: 0.9558)
[epoch : 20] (l_loss: 0.12801) (t_loss: 0.15089) (accu: 0.9566)
[epoch : 21] (l_loss: 0.12674) (t_loss: 0.15110) (accu: 0.9554)
[epoch : 22] (l_loss: 0.12562) (t_loss: 0.15010) (accu: 0.9562)
[epoch : 23] (l_loss: 0.12484) (t_loss: 0.15123) (accu: 0.9568)
[epoch : 24] (l_loss: 0.12356) (t_loss: 0.15093) (accu: 0.9568)
[epoch : 25] (l_loss: 0.12278) (t_loss: 0.15196) (accu: 0.9565)
[epoch : 26] (l_loss: 0.12197) (t_loss: 0.14858) (accu: 0.9567)
[epoch : 27] (l_loss: 0.12158) (t_loss: 0.14910) (accu: 0.9566)
[epoch : 28] (l_loss: 0.12082) (t_loss: 0.14996) (accu: 0.9559)
[epoch : 29] (l_loss: 0.12016) (t_loss: 0.14942) (accu: 0.9570)
[epoch : 30] (l_loss: 0.11942) (t_loss: 0.14948) (accu: 0.9567)
Finish! (Best accu: 0.9570) (Time taken(sec) : 403.96) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (35982 | 230218)         13.52
fc1.weight   :      235200 (31568 | 203632)         13.42
fc2.weight   :        30000 (4027 | 25973)          13.42
fcout.weight :          1000 (387 | 613)            38.70
------------------------------------------------------------
Learning start! [Prune_iter : (10/21), Remaining weight : 13.52 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.36181) (accu: 0.0866)
[epoch : 1] (l_loss: 0.87449) (t_loss: 0.32686) (accu: 0.9054)
[epoch : 2] (l_loss: 0.27241) (t_loss: 0.22951) (accu: 0.9302)
[epoch : 3] (l_loss: 0.21441) (t_loss: 0.19876) (accu: 0.9389)
[epoch : 4] (l_loss: 0.19130) (t_loss: 0.18673) (accu: 0.9434)
[epoch : 5] (l_loss: 0.17773) (t_loss: 0.17736) (accu: 0.9464)
[epoch : 6] (l_loss: 0.16858) (t_loss: 0.17197) (accu: 0.9482)
[epoch : 7] (l_loss: 0.16154) (t_loss: 0.16825) (accu: 0.9497)
[epoch : 8] (l_loss: 0.15606) (t_loss: 0.16470) (accu: 0.9517)
[epoch : 9] (l_loss: 0.15153) (t_loss: 0.16478) (accu: 0.9515)
[epoch : 10] (l_loss: 0.14771) (t_loss: 0.16186) (accu: 0.9531)
[epoch : 11] (l_loss: 0.14505) (t_loss: 0.15844) (accu: 0.9533)
[epoch : 12] (l_loss: 0.14236) (t_loss: 0.15959) (accu: 0.9527)
[epoch : 13] (l_loss: 0.13979) (t_loss: 0.15521) (accu: 0.9546)
[epoch : 14] (l_loss: 0.13780) (t_loss: 0.15458) (accu: 0.9548)
[epoch : 15] (l_loss: 0.13579) (t_loss: 0.15669) (accu: 0.9538)
[epoch : 16] (l_loss: 0.13429) (t_loss: 0.15281) (accu: 0.9546)
[epoch : 17] (l_loss: 0.13259) (t_loss: 0.15432) (accu: 0.9539)
[epoch : 18] (l_loss: 0.13127) (t_loss: 0.15297) (accu: 0.9551)
[epoch : 19] (l_loss: 0.13030) (t_loss: 0.15169) (accu: 0.9552)
[epoch : 20] (l_loss: 0.12911) (t_loss: 0.15205) (accu: 0.9550)
[epoch : 21] (l_loss: 0.12801) (t_loss: 0.15156) (accu: 0.9543)
[epoch : 22] (l_loss: 0.12706) (t_loss: 0.15070) (accu: 0.9544)
[epoch : 23] (l_loss: 0.12614) (t_loss: 0.14976) (accu: 0.9550)
[epoch : 24] (l_loss: 0.12572) (t_loss: 0.15039) (accu: 0.9547)
[epoch : 25] (l_loss: 0.12485) (t_loss: 0.14927) (accu: 0.9543)
[epoch : 26] (l_loss: 0.12405) (t_loss: 0.15013) (accu: 0.9543)
[epoch : 27] (l_loss: 0.12336) (t_loss: 0.14994) (accu: 0.9538)
[epoch : 28] (l_loss: 0.12242) (t_loss: 0.14962) (accu: 0.9550)
[epoch : 29] (l_loss: 0.12168) (t_loss: 0.14877) (accu: 0.9539)
[epoch : 30] (l_loss: 0.12125) (t_loss: 0.14817) (accu: 0.9543)
Finish! (Best accu: 0.9552) (Time taken(sec) : 413.48) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (28824 | 237376)         10.83
fc1.weight   :      235200 (25254 | 209946)         10.74
fc2.weight   :        30000 (3221 | 26779)          10.74
fcout.weight :          1000 (349 | 651)            34.90
------------------------------------------------------------
Learning start! [Prune_iter : (11/21), Remaining weight : 10.83 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.33023) (accu: 0.0924)
[epoch : 1] (l_loss: 0.90876) (t_loss: 0.33953) (accu: 0.9056)
[epoch : 2] (l_loss: 0.28841) (t_loss: 0.23926) (accu: 0.9276)
[epoch : 3] (l_loss: 0.22681) (t_loss: 0.20727) (accu: 0.9356)
[epoch : 4] (l_loss: 0.20168) (t_loss: 0.19391) (accu: 0.9407)
[epoch : 5] (l_loss: 0.18635) (t_loss: 0.18369) (accu: 0.9432)
[epoch : 6] (l_loss: 0.17635) (t_loss: 0.17679) (accu: 0.9454)
[epoch : 7] (l_loss: 0.16857) (t_loss: 0.17410) (accu: 0.9466)
[epoch : 8] (l_loss: 0.16291) (t_loss: 0.17006) (accu: 0.9461)
[epoch : 9] (l_loss: 0.15780) (t_loss: 0.16821) (accu: 0.9477)
[epoch : 10] (l_loss: 0.15374) (t_loss: 0.16398) (accu: 0.9487)
[epoch : 11] (l_loss: 0.15000) (t_loss: 0.16460) (accu: 0.9501)
[epoch : 12] (l_loss: 0.14645) (t_loss: 0.16185) (accu: 0.9512)
[epoch : 13] (l_loss: 0.14344) (t_loss: 0.15823) (accu: 0.9524)
[epoch : 14] (l_loss: 0.14055) (t_loss: 0.15820) (accu: 0.9523)
[epoch : 15] (l_loss: 0.13822) (t_loss: 0.15548) (accu: 0.9531)
[epoch : 16] (l_loss: 0.13573) (t_loss: 0.15486) (accu: 0.9541)
[epoch : 17] (l_loss: 0.13431) (t_loss: 0.15628) (accu: 0.9536)
[epoch : 18] (l_loss: 0.13274) (t_loss: 0.15244) (accu: 0.9551)
[epoch : 19] (l_loss: 0.13126) (t_loss: 0.15506) (accu: 0.9548)
[epoch : 20] (l_loss: 0.13013) (t_loss: 0.15380) (accu: 0.9555)
[epoch : 21] (l_loss: 0.12910) (t_loss: 0.15169) (accu: 0.9551)
[epoch : 22] (l_loss: 0.12822) (t_loss: 0.15079) (accu: 0.9563)
[epoch : 23] (l_loss: 0.12712) (t_loss: 0.15051) (accu: 0.9560)
[epoch : 24] (l_loss: 0.12637) (t_loss: 0.15016) (accu: 0.9563)
[epoch : 25] (l_loss: 0.12545) (t_loss: 0.15235) (accu: 0.9562)
[epoch : 26] (l_loss: 0.12469) (t_loss: 0.15077) (accu: 0.9564)
[epoch : 27] (l_loss: 0.12385) (t_loss: 0.15007) (accu: 0.9565)
[epoch : 28] (l_loss: 0.12321) (t_loss: 0.15013) (accu: 0.9572)
[epoch : 29] (l_loss: 0.12275) (t_loss: 0.15034) (accu: 0.9568)
[epoch : 30] (l_loss: 0.12187) (t_loss: 0.15042) (accu: 0.9560)
Finish! (Best accu: 0.9572) (Time taken(sec) : 415.67) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (23095 | 243105)          8.68
fc1.weight   :      235200 (20204 | 214996)          8.59
fc2.weight   :        30000 (2577 | 27423)           8.59
fcout.weight :          1000 (314 | 686)            31.40
------------------------------------------------------------
Learning start! [Prune_iter : (12/21), Remaining weight : 8.68 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32515) (accu: 0.1074)
[epoch : 1] (l_loss: 0.90983) (t_loss: 0.32643) (accu: 0.9076)
[epoch : 2] (l_loss: 0.27814) (t_loss: 0.22866) (accu: 0.9324)
[epoch : 3] (l_loss: 0.22034) (t_loss: 0.19906) (accu: 0.9401)
[epoch : 4] (l_loss: 0.19590) (t_loss: 0.18507) (accu: 0.9447)
[epoch : 5] (l_loss: 0.18187) (t_loss: 0.17662) (accu: 0.9457)
[epoch : 6] (l_loss: 0.17220) (t_loss: 0.17128) (accu: 0.9471)
[epoch : 7] (l_loss: 0.16494) (t_loss: 0.16751) (accu: 0.9496)
[epoch : 8] (l_loss: 0.15936) (t_loss: 0.16298) (accu: 0.9499)
[epoch : 9] (l_loss: 0.15462) (t_loss: 0.16262) (accu: 0.9491)
[epoch : 10] (l_loss: 0.15089) (t_loss: 0.15871) (accu: 0.9512)
[epoch : 11] (l_loss: 0.14762) (t_loss: 0.15686) (accu: 0.9513)
[epoch : 12] (l_loss: 0.14463) (t_loss: 0.15582) (accu: 0.9519)
[epoch : 13] (l_loss: 0.14229) (t_loss: 0.15341) (accu: 0.9525)
[epoch : 14] (l_loss: 0.14000) (t_loss: 0.15310) (accu: 0.9542)
[epoch : 15] (l_loss: 0.13848) (t_loss: 0.15310) (accu: 0.9537)
[epoch : 16] (l_loss: 0.13670) (t_loss: 0.14989) (accu: 0.9539)
[epoch : 17] (l_loss: 0.13495) (t_loss: 0.15035) (accu: 0.9549)
[epoch : 18] (l_loss: 0.13377) (t_loss: 0.14914) (accu: 0.9555)
[epoch : 19] (l_loss: 0.13265) (t_loss: 0.14880) (accu: 0.9545)
[epoch : 20] (l_loss: 0.13150) (t_loss: 0.14713) (accu: 0.9556)
[epoch : 21] (l_loss: 0.13052) (t_loss: 0.14936) (accu: 0.9536)
[epoch : 22] (l_loss: 0.12970) (t_loss: 0.14723) (accu: 0.9554)
[epoch : 23] (l_loss: 0.12877) (t_loss: 0.14959) (accu: 0.9541)
[epoch : 24] (l_loss: 0.12788) (t_loss: 0.14667) (accu: 0.9539)
[epoch : 25] (l_loss: 0.12705) (t_loss: 0.14614) (accu: 0.9551)
[epoch : 26] (l_loss: 0.12617) (t_loss: 0.14658) (accu: 0.9561)
[epoch : 27] (l_loss: 0.12576) (t_loss: 0.14384) (accu: 0.9564)
[epoch : 28] (l_loss: 0.12527) (t_loss: 0.14348) (accu: 0.9566)
[epoch : 29] (l_loss: 0.12415) (t_loss: 0.14423) (accu: 0.9560)
[epoch : 30] (l_loss: 0.12382) (t_loss: 0.14422) (accu: 0.9556)
Finish! (Best accu: 0.9566) (Time taken(sec) : 404.25) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (18507 | 247693)          6.95
fc1.weight   :      235200 (16163 | 219037)          6.87
fc2.weight   :        30000 (2062 | 27938)           6.87
fcout.weight :          1000 (282 | 718)            28.20
------------------------------------------------------------
Learning start! [Prune_iter : (13/21), Remaining weight : 6.95 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29677) (accu: 0.1130)
[epoch : 1] (l_loss: 0.92092) (t_loss: 0.34565) (accu: 0.9013)
[epoch : 2] (l_loss: 0.29705) (t_loss: 0.24574) (accu: 0.9251)
[epoch : 3] (l_loss: 0.23481) (t_loss: 0.21303) (accu: 0.9355)
[epoch : 4] (l_loss: 0.20710) (t_loss: 0.19860) (accu: 0.9391)
[epoch : 5] (l_loss: 0.19164) (t_loss: 0.18704) (accu: 0.9426)
[epoch : 6] (l_loss: 0.18064) (t_loss: 0.18063) (accu: 0.9449)
[epoch : 7] (l_loss: 0.17364) (t_loss: 0.17554) (accu: 0.9457)
[epoch : 8] (l_loss: 0.16844) (t_loss: 0.17133) (accu: 0.9466)
[epoch : 9] (l_loss: 0.16415) (t_loss: 0.16902) (accu: 0.9476)
[epoch : 10] (l_loss: 0.16067) (t_loss: 0.16572) (accu: 0.9487)
[epoch : 11] (l_loss: 0.15743) (t_loss: 0.16595) (accu: 0.9497)
[epoch : 12] (l_loss: 0.15483) (t_loss: 0.16413) (accu: 0.9498)
[epoch : 13] (l_loss: 0.15236) (t_loss: 0.16491) (accu: 0.9507)
[epoch : 14] (l_loss: 0.15014) (t_loss: 0.16194) (accu: 0.9517)
[epoch : 15] (l_loss: 0.14848) (t_loss: 0.16078) (accu: 0.9514)
[epoch : 16] (l_loss: 0.14687) (t_loss: 0.16208) (accu: 0.9523)
[epoch : 17] (l_loss: 0.14514) (t_loss: 0.16276) (accu: 0.9540)
[epoch : 18] (l_loss: 0.14390) (t_loss: 0.16248) (accu: 0.9522)
[epoch : 19] (l_loss: 0.14267) (t_loss: 0.16050) (accu: 0.9523)
[epoch : 20] (l_loss: 0.14153) (t_loss: 0.15898) (accu: 0.9526)
[epoch : 21] (l_loss: 0.14054) (t_loss: 0.15873) (accu: 0.9534)
[epoch : 22] (l_loss: 0.13928) (t_loss: 0.15861) (accu: 0.9524)
[epoch : 23] (l_loss: 0.13851) (t_loss: 0.15839) (accu: 0.9531)
[epoch : 24] (l_loss: 0.13806) (t_loss: 0.15971) (accu: 0.9531)
[epoch : 25] (l_loss: 0.13674) (t_loss: 0.15838) (accu: 0.9538)
[epoch : 26] (l_loss: 0.13643) (t_loss: 0.15835) (accu: 0.9532)
[epoch : 27] (l_loss: 0.13565) (t_loss: 0.15729) (accu: 0.9538)
[epoch : 28] (l_loss: 0.13501) (t_loss: 0.15897) (accu: 0.9532)
[epoch : 29] (l_loss: 0.13429) (t_loss: 0.15792) (accu: 0.9546)
[epoch : 30] (l_loss: 0.13370) (t_loss: 0.15640) (accu: 0.9546)
Finish! (Best accu: 0.9546) (Time taken(sec) : 401.77) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (14833 | 251367)          5.57
fc1.weight   :      235200 (12930 | 222270)          5.50
fc2.weight   :        30000 (1649 | 28351)           5.50
fcout.weight :          1000 (254 | 746)            25.40
------------------------------------------------------------
Learning start! [Prune_iter : (14/21), Remaining weight : 5.57 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30841) (accu: 0.1039)
[epoch : 1] (l_loss: 0.96560) (t_loss: 0.37176) (accu: 0.8923)
[epoch : 2] (l_loss: 0.32029) (t_loss: 0.27022) (accu: 0.9179)
[epoch : 3] (l_loss: 0.25506) (t_loss: 0.23281) (accu: 0.9292)
[epoch : 4] (l_loss: 0.22606) (t_loss: 0.21324) (accu: 0.9333)
[epoch : 5] (l_loss: 0.20874) (t_loss: 0.20057) (accu: 0.9375)
[epoch : 6] (l_loss: 0.19831) (t_loss: 0.19551) (accu: 0.9405)
[epoch : 7] (l_loss: 0.18999) (t_loss: 0.18795) (accu: 0.9425)
[epoch : 8] (l_loss: 0.18388) (t_loss: 0.18485) (accu: 0.9428)
[epoch : 9] (l_loss: 0.17862) (t_loss: 0.18048) (accu: 0.9447)
[epoch : 10] (l_loss: 0.17472) (t_loss: 0.17755) (accu: 0.9443)
[epoch : 11] (l_loss: 0.17114) (t_loss: 0.17548) (accu: 0.9453)
[epoch : 12] (l_loss: 0.16798) (t_loss: 0.17356) (accu: 0.9468)
[epoch : 13] (l_loss: 0.16533) (t_loss: 0.17235) (accu: 0.9477)
[epoch : 14] (l_loss: 0.16303) (t_loss: 0.17118) (accu: 0.9481)
[epoch : 15] (l_loss: 0.16102) (t_loss: 0.17224) (accu: 0.9495)
[epoch : 16] (l_loss: 0.15929) (t_loss: 0.16752) (accu: 0.9489)
[epoch : 17] (l_loss: 0.15775) (t_loss: 0.16843) (accu: 0.9498)
[epoch : 18] (l_loss: 0.15645) (t_loss: 0.16717) (accu: 0.9506)
[epoch : 19] (l_loss: 0.15476) (t_loss: 0.16807) (accu: 0.9515)
[epoch : 20] (l_loss: 0.15362) (t_loss: 0.16681) (accu: 0.9513)
[epoch : 21] (l_loss: 0.15236) (t_loss: 0.16889) (accu: 0.9502)
[epoch : 22] (l_loss: 0.15150) (t_loss: 0.16460) (accu: 0.9519)
[epoch : 23] (l_loss: 0.14999) (t_loss: 0.16437) (accu: 0.9510)
[epoch : 24] (l_loss: 0.14960) (t_loss: 0.16492) (accu: 0.9512)
[epoch : 25] (l_loss: 0.14884) (t_loss: 0.16434) (accu: 0.9511)
[epoch : 26] (l_loss: 0.14820) (t_loss: 0.16451) (accu: 0.9517)
[epoch : 27] (l_loss: 0.14734) (t_loss: 0.16484) (accu: 0.9512)
[epoch : 28] (l_loss: 0.14644) (t_loss: 0.16591) (accu: 0.9511)
[epoch : 29] (l_loss: 0.14583) (t_loss: 0.16413) (accu: 0.9524)
[epoch : 30] (l_loss: 0.14488) (t_loss: 0.16382) (accu: 0.9518)
Finish! (Best accu: 0.9524) (Time taken(sec) : 414.93) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (11892 | 254308)          4.47
fc1.weight   :      235200 (10344 | 224856)          4.40
fc2.weight   :        30000 (1319 | 28681)           4.40
fcout.weight :          1000 (229 | 771)            22.90
------------------------------------------------------------
Learning start! [Prune_iter : (15/21), Remaining weight : 4.47 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30874) (accu: 0.0903)
[epoch : 1] (l_loss: 0.94998) (t_loss: 0.36467) (accu: 0.8907)
[epoch : 2] (l_loss: 0.32096) (t_loss: 0.26925) (accu: 0.9180)
[epoch : 3] (l_loss: 0.26218) (t_loss: 0.23875) (accu: 0.9268)
[epoch : 4] (l_loss: 0.23515) (t_loss: 0.22381) (accu: 0.9318)
[epoch : 5] (l_loss: 0.21817) (t_loss: 0.21261) (accu: 0.9336)
[epoch : 6] (l_loss: 0.20550) (t_loss: 0.20472) (accu: 0.9371)
[epoch : 7] (l_loss: 0.19569) (t_loss: 0.19705) (accu: 0.9411)
[epoch : 8] (l_loss: 0.18863) (t_loss: 0.19301) (accu: 0.9418)
[epoch : 9] (l_loss: 0.18375) (t_loss: 0.18941) (accu: 0.9424)
[epoch : 10] (l_loss: 0.17968) (t_loss: 0.18499) (accu: 0.9457)
[epoch : 11] (l_loss: 0.17586) (t_loss: 0.18162) (accu: 0.9450)
[epoch : 12] (l_loss: 0.17324) (t_loss: 0.17932) (accu: 0.9473)
[epoch : 13] (l_loss: 0.17031) (t_loss: 0.17774) (accu: 0.9458)
[epoch : 14] (l_loss: 0.16820) (t_loss: 0.17708) (accu: 0.9447)
[epoch : 15] (l_loss: 0.16595) (t_loss: 0.17689) (accu: 0.9472)
[epoch : 16] (l_loss: 0.16433) (t_loss: 0.17508) (accu: 0.9470)
[epoch : 17] (l_loss: 0.16267) (t_loss: 0.17522) (accu: 0.9469)
[epoch : 18] (l_loss: 0.16150) (t_loss: 0.17370) (accu: 0.9477)
[epoch : 19] (l_loss: 0.16009) (t_loss: 0.17064) (accu: 0.9485)
[epoch : 20] (l_loss: 0.15854) (t_loss: 0.17202) (accu: 0.9482)
[epoch : 21] (l_loss: 0.15726) (t_loss: 0.16865) (accu: 0.9486)
[epoch : 22] (l_loss: 0.15634) (t_loss: 0.16982) (accu: 0.9489)
[epoch : 23] (l_loss: 0.15501) (t_loss: 0.16717) (accu: 0.9499)
[epoch : 24] (l_loss: 0.15433) (t_loss: 0.16792) (accu: 0.9494)
[epoch : 25] (l_loss: 0.15345) (t_loss: 0.16592) (accu: 0.9497)
[epoch : 26] (l_loss: 0.15283) (t_loss: 0.16608) (accu: 0.9486)
[epoch : 27] (l_loss: 0.15169) (t_loss: 0.16629) (accu: 0.9497)
[epoch : 28] (l_loss: 0.15130) (t_loss: 0.16508) (accu: 0.9500)
[epoch : 29] (l_loss: 0.15060) (t_loss: 0.16529) (accu: 0.9499)
[epoch : 30] (l_loss: 0.14977) (t_loss: 0.16520) (accu: 0.9494)
Finish! (Best accu: 0.9500) (Time taken(sec) : 413.52) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (9537 | 256663)          3.58
fc1.weight   :       235200 (8275 | 226925)          3.52
fc2.weight   :        30000 (1056 | 28944)           3.52
fcout.weight :          1000 (206 | 794)            20.60
------------------------------------------------------------
Learning start! [Prune_iter : (16/21), Remaining weight : 3.58 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29698) (accu: 0.1013)
[epoch : 1] (l_loss: 0.94983) (t_loss: 0.37456) (accu: 0.8896)
[epoch : 2] (l_loss: 0.32985) (t_loss: 0.27475) (accu: 0.9161)
[epoch : 3] (l_loss: 0.26389) (t_loss: 0.23904) (accu: 0.9268)
[epoch : 4] (l_loss: 0.23366) (t_loss: 0.21979) (accu: 0.9332)
[epoch : 5] (l_loss: 0.21587) (t_loss: 0.20842) (accu: 0.9343)
[epoch : 6] (l_loss: 0.20481) (t_loss: 0.20169) (accu: 0.9380)
[epoch : 7] (l_loss: 0.19692) (t_loss: 0.19537) (accu: 0.9416)
[epoch : 8] (l_loss: 0.19089) (t_loss: 0.19135) (accu: 0.9413)
[epoch : 9] (l_loss: 0.18631) (t_loss: 0.18827) (accu: 0.9425)
[epoch : 10] (l_loss: 0.18201) (t_loss: 0.18712) (accu: 0.9455)
[epoch : 11] (l_loss: 0.17880) (t_loss: 0.18469) (accu: 0.9462)
[epoch : 12] (l_loss: 0.17582) (t_loss: 0.18400) (accu: 0.9468)
[epoch : 13] (l_loss: 0.17334) (t_loss: 0.18179) (accu: 0.9451)
[epoch : 14] (l_loss: 0.17106) (t_loss: 0.17986) (accu: 0.9460)
[epoch : 15] (l_loss: 0.16914) (t_loss: 0.18012) (accu: 0.9472)
[epoch : 16] (l_loss: 0.16712) (t_loss: 0.17822) (accu: 0.9474)
[epoch : 17] (l_loss: 0.16569) (t_loss: 0.18020) (accu: 0.9467)
[epoch : 18] (l_loss: 0.16410) (t_loss: 0.17865) (accu: 0.9462)
[epoch : 19] (l_loss: 0.16303) (t_loss: 0.17532) (accu: 0.9473)
[epoch : 20] (l_loss: 0.16166) (t_loss: 0.17512) (accu: 0.9482)
[epoch : 21] (l_loss: 0.16064) (t_loss: 0.17393) (accu: 0.9483)
[epoch : 22] (l_loss: 0.15985) (t_loss: 0.17441) (accu: 0.9479)
[epoch : 23] (l_loss: 0.15860) (t_loss: 0.17642) (accu: 0.9472)
[epoch : 24] (l_loss: 0.15787) (t_loss: 0.17363) (accu: 0.9481)
[epoch : 25] (l_loss: 0.15677) (t_loss: 0.17288) (accu: 0.9502)
[epoch : 26] (l_loss: 0.15649) (t_loss: 0.17160) (accu: 0.9490)
[epoch : 27] (l_loss: 0.15587) (t_loss: 0.17238) (accu: 0.9484)
[epoch : 28] (l_loss: 0.15472) (t_loss: 0.17212) (accu: 0.9489)
[epoch : 29] (l_loss: 0.15439) (t_loss: 0.17025) (accu: 0.9501)
[epoch : 30] (l_loss: 0.15399) (t_loss: 0.17127) (accu: 0.9497)
Finish! (Best accu: 0.9502) (Time taken(sec) : 413.48) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (7649 | 258551)          2.87
fc1.weight   :       235200 (6620 | 228580)          2.81
fc2.weight   :        30000 (844 | 29156)            2.81
fcout.weight :          1000 (185 | 815)            18.50
------------------------------------------------------------
Learning start! [Prune_iter : (17/21), Remaining weight : 2.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29921) (accu: 0.0924)
[epoch : 1] (l_loss: 0.98313) (t_loss: 0.38731) (accu: 0.8860)
[epoch : 2] (l_loss: 0.34795) (t_loss: 0.29565) (accu: 0.9100)
[epoch : 3] (l_loss: 0.28550) (t_loss: 0.25787) (accu: 0.9203)
[epoch : 4] (l_loss: 0.25474) (t_loss: 0.23650) (accu: 0.9275)
[epoch : 5] (l_loss: 0.23709) (t_loss: 0.22599) (accu: 0.9309)
[epoch : 6] (l_loss: 0.22590) (t_loss: 0.21882) (accu: 0.9335)
[epoch : 7] (l_loss: 0.21824) (t_loss: 0.21290) (accu: 0.9350)
[epoch : 8] (l_loss: 0.21258) (t_loss: 0.21118) (accu: 0.9361)
[epoch : 9] (l_loss: 0.20823) (t_loss: 0.20634) (accu: 0.9379)
[epoch : 10] (l_loss: 0.20486) (t_loss: 0.20813) (accu: 0.9372)
[epoch : 11] (l_loss: 0.20209) (t_loss: 0.20345) (accu: 0.9381)
[epoch : 12] (l_loss: 0.19932) (t_loss: 0.20194) (accu: 0.9384)
[epoch : 13] (l_loss: 0.19740) (t_loss: 0.20051) (accu: 0.9394)
[epoch : 14] (l_loss: 0.19542) (t_loss: 0.20022) (accu: 0.9389)
[epoch : 15] (l_loss: 0.19337) (t_loss: 0.19635) (accu: 0.9392)
[epoch : 16] (l_loss: 0.19197) (t_loss: 0.19968) (accu: 0.9384)
[epoch : 17] (l_loss: 0.19036) (t_loss: 0.19549) (accu: 0.9388)
[epoch : 18] (l_loss: 0.18930) (t_loss: 0.19774) (accu: 0.9389)
[epoch : 19] (l_loss: 0.18788) (t_loss: 0.19781) (accu: 0.9393)
[epoch : 20] (l_loss: 0.18673) (t_loss: 0.19618) (accu: 0.9398)
[epoch : 21] (l_loss: 0.18579) (t_loss: 0.19513) (accu: 0.9397)
[epoch : 22] (l_loss: 0.18468) (t_loss: 0.19240) (accu: 0.9412)
[epoch : 23] (l_loss: 0.18352) (t_loss: 0.19403) (accu: 0.9398)
[epoch : 24] (l_loss: 0.18279) (t_loss: 0.19427) (accu: 0.9409)
[epoch : 25] (l_loss: 0.18185) (t_loss: 0.19336) (accu: 0.9409)
[epoch : 26] (l_loss: 0.18112) (t_loss: 0.19258) (accu: 0.9403)
[epoch : 27] (l_loss: 0.18058) (t_loss: 0.19255) (accu: 0.9414)
[epoch : 28] (l_loss: 0.17958) (t_loss: 0.19563) (accu: 0.9406)
[epoch : 29] (l_loss: 0.17900) (t_loss: 0.19111) (accu: 0.9413)
[epoch : 30] (l_loss: 0.17778) (t_loss: 0.19164) (accu: 0.9420)
Finish! (Best accu: 0.9420) (Time taken(sec) : 404.12) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (6139 | 260061)          2.31
fc1.weight   :       235200 (5296 | 229904)          2.25
fc2.weight   :        30000 (676 | 29324)            2.25
fcout.weight :          1000 (167 | 833)            16.70
------------------------------------------------------------
Learning start! [Prune_iter : (18/21), Remaining weight : 2.31 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29136) (accu: 0.0926)
[epoch : 1] (l_loss: 0.97344) (t_loss: 0.38221) (accu: 0.8879)
[epoch : 2] (l_loss: 0.33688) (t_loss: 0.28632) (accu: 0.9142)
[epoch : 3] (l_loss: 0.27935) (t_loss: 0.25681) (accu: 0.9207)
[epoch : 4] (l_loss: 0.25464) (t_loss: 0.24223) (accu: 0.9241)
[epoch : 5] (l_loss: 0.24003) (t_loss: 0.23286) (accu: 0.9265)
[epoch : 6] (l_loss: 0.23026) (t_loss: 0.22512) (accu: 0.9315)
[epoch : 7] (l_loss: 0.22249) (t_loss: 0.22105) (accu: 0.9316)
[epoch : 8] (l_loss: 0.21757) (t_loss: 0.21867) (accu: 0.9310)
[epoch : 9] (l_loss: 0.21314) (t_loss: 0.21457) (accu: 0.9330)
[epoch : 10] (l_loss: 0.20976) (t_loss: 0.21264) (accu: 0.9335)
[epoch : 11] (l_loss: 0.20665) (t_loss: 0.21267) (accu: 0.9353)
[epoch : 12] (l_loss: 0.20438) (t_loss: 0.21411) (accu: 0.9357)
[epoch : 13] (l_loss: 0.20198) (t_loss: 0.20978) (accu: 0.9347)
[epoch : 14] (l_loss: 0.20000) (t_loss: 0.20966) (accu: 0.9356)
[epoch : 15] (l_loss: 0.19836) (t_loss: 0.20809) (accu: 0.9363)
[epoch : 16] (l_loss: 0.19707) (t_loss: 0.20559) (accu: 0.9373)
[epoch : 17] (l_loss: 0.19539) (t_loss: 0.20751) (accu: 0.9376)
[epoch : 18] (l_loss: 0.19421) (t_loss: 0.20598) (accu: 0.9375)
[epoch : 19] (l_loss: 0.19315) (t_loss: 0.20431) (accu: 0.9367)
[epoch : 20] (l_loss: 0.19191) (t_loss: 0.20681) (accu: 0.9371)
[epoch : 21] (l_loss: 0.19099) (t_loss: 0.20298) (accu: 0.9376)
[epoch : 22] (l_loss: 0.18977) (t_loss: 0.20234) (accu: 0.9385)
[epoch : 23] (l_loss: 0.18915) (t_loss: 0.20310) (accu: 0.9381)
[epoch : 24] (l_loss: 0.18827) (t_loss: 0.20212) (accu: 0.9392)
[epoch : 25] (l_loss: 0.18774) (t_loss: 0.20160) (accu: 0.9409)
[epoch : 26] (l_loss: 0.18682) (t_loss: 0.20171) (accu: 0.9390)
[epoch : 27] (l_loss: 0.18620) (t_loss: 0.20039) (accu: 0.9396)
[epoch : 28] (l_loss: 0.18569) (t_loss: 0.20114) (accu: 0.9403)
[epoch : 29] (l_loss: 0.18509) (t_loss: 0.19924) (accu: 0.9407)
[epoch : 30] (l_loss: 0.18412) (t_loss: 0.20012) (accu: 0.9397)
Finish! (Best accu: 0.9409) (Time taken(sec) : 408.01) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (4927 | 261273)          1.85
fc1.weight   :       235200 (4237 | 230963)          1.80
fc2.weight   :        30000 (540 | 29460)            1.80
fcout.weight :          1000 (150 | 850)            15.00
------------------------------------------------------------
Learning start! [Prune_iter : (19/21), Remaining weight : 1.85 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.28440) (accu: 0.0978)
[epoch : 1] (l_loss: 0.97796) (t_loss: 0.40564) (accu: 0.8783)
[epoch : 2] (l_loss: 0.35449) (t_loss: 0.30380) (accu: 0.9059)
[epoch : 3] (l_loss: 0.29455) (t_loss: 0.27158) (accu: 0.9178)
[epoch : 4] (l_loss: 0.26770) (t_loss: 0.25304) (accu: 0.9232)
[epoch : 5] (l_loss: 0.25218) (t_loss: 0.24285) (accu: 0.9254)
[epoch : 6] (l_loss: 0.24210) (t_loss: 0.23592) (accu: 0.9267)
[epoch : 7] (l_loss: 0.23499) (t_loss: 0.23016) (accu: 0.9305)
[epoch : 8] (l_loss: 0.22955) (t_loss: 0.22832) (accu: 0.9281)
[epoch : 9] (l_loss: 0.22502) (t_loss: 0.22471) (accu: 0.9307)
[epoch : 10] (l_loss: 0.22152) (t_loss: 0.22386) (accu: 0.9319)
[epoch : 11] (l_loss: 0.21849) (t_loss: 0.21957) (accu: 0.9321)
[epoch : 12] (l_loss: 0.21623) (t_loss: 0.21721) (accu: 0.9318)
[epoch : 13] (l_loss: 0.21385) (t_loss: 0.21687) (accu: 0.9330)
[epoch : 14] (l_loss: 0.21174) (t_loss: 0.21811) (accu: 0.9325)
[epoch : 15] (l_loss: 0.20995) (t_loss: 0.21292) (accu: 0.9339)
[epoch : 16] (l_loss: 0.20828) (t_loss: 0.21755) (accu: 0.9325)
[epoch : 17] (l_loss: 0.20737) (t_loss: 0.21445) (accu: 0.9339)
[epoch : 18] (l_loss: 0.20588) (t_loss: 0.21095) (accu: 0.9350)
[epoch : 19] (l_loss: 0.20450) (t_loss: 0.21164) (accu: 0.9368)
[epoch : 20] (l_loss: 0.20356) (t_loss: 0.21172) (accu: 0.9352)
[epoch : 21] (l_loss: 0.20229) (t_loss: 0.20930) (accu: 0.9343)
[epoch : 22] (l_loss: 0.20178) (t_loss: 0.20848) (accu: 0.9365)
[epoch : 23] (l_loss: 0.20076) (t_loss: 0.20721) (accu: 0.9372)
[epoch : 24] (l_loss: 0.20008) (t_loss: 0.20826) (accu: 0.9375)
[epoch : 25] (l_loss: 0.19931) (t_loss: 0.20735) (accu: 0.9359)
[epoch : 26] (l_loss: 0.19860) (t_loss: 0.20966) (accu: 0.9370)
[epoch : 27] (l_loss: 0.19825) (t_loss: 0.20727) (accu: 0.9371)
[epoch : 28] (l_loss: 0.19727) (t_loss: 0.20701) (accu: 0.9365)
[epoch : 29] (l_loss: 0.19630) (t_loss: 0.20733) (accu: 0.9382)
[epoch : 30] (l_loss: 0.19586) (t_loss: 0.20605) (accu: 0.9379)
Finish! (Best accu: 0.9382) (Time taken(sec) : 404.75) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3957 | 262243)          1.49
fc1.weight   :       235200 (3390 | 231810)          1.44
fc2.weight   :        30000 (432 | 29568)            1.44
fcout.weight :          1000 (135 | 865)            13.50
------------------------------------------------------------
Learning start! [Prune_iter : (20/21), Remaining weight : 1.49 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29439) (accu: 0.0954)
[epoch : 1] (l_loss: 1.01108) (t_loss: 0.41903) (accu: 0.8754)
[epoch : 2] (l_loss: 0.36777) (t_loss: 0.31917) (accu: 0.9005)
[epoch : 3] (l_loss: 0.30945) (t_loss: 0.28854) (accu: 0.9110)
[epoch : 4] (l_loss: 0.28432) (t_loss: 0.27502) (accu: 0.9153)
[epoch : 5] (l_loss: 0.27024) (t_loss: 0.26478) (accu: 0.9174)
[epoch : 6] (l_loss: 0.25994) (t_loss: 0.25678) (accu: 0.9205)
[epoch : 7] (l_loss: 0.25285) (t_loss: 0.25259) (accu: 0.9215)
[epoch : 8] (l_loss: 0.24677) (t_loss: 0.24978) (accu: 0.9222)
[epoch : 9] (l_loss: 0.24292) (t_loss: 0.24541) (accu: 0.9235)
[epoch : 10] (l_loss: 0.23940) (t_loss: 0.24281) (accu: 0.9268)
[epoch : 11] (l_loss: 0.23666) (t_loss: 0.24212) (accu: 0.9248)
[epoch : 12] (l_loss: 0.23422) (t_loss: 0.24208) (accu: 0.9259)
[epoch : 13] (l_loss: 0.23187) (t_loss: 0.23874) (accu: 0.9270)
[epoch : 14] (l_loss: 0.23017) (t_loss: 0.23656) (accu: 0.9276)
[epoch : 15] (l_loss: 0.22827) (t_loss: 0.23689) (accu: 0.9259)
[epoch : 16] (l_loss: 0.22684) (t_loss: 0.23546) (accu: 0.9294)
[epoch : 17] (l_loss: 0.22595) (t_loss: 0.23711) (accu: 0.9271)
[epoch : 18] (l_loss: 0.22473) (t_loss: 0.23555) (accu: 0.9284)
[epoch : 19] (l_loss: 0.22348) (t_loss: 0.23503) (accu: 0.9289)
[epoch : 20] (l_loss: 0.22221) (t_loss: 0.23455) (accu: 0.9288)
[epoch : 21] (l_loss: 0.22154) (t_loss: 0.23328) (accu: 0.9289)
[epoch : 22] (l_loss: 0.22084) (t_loss: 0.23425) (accu: 0.9312)
[epoch : 23] (l_loss: 0.22017) (t_loss: 0.23201) (accu: 0.9294)
[epoch : 24] (l_loss: 0.21937) (t_loss: 0.23353) (accu: 0.9308)
[epoch : 25] (l_loss: 0.21832) (t_loss: 0.23193) (accu: 0.9298)
[epoch : 26] (l_loss: 0.21796) (t_loss: 0.23146) (accu: 0.9296)
[epoch : 27] (l_loss: 0.21756) (t_loss: 0.23256) (accu: 0.9305)
[epoch : 28] (l_loss: 0.21699) (t_loss: 0.23215) (accu: 0.9318)
[epoch : 29] (l_loss: 0.21633) (t_loss: 0.22920) (accu: 0.9296)
[epoch : 30] (l_loss: 0.21552) (t_loss: 0.23065) (accu: 0.9306)
Finish! (Best accu: 0.9318) (Time taken(sec) : 400.49) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3180 | 263020)          1.19
fc1.weight   :       235200 (2712 | 232488)          1.15
fc2.weight   :        30000 (346 | 29654)            1.15
fcout.weight :          1000 (122 | 878)            12.20
------------------------------------------------------------
Learning start! [Prune_iter : (21/21), Remaining weight : 1.19 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29458) (accu: 0.1106)
[epoch : 1] (l_loss: 1.01942) (t_loss: 0.43202) (accu: 0.8671)
[epoch : 2] (l_loss: 0.38448) (t_loss: 0.33435) (accu: 0.8957)
[epoch : 3] (l_loss: 0.32708) (t_loss: 0.30603) (accu: 0.9049)
[epoch : 4] (l_loss: 0.30187) (t_loss: 0.28822) (accu: 0.9090)
[epoch : 5] (l_loss: 0.28515) (t_loss: 0.27792) (accu: 0.9125)
[epoch : 6] (l_loss: 0.27504) (t_loss: 0.26949) (accu: 0.9139)
[epoch : 7] (l_loss: 0.26776) (t_loss: 0.26411) (accu: 0.9143)
[epoch : 8] (l_loss: 0.26219) (t_loss: 0.26402) (accu: 0.9164)
[epoch : 9] (l_loss: 0.25785) (t_loss: 0.25910) (accu: 0.9166)
[epoch : 10] (l_loss: 0.25474) (t_loss: 0.25889) (accu: 0.9185)
[epoch : 11] (l_loss: 0.25165) (t_loss: 0.25542) (accu: 0.9194)
[epoch : 12] (l_loss: 0.24959) (t_loss: 0.25544) (accu: 0.9202)
[epoch : 13] (l_loss: 0.24743) (t_loss: 0.25294) (accu: 0.9196)
[epoch : 14] (l_loss: 0.24451) (t_loss: 0.25115) (accu: 0.9215)
[epoch : 15] (l_loss: 0.24259) (t_loss: 0.24952) (accu: 0.9217)
[epoch : 16] (l_loss: 0.24119) (t_loss: 0.24917) (accu: 0.9225)
[epoch : 17] (l_loss: 0.24009) (t_loss: 0.24698) (accu: 0.9218)
[epoch : 18] (l_loss: 0.23875) (t_loss: 0.24579) (accu: 0.9224)
[epoch : 19] (l_loss: 0.23730) (t_loss: 0.24586) (accu: 0.9234)
[epoch : 20] (l_loss: 0.23655) (t_loss: 0.24506) (accu: 0.9230)
[epoch : 21] (l_loss: 0.23583) (t_loss: 0.24509) (accu: 0.9225)
[epoch : 22] (l_loss: 0.23482) (t_loss: 0.24361) (accu: 0.9227)
[epoch : 23] (l_loss: 0.23410) (t_loss: 0.24193) (accu: 0.9235)
[epoch : 24] (l_loss: 0.23318) (t_loss: 0.24428) (accu: 0.9236)
[epoch : 25] (l_loss: 0.23272) (t_loss: 0.24389) (accu: 0.9246)
[epoch : 26] (l_loss: 0.23175) (t_loss: 0.24108) (accu: 0.9240)
[epoch : 27] (l_loss: 0.23142) (t_loss: 0.23950) (accu: 0.9241)
[epoch : 28] (l_loss: 0.23096) (t_loss: 0.24274) (accu: 0.9238)
[epoch : 29] (l_loss: 0.23045) (t_loss: 0.23994) (accu: 0.9246)
[epoch : 30] (l_loss: 0.23039) (t_loss: 0.24256) (accu: 0.9237)
Finish! (Best accu: 0.9246) (Time taken(sec) : 401.66) 


Maximum accuracy per weight remaining
Remaining weight 100.0 %  Epoch 27 Accu 0.9597
Remaining weight 80.04 %  Epoch 22 Accu 0.9598
Remaining weight 64.06 %  Epoch 29 Accu 0.9593
Remaining weight 51.28 %  Epoch 29 Accu 0.9585
Remaining weight 41.05 %  Epoch 27 Accu 0.9597
Remaining weight 32.87 %  Epoch 25 Accu 0.9595
Remaining weight 26.32 %  Epoch 28 Accu 0.9581
Remaining weight 21.07 %  Epoch 27 Accu 0.9589
Remaining weight 16.88 %  Epoch 28 Accu 0.9570
Remaining weight 13.52 %  Epoch 18 Accu 0.9552
Remaining weight 10.83 %  Epoch 27 Accu 0.9572
Remaining weight 8.68 %  Epoch 27 Accu 0.9566
Remaining weight 6.95 %  Epoch 29 Accu 0.9546
Remaining weight 5.57 %  Epoch 28 Accu 0.9524
Remaining weight 4.47 %  Epoch 27 Accu 0.9500
Remaining weight 3.58 %  Epoch 24 Accu 0.9502
Remaining weight 2.87 %  Epoch 29 Accu 0.9420
Remaining weight 2.31 %  Epoch 24 Accu 0.9409
Remaining weight 1.85 %  Epoch 28 Accu 0.9382
Remaining weight 1.49 %  Epoch 27 Accu 0.9318
Remaining weight 1.19 %  Epoch 28 Accu 0.9246
===================================================================== 

Test_Iter (4/5)
------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :        266200 (266200 | 0)          100.00
fc1.weight   :        235200 (235200 | 0)          100.00
fc2.weight   :         30000 (30000 | 0)           100.00
fcout.weight :          1000 (1000 | 0)            100.00
------------------------------------------------------------
Learning start! [Prune_iter : (1/21), Remaining weight : 100.0 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69095) (accu: 0.0912)
[epoch : 1] (l_loss: 1.16998) (t_loss: 0.49326) (accu: 0.8453)
[epoch : 2] (l_loss: 0.41033) (t_loss: 0.32116) (accu: 0.8994)
[epoch : 3] (l_loss: 0.31366) (t_loss: 0.27294) (accu: 0.9141)
[epoch : 4] (l_loss: 0.27614) (t_loss: 0.25010) (accu: 0.9202)
[epoch : 5] (l_loss: 0.25483) (t_loss: 0.23856) (accu: 0.9248)
[epoch : 6] (l_loss: 0.24028) (t_loss: 0.22701) (accu: 0.9296)
[epoch : 7] (l_loss: 0.22931) (t_loss: 0.22002) (accu: 0.9312)
[epoch : 8] (l_loss: 0.22150) (t_loss: 0.21649) (accu: 0.9323)
[epoch : 9] (l_loss: 0.21511) (t_loss: 0.20986) (accu: 0.9341)
[epoch : 10] (l_loss: 0.21027) (t_loss: 0.20799) (accu: 0.9353)
[epoch : 11] (l_loss: 0.20629) (t_loss: 0.20431) (accu: 0.9370)
[epoch : 12] (l_loss: 0.20315) (t_loss: 0.20467) (accu: 0.9370)
[epoch : 13] (l_loss: 0.20004) (t_loss: 0.20071) (accu: 0.9377)
[epoch : 14] (l_loss: 0.19743) (t_loss: 0.19987) (accu: 0.9387)
[epoch : 15] (l_loss: 0.19531) (t_loss: 0.19852) (accu: 0.9392)
[epoch : 16] (l_loss: 0.19317) (t_loss: 0.19721) (accu: 0.9389)
[epoch : 17] (l_loss: 0.19161) (t_loss: 0.19557) (accu: 0.9392)
[epoch : 18] (l_loss: 0.18967) (t_loss: 0.19557) (accu: 0.9410)
[epoch : 19] (l_loss: 0.18771) (t_loss: 0.19247) (accu: 0.9405)
[epoch : 20] (l_loss: 0.18664) (t_loss: 0.19392) (accu: 0.9400)
[epoch : 21] (l_loss: 0.18525) (t_loss: 0.19330) (accu: 0.9407)
[epoch : 22] (l_loss: 0.18427) (t_loss: 0.19254) (accu: 0.9402)
[epoch : 23] (l_loss: 0.18296) (t_loss: 0.19210) (accu: 0.9416)
[epoch : 24] (l_loss: 0.18190) (t_loss: 0.19194) (accu: 0.9415)
[epoch : 25] (l_loss: 0.18085) (t_loss: 0.18928) (accu: 0.9423)
[epoch : 26] (l_loss: 0.18016) (t_loss: 0.18978) (accu: 0.9419)
[epoch : 27] (l_loss: 0.17899) (t_loss: 0.18884) (accu: 0.9421)
[epoch : 28] (l_loss: 0.17851) (t_loss: 0.18854) (accu: 0.9421)
[epoch : 29] (l_loss: 0.17748) (t_loss: 0.18764) (accu: 0.9427)
[epoch : 30] (l_loss: 0.17669) (t_loss: 0.18807) (accu: 0.9439)
Finish! (Best accu: 0.9439) (Time taken(sec) : 404.35) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (213060 | 53140)         80.04
fc1.weight   :      235200 (188160 | 47040)         80.00
fc2.weight   :        30000 (24000 | 6000)          80.00
fcout.weight :          1000 (900 | 100)            90.00
------------------------------------------------------------
Learning start! [Prune_iter : (2/21), Remaining weight : 80.04 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69590) (accu: 0.0898)
[epoch : 1] (l_loss: 1.18115) (t_loss: 0.50073) (accu: 0.8450)
[epoch : 2] (l_loss: 0.41659) (t_loss: 0.32463) (accu: 0.8966)
[epoch : 3] (l_loss: 0.31802) (t_loss: 0.27871) (accu: 0.9105)
[epoch : 4] (l_loss: 0.28040) (t_loss: 0.25596) (accu: 0.9190)
[epoch : 5] (l_loss: 0.25882) (t_loss: 0.24276) (accu: 0.9223)
[epoch : 6] (l_loss: 0.24448) (t_loss: 0.23187) (accu: 0.9261)
[epoch : 7] (l_loss: 0.23375) (t_loss: 0.22467) (accu: 0.9292)
[epoch : 8] (l_loss: 0.22557) (t_loss: 0.21875) (accu: 0.9322)
[epoch : 9] (l_loss: 0.21892) (t_loss: 0.21489) (accu: 0.9337)
[epoch : 10] (l_loss: 0.21330) (t_loss: 0.21157) (accu: 0.9349)
[epoch : 11] (l_loss: 0.20862) (t_loss: 0.20757) (accu: 0.9374)
[epoch : 12] (l_loss: 0.20506) (t_loss: 0.20446) (accu: 0.9377)
[epoch : 13] (l_loss: 0.20144) (t_loss: 0.20352) (accu: 0.9398)
[epoch : 14] (l_loss: 0.19880) (t_loss: 0.20074) (accu: 0.9394)
[epoch : 15] (l_loss: 0.19625) (t_loss: 0.19980) (accu: 0.9397)
[epoch : 16] (l_loss: 0.19359) (t_loss: 0.19868) (accu: 0.9402)
[epoch : 17] (l_loss: 0.19209) (t_loss: 0.19749) (accu: 0.9412)
[epoch : 18] (l_loss: 0.18997) (t_loss: 0.19841) (accu: 0.9411)
[epoch : 19] (l_loss: 0.18849) (t_loss: 0.19572) (accu: 0.9416)
[epoch : 20] (l_loss: 0.18727) (t_loss: 0.19433) (accu: 0.9419)
[epoch : 21] (l_loss: 0.18569) (t_loss: 0.19314) (accu: 0.9430)
[epoch : 22] (l_loss: 0.18409) (t_loss: 0.19233) (accu: 0.9435)
[epoch : 23] (l_loss: 0.18314) (t_loss: 0.19154) (accu: 0.9433)
[epoch : 24] (l_loss: 0.18234) (t_loss: 0.19087) (accu: 0.9434)
[epoch : 25] (l_loss: 0.18109) (t_loss: 0.18951) (accu: 0.9428)
[epoch : 26] (l_loss: 0.18021) (t_loss: 0.19022) (accu: 0.9423)
[epoch : 27] (l_loss: 0.17925) (t_loss: 0.18999) (accu: 0.9434)
[epoch : 28] (l_loss: 0.17833) (t_loss: 0.18755) (accu: 0.9444)
[epoch : 29] (l_loss: 0.17744) (t_loss: 0.18918) (accu: 0.9427)
[epoch : 30] (l_loss: 0.17660) (t_loss: 0.18715) (accu: 0.9430)
Finish! (Best accu: 0.9444) (Time taken(sec) : 418.31) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (170538 | 95662)         64.06
fc1.weight   :      235200 (150528 | 84672)         64.00
fc2.weight   :       30000 (19200 | 10800)          64.00
fcout.weight :          1000 (810 | 190)            81.00
------------------------------------------------------------
Learning start! [Prune_iter : (3/21), Remaining weight : 64.06 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.66969) (accu: 0.0978)
[epoch : 1] (l_loss: 1.16086) (t_loss: 0.48565) (accu: 0.8458)
[epoch : 2] (l_loss: 0.40764) (t_loss: 0.31925) (accu: 0.8998)
[epoch : 3] (l_loss: 0.31286) (t_loss: 0.27516) (accu: 0.9129)
[epoch : 4] (l_loss: 0.27497) (t_loss: 0.25387) (accu: 0.9190)
[epoch : 5] (l_loss: 0.25409) (t_loss: 0.24024) (accu: 0.9247)
[epoch : 6] (l_loss: 0.24058) (t_loss: 0.23126) (accu: 0.9265)
[epoch : 7] (l_loss: 0.23053) (t_loss: 0.22398) (accu: 0.9301)
[epoch : 8] (l_loss: 0.22289) (t_loss: 0.21910) (accu: 0.9304)
[epoch : 9] (l_loss: 0.21717) (t_loss: 0.21491) (accu: 0.9323)
[epoch : 10] (l_loss: 0.21191) (t_loss: 0.21087) (accu: 0.9334)
[epoch : 11] (l_loss: 0.20752) (t_loss: 0.20796) (accu: 0.9358)
[epoch : 12] (l_loss: 0.20415) (t_loss: 0.20568) (accu: 0.9353)
[epoch : 13] (l_loss: 0.20081) (t_loss: 0.20547) (accu: 0.9379)
[epoch : 14] (l_loss: 0.19797) (t_loss: 0.20325) (accu: 0.9381)
[epoch : 15] (l_loss: 0.19573) (t_loss: 0.20142) (accu: 0.9380)
[epoch : 16] (l_loss: 0.19358) (t_loss: 0.20078) (accu: 0.9396)
[epoch : 17] (l_loss: 0.19178) (t_loss: 0.19862) (accu: 0.9407)
[epoch : 18] (l_loss: 0.18970) (t_loss: 0.19795) (accu: 0.9396)
[epoch : 19] (l_loss: 0.18848) (t_loss: 0.19725) (accu: 0.9391)
[epoch : 20] (l_loss: 0.18671) (t_loss: 0.19690) (accu: 0.9396)
[epoch : 21] (l_loss: 0.18570) (t_loss: 0.19689) (accu: 0.9411)
[epoch : 22] (l_loss: 0.18442) (t_loss: 0.19536) (accu: 0.9413)
[epoch : 23] (l_loss: 0.18309) (t_loss: 0.19347) (accu: 0.9410)
[epoch : 24] (l_loss: 0.18228) (t_loss: 0.19400) (accu: 0.9410)
[epoch : 25] (l_loss: 0.18097) (t_loss: 0.19290) (accu: 0.9416)
[epoch : 26] (l_loss: 0.18000) (t_loss: 0.19283) (accu: 0.9426)
[epoch : 27] (l_loss: 0.17912) (t_loss: 0.19177) (accu: 0.9426)
[epoch : 28] (l_loss: 0.17819) (t_loss: 0.19066) (accu: 0.9424)
[epoch : 29] (l_loss: 0.17735) (t_loss: 0.19066) (accu: 0.9432)
[epoch : 30] (l_loss: 0.17682) (t_loss: 0.19118) (accu: 0.9432)
Finish! (Best accu: 0.9432) (Time taken(sec) : 416.59) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (136511 | 129689)        51.28
fc1.weight   :      235200 (120422 | 114778)        51.20
fc2.weight   :       30000 (15360 | 14640)          51.20
fcout.weight :          1000 (729 | 271)            72.90
------------------------------------------------------------
Learning start! [Prune_iter : (4/21), Remaining weight : 51.28 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.57575) (accu: 0.0912)
[epoch : 1] (l_loss: 1.12959) (t_loss: 0.48878) (accu: 0.8482)
[epoch : 2] (l_loss: 0.40882) (t_loss: 0.32042) (accu: 0.8958)
[epoch : 3] (l_loss: 0.31241) (t_loss: 0.27525) (accu: 0.9116)
[epoch : 4] (l_loss: 0.27539) (t_loss: 0.25211) (accu: 0.9200)
[epoch : 5] (l_loss: 0.25419) (t_loss: 0.23987) (accu: 0.9234)
[epoch : 6] (l_loss: 0.24046) (t_loss: 0.22979) (accu: 0.9284)
[epoch : 7] (l_loss: 0.23011) (t_loss: 0.22384) (accu: 0.9307)
[epoch : 8] (l_loss: 0.22260) (t_loss: 0.21962) (accu: 0.9315)
[epoch : 9] (l_loss: 0.21659) (t_loss: 0.21498) (accu: 0.9339)
[epoch : 10] (l_loss: 0.21166) (t_loss: 0.21199) (accu: 0.9362)
[epoch : 11] (l_loss: 0.20759) (t_loss: 0.20735) (accu: 0.9366)
[epoch : 12] (l_loss: 0.20409) (t_loss: 0.20579) (accu: 0.9368)
[epoch : 13] (l_loss: 0.20078) (t_loss: 0.20263) (accu: 0.9378)
[epoch : 14] (l_loss: 0.19861) (t_loss: 0.20101) (accu: 0.9382)
[epoch : 15] (l_loss: 0.19627) (t_loss: 0.20039) (accu: 0.9380)
[epoch : 16] (l_loss: 0.19379) (t_loss: 0.19938) (accu: 0.9388)
[epoch : 17] (l_loss: 0.19201) (t_loss: 0.19847) (accu: 0.9390)
[epoch : 18] (l_loss: 0.19038) (t_loss: 0.19642) (accu: 0.9396)
[epoch : 19] (l_loss: 0.18852) (t_loss: 0.19639) (accu: 0.9401)
[epoch : 20] (l_loss: 0.18707) (t_loss: 0.19386) (accu: 0.9404)
[epoch : 21] (l_loss: 0.18560) (t_loss: 0.19339) (accu: 0.9410)
[epoch : 22] (l_loss: 0.18437) (t_loss: 0.19198) (accu: 0.9406)
[epoch : 23] (l_loss: 0.18291) (t_loss: 0.19091) (accu: 0.9403)
[epoch : 24] (l_loss: 0.18207) (t_loss: 0.19078) (accu: 0.9415)
[epoch : 25] (l_loss: 0.18097) (t_loss: 0.19086) (accu: 0.9409)
[epoch : 26] (l_loss: 0.17975) (t_loss: 0.19143) (accu: 0.9415)
[epoch : 27] (l_loss: 0.17912) (t_loss: 0.18879) (accu: 0.9415)
[epoch : 28] (l_loss: 0.17808) (t_loss: 0.18774) (accu: 0.9409)
[epoch : 29] (l_loss: 0.17712) (t_loss: 0.18801) (accu: 0.9424)
[epoch : 30] (l_loss: 0.17648) (t_loss: 0.18791) (accu: 0.9426)
Finish! (Best accu: 0.9426) (Time taken(sec) : 422.47) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (109282 | 156918)        41.05
fc1.weight   :      235200 (96338 | 138862)         40.96
fc2.weight   :       30000 (12288 | 17712)          40.96
fcout.weight :          1000 (656 | 344)            65.60
------------------------------------------------------------
Learning start! [Prune_iter : (5/21), Remaining weight : 41.05 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.58332) (accu: 0.1012)
[epoch : 1] (l_loss: 1.11903) (t_loss: 0.47826) (accu: 0.8509)
[epoch : 2] (l_loss: 0.39971) (t_loss: 0.31985) (accu: 0.8981)
[epoch : 3] (l_loss: 0.30791) (t_loss: 0.27481) (accu: 0.9135)
[epoch : 4] (l_loss: 0.27268) (t_loss: 0.25330) (accu: 0.9200)
[epoch : 5] (l_loss: 0.25228) (t_loss: 0.24053) (accu: 0.9241)
[epoch : 6] (l_loss: 0.23824) (t_loss: 0.23078) (accu: 0.9277)
[epoch : 7] (l_loss: 0.22846) (t_loss: 0.22374) (accu: 0.9286)
[epoch : 8] (l_loss: 0.22091) (t_loss: 0.21768) (accu: 0.9311)
[epoch : 9] (l_loss: 0.21473) (t_loss: 0.21393) (accu: 0.9333)
[epoch : 10] (l_loss: 0.20975) (t_loss: 0.20918) (accu: 0.9337)
[epoch : 11] (l_loss: 0.20553) (t_loss: 0.20688) (accu: 0.9347)
[epoch : 12] (l_loss: 0.20172) (t_loss: 0.20523) (accu: 0.9367)
[epoch : 13] (l_loss: 0.19868) (t_loss: 0.20184) (accu: 0.9361)
[epoch : 14] (l_loss: 0.19570) (t_loss: 0.20045) (accu: 0.9369)
[epoch : 15] (l_loss: 0.19329) (t_loss: 0.19847) (accu: 0.9382)
[epoch : 16] (l_loss: 0.19118) (t_loss: 0.19716) (accu: 0.9376)
[epoch : 17] (l_loss: 0.18920) (t_loss: 0.19577) (accu: 0.9398)
[epoch : 18] (l_loss: 0.18759) (t_loss: 0.19491) (accu: 0.9406)
[epoch : 19] (l_loss: 0.18577) (t_loss: 0.19358) (accu: 0.9405)
[epoch : 20] (l_loss: 0.18446) (t_loss: 0.19157) (accu: 0.9402)
[epoch : 21] (l_loss: 0.18335) (t_loss: 0.19078) (accu: 0.9404)
[epoch : 22] (l_loss: 0.18188) (t_loss: 0.19125) (accu: 0.9409)
[epoch : 23] (l_loss: 0.18062) (t_loss: 0.18971) (accu: 0.9423)
[epoch : 24] (l_loss: 0.17993) (t_loss: 0.18792) (accu: 0.9414)
[epoch : 25] (l_loss: 0.17860) (t_loss: 0.18740) (accu: 0.9427)
[epoch : 26] (l_loss: 0.17748) (t_loss: 0.18781) (accu: 0.9414)
[epoch : 27] (l_loss: 0.17687) (t_loss: 0.18767) (accu: 0.9434)
[epoch : 28] (l_loss: 0.17593) (t_loss: 0.18783) (accu: 0.9424)
[epoch : 29] (l_loss: 0.17516) (t_loss: 0.18575) (accu: 0.9448)
[epoch : 30] (l_loss: 0.17423) (t_loss: 0.18550) (accu: 0.9432)
Finish! (Best accu: 0.9448) (Time taken(sec) : 424.22) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (87490 | 178710)         32.87
fc1.weight   :      235200 (77070 | 158130)         32.77
fc2.weight   :        30000 (9830 | 20170)          32.77
fcout.weight :          1000 (590 | 410)            59.00
------------------------------------------------------------
Learning start! [Prune_iter : (6/21), Remaining weight : 32.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.57609) (accu: 0.0914)
[epoch : 1] (l_loss: 1.12833) (t_loss: 0.45683) (accu: 0.8574)
[epoch : 2] (l_loss: 0.38106) (t_loss: 0.30999) (accu: 0.9012)
[epoch : 3] (l_loss: 0.29680) (t_loss: 0.26931) (accu: 0.9156)
[epoch : 4] (l_loss: 0.26357) (t_loss: 0.24589) (accu: 0.9237)
[epoch : 5] (l_loss: 0.24466) (t_loss: 0.23395) (accu: 0.9266)
[epoch : 6] (l_loss: 0.23179) (t_loss: 0.22637) (accu: 0.9296)
[epoch : 7] (l_loss: 0.22314) (t_loss: 0.21903) (accu: 0.9315)
[epoch : 8] (l_loss: 0.21601) (t_loss: 0.21464) (accu: 0.9323)
[epoch : 9] (l_loss: 0.21026) (t_loss: 0.21018) (accu: 0.9329)
[epoch : 10] (l_loss: 0.20591) (t_loss: 0.20865) (accu: 0.9354)
[epoch : 11] (l_loss: 0.20223) (t_loss: 0.20511) (accu: 0.9359)
[epoch : 12] (l_loss: 0.19936) (t_loss: 0.20384) (accu: 0.9359)
[epoch : 13] (l_loss: 0.19660) (t_loss: 0.20180) (accu: 0.9363)
[epoch : 14] (l_loss: 0.19422) (t_loss: 0.20091) (accu: 0.9370)
[epoch : 15] (l_loss: 0.19203) (t_loss: 0.20009) (accu: 0.9355)
[epoch : 16] (l_loss: 0.19028) (t_loss: 0.19882) (accu: 0.9392)
[epoch : 17] (l_loss: 0.18858) (t_loss: 0.19799) (accu: 0.9373)
[epoch : 18] (l_loss: 0.18722) (t_loss: 0.19552) (accu: 0.9390)
[epoch : 19] (l_loss: 0.18612) (t_loss: 0.19666) (accu: 0.9398)
[epoch : 20] (l_loss: 0.18477) (t_loss: 0.19600) (accu: 0.9381)
[epoch : 21] (l_loss: 0.18366) (t_loss: 0.19514) (accu: 0.9394)
[epoch : 22] (l_loss: 0.18283) (t_loss: 0.19298) (accu: 0.9400)
[epoch : 23] (l_loss: 0.18158) (t_loss: 0.19265) (accu: 0.9402)
[epoch : 24] (l_loss: 0.18058) (t_loss: 0.19262) (accu: 0.9394)
[epoch : 25] (l_loss: 0.18015) (t_loss: 0.19170) (accu: 0.9402)
[epoch : 26] (l_loss: 0.17876) (t_loss: 0.19193) (accu: 0.9408)
[epoch : 27] (l_loss: 0.17822) (t_loss: 0.19362) (accu: 0.9384)
[epoch : 28] (l_loss: 0.17760) (t_loss: 0.18975) (accu: 0.9417)
[epoch : 29] (l_loss: 0.17711) (t_loss: 0.18918) (accu: 0.9411)
[epoch : 30] (l_loss: 0.17663) (t_loss: 0.18850) (accu: 0.9403)
Finish! (Best accu: 0.9417) (Time taken(sec) : 429.76) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (70051 | 196149)         26.32
fc1.weight   :      235200 (61656 | 173544)         26.21
fc2.weight   :        30000 (7864 | 22136)          26.21
fcout.weight :          1000 (531 | 469)            53.10
------------------------------------------------------------
Learning start! [Prune_iter : (7/21), Remaining weight : 26.32 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.48066) (accu: 0.1095)
[epoch : 1] (l_loss: 1.11829) (t_loss: 0.45617) (accu: 0.8557)
[epoch : 2] (l_loss: 0.38084) (t_loss: 0.31263) (accu: 0.8991)
[epoch : 3] (l_loss: 0.29826) (t_loss: 0.27219) (accu: 0.9142)
[epoch : 4] (l_loss: 0.26556) (t_loss: 0.25048) (accu: 0.9212)
[epoch : 5] (l_loss: 0.24639) (t_loss: 0.23761) (accu: 0.9253)
[epoch : 6] (l_loss: 0.23342) (t_loss: 0.22994) (accu: 0.9265)
[epoch : 7] (l_loss: 0.22405) (t_loss: 0.22514) (accu: 0.9281)
[epoch : 8] (l_loss: 0.21692) (t_loss: 0.21824) (accu: 0.9318)
[epoch : 9] (l_loss: 0.21073) (t_loss: 0.21389) (accu: 0.9326)
[epoch : 10] (l_loss: 0.20632) (t_loss: 0.21010) (accu: 0.9338)
[epoch : 11] (l_loss: 0.20206) (t_loss: 0.20629) (accu: 0.9348)
[epoch : 12] (l_loss: 0.19823) (t_loss: 0.20601) (accu: 0.9359)
[epoch : 13] (l_loss: 0.19529) (t_loss: 0.20296) (accu: 0.9355)
[epoch : 14] (l_loss: 0.19276) (t_loss: 0.20217) (accu: 0.9354)
[epoch : 15] (l_loss: 0.19023) (t_loss: 0.20041) (accu: 0.9389)
[epoch : 16] (l_loss: 0.18807) (t_loss: 0.19876) (accu: 0.9385)
[epoch : 17] (l_loss: 0.18617) (t_loss: 0.19815) (accu: 0.9383)
[epoch : 18] (l_loss: 0.18484) (t_loss: 0.19632) (accu: 0.9394)
[epoch : 19] (l_loss: 0.18308) (t_loss: 0.19526) (accu: 0.9388)
[epoch : 20] (l_loss: 0.18193) (t_loss: 0.19537) (accu: 0.9403)
[epoch : 21] (l_loss: 0.18091) (t_loss: 0.19493) (accu: 0.9386)
[epoch : 22] (l_loss: 0.17962) (t_loss: 0.19311) (accu: 0.9398)
[epoch : 23] (l_loss: 0.17859) (t_loss: 0.19276) (accu: 0.9414)
[epoch : 24] (l_loss: 0.17773) (t_loss: 0.19062) (accu: 0.9414)
[epoch : 25] (l_loss: 0.17619) (t_loss: 0.19153) (accu: 0.9413)
[epoch : 26] (l_loss: 0.17589) (t_loss: 0.19014) (accu: 0.9423)
[epoch : 27] (l_loss: 0.17497) (t_loss: 0.19097) (accu: 0.9418)
[epoch : 28] (l_loss: 0.17426) (t_loss: 0.18993) (accu: 0.9429)
[epoch : 29] (l_loss: 0.17355) (t_loss: 0.18988) (accu: 0.9427)
[epoch : 30] (l_loss: 0.17288) (t_loss: 0.18793) (accu: 0.9423)
Finish! (Best accu: 0.9429) (Time taken(sec) : 426.29) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (56094 | 210106)         21.07
fc1.weight   :      235200 (49325 | 185875)         20.97
fc2.weight   :        30000 (6291 | 23709)          20.97
fcout.weight :          1000 (478 | 522)            47.80
------------------------------------------------------------
Learning start! [Prune_iter : (8/21), Remaining weight : 21.07 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.49435) (accu: 0.1048)
[epoch : 1] (l_loss: 1.11000) (t_loss: 0.44273) (accu: 0.8605)
[epoch : 2] (l_loss: 0.37093) (t_loss: 0.30761) (accu: 0.9025)
[epoch : 3] (l_loss: 0.29046) (t_loss: 0.26385) (accu: 0.9161)
[epoch : 4] (l_loss: 0.25877) (t_loss: 0.24521) (accu: 0.9226)
[epoch : 5] (l_loss: 0.24103) (t_loss: 0.23303) (accu: 0.9253)
[epoch : 6] (l_loss: 0.22903) (t_loss: 0.22448) (accu: 0.9277)
[epoch : 7] (l_loss: 0.22051) (t_loss: 0.21742) (accu: 0.9303)
[epoch : 8] (l_loss: 0.21404) (t_loss: 0.21355) (accu: 0.9332)
[epoch : 9] (l_loss: 0.20886) (t_loss: 0.21050) (accu: 0.9349)
[epoch : 10] (l_loss: 0.20442) (t_loss: 0.20793) (accu: 0.9347)
[epoch : 11] (l_loss: 0.20060) (t_loss: 0.20525) (accu: 0.9347)
[epoch : 12] (l_loss: 0.19779) (t_loss: 0.20302) (accu: 0.9358)
[epoch : 13] (l_loss: 0.19511) (t_loss: 0.20169) (accu: 0.9362)
[epoch : 14] (l_loss: 0.19237) (t_loss: 0.19911) (accu: 0.9367)
[epoch : 15] (l_loss: 0.19046) (t_loss: 0.19833) (accu: 0.9373)
[epoch : 16] (l_loss: 0.18814) (t_loss: 0.19763) (accu: 0.9384)
[epoch : 17] (l_loss: 0.18653) (t_loss: 0.19651) (accu: 0.9375)
[epoch : 18] (l_loss: 0.18502) (t_loss: 0.19541) (accu: 0.9403)
[epoch : 19] (l_loss: 0.18331) (t_loss: 0.19357) (accu: 0.9383)
[epoch : 20] (l_loss: 0.18197) (t_loss: 0.19313) (accu: 0.9389)
[epoch : 21] (l_loss: 0.18080) (t_loss: 0.19039) (accu: 0.9409)
[epoch : 22] (l_loss: 0.17944) (t_loss: 0.19010) (accu: 0.9407)
[epoch : 23] (l_loss: 0.17862) (t_loss: 0.19012) (accu: 0.9408)
[epoch : 24] (l_loss: 0.17752) (t_loss: 0.18846) (accu: 0.9414)
[epoch : 25] (l_loss: 0.17684) (t_loss: 0.18962) (accu: 0.9403)
[epoch : 26] (l_loss: 0.17592) (t_loss: 0.18732) (accu: 0.9424)
[epoch : 27] (l_loss: 0.17515) (t_loss: 0.18679) (accu: 0.9425)
[epoch : 28] (l_loss: 0.17412) (t_loss: 0.18571) (accu: 0.9426)
[epoch : 29] (l_loss: 0.17344) (t_loss: 0.18565) (accu: 0.9431)
[epoch : 30] (l_loss: 0.17314) (t_loss: 0.18364) (accu: 0.9448)
Finish! (Best accu: 0.9448) (Time taken(sec) : 421.85) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (44923 | 221277)         16.88
fc1.weight   :      235200 (39460 | 195740)         16.78
fc2.weight   :        30000 (5033 | 24967)          16.78
fcout.weight :          1000 (430 | 570)            43.00
------------------------------------------------------------
Learning start! [Prune_iter : (9/21), Remaining weight : 16.88 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.43599) (accu: 0.0928)
[epoch : 1] (l_loss: 1.05742) (t_loss: 0.43749) (accu: 0.8648)
[epoch : 2] (l_loss: 0.37544) (t_loss: 0.31581) (accu: 0.9026)
[epoch : 3] (l_loss: 0.30327) (t_loss: 0.27604) (accu: 0.9147)
[epoch : 4] (l_loss: 0.27212) (t_loss: 0.25510) (accu: 0.9209)
[epoch : 5] (l_loss: 0.25332) (t_loss: 0.24182) (accu: 0.9244)
[epoch : 6] (l_loss: 0.24051) (t_loss: 0.23190) (accu: 0.9284)
[epoch : 7] (l_loss: 0.23121) (t_loss: 0.22551) (accu: 0.9305)
[epoch : 8] (l_loss: 0.22412) (t_loss: 0.22008) (accu: 0.9332)
[epoch : 9] (l_loss: 0.21834) (t_loss: 0.21474) (accu: 0.9340)
[epoch : 10] (l_loss: 0.21334) (t_loss: 0.21220) (accu: 0.9337)
[epoch : 11] (l_loss: 0.20948) (t_loss: 0.20940) (accu: 0.9365)
[epoch : 12] (l_loss: 0.20614) (t_loss: 0.20767) (accu: 0.9369)
[epoch : 13] (l_loss: 0.20328) (t_loss: 0.20617) (accu: 0.9362)
[epoch : 14] (l_loss: 0.20061) (t_loss: 0.20423) (accu: 0.9380)
[epoch : 15] (l_loss: 0.19817) (t_loss: 0.20278) (accu: 0.9382)
[epoch : 16] (l_loss: 0.19619) (t_loss: 0.20221) (accu: 0.9390)
[epoch : 17] (l_loss: 0.19453) (t_loss: 0.20054) (accu: 0.9398)
[epoch : 18] (l_loss: 0.19263) (t_loss: 0.19851) (accu: 0.9389)
[epoch : 19] (l_loss: 0.19114) (t_loss: 0.19907) (accu: 0.9389)
[epoch : 20] (l_loss: 0.18990) (t_loss: 0.19770) (accu: 0.9409)
[epoch : 21] (l_loss: 0.18846) (t_loss: 0.19644) (accu: 0.9397)
[epoch : 22] (l_loss: 0.18720) (t_loss: 0.19636) (accu: 0.9405)
[epoch : 23] (l_loss: 0.18631) (t_loss: 0.19624) (accu: 0.9414)
[epoch : 24] (l_loss: 0.18510) (t_loss: 0.19554) (accu: 0.9409)
[epoch : 25] (l_loss: 0.18407) (t_loss: 0.19666) (accu: 0.9413)
[epoch : 26] (l_loss: 0.18302) (t_loss: 0.19432) (accu: 0.9415)
[epoch : 27] (l_loss: 0.18237) (t_loss: 0.19363) (accu: 0.9417)
[epoch : 28] (l_loss: 0.18182) (t_loss: 0.19348) (accu: 0.9414)
[epoch : 29] (l_loss: 0.18094) (t_loss: 0.19375) (accu: 0.9421)
[epoch : 30] (l_loss: 0.18024) (t_loss: 0.19402) (accu: 0.9430)
Finish! (Best accu: 0.9430) (Time taken(sec) : 413.07) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (35982 | 230218)         13.52
fc1.weight   :      235200 (31568 | 203632)         13.42
fc2.weight   :        30000 (4027 | 25973)          13.42
fcout.weight :          1000 (387 | 613)            38.70
------------------------------------------------------------
Learning start! [Prune_iter : (10/21), Remaining weight : 13.52 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.39134) (accu: 0.0933)
[epoch : 1] (l_loss: 1.03030) (t_loss: 0.41959) (accu: 0.8757)
[epoch : 2] (l_loss: 0.36411) (t_loss: 0.31557) (accu: 0.9030)
[epoch : 3] (l_loss: 0.29640) (t_loss: 0.27798) (accu: 0.9141)
[epoch : 4] (l_loss: 0.26529) (t_loss: 0.25774) (accu: 0.9202)
[epoch : 5] (l_loss: 0.24694) (t_loss: 0.24495) (accu: 0.9223)
[epoch : 6] (l_loss: 0.23475) (t_loss: 0.23487) (accu: 0.9286)
[epoch : 7] (l_loss: 0.22554) (t_loss: 0.23077) (accu: 0.9292)
[epoch : 8] (l_loss: 0.21834) (t_loss: 0.22279) (accu: 0.9317)
[epoch : 9] (l_loss: 0.21276) (t_loss: 0.21727) (accu: 0.9336)
[epoch : 10] (l_loss: 0.20811) (t_loss: 0.21407) (accu: 0.9339)
[epoch : 11] (l_loss: 0.20411) (t_loss: 0.21128) (accu: 0.9354)
[epoch : 12] (l_loss: 0.20038) (t_loss: 0.20811) (accu: 0.9362)
[epoch : 13] (l_loss: 0.19764) (t_loss: 0.20620) (accu: 0.9376)
[epoch : 14] (l_loss: 0.19521) (t_loss: 0.20310) (accu: 0.9389)
[epoch : 15] (l_loss: 0.19298) (t_loss: 0.20276) (accu: 0.9397)
[epoch : 16] (l_loss: 0.19105) (t_loss: 0.20059) (accu: 0.9389)
[epoch : 17] (l_loss: 0.18928) (t_loss: 0.19860) (accu: 0.9384)
[epoch : 18] (l_loss: 0.18749) (t_loss: 0.19877) (accu: 0.9405)
[epoch : 19] (l_loss: 0.18594) (t_loss: 0.19663) (accu: 0.9418)
[epoch : 20] (l_loss: 0.18482) (t_loss: 0.19510) (accu: 0.9411)
[epoch : 21] (l_loss: 0.18320) (t_loss: 0.19471) (accu: 0.9413)
[epoch : 22] (l_loss: 0.18229) (t_loss: 0.19214) (accu: 0.9421)
[epoch : 23] (l_loss: 0.18114) (t_loss: 0.19424) (accu: 0.9421)
[epoch : 24] (l_loss: 0.18017) (t_loss: 0.19304) (accu: 0.9417)
[epoch : 25] (l_loss: 0.17913) (t_loss: 0.19387) (accu: 0.9421)
[epoch : 26] (l_loss: 0.17844) (t_loss: 0.19075) (accu: 0.9430)
[epoch : 27] (l_loss: 0.17753) (t_loss: 0.19046) (accu: 0.9432)
[epoch : 28] (l_loss: 0.17721) (t_loss: 0.19014) (accu: 0.9429)
[epoch : 29] (l_loss: 0.17623) (t_loss: 0.19065) (accu: 0.9448)
[epoch : 30] (l_loss: 0.17591) (t_loss: 0.18969) (accu: 0.9447)
Finish! (Best accu: 0.9448) (Time taken(sec) : 406.71) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (28824 | 237376)         10.83
fc1.weight   :      235200 (25254 | 209946)         10.74
fc2.weight   :        30000 (3221 | 26779)          10.74
fcout.weight :          1000 (349 | 651)            34.90
------------------------------------------------------------
Learning start! [Prune_iter : (11/21), Remaining weight : 10.83 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.34725) (accu: 0.1003)
[epoch : 1] (l_loss: 1.03534) (t_loss: 0.42195) (accu: 0.8723)
[epoch : 2] (l_loss: 0.36618) (t_loss: 0.31494) (accu: 0.9018)
[epoch : 3] (l_loss: 0.29838) (t_loss: 0.27768) (accu: 0.9136)
[epoch : 4] (l_loss: 0.26683) (t_loss: 0.25824) (accu: 0.9211)
[epoch : 5] (l_loss: 0.24780) (t_loss: 0.24656) (accu: 0.9244)
[epoch : 6] (l_loss: 0.23460) (t_loss: 0.23622) (accu: 0.9279)
[epoch : 7] (l_loss: 0.22481) (t_loss: 0.23002) (accu: 0.9289)
[epoch : 8] (l_loss: 0.21700) (t_loss: 0.22266) (accu: 0.9323)
[epoch : 9] (l_loss: 0.21078) (t_loss: 0.21839) (accu: 0.9323)
[epoch : 10] (l_loss: 0.20567) (t_loss: 0.21509) (accu: 0.9349)
[epoch : 11] (l_loss: 0.20181) (t_loss: 0.21435) (accu: 0.9361)
[epoch : 12] (l_loss: 0.19838) (t_loss: 0.21020) (accu: 0.9371)
[epoch : 13] (l_loss: 0.19601) (t_loss: 0.21078) (accu: 0.9366)
[epoch : 14] (l_loss: 0.19359) (t_loss: 0.20844) (accu: 0.9373)
[epoch : 15] (l_loss: 0.19176) (t_loss: 0.20910) (accu: 0.9372)
[epoch : 16] (l_loss: 0.18993) (t_loss: 0.20526) (accu: 0.9395)
[epoch : 17] (l_loss: 0.18845) (t_loss: 0.20464) (accu: 0.9394)
[epoch : 18] (l_loss: 0.18707) (t_loss: 0.20459) (accu: 0.9397)
[epoch : 19] (l_loss: 0.18609) (t_loss: 0.20422) (accu: 0.9395)
[epoch : 20] (l_loss: 0.18474) (t_loss: 0.20210) (accu: 0.9394)
[epoch : 21] (l_loss: 0.18369) (t_loss: 0.20140) (accu: 0.9412)
[epoch : 22] (l_loss: 0.18266) (t_loss: 0.20112) (accu: 0.9405)
[epoch : 23] (l_loss: 0.18176) (t_loss: 0.20003) (accu: 0.9406)
[epoch : 24] (l_loss: 0.18061) (t_loss: 0.20184) (accu: 0.9412)
[epoch : 25] (l_loss: 0.18019) (t_loss: 0.20001) (accu: 0.9407)
[epoch : 26] (l_loss: 0.17974) (t_loss: 0.20027) (accu: 0.9413)
[epoch : 27] (l_loss: 0.17897) (t_loss: 0.19919) (accu: 0.9417)
[epoch : 28] (l_loss: 0.17836) (t_loss: 0.19814) (accu: 0.9427)
[epoch : 29] (l_loss: 0.17759) (t_loss: 0.19936) (accu: 0.9424)
[epoch : 30] (l_loss: 0.17704) (t_loss: 0.19791) (accu: 0.9429)
Finish! (Best accu: 0.9429) (Time taken(sec) : 414.53) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (23095 | 243105)          8.68
fc1.weight   :      235200 (20204 | 214996)          8.59
fc2.weight   :        30000 (2577 | 27423)           8.59
fcout.weight :          1000 (314 | 686)            31.40
------------------------------------------------------------
Learning start! [Prune_iter : (12/21), Remaining weight : 8.68 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32799) (accu: 0.1027)
[epoch : 1] (l_loss: 1.02671) (t_loss: 0.43199) (accu: 0.8685)
[epoch : 2] (l_loss: 0.37333) (t_loss: 0.32800) (accu: 0.8963)
[epoch : 3] (l_loss: 0.30645) (t_loss: 0.29307) (accu: 0.9077)
[epoch : 4] (l_loss: 0.27733) (t_loss: 0.27418) (accu: 0.9147)
[epoch : 5] (l_loss: 0.25943) (t_loss: 0.26236) (accu: 0.9173)
[epoch : 6] (l_loss: 0.24662) (t_loss: 0.25178) (accu: 0.9225)
[epoch : 7] (l_loss: 0.23753) (t_loss: 0.24346) (accu: 0.9249)
[epoch : 8] (l_loss: 0.22988) (t_loss: 0.23807) (accu: 0.9272)
[epoch : 9] (l_loss: 0.22362) (t_loss: 0.23317) (accu: 0.9289)
[epoch : 10] (l_loss: 0.21826) (t_loss: 0.22747) (accu: 0.9308)
[epoch : 11] (l_loss: 0.21375) (t_loss: 0.22411) (accu: 0.9320)
[epoch : 12] (l_loss: 0.21024) (t_loss: 0.22078) (accu: 0.9331)
[epoch : 13] (l_loss: 0.20701) (t_loss: 0.21812) (accu: 0.9351)
[epoch : 14] (l_loss: 0.20418) (t_loss: 0.21582) (accu: 0.9346)
[epoch : 15] (l_loss: 0.20205) (t_loss: 0.21443) (accu: 0.9354)
[epoch : 16] (l_loss: 0.19985) (t_loss: 0.21177) (accu: 0.9370)
[epoch : 17] (l_loss: 0.19791) (t_loss: 0.20918) (accu: 0.9367)
[epoch : 18] (l_loss: 0.19663) (t_loss: 0.21027) (accu: 0.9370)
[epoch : 19] (l_loss: 0.19469) (t_loss: 0.20927) (accu: 0.9363)
[epoch : 20] (l_loss: 0.19309) (t_loss: 0.20921) (accu: 0.9361)
[epoch : 21] (l_loss: 0.19207) (t_loss: 0.20654) (accu: 0.9361)
[epoch : 22] (l_loss: 0.19087) (t_loss: 0.20449) (accu: 0.9385)
[epoch : 23] (l_loss: 0.18949) (t_loss: 0.20277) (accu: 0.9403)
[epoch : 24] (l_loss: 0.18859) (t_loss: 0.20174) (accu: 0.9383)
[epoch : 25] (l_loss: 0.18744) (t_loss: 0.20093) (accu: 0.9399)
[epoch : 26] (l_loss: 0.18668) (t_loss: 0.20082) (accu: 0.9381)
[epoch : 27] (l_loss: 0.18589) (t_loss: 0.19952) (accu: 0.9401)
[epoch : 28] (l_loss: 0.18524) (t_loss: 0.19800) (accu: 0.9402)
[epoch : 29] (l_loss: 0.18420) (t_loss: 0.19943) (accu: 0.9393)
[epoch : 30] (l_loss: 0.18353) (t_loss: 0.19891) (accu: 0.9403)
Finish! (Best accu: 0.9403) (Time taken(sec) : 428.09) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (18507 | 247693)          6.95
fc1.weight   :      235200 (16163 | 219037)          6.87
fc2.weight   :        30000 (2062 | 27938)           6.87
fcout.weight :          1000 (282 | 718)            28.20
------------------------------------------------------------
Learning start! [Prune_iter : (13/21), Remaining weight : 6.95 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29143) (accu: 0.1237)
[epoch : 1] (l_loss: 1.04512) (t_loss: 0.44453) (accu: 0.8679)
[epoch : 2] (l_loss: 0.38915) (t_loss: 0.33173) (accu: 0.8966)
[epoch : 3] (l_loss: 0.31589) (t_loss: 0.29167) (accu: 0.9062)
[epoch : 4] (l_loss: 0.28430) (t_loss: 0.27128) (accu: 0.9147)
[epoch : 5] (l_loss: 0.26662) (t_loss: 0.25755) (accu: 0.9204)
[epoch : 6] (l_loss: 0.25471) (t_loss: 0.25076) (accu: 0.9233)
[epoch : 7] (l_loss: 0.24596) (t_loss: 0.24259) (accu: 0.9249)
[epoch : 8] (l_loss: 0.23929) (t_loss: 0.23739) (accu: 0.9280)
[epoch : 9] (l_loss: 0.23423) (t_loss: 0.23294) (accu: 0.9298)
[epoch : 10] (l_loss: 0.23005) (t_loss: 0.22915) (accu: 0.9302)
[epoch : 11] (l_loss: 0.22628) (t_loss: 0.22633) (accu: 0.9308)
[epoch : 12] (l_loss: 0.22348) (t_loss: 0.22381) (accu: 0.9326)
[epoch : 13] (l_loss: 0.22088) (t_loss: 0.22139) (accu: 0.9329)
[epoch : 14] (l_loss: 0.21846) (t_loss: 0.21952) (accu: 0.9338)
[epoch : 15] (l_loss: 0.21634) (t_loss: 0.21673) (accu: 0.9333)
[epoch : 16] (l_loss: 0.21455) (t_loss: 0.21534) (accu: 0.9348)
[epoch : 17] (l_loss: 0.21277) (t_loss: 0.21348) (accu: 0.9349)
[epoch : 18] (l_loss: 0.21149) (t_loss: 0.21386) (accu: 0.9356)
[epoch : 19] (l_loss: 0.21011) (t_loss: 0.21197) (accu: 0.9363)
[epoch : 20] (l_loss: 0.20866) (t_loss: 0.21145) (accu: 0.9349)
[epoch : 21] (l_loss: 0.20798) (t_loss: 0.20874) (accu: 0.9372)
[epoch : 22] (l_loss: 0.20655) (t_loss: 0.20857) (accu: 0.9370)
[epoch : 23] (l_loss: 0.20558) (t_loss: 0.20845) (accu: 0.9376)
[epoch : 24] (l_loss: 0.20479) (t_loss: 0.20697) (accu: 0.9360)
[epoch : 25] (l_loss: 0.20412) (t_loss: 0.20734) (accu: 0.9363)
[epoch : 26] (l_loss: 0.20303) (t_loss: 0.20653) (accu: 0.9368)
[epoch : 27] (l_loss: 0.20233) (t_loss: 0.20587) (accu: 0.9383)
[epoch : 28] (l_loss: 0.20178) (t_loss: 0.20580) (accu: 0.9374)
[epoch : 29] (l_loss: 0.20081) (t_loss: 0.20606) (accu: 0.9387)
[epoch : 30] (l_loss: 0.20057) (t_loss: 0.20581) (accu: 0.9382)
Finish! (Best accu: 0.9387) (Time taken(sec) : 427.77) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (14833 | 251367)          5.57
fc1.weight   :      235200 (12930 | 222270)          5.50
fc2.weight   :        30000 (1649 | 28351)           5.50
fcout.weight :          1000 (254 | 746)            25.40
------------------------------------------------------------
Learning start! [Prune_iter : (14/21), Remaining weight : 5.57 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32235) (accu: 0.1042)
[epoch : 1] (l_loss: 1.07712) (t_loss: 0.46229) (accu: 0.8650)
[epoch : 2] (l_loss: 0.40554) (t_loss: 0.35002) (accu: 0.8938)
[epoch : 3] (l_loss: 0.33470) (t_loss: 0.30966) (accu: 0.9048)
[epoch : 4] (l_loss: 0.30249) (t_loss: 0.28759) (accu: 0.9101)
[epoch : 5] (l_loss: 0.28290) (t_loss: 0.27390) (accu: 0.9125)
[epoch : 6] (l_loss: 0.27083) (t_loss: 0.26248) (accu: 0.9181)
[epoch : 7] (l_loss: 0.26144) (t_loss: 0.25623) (accu: 0.9196)
[epoch : 8] (l_loss: 0.25408) (t_loss: 0.24947) (accu: 0.9204)
[epoch : 9] (l_loss: 0.24879) (t_loss: 0.24560) (accu: 0.9230)
[epoch : 10] (l_loss: 0.24356) (t_loss: 0.24154) (accu: 0.9244)
[epoch : 11] (l_loss: 0.23946) (t_loss: 0.23970) (accu: 0.9263)
[epoch : 12] (l_loss: 0.23592) (t_loss: 0.23451) (accu: 0.9281)
[epoch : 13] (l_loss: 0.23286) (t_loss: 0.23229) (accu: 0.9289)
[epoch : 14] (l_loss: 0.22975) (t_loss: 0.23010) (accu: 0.9301)
[epoch : 15] (l_loss: 0.22743) (t_loss: 0.22863) (accu: 0.9305)
[epoch : 16] (l_loss: 0.22495) (t_loss: 0.22750) (accu: 0.9317)
[epoch : 17] (l_loss: 0.22303) (t_loss: 0.22597) (accu: 0.9326)
[epoch : 18] (l_loss: 0.22112) (t_loss: 0.22480) (accu: 0.9319)
[epoch : 19] (l_loss: 0.22009) (t_loss: 0.22170) (accu: 0.9332)
[epoch : 20] (l_loss: 0.21843) (t_loss: 0.22032) (accu: 0.9330)
[epoch : 21] (l_loss: 0.21693) (t_loss: 0.22037) (accu: 0.9341)
[epoch : 22] (l_loss: 0.21572) (t_loss: 0.21872) (accu: 0.9346)
[epoch : 23] (l_loss: 0.21500) (t_loss: 0.21881) (accu: 0.9353)
[epoch : 24] (l_loss: 0.21392) (t_loss: 0.21665) (accu: 0.9362)
[epoch : 25] (l_loss: 0.21268) (t_loss: 0.21895) (accu: 0.9343)
[epoch : 26] (l_loss: 0.21180) (t_loss: 0.21525) (accu: 0.9362)
[epoch : 27] (l_loss: 0.21090) (t_loss: 0.21666) (accu: 0.9350)
[epoch : 28] (l_loss: 0.21059) (t_loss: 0.21469) (accu: 0.9357)
[epoch : 29] (l_loss: 0.20937) (t_loss: 0.21566) (accu: 0.9353)
[epoch : 30] (l_loss: 0.20869) (t_loss: 0.21349) (accu: 0.9358)
Finish! (Best accu: 0.9362) (Time taken(sec) : 439.66) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (11892 | 254308)          4.47
fc1.weight   :      235200 (10344 | 224856)          4.40
fc2.weight   :        30000 (1319 | 28681)           4.40
fcout.weight :          1000 (229 | 771)            22.90
------------------------------------------------------------
Learning start! [Prune_iter : (15/21), Remaining weight : 4.47 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32319) (accu: 0.0709)
[epoch : 1] (l_loss: 1.10477) (t_loss: 0.48155) (accu: 0.8545)
[epoch : 2] (l_loss: 0.43085) (t_loss: 0.36228) (accu: 0.8885)
[epoch : 3] (l_loss: 0.35004) (t_loss: 0.31498) (accu: 0.9023)
[epoch : 4] (l_loss: 0.31367) (t_loss: 0.29074) (accu: 0.9112)
[epoch : 5] (l_loss: 0.29287) (t_loss: 0.27537) (accu: 0.9166)
[epoch : 6] (l_loss: 0.27962) (t_loss: 0.26812) (accu: 0.9186)
[epoch : 7] (l_loss: 0.26962) (t_loss: 0.25924) (accu: 0.9218)
[epoch : 8] (l_loss: 0.26162) (t_loss: 0.25198) (accu: 0.9244)
[epoch : 9] (l_loss: 0.25598) (t_loss: 0.24807) (accu: 0.9259)
[epoch : 10] (l_loss: 0.25056) (t_loss: 0.24507) (accu: 0.9268)
[epoch : 11] (l_loss: 0.24603) (t_loss: 0.24169) (accu: 0.9270)
[epoch : 12] (l_loss: 0.24267) (t_loss: 0.24080) (accu: 0.9278)
[epoch : 13] (l_loss: 0.23928) (t_loss: 0.23856) (accu: 0.9294)
[epoch : 14] (l_loss: 0.23637) (t_loss: 0.23450) (accu: 0.9307)
[epoch : 15] (l_loss: 0.23425) (t_loss: 0.23480) (accu: 0.9289)
[epoch : 16] (l_loss: 0.23194) (t_loss: 0.23218) (accu: 0.9303)
[epoch : 17] (l_loss: 0.23006) (t_loss: 0.22983) (accu: 0.9307)
[epoch : 18] (l_loss: 0.22843) (t_loss: 0.23022) (accu: 0.9300)
[epoch : 19] (l_loss: 0.22723) (t_loss: 0.22899) (accu: 0.9291)
[epoch : 20] (l_loss: 0.22590) (t_loss: 0.22838) (accu: 0.9314)
[epoch : 21] (l_loss: 0.22477) (t_loss: 0.22770) (accu: 0.9314)
[epoch : 22] (l_loss: 0.22341) (t_loss: 0.22654) (accu: 0.9313)
[epoch : 23] (l_loss: 0.22246) (t_loss: 0.22771) (accu: 0.9307)
[epoch : 24] (l_loss: 0.22163) (t_loss: 0.22579) (accu: 0.9315)
[epoch : 25] (l_loss: 0.22090) (t_loss: 0.22608) (accu: 0.9313)
[epoch : 26] (l_loss: 0.22021) (t_loss: 0.22641) (accu: 0.9314)
[epoch : 27] (l_loss: 0.21923) (t_loss: 0.22781) (accu: 0.9309)
[epoch : 28] (l_loss: 0.21856) (t_loss: 0.22526) (accu: 0.9311)
[epoch : 29] (l_loss: 0.21763) (t_loss: 0.22348) (accu: 0.9317)
[epoch : 30] (l_loss: 0.21737) (t_loss: 0.22449) (accu: 0.9311)
Finish! (Best accu: 0.9317) (Time taken(sec) : 434.07) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (9537 | 256663)          3.58
fc1.weight   :       235200 (8275 | 226925)          3.52
fc2.weight   :        30000 (1056 | 28944)           3.52
fcout.weight :          1000 (206 | 794)            20.60
------------------------------------------------------------
Learning start! [Prune_iter : (16/21), Remaining weight : 3.58 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32151) (accu: 0.1032)
[epoch : 1] (l_loss: 1.11308) (t_loss: 0.49302) (accu: 0.8484)
[epoch : 2] (l_loss: 0.43984) (t_loss: 0.37870) (accu: 0.8815)
[epoch : 3] (l_loss: 0.36411) (t_loss: 0.33611) (accu: 0.8938)
[epoch : 4] (l_loss: 0.33055) (t_loss: 0.31445) (accu: 0.9016)
[epoch : 5] (l_loss: 0.31168) (t_loss: 0.29994) (accu: 0.9067)
[epoch : 6] (l_loss: 0.29842) (t_loss: 0.29221) (accu: 0.9087)
[epoch : 7] (l_loss: 0.28915) (t_loss: 0.28537) (accu: 0.9122)
[epoch : 8] (l_loss: 0.28191) (t_loss: 0.27945) (accu: 0.9120)
[epoch : 9] (l_loss: 0.27579) (t_loss: 0.27348) (accu: 0.9140)
[epoch : 10] (l_loss: 0.27102) (t_loss: 0.26896) (accu: 0.9160)
[epoch : 11] (l_loss: 0.26684) (t_loss: 0.26734) (accu: 0.9173)
[epoch : 12] (l_loss: 0.26347) (t_loss: 0.26499) (accu: 0.9184)
[epoch : 13] (l_loss: 0.26070) (t_loss: 0.26254) (accu: 0.9184)
[epoch : 14] (l_loss: 0.25774) (t_loss: 0.26083) (accu: 0.9195)
[epoch : 15] (l_loss: 0.25569) (t_loss: 0.25878) (accu: 0.9210)
[epoch : 16] (l_loss: 0.25352) (t_loss: 0.25742) (accu: 0.9215)
[epoch : 17] (l_loss: 0.25196) (t_loss: 0.25761) (accu: 0.9219)
[epoch : 18] (l_loss: 0.25052) (t_loss: 0.25691) (accu: 0.9225)
[epoch : 19] (l_loss: 0.24877) (t_loss: 0.25519) (accu: 0.9217)
[epoch : 20] (l_loss: 0.24787) (t_loss: 0.25343) (accu: 0.9223)
[epoch : 21] (l_loss: 0.24670) (t_loss: 0.25558) (accu: 0.9226)
[epoch : 22] (l_loss: 0.24584) (t_loss: 0.25218) (accu: 0.9232)
[epoch : 23] (l_loss: 0.24452) (t_loss: 0.25201) (accu: 0.9225)
[epoch : 24] (l_loss: 0.24366) (t_loss: 0.25246) (accu: 0.9233)
[epoch : 25] (l_loss: 0.24278) (t_loss: 0.25265) (accu: 0.9227)
[epoch : 26] (l_loss: 0.24188) (t_loss: 0.25246) (accu: 0.9251)
[epoch : 27] (l_loss: 0.24101) (t_loss: 0.25191) (accu: 0.9239)
[epoch : 28] (l_loss: 0.24076) (t_loss: 0.24941) (accu: 0.9237)
[epoch : 29] (l_loss: 0.24029) (t_loss: 0.25442) (accu: 0.9248)
[epoch : 30] (l_loss: 0.23973) (t_loss: 0.24855) (accu: 0.9246)
Finish! (Best accu: 0.9251) (Time taken(sec) : 439.81) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (7649 | 258551)          2.87
fc1.weight   :       235200 (6620 | 228580)          2.81
fc2.weight   :        30000 (844 | 29156)            2.81
fcout.weight :          1000 (185 | 815)            18.50
------------------------------------------------------------
Learning start! [Prune_iter : (17/21), Remaining weight : 2.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.31652) (accu: 0.0907)
[epoch : 1] (l_loss: 1.13619) (t_loss: 0.50115) (accu: 0.8557)
[epoch : 2] (l_loss: 0.44323) (t_loss: 0.38466) (accu: 0.8834)
[epoch : 3] (l_loss: 0.37178) (t_loss: 0.34389) (accu: 0.8945)
[epoch : 4] (l_loss: 0.34062) (t_loss: 0.32374) (accu: 0.9006)
[epoch : 5] (l_loss: 0.32226) (t_loss: 0.31102) (accu: 0.9050)
[epoch : 6] (l_loss: 0.30981) (t_loss: 0.30301) (accu: 0.9083)
[epoch : 7] (l_loss: 0.30115) (t_loss: 0.29435) (accu: 0.9089)
[epoch : 8] (l_loss: 0.29449) (t_loss: 0.28890) (accu: 0.9119)
[epoch : 9] (l_loss: 0.28892) (t_loss: 0.28345) (accu: 0.9118)
[epoch : 10] (l_loss: 0.28410) (t_loss: 0.28168) (accu: 0.9126)
[epoch : 11] (l_loss: 0.28061) (t_loss: 0.27898) (accu: 0.9149)
[epoch : 12] (l_loss: 0.27739) (t_loss: 0.27736) (accu: 0.9161)
[epoch : 13] (l_loss: 0.27449) (t_loss: 0.27639) (accu: 0.9161)
[epoch : 14] (l_loss: 0.27227) (t_loss: 0.27349) (accu: 0.9163)
[epoch : 15] (l_loss: 0.27013) (t_loss: 0.27188) (accu: 0.9154)
[epoch : 16] (l_loss: 0.26778) (t_loss: 0.27429) (accu: 0.9168)
[epoch : 17] (l_loss: 0.26672) (t_loss: 0.27081) (accu: 0.9176)
[epoch : 18] (l_loss: 0.26496) (t_loss: 0.26791) (accu: 0.9175)
[epoch : 19] (l_loss: 0.26370) (t_loss: 0.26825) (accu: 0.9194)
[epoch : 20] (l_loss: 0.26249) (t_loss: 0.26686) (accu: 0.9179)
[epoch : 21] (l_loss: 0.26147) (t_loss: 0.26570) (accu: 0.9177)
[epoch : 22] (l_loss: 0.26020) (t_loss: 0.26483) (accu: 0.9188)
[epoch : 23] (l_loss: 0.25931) (t_loss: 0.26609) (accu: 0.9212)
[epoch : 24] (l_loss: 0.25844) (t_loss: 0.26454) (accu: 0.9196)
[epoch : 25] (l_loss: 0.25755) (t_loss: 0.26279) (accu: 0.9210)
[epoch : 26] (l_loss: 0.25663) (t_loss: 0.26269) (accu: 0.9210)
[epoch : 27] (l_loss: 0.25575) (t_loss: 0.26382) (accu: 0.9206)
[epoch : 28] (l_loss: 0.25547) (t_loss: 0.26297) (accu: 0.9204)
[epoch : 29] (l_loss: 0.25458) (t_loss: 0.26256) (accu: 0.9193)
[epoch : 30] (l_loss: 0.25383) (t_loss: 0.26162) (accu: 0.9205)
Finish! (Best accu: 0.9212) (Time taken(sec) : 426.19) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (6139 | 260061)          2.31
fc1.weight   :       235200 (5296 | 229904)          2.25
fc2.weight   :        30000 (676 | 29324)            2.25
fcout.weight :          1000 (167 | 833)            16.70
------------------------------------------------------------
Learning start! [Prune_iter : (18/21), Remaining weight : 2.31 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.31491) (accu: 0.0901)
[epoch : 1] (l_loss: 1.14314) (t_loss: 0.51950) (accu: 0.8474)
[epoch : 2] (l_loss: 0.46239) (t_loss: 0.39369) (accu: 0.8793)
[epoch : 3] (l_loss: 0.38597) (t_loss: 0.35635) (accu: 0.8892)
[epoch : 4] (l_loss: 0.35392) (t_loss: 0.33458) (accu: 0.8947)
[epoch : 5] (l_loss: 0.33584) (t_loss: 0.32028) (accu: 0.9011)
[epoch : 6] (l_loss: 0.32339) (t_loss: 0.31127) (accu: 0.9044)
[epoch : 7] (l_loss: 0.31435) (t_loss: 0.30394) (accu: 0.9070)
[epoch : 8] (l_loss: 0.30736) (t_loss: 0.29887) (accu: 0.9099)
[epoch : 9] (l_loss: 0.30170) (t_loss: 0.29558) (accu: 0.9096)
[epoch : 10] (l_loss: 0.29680) (t_loss: 0.29012) (accu: 0.9115)
[epoch : 11] (l_loss: 0.29267) (t_loss: 0.28833) (accu: 0.9127)
[epoch : 12] (l_loss: 0.28951) (t_loss: 0.28632) (accu: 0.9143)
[epoch : 13] (l_loss: 0.28658) (t_loss: 0.28377) (accu: 0.9143)
[epoch : 14] (l_loss: 0.28372) (t_loss: 0.28398) (accu: 0.9139)
[epoch : 15] (l_loss: 0.28176) (t_loss: 0.28208) (accu: 0.9160)
[epoch : 16] (l_loss: 0.27991) (t_loss: 0.27973) (accu: 0.9149)
[epoch : 17] (l_loss: 0.27819) (t_loss: 0.27979) (accu: 0.9160)
[epoch : 18] (l_loss: 0.27686) (t_loss: 0.27871) (accu: 0.9165)
[epoch : 19] (l_loss: 0.27535) (t_loss: 0.27788) (accu: 0.9153)
[epoch : 20] (l_loss: 0.27406) (t_loss: 0.27635) (accu: 0.9178)
[epoch : 21] (l_loss: 0.27317) (t_loss: 0.27746) (accu: 0.9171)
[epoch : 22] (l_loss: 0.27200) (t_loss: 0.27445) (accu: 0.9186)
[epoch : 23] (l_loss: 0.27098) (t_loss: 0.27272) (accu: 0.9187)
[epoch : 24] (l_loss: 0.26970) (t_loss: 0.27350) (accu: 0.9179)
[epoch : 25] (l_loss: 0.26875) (t_loss: 0.27465) (accu: 0.9182)
[epoch : 26] (l_loss: 0.26808) (t_loss: 0.27180) (accu: 0.9173)
[epoch : 27] (l_loss: 0.26719) (t_loss: 0.27290) (accu: 0.9189)
[epoch : 28] (l_loss: 0.26639) (t_loss: 0.27397) (accu: 0.9188)
[epoch : 29] (l_loss: 0.26575) (t_loss: 0.27255) (accu: 0.9191)
[epoch : 30] (l_loss: 0.26528) (t_loss: 0.27269) (accu: 0.9171)
Finish! (Best accu: 0.9191) (Time taken(sec) : 422.71) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (4927 | 261273)          1.85
fc1.weight   :       235200 (4237 | 230963)          1.80
fc2.weight   :        30000 (540 | 29460)            1.80
fcout.weight :          1000 (150 | 850)            15.00
------------------------------------------------------------
Learning start! [Prune_iter : (19/21), Remaining weight : 1.85 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30282) (accu: 0.0886)
[epoch : 1] (l_loss: 1.14900) (t_loss: 0.54341) (accu: 0.8385)
[epoch : 2] (l_loss: 0.47514) (t_loss: 0.41266) (accu: 0.8737)
[epoch : 3] (l_loss: 0.40015) (t_loss: 0.37284) (accu: 0.8859)
[epoch : 4] (l_loss: 0.37105) (t_loss: 0.35544) (accu: 0.8926)
[epoch : 5] (l_loss: 0.35403) (t_loss: 0.33994) (accu: 0.8964)
[epoch : 6] (l_loss: 0.34233) (t_loss: 0.33214) (accu: 0.8979)
[epoch : 7] (l_loss: 0.33463) (t_loss: 0.32760) (accu: 0.8991)
[epoch : 8] (l_loss: 0.32836) (t_loss: 0.32057) (accu: 0.9017)
[epoch : 9] (l_loss: 0.32316) (t_loss: 0.31646) (accu: 0.9035)
[epoch : 10] (l_loss: 0.31828) (t_loss: 0.31229) (accu: 0.9040)
[epoch : 11] (l_loss: 0.31439) (t_loss: 0.30932) (accu: 0.9051)
[epoch : 12] (l_loss: 0.31144) (t_loss: 0.30686) (accu: 0.9045)
[epoch : 13] (l_loss: 0.30904) (t_loss: 0.30608) (accu: 0.9062)
[epoch : 14] (l_loss: 0.30635) (t_loss: 0.30480) (accu: 0.9066)
[epoch : 15] (l_loss: 0.30441) (t_loss: 0.30226) (accu: 0.9069)
[epoch : 16] (l_loss: 0.30256) (t_loss: 0.30258) (accu: 0.9063)
[epoch : 17] (l_loss: 0.30124) (t_loss: 0.30001) (accu: 0.9078)
[epoch : 18] (l_loss: 0.29961) (t_loss: 0.29995) (accu: 0.9084)
[epoch : 19] (l_loss: 0.29823) (t_loss: 0.29905) (accu: 0.9078)
[epoch : 20] (l_loss: 0.29705) (t_loss: 0.29923) (accu: 0.9071)
[epoch : 21] (l_loss: 0.29566) (t_loss: 0.29697) (accu: 0.9083)
[epoch : 22] (l_loss: 0.29470) (t_loss: 0.29799) (accu: 0.9093)
[epoch : 23] (l_loss: 0.29382) (t_loss: 0.29511) (accu: 0.9090)
[epoch : 24] (l_loss: 0.29284) (t_loss: 0.29629) (accu: 0.9081)
[epoch : 25] (l_loss: 0.29186) (t_loss: 0.29539) (accu: 0.9075)
[epoch : 26] (l_loss: 0.29138) (t_loss: 0.29495) (accu: 0.9092)
[epoch : 27] (l_loss: 0.29021) (t_loss: 0.29319) (accu: 0.9096)
[epoch : 28] (l_loss: 0.28968) (t_loss: 0.29498) (accu: 0.9091)
[epoch : 29] (l_loss: 0.28908) (t_loss: 0.29313) (accu: 0.9074)
[epoch : 30] (l_loss: 0.28858) (t_loss: 0.29434) (accu: 0.9088)
Finish! (Best accu: 0.9096) (Time taken(sec) : 431.73) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3957 | 262243)          1.49
fc1.weight   :       235200 (3390 | 231810)          1.44
fc2.weight   :        30000 (432 | 29568)            1.44
fcout.weight :          1000 (135 | 865)            13.50
------------------------------------------------------------
Learning start! [Prune_iter : (20/21), Remaining weight : 1.49 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30275) (accu: 0.0909)
[epoch : 1] (l_loss: 1.17526) (t_loss: 0.57703) (accu: 0.8210)
[epoch : 2] (l_loss: 0.51398) (t_loss: 0.45245) (accu: 0.8584)
[epoch : 3] (l_loss: 0.44123) (t_loss: 0.41266) (accu: 0.8697)
[epoch : 4] (l_loss: 0.40957) (t_loss: 0.39122) (accu: 0.8790)
[epoch : 5] (l_loss: 0.39097) (t_loss: 0.37849) (accu: 0.8833)
[epoch : 6] (l_loss: 0.37828) (t_loss: 0.36542) (accu: 0.8875)
[epoch : 7] (l_loss: 0.36833) (t_loss: 0.35742) (accu: 0.8905)
[epoch : 8] (l_loss: 0.36043) (t_loss: 0.34971) (accu: 0.8923)
[epoch : 9] (l_loss: 0.35373) (t_loss: 0.34553) (accu: 0.8941)
[epoch : 10] (l_loss: 0.34373) (t_loss: 0.33400) (accu: 0.8991)
[epoch : 11] (l_loss: 0.33691) (t_loss: 0.33136) (accu: 0.9005)
[epoch : 12] (l_loss: 0.33267) (t_loss: 0.32717) (accu: 0.9004)
[epoch : 13] (l_loss: 0.32907) (t_loss: 0.32609) (accu: 0.9016)
[epoch : 14] (l_loss: 0.32593) (t_loss: 0.32403) (accu: 0.9021)
[epoch : 15] (l_loss: 0.32363) (t_loss: 0.32082) (accu: 0.9011)
[epoch : 16] (l_loss: 0.32111) (t_loss: 0.31803) (accu: 0.9014)
[epoch : 17] (l_loss: 0.31908) (t_loss: 0.31690) (accu: 0.9018)
[epoch : 18] (l_loss: 0.31711) (t_loss: 0.31473) (accu: 0.9040)
[epoch : 19] (l_loss: 0.31555) (t_loss: 0.31632) (accu: 0.9037)
[epoch : 20] (l_loss: 0.31406) (t_loss: 0.31318) (accu: 0.9036)
[epoch : 21] (l_loss: 0.31299) (t_loss: 0.31553) (accu: 0.9044)
[epoch : 22] (l_loss: 0.31183) (t_loss: 0.31095) (accu: 0.9051)
[epoch : 23] (l_loss: 0.31030) (t_loss: 0.31164) (accu: 0.9053)
[epoch : 24] (l_loss: 0.30968) (t_loss: 0.31172) (accu: 0.9058)
[epoch : 25] (l_loss: 0.30878) (t_loss: 0.30894) (accu: 0.9056)
[epoch : 26] (l_loss: 0.30800) (t_loss: 0.30995) (accu: 0.9050)
[epoch : 27] (l_loss: 0.30719) (t_loss: 0.30871) (accu: 0.9070)
[epoch : 28] (l_loss: 0.30682) (t_loss: 0.30766) (accu: 0.9065)
[epoch : 29] (l_loss: 0.30598) (t_loss: 0.31189) (accu: 0.9036)
[epoch : 30] (l_loss: 0.30568) (t_loss: 0.30644) (accu: 0.9095)
Finish! (Best accu: 0.9095) (Time taken(sec) : 430.44) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3180 | 263020)          1.19
fc1.weight   :       235200 (2712 | 232488)          1.15
fc2.weight   :        30000 (346 | 29654)            1.15
fcout.weight :          1000 (122 | 878)            12.20
------------------------------------------------------------
Learning start! [Prune_iter : (21/21), Remaining weight : 1.19 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.29842) (accu: 0.1101)
[epoch : 1] (l_loss: 1.16563) (t_loss: 0.56430) (accu: 0.8272)
[epoch : 2] (l_loss: 0.51106) (t_loss: 0.44844) (accu: 0.8600)
[epoch : 3] (l_loss: 0.43772) (t_loss: 0.40661) (accu: 0.8737)
[epoch : 4] (l_loss: 0.40582) (t_loss: 0.38484) (accu: 0.8796)
[epoch : 5] (l_loss: 0.38865) (t_loss: 0.37161) (accu: 0.8845)
[epoch : 6] (l_loss: 0.37768) (t_loss: 0.36519) (accu: 0.8877)
[epoch : 7] (l_loss: 0.37004) (t_loss: 0.35863) (accu: 0.8898)
[epoch : 8] (l_loss: 0.36427) (t_loss: 0.35565) (accu: 0.8910)
[epoch : 9] (l_loss: 0.36016) (t_loss: 0.35167) (accu: 0.8930)
[epoch : 10] (l_loss: 0.35626) (t_loss: 0.34882) (accu: 0.8925)
[epoch : 11] (l_loss: 0.35329) (t_loss: 0.34502) (accu: 0.8944)
[epoch : 12] (l_loss: 0.35010) (t_loss: 0.34300) (accu: 0.8941)
[epoch : 13] (l_loss: 0.34742) (t_loss: 0.34183) (accu: 0.8936)
[epoch : 14] (l_loss: 0.34506) (t_loss: 0.34081) (accu: 0.8946)
[epoch : 15] (l_loss: 0.34325) (t_loss: 0.33803) (accu: 0.8957)
[epoch : 16] (l_loss: 0.34186) (t_loss: 0.33745) (accu: 0.8965)
[epoch : 17] (l_loss: 0.34011) (t_loss: 0.33600) (accu: 0.8965)
[epoch : 18] (l_loss: 0.33845) (t_loss: 0.33618) (accu: 0.8965)
[epoch : 19] (l_loss: 0.33728) (t_loss: 0.33319) (accu: 0.8973)
[epoch : 20] (l_loss: 0.33607) (t_loss: 0.33559) (accu: 0.8985)
[epoch : 21] (l_loss: 0.33501) (t_loss: 0.33322) (accu: 0.8978)
[epoch : 22] (l_loss: 0.33390) (t_loss: 0.33315) (accu: 0.8976)
[epoch : 23] (l_loss: 0.33306) (t_loss: 0.33302) (accu: 0.8976)
[epoch : 24] (l_loss: 0.33236) (t_loss: 0.33152) (accu: 0.8992)
[epoch : 25] (l_loss: 0.33140) (t_loss: 0.33145) (accu: 0.8987)
[epoch : 26] (l_loss: 0.33081) (t_loss: 0.33102) (accu: 0.9009)
[epoch : 27] (l_loss: 0.32996) (t_loss: 0.32982) (accu: 0.8987)
[epoch : 28] (l_loss: 0.32951) (t_loss: 0.33158) (accu: 0.8985)
[epoch : 29] (l_loss: 0.32873) (t_loss: 0.32838) (accu: 0.8988)
[epoch : 30] (l_loss: 0.32802) (t_loss: 0.32879) (accu: 0.9008)
Finish! (Best accu: 0.9009) (Time taken(sec) : 431.74) 


Maximum accuracy per weight remaining
Remaining weight 100.0 %  Epoch 29 Accu 0.9439
Remaining weight 80.04 %  Epoch 27 Accu 0.9444
Remaining weight 64.06 %  Epoch 29 Accu 0.9432
Remaining weight 51.28 %  Epoch 29 Accu 0.9426
Remaining weight 41.05 %  Epoch 28 Accu 0.9448
Remaining weight 32.87 %  Epoch 27 Accu 0.9417
Remaining weight 26.32 %  Epoch 27 Accu 0.9429
Remaining weight 21.07 %  Epoch 29 Accu 0.9448
Remaining weight 16.88 %  Epoch 29 Accu 0.9430
Remaining weight 13.52 %  Epoch 28 Accu 0.9448
Remaining weight 10.83 %  Epoch 29 Accu 0.9429
Remaining weight 8.68 %  Epoch 29 Accu 0.9403
Remaining weight 6.95 %  Epoch 28 Accu 0.9387
Remaining weight 5.57 %  Epoch 25 Accu 0.9362
Remaining weight 4.47 %  Epoch 28 Accu 0.9317
Remaining weight 3.58 %  Epoch 25 Accu 0.9251
Remaining weight 2.87 %  Epoch 22 Accu 0.9212
Remaining weight 2.31 %  Epoch 28 Accu 0.9191
Remaining weight 1.85 %  Epoch 26 Accu 0.9096
Remaining weight 1.49 %  Epoch 29 Accu 0.9095
Remaining weight 1.19 %  Epoch 25 Accu 0.9009
===================================================================== 

Test_Iter (5/5)
------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :        266200 (266200 | 0)          100.00
fc1.weight   :        235200 (235200 | 0)          100.00
fc2.weight   :         30000 (30000 | 0)           100.00
fcout.weight :          1000 (1000 | 0)            100.00
------------------------------------------------------------
Learning start! [Prune_iter : (1/21), Remaining weight : 100.0 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69095) (accu: 0.0912)
[epoch : 1] (l_loss: 1.26613) (t_loss: 0.58838) (accu: 0.8173)
[epoch : 2] (l_loss: 0.49800) (t_loss: 0.39164) (accu: 0.8757)
[epoch : 3] (l_loss: 0.38333) (t_loss: 0.33405) (accu: 0.8958)
[epoch : 4] (l_loss: 0.33784) (t_loss: 0.30596) (accu: 0.9043)
[epoch : 5] (l_loss: 0.31109) (t_loss: 0.28737) (accu: 0.9115)
[epoch : 6] (l_loss: 0.29371) (t_loss: 0.27702) (accu: 0.9134)
[epoch : 7] (l_loss: 0.28178) (t_loss: 0.26812) (accu: 0.9160)
[epoch : 8] (l_loss: 0.27244) (t_loss: 0.26191) (accu: 0.9202)
[epoch : 9] (l_loss: 0.26558) (t_loss: 0.25534) (accu: 0.9230)
[epoch : 10] (l_loss: 0.25958) (t_loss: 0.25320) (accu: 0.9233)
[epoch : 11] (l_loss: 0.25512) (t_loss: 0.24771) (accu: 0.9243)
[epoch : 12] (l_loss: 0.25117) (t_loss: 0.24537) (accu: 0.9243)
[epoch : 13] (l_loss: 0.24768) (t_loss: 0.24389) (accu: 0.9250)
[epoch : 14] (l_loss: 0.24493) (t_loss: 0.24088) (accu: 0.9266)
[epoch : 15] (l_loss: 0.24235) (t_loss: 0.23719) (accu: 0.9262)
[epoch : 16] (l_loss: 0.23994) (t_loss: 0.23563) (accu: 0.9268)
[epoch : 17] (l_loss: 0.23779) (t_loss: 0.23485) (accu: 0.9269)
[epoch : 18] (l_loss: 0.23591) (t_loss: 0.23296) (accu: 0.9272)
[epoch : 19] (l_loss: 0.23414) (t_loss: 0.23090) (accu: 0.9269)
[epoch : 20] (l_loss: 0.23251) (t_loss: 0.23130) (accu: 0.9275)
[epoch : 21] (l_loss: 0.23080) (t_loss: 0.23087) (accu: 0.9279)
[epoch : 22] (l_loss: 0.22992) (t_loss: 0.22897) (accu: 0.9287)
[epoch : 23] (l_loss: 0.22878) (t_loss: 0.22741) (accu: 0.9285)
[epoch : 24] (l_loss: 0.22739) (t_loss: 0.22854) (accu: 0.9290)
[epoch : 25] (l_loss: 0.22665) (t_loss: 0.22699) (accu: 0.9285)
[epoch : 26] (l_loss: 0.22519) (t_loss: 0.22594) (accu: 0.9292)
[epoch : 27] (l_loss: 0.22478) (t_loss: 0.22673) (accu: 0.9283)
[epoch : 28] (l_loss: 0.22374) (t_loss: 0.22421) (accu: 0.9296)
[epoch : 29] (l_loss: 0.22316) (t_loss: 0.22476) (accu: 0.9289)
[epoch : 30] (l_loss: 0.22214) (t_loss: 0.22329) (accu: 0.9298)
Finish! (Best accu: 0.9298) (Time taken(sec) : 421.05) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (213060 | 53140)         80.04
fc1.weight   :      235200 (188160 | 47040)         80.00
fc2.weight   :        30000 (24000 | 6000)          80.00
fcout.weight :          1000 (900 | 100)            90.00
------------------------------------------------------------
Learning start! [Prune_iter : (2/21), Remaining weight : 80.04 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.69616) (accu: 0.0897)
[epoch : 1] (l_loss: 1.27816) (t_loss: 0.59065) (accu: 0.8176)
[epoch : 2] (l_loss: 0.50171) (t_loss: 0.39531) (accu: 0.8753)
[epoch : 3] (l_loss: 0.38816) (t_loss: 0.34018) (accu: 0.8920)
[epoch : 4] (l_loss: 0.34288) (t_loss: 0.31235) (accu: 0.9032)
[epoch : 5] (l_loss: 0.31764) (t_loss: 0.29476) (accu: 0.9090)
[epoch : 6] (l_loss: 0.30082) (t_loss: 0.28372) (accu: 0.9121)
[epoch : 7] (l_loss: 0.28894) (t_loss: 0.27405) (accu: 0.9180)
[epoch : 8] (l_loss: 0.27962) (t_loss: 0.26613) (accu: 0.9190)
[epoch : 9] (l_loss: 0.27213) (t_loss: 0.26086) (accu: 0.9207)
[epoch : 10] (l_loss: 0.26593) (t_loss: 0.25566) (accu: 0.9225)
[epoch : 11] (l_loss: 0.26073) (t_loss: 0.25347) (accu: 0.9234)
[epoch : 12] (l_loss: 0.25639) (t_loss: 0.24875) (accu: 0.9243)
[epoch : 13] (l_loss: 0.25327) (t_loss: 0.24548) (accu: 0.9250)
[epoch : 14] (l_loss: 0.24967) (t_loss: 0.24292) (accu: 0.9258)
[epoch : 15] (l_loss: 0.24717) (t_loss: 0.24153) (accu: 0.9256)
[epoch : 16] (l_loss: 0.24473) (t_loss: 0.23983) (accu: 0.9259)
[epoch : 17] (l_loss: 0.24262) (t_loss: 0.23778) (accu: 0.9268)
[epoch : 18] (l_loss: 0.24025) (t_loss: 0.23697) (accu: 0.9270)
[epoch : 19] (l_loss: 0.23894) (t_loss: 0.23494) (accu: 0.9279)
[epoch : 20] (l_loss: 0.23740) (t_loss: 0.23340) (accu: 0.9281)
[epoch : 21] (l_loss: 0.23563) (t_loss: 0.23133) (accu: 0.9278)
[epoch : 22] (l_loss: 0.23425) (t_loss: 0.22991) (accu: 0.9282)
[epoch : 23] (l_loss: 0.23321) (t_loss: 0.22978) (accu: 0.9295)
[epoch : 24] (l_loss: 0.23210) (t_loss: 0.22858) (accu: 0.9292)
[epoch : 25] (l_loss: 0.23068) (t_loss: 0.22908) (accu: 0.9293)
[epoch : 26] (l_loss: 0.22993) (t_loss: 0.22774) (accu: 0.9302)
[epoch : 27] (l_loss: 0.22883) (t_loss: 0.22774) (accu: 0.9296)
[epoch : 28] (l_loss: 0.22800) (t_loss: 0.22706) (accu: 0.9283)
[epoch : 29] (l_loss: 0.22729) (t_loss: 0.22551) (accu: 0.9294)
[epoch : 30] (l_loss: 0.22644) (t_loss: 0.22535) (accu: 0.9294)
Finish! (Best accu: 0.9302) (Time taken(sec) : 425.95) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (170538 | 95662)         64.06
fc1.weight   :      235200 (150528 | 84672)         64.00
fc2.weight   :       30000 (19200 | 10800)          64.00
fcout.weight :          1000 (810 | 190)            81.00
------------------------------------------------------------
Learning start! [Prune_iter : (3/21), Remaining weight : 64.06 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.66692) (accu: 0.0971)
[epoch : 1] (l_loss: 1.25581) (t_loss: 0.56927) (accu: 0.8207)
[epoch : 2] (l_loss: 0.48689) (t_loss: 0.38649) (accu: 0.8752)
[epoch : 3] (l_loss: 0.38047) (t_loss: 0.33632) (accu: 0.8908)
[epoch : 4] (l_loss: 0.33862) (t_loss: 0.30857) (accu: 0.9028)
[epoch : 5] (l_loss: 0.31429) (t_loss: 0.29156) (accu: 0.9094)
[epoch : 6] (l_loss: 0.29795) (t_loss: 0.28085) (accu: 0.9139)
[epoch : 7] (l_loss: 0.28605) (t_loss: 0.26994) (accu: 0.9167)
[epoch : 8] (l_loss: 0.27670) (t_loss: 0.26349) (accu: 0.9183)
[epoch : 9] (l_loss: 0.26903) (t_loss: 0.25927) (accu: 0.9192)
[epoch : 10] (l_loss: 0.26264) (t_loss: 0.25506) (accu: 0.9196)
[epoch : 11] (l_loss: 0.25738) (t_loss: 0.25083) (accu: 0.9203)
[epoch : 12] (l_loss: 0.25289) (t_loss: 0.24816) (accu: 0.9212)
[epoch : 13] (l_loss: 0.24926) (t_loss: 0.24420) (accu: 0.9224)
[epoch : 14] (l_loss: 0.24619) (t_loss: 0.24224) (accu: 0.9238)
[epoch : 15] (l_loss: 0.24355) (t_loss: 0.24187) (accu: 0.9227)
[epoch : 16] (l_loss: 0.24112) (t_loss: 0.23824) (accu: 0.9243)
[epoch : 17] (l_loss: 0.23954) (t_loss: 0.23780) (accu: 0.9258)
[epoch : 18] (l_loss: 0.23749) (t_loss: 0.23745) (accu: 0.9253)
[epoch : 19] (l_loss: 0.23596) (t_loss: 0.23467) (accu: 0.9255)
[epoch : 20] (l_loss: 0.23460) (t_loss: 0.23398) (accu: 0.9270)
[epoch : 21] (l_loss: 0.23330) (t_loss: 0.23471) (accu: 0.9265)
[epoch : 22] (l_loss: 0.23204) (t_loss: 0.23334) (accu: 0.9269)
[epoch : 23] (l_loss: 0.23101) (t_loss: 0.23274) (accu: 0.9271)
[epoch : 24] (l_loss: 0.22975) (t_loss: 0.23250) (accu: 0.9278)
[epoch : 25] (l_loss: 0.22901) (t_loss: 0.23038) (accu: 0.9283)
[epoch : 26] (l_loss: 0.22795) (t_loss: 0.23091) (accu: 0.9273)
[epoch : 27] (l_loss: 0.22714) (t_loss: 0.23104) (accu: 0.9281)
[epoch : 28] (l_loss: 0.22621) (t_loss: 0.22952) (accu: 0.9279)
[epoch : 29] (l_loss: 0.22562) (t_loss: 0.22987) (accu: 0.9282)
[epoch : 30] (l_loss: 0.22491) (t_loss: 0.22968) (accu: 0.9277)
Finish! (Best accu: 0.9283) (Time taken(sec) : 427.02) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (136511 | 129689)        51.28
fc1.weight   :      235200 (120422 | 114778)        51.20
fc2.weight   :       30000 (15360 | 14640)          51.20
fcout.weight :          1000 (729 | 271)            72.90
------------------------------------------------------------
Learning start! [Prune_iter : (4/21), Remaining weight : 51.28 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.58024) (accu: 0.0922)
[epoch : 1] (l_loss: 1.23099) (t_loss: 0.57273) (accu: 0.8208)
[epoch : 2] (l_loss: 0.48652) (t_loss: 0.38861) (accu: 0.8740)
[epoch : 3] (l_loss: 0.38065) (t_loss: 0.33820) (accu: 0.8916)
[epoch : 4] (l_loss: 0.33831) (t_loss: 0.30995) (accu: 0.9013)
[epoch : 5] (l_loss: 0.31358) (t_loss: 0.29346) (accu: 0.9063)
[epoch : 6] (l_loss: 0.29699) (t_loss: 0.28033) (accu: 0.9119)
[epoch : 7] (l_loss: 0.28473) (t_loss: 0.27364) (accu: 0.9137)
[epoch : 8] (l_loss: 0.27556) (t_loss: 0.26559) (accu: 0.9164)
[epoch : 9] (l_loss: 0.26817) (t_loss: 0.25896) (accu: 0.9181)
[epoch : 10] (l_loss: 0.26282) (t_loss: 0.25437) (accu: 0.9190)
[epoch : 11] (l_loss: 0.25801) (t_loss: 0.25138) (accu: 0.9201)
[epoch : 12] (l_loss: 0.25417) (t_loss: 0.24766) (accu: 0.9217)
[epoch : 13] (l_loss: 0.25100) (t_loss: 0.24527) (accu: 0.9211)
[epoch : 14] (l_loss: 0.24810) (t_loss: 0.24305) (accu: 0.9240)
[epoch : 15] (l_loss: 0.24544) (t_loss: 0.24116) (accu: 0.9241)
[epoch : 16] (l_loss: 0.24325) (t_loss: 0.24028) (accu: 0.9240)
[epoch : 17] (l_loss: 0.24104) (t_loss: 0.23838) (accu: 0.9258)
[epoch : 18] (l_loss: 0.23935) (t_loss: 0.23733) (accu: 0.9267)
[epoch : 19] (l_loss: 0.23802) (t_loss: 0.23810) (accu: 0.9256)
[epoch : 20] (l_loss: 0.23652) (t_loss: 0.23391) (accu: 0.9272)
[epoch : 21] (l_loss: 0.23512) (t_loss: 0.23488) (accu: 0.9260)
[epoch : 22] (l_loss: 0.23390) (t_loss: 0.23328) (accu: 0.9273)
[epoch : 23] (l_loss: 0.23282) (t_loss: 0.23133) (accu: 0.9273)
[epoch : 24] (l_loss: 0.23184) (t_loss: 0.23019) (accu: 0.9280)
[epoch : 25] (l_loss: 0.23079) (t_loss: 0.22898) (accu: 0.9277)
[epoch : 26] (l_loss: 0.22970) (t_loss: 0.22903) (accu: 0.9280)
[epoch : 27] (l_loss: 0.22902) (t_loss: 0.22771) (accu: 0.9283)
[epoch : 28] (l_loss: 0.22772) (t_loss: 0.22993) (accu: 0.9276)
[epoch : 29] (l_loss: 0.22724) (t_loss: 0.22881) (accu: 0.9280)
[epoch : 30] (l_loss: 0.22674) (t_loss: 0.22658) (accu: 0.9297)
Finish! (Best accu: 0.9297) (Time taken(sec) : 447.08) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (109282 | 156918)        41.05
fc1.weight   :      235200 (96338 | 138862)         40.96
fc2.weight   :       30000 (12288 | 17712)          40.96
fcout.weight :          1000 (656 | 344)            65.60
------------------------------------------------------------
Learning start! [Prune_iter : (5/21), Remaining weight : 41.05 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.59296) (accu: 0.0999)
[epoch : 1] (l_loss: 1.23868) (t_loss: 0.58054) (accu: 0.8139)
[epoch : 2] (l_loss: 0.49356) (t_loss: 0.39806) (accu: 0.8725)
[epoch : 3] (l_loss: 0.38626) (t_loss: 0.34292) (accu: 0.8897)
[epoch : 4] (l_loss: 0.34160) (t_loss: 0.31268) (accu: 0.9009)
[epoch : 5] (l_loss: 0.31514) (t_loss: 0.29543) (accu: 0.9059)
[epoch : 6] (l_loss: 0.29751) (t_loss: 0.28007) (accu: 0.9119)
[epoch : 7] (l_loss: 0.28467) (t_loss: 0.26950) (accu: 0.9156)
[epoch : 8] (l_loss: 0.27498) (t_loss: 0.26224) (accu: 0.9159)
[epoch : 9] (l_loss: 0.26723) (t_loss: 0.25644) (accu: 0.9175)
[epoch : 10] (l_loss: 0.26134) (t_loss: 0.25232) (accu: 0.9192)
[epoch : 11] (l_loss: 0.25644) (t_loss: 0.24787) (accu: 0.9221)
[epoch : 12] (l_loss: 0.25195) (t_loss: 0.24458) (accu: 0.9228)
[epoch : 13] (l_loss: 0.24867) (t_loss: 0.24236) (accu: 0.9234)
[epoch : 14] (l_loss: 0.24540) (t_loss: 0.23930) (accu: 0.9251)
[epoch : 15] (l_loss: 0.24286) (t_loss: 0.23786) (accu: 0.9238)
[epoch : 16] (l_loss: 0.24041) (t_loss: 0.23604) (accu: 0.9253)
[epoch : 17] (l_loss: 0.23832) (t_loss: 0.23443) (accu: 0.9265)
[epoch : 18] (l_loss: 0.23605) (t_loss: 0.23244) (accu: 0.9262)
[epoch : 19] (l_loss: 0.23453) (t_loss: 0.23133) (accu: 0.9269)
[epoch : 20] (l_loss: 0.23305) (t_loss: 0.23039) (accu: 0.9272)
[epoch : 21] (l_loss: 0.23155) (t_loss: 0.22949) (accu: 0.9281)
[epoch : 22] (l_loss: 0.23007) (t_loss: 0.22943) (accu: 0.9297)
[epoch : 23] (l_loss: 0.22872) (t_loss: 0.22837) (accu: 0.9282)
[epoch : 24] (l_loss: 0.22800) (t_loss: 0.22908) (accu: 0.9285)
[epoch : 25] (l_loss: 0.22716) (t_loss: 0.22667) (accu: 0.9295)
[epoch : 26] (l_loss: 0.22614) (t_loss: 0.22613) (accu: 0.9290)
[epoch : 27] (l_loss: 0.22505) (t_loss: 0.22539) (accu: 0.9297)
[epoch : 28] (l_loss: 0.22440) (t_loss: 0.22550) (accu: 0.9296)
[epoch : 29] (l_loss: 0.22362) (t_loss: 0.22377) (accu: 0.9297)
[epoch : 30] (l_loss: 0.22277) (t_loss: 0.22457) (accu: 0.9294)
Finish! (Best accu: 0.9297) (Time taken(sec) : 451.99) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (87490 | 178710)         32.87
fc1.weight   :      235200 (77070 | 158130)         32.77
fc2.weight   :        30000 (9830 | 20170)          32.77
fcout.weight :          1000 (590 | 410)            59.00
------------------------------------------------------------
Learning start! [Prune_iter : (6/21), Remaining weight : 32.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.57936) (accu: 0.0915)
[epoch : 1] (l_loss: 1.24379) (t_loss: 0.56137) (accu: 0.8214)
[epoch : 2] (l_loss: 0.47149) (t_loss: 0.38276) (accu: 0.8766)
[epoch : 3] (l_loss: 0.36964) (t_loss: 0.33087) (accu: 0.8937)
[epoch : 4] (l_loss: 0.32909) (t_loss: 0.30256) (accu: 0.9034)
[epoch : 5] (l_loss: 0.30540) (t_loss: 0.28545) (accu: 0.9081)
[epoch : 6] (l_loss: 0.28952) (t_loss: 0.27354) (accu: 0.9137)
[epoch : 7] (l_loss: 0.27859) (t_loss: 0.26638) (accu: 0.9165)
[epoch : 8] (l_loss: 0.27012) (t_loss: 0.25999) (accu: 0.9178)
[epoch : 9] (l_loss: 0.26357) (t_loss: 0.25515) (accu: 0.9203)
[epoch : 10] (l_loss: 0.25843) (t_loss: 0.25116) (accu: 0.9218)
[epoch : 11] (l_loss: 0.25427) (t_loss: 0.24760) (accu: 0.9223)
[epoch : 12] (l_loss: 0.25067) (t_loss: 0.24533) (accu: 0.9242)
[epoch : 13] (l_loss: 0.24753) (t_loss: 0.24300) (accu: 0.9255)
[epoch : 14] (l_loss: 0.24477) (t_loss: 0.24005) (accu: 0.9259)
[epoch : 15] (l_loss: 0.24245) (t_loss: 0.23912) (accu: 0.9273)
[epoch : 16] (l_loss: 0.24060) (t_loss: 0.23726) (accu: 0.9275)
[epoch : 17] (l_loss: 0.23825) (t_loss: 0.23801) (accu: 0.9274)
[epoch : 18] (l_loss: 0.23694) (t_loss: 0.23500) (accu: 0.9289)
[epoch : 19] (l_loss: 0.23567) (t_loss: 0.23438) (accu: 0.9275)
[epoch : 20] (l_loss: 0.23410) (t_loss: 0.23420) (accu: 0.9280)
[epoch : 21] (l_loss: 0.23289) (t_loss: 0.23297) (accu: 0.9297)
[epoch : 22] (l_loss: 0.23171) (t_loss: 0.23216) (accu: 0.9298)
[epoch : 23] (l_loss: 0.23079) (t_loss: 0.23305) (accu: 0.9301)
[epoch : 24] (l_loss: 0.22992) (t_loss: 0.23151) (accu: 0.9286)
[epoch : 25] (l_loss: 0.22878) (t_loss: 0.23004) (accu: 0.9302)
[epoch : 26] (l_loss: 0.22809) (t_loss: 0.22862) (accu: 0.9299)
[epoch : 27] (l_loss: 0.22659) (t_loss: 0.22875) (accu: 0.9293)
[epoch : 28] (l_loss: 0.22626) (t_loss: 0.22790) (accu: 0.9311)
[epoch : 29] (l_loss: 0.22569) (t_loss: 0.22650) (accu: 0.9308)
[epoch : 30] (l_loss: 0.22487) (t_loss: 0.22704) (accu: 0.9320)
Finish! (Best accu: 0.9320) (Time taken(sec) : 445.43) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (70051 | 196149)         26.32
fc1.weight   :      235200 (61656 | 173544)         26.21
fc2.weight   :        30000 (7864 | 22136)          26.21
fcout.weight :          1000 (531 | 469)            53.10
------------------------------------------------------------
Learning start! [Prune_iter : (7/21), Remaining weight : 26.32 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.47822) (accu: 0.0964)
[epoch : 1] (l_loss: 1.23762) (t_loss: 0.55481) (accu: 0.8265)
[epoch : 2] (l_loss: 0.47188) (t_loss: 0.38543) (accu: 0.8756)
[epoch : 3] (l_loss: 0.37268) (t_loss: 0.33299) (accu: 0.8932)
[epoch : 4] (l_loss: 0.33073) (t_loss: 0.30655) (accu: 0.9019)
[epoch : 5] (l_loss: 0.30682) (t_loss: 0.29136) (accu: 0.9063)
[epoch : 6] (l_loss: 0.29164) (t_loss: 0.27913) (accu: 0.9109)
[epoch : 7] (l_loss: 0.28057) (t_loss: 0.27148) (accu: 0.9144)
[epoch : 8] (l_loss: 0.27211) (t_loss: 0.26578) (accu: 0.9161)
[epoch : 9] (l_loss: 0.26562) (t_loss: 0.26316) (accu: 0.9189)
[epoch : 10] (l_loss: 0.26044) (t_loss: 0.25877) (accu: 0.9181)
[epoch : 11] (l_loss: 0.25600) (t_loss: 0.25664) (accu: 0.9215)
[epoch : 12] (l_loss: 0.25222) (t_loss: 0.25319) (accu: 0.9207)
[epoch : 13] (l_loss: 0.24921) (t_loss: 0.25176) (accu: 0.9225)
[epoch : 14] (l_loss: 0.24667) (t_loss: 0.25153) (accu: 0.9214)
[epoch : 15] (l_loss: 0.24433) (t_loss: 0.24784) (accu: 0.9228)
[epoch : 16] (l_loss: 0.24207) (t_loss: 0.24697) (accu: 0.9227)
[epoch : 17] (l_loss: 0.24045) (t_loss: 0.24708) (accu: 0.9230)
[epoch : 18] (l_loss: 0.23878) (t_loss: 0.24495) (accu: 0.9230)
[epoch : 19] (l_loss: 0.23700) (t_loss: 0.24465) (accu: 0.9226)
[epoch : 20] (l_loss: 0.23544) (t_loss: 0.24470) (accu: 0.9227)
[epoch : 21] (l_loss: 0.23405) (t_loss: 0.24161) (accu: 0.9248)
[epoch : 22] (l_loss: 0.23290) (t_loss: 0.24132) (accu: 0.9245)
[epoch : 23] (l_loss: 0.23206) (t_loss: 0.23955) (accu: 0.9255)
[epoch : 24] (l_loss: 0.23096) (t_loss: 0.23943) (accu: 0.9250)
[epoch : 25] (l_loss: 0.22987) (t_loss: 0.23989) (accu: 0.9244)
[epoch : 26] (l_loss: 0.22910) (t_loss: 0.23923) (accu: 0.9257)
[epoch : 27] (l_loss: 0.22830) (t_loss: 0.23736) (accu: 0.9259)
[epoch : 28] (l_loss: 0.22731) (t_loss: 0.23711) (accu: 0.9257)
[epoch : 29] (l_loss: 0.22657) (t_loss: 0.23811) (accu: 0.9256)
[epoch : 30] (l_loss: 0.22587) (t_loss: 0.23759) (accu: 0.9264)
Finish! (Best accu: 0.9264) (Time taken(sec) : 455.18) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (56094 | 210106)         21.07
fc1.weight   :      235200 (49325 | 185875)         20.97
fc2.weight   :        30000 (6291 | 23709)          20.97
fcout.weight :          1000 (478 | 522)            47.80
------------------------------------------------------------
Learning start! [Prune_iter : (8/21), Remaining weight : 21.07 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.49507) (accu: 0.0947)
[epoch : 1] (l_loss: 1.21557) (t_loss: 0.52821) (accu: 0.8355)
[epoch : 2] (l_loss: 0.45228) (t_loss: 0.37094) (accu: 0.8816)
[epoch : 3] (l_loss: 0.35974) (t_loss: 0.32125) (accu: 0.8984)
[epoch : 4] (l_loss: 0.32158) (t_loss: 0.29703) (accu: 0.9057)
[epoch : 5] (l_loss: 0.29897) (t_loss: 0.28279) (accu: 0.9115)
[epoch : 6] (l_loss: 0.28410) (t_loss: 0.27371) (accu: 0.9133)
[epoch : 7] (l_loss: 0.27359) (t_loss: 0.26633) (accu: 0.9163)
[epoch : 8] (l_loss: 0.26565) (t_loss: 0.26111) (accu: 0.9186)
[epoch : 9] (l_loss: 0.25990) (t_loss: 0.25790) (accu: 0.9203)
[epoch : 10] (l_loss: 0.25480) (t_loss: 0.25423) (accu: 0.9222)
[epoch : 11] (l_loss: 0.25055) (t_loss: 0.25137) (accu: 0.9225)
[epoch : 12] (l_loss: 0.24714) (t_loss: 0.25062) (accu: 0.9233)
[epoch : 13] (l_loss: 0.24400) (t_loss: 0.24685) (accu: 0.9235)
[epoch : 14] (l_loss: 0.24139) (t_loss: 0.24752) (accu: 0.9228)
[epoch : 15] (l_loss: 0.23871) (t_loss: 0.24374) (accu: 0.9255)
[epoch : 16] (l_loss: 0.23636) (t_loss: 0.24233) (accu: 0.9247)
[epoch : 17] (l_loss: 0.23433) (t_loss: 0.24039) (accu: 0.9257)
[epoch : 18] (l_loss: 0.23271) (t_loss: 0.23951) (accu: 0.9262)
[epoch : 19] (l_loss: 0.23102) (t_loss: 0.23723) (accu: 0.9259)
[epoch : 20] (l_loss: 0.22946) (t_loss: 0.23717) (accu: 0.9263)
[epoch : 21] (l_loss: 0.22803) (t_loss: 0.23526) (accu: 0.9269)
[epoch : 22] (l_loss: 0.22686) (t_loss: 0.23679) (accu: 0.9268)
[epoch : 23] (l_loss: 0.22575) (t_loss: 0.23530) (accu: 0.9271)
[epoch : 24] (l_loss: 0.22444) (t_loss: 0.23312) (accu: 0.9275)
[epoch : 25] (l_loss: 0.22322) (t_loss: 0.23302) (accu: 0.9272)
[epoch : 26] (l_loss: 0.22275) (t_loss: 0.23135) (accu: 0.9283)
[epoch : 27] (l_loss: 0.22172) (t_loss: 0.23107) (accu: 0.9280)
[epoch : 28] (l_loss: 0.22117) (t_loss: 0.23148) (accu: 0.9282)
[epoch : 29] (l_loss: 0.22024) (t_loss: 0.22950) (accu: 0.9297)
[epoch : 30] (l_loss: 0.21936) (t_loss: 0.23125) (accu: 0.9287)
Finish! (Best accu: 0.9297) (Time taken(sec) : 452.87) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (44923 | 221277)         16.88
fc1.weight   :      235200 (39460 | 195740)         16.78
fc2.weight   :        30000 (5033 | 24967)          16.78
fcout.weight :          1000 (430 | 570)            43.00
------------------------------------------------------------
Learning start! [Prune_iter : (9/21), Remaining weight : 16.88 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.43408) (accu: 0.0878)
[epoch : 1] (l_loss: 1.15947) (t_loss: 0.52422) (accu: 0.8377)
[epoch : 2] (l_loss: 0.45922) (t_loss: 0.39087) (accu: 0.8799)
[epoch : 3] (l_loss: 0.38027) (t_loss: 0.34759) (accu: 0.8916)
[epoch : 4] (l_loss: 0.34543) (t_loss: 0.32290) (accu: 0.8983)
[epoch : 5] (l_loss: 0.32336) (t_loss: 0.30363) (accu: 0.9037)
[epoch : 6] (l_loss: 0.30691) (t_loss: 0.29075) (accu: 0.9110)
[epoch : 7] (l_loss: 0.29503) (t_loss: 0.28123) (accu: 0.9137)
[epoch : 8] (l_loss: 0.28588) (t_loss: 0.27208) (accu: 0.9156)
[epoch : 9] (l_loss: 0.27783) (t_loss: 0.26783) (accu: 0.9194)
[epoch : 10] (l_loss: 0.27226) (t_loss: 0.26109) (accu: 0.9207)
[epoch : 11] (l_loss: 0.26758) (t_loss: 0.25733) (accu: 0.9217)
[epoch : 12] (l_loss: 0.26320) (t_loss: 0.25436) (accu: 0.9235)
[epoch : 13] (l_loss: 0.25982) (t_loss: 0.25270) (accu: 0.9249)
[epoch : 14] (l_loss: 0.25701) (t_loss: 0.24855) (accu: 0.9249)
[epoch : 15] (l_loss: 0.25419) (t_loss: 0.24896) (accu: 0.9258)
[epoch : 16] (l_loss: 0.25236) (t_loss: 0.24608) (accu: 0.9266)
[epoch : 17] (l_loss: 0.25024) (t_loss: 0.24515) (accu: 0.9255)
[epoch : 18] (l_loss: 0.24859) (t_loss: 0.24336) (accu: 0.9275)
[epoch : 19] (l_loss: 0.24672) (t_loss: 0.24380) (accu: 0.9272)
[epoch : 20] (l_loss: 0.24589) (t_loss: 0.24219) (accu: 0.9275)
[epoch : 21] (l_loss: 0.24437) (t_loss: 0.24182) (accu: 0.9274)
[epoch : 22] (l_loss: 0.24329) (t_loss: 0.24065) (accu: 0.9275)
[epoch : 23] (l_loss: 0.24235) (t_loss: 0.23996) (accu: 0.9286)
[epoch : 24] (l_loss: 0.24119) (t_loss: 0.23943) (accu: 0.9284)
[epoch : 25] (l_loss: 0.24024) (t_loss: 0.23962) (accu: 0.9288)
[epoch : 26] (l_loss: 0.23949) (t_loss: 0.23816) (accu: 0.9289)
[epoch : 27] (l_loss: 0.23878) (t_loss: 0.23714) (accu: 0.9285)
[epoch : 28] (l_loss: 0.23802) (t_loss: 0.23645) (accu: 0.9289)
[epoch : 29] (l_loss: 0.23698) (t_loss: 0.23856) (accu: 0.9293)
[epoch : 30] (l_loss: 0.23669) (t_loss: 0.23758) (accu: 0.9292)
Finish! (Best accu: 0.9293) (Time taken(sec) : 448.96) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (35982 | 230218)         13.52
fc1.weight   :      235200 (31568 | 203632)         13.42
fc2.weight   :        30000 (4027 | 25973)          13.42
fcout.weight :          1000 (387 | 613)            38.70
------------------------------------------------------------
Learning start! [Prune_iter : (10/21), Remaining weight : 13.52 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.39936) (accu: 0.0866)
[epoch : 1] (l_loss: 1.14349) (t_loss: 0.50974) (accu: 0.8412)
[epoch : 2] (l_loss: 0.44406) (t_loss: 0.38113) (accu: 0.8794)
[epoch : 3] (l_loss: 0.36203) (t_loss: 0.33359) (accu: 0.8973)
[epoch : 4] (l_loss: 0.32521) (t_loss: 0.30834) (accu: 0.9047)
[epoch : 5] (l_loss: 0.30163) (t_loss: 0.29007) (accu: 0.9105)
[epoch : 6] (l_loss: 0.28595) (t_loss: 0.27978) (accu: 0.9145)
[epoch : 7] (l_loss: 0.27502) (t_loss: 0.27066) (accu: 0.9170)
[epoch : 8] (l_loss: 0.26637) (t_loss: 0.26606) (accu: 0.9189)
[epoch : 9] (l_loss: 0.26037) (t_loss: 0.26056) (accu: 0.9199)
[epoch : 10] (l_loss: 0.25546) (t_loss: 0.25678) (accu: 0.9212)
[epoch : 11] (l_loss: 0.25119) (t_loss: 0.25186) (accu: 0.9218)
[epoch : 12] (l_loss: 0.24790) (t_loss: 0.25108) (accu: 0.9216)
[epoch : 13] (l_loss: 0.24495) (t_loss: 0.25097) (accu: 0.9231)
[epoch : 14] (l_loss: 0.24254) (t_loss: 0.24688) (accu: 0.9242)
[epoch : 15] (l_loss: 0.24022) (t_loss: 0.24704) (accu: 0.9233)
[epoch : 16] (l_loss: 0.23823) (t_loss: 0.24289) (accu: 0.9258)
[epoch : 17] (l_loss: 0.23643) (t_loss: 0.24212) (accu: 0.9259)
[epoch : 18] (l_loss: 0.23488) (t_loss: 0.24117) (accu: 0.9259)
[epoch : 19] (l_loss: 0.23342) (t_loss: 0.24100) (accu: 0.9265)
[epoch : 20] (l_loss: 0.23229) (t_loss: 0.23888) (accu: 0.9265)
[epoch : 21] (l_loss: 0.23090) (t_loss: 0.23740) (accu: 0.9277)
[epoch : 22] (l_loss: 0.22961) (t_loss: 0.23713) (accu: 0.9267)
[epoch : 23] (l_loss: 0.22852) (t_loss: 0.23527) (accu: 0.9283)
[epoch : 24] (l_loss: 0.22770) (t_loss: 0.23506) (accu: 0.9271)
[epoch : 25] (l_loss: 0.22689) (t_loss: 0.23377) (accu: 0.9285)
[epoch : 26] (l_loss: 0.22599) (t_loss: 0.23325) (accu: 0.9294)
[epoch : 27] (l_loss: 0.22521) (t_loss: 0.23250) (accu: 0.9296)
[epoch : 28] (l_loss: 0.22442) (t_loss: 0.23401) (accu: 0.9283)
[epoch : 29] (l_loss: 0.22385) (t_loss: 0.23187) (accu: 0.9297)
[epoch : 30] (l_loss: 0.22309) (t_loss: 0.23185) (accu: 0.9295)
Finish! (Best accu: 0.9297) (Time taken(sec) : 440.75) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (28824 | 237376)         10.83
fc1.weight   :      235200 (25254 | 209946)         10.74
fc2.weight   :        30000 (3221 | 26779)          10.74
fcout.weight :          1000 (349 | 651)            34.90
------------------------------------------------------------
Learning start! [Prune_iter : (11/21), Remaining weight : 10.83 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.35720) (accu: 0.1014)
[epoch : 1] (l_loss: 1.15467) (t_loss: 0.51102) (accu: 0.8452)
[epoch : 2] (l_loss: 0.43610) (t_loss: 0.36852) (accu: 0.8853)
[epoch : 3] (l_loss: 0.34954) (t_loss: 0.32286) (accu: 0.8991)
[epoch : 4] (l_loss: 0.31258) (t_loss: 0.29800) (accu: 0.9094)
[epoch : 5] (l_loss: 0.29067) (t_loss: 0.28159) (accu: 0.9142)
[epoch : 6] (l_loss: 0.27627) (t_loss: 0.27249) (accu: 0.9175)
[epoch : 7] (l_loss: 0.26681) (t_loss: 0.26299) (accu: 0.9200)
[epoch : 8] (l_loss: 0.25996) (t_loss: 0.25832) (accu: 0.9214)
[epoch : 9] (l_loss: 0.25478) (t_loss: 0.25337) (accu: 0.9231)
[epoch : 10] (l_loss: 0.25020) (t_loss: 0.25150) (accu: 0.9241)
[epoch : 11] (l_loss: 0.24661) (t_loss: 0.24750) (accu: 0.9252)
[epoch : 12] (l_loss: 0.24372) (t_loss: 0.24585) (accu: 0.9254)
[epoch : 13] (l_loss: 0.24124) (t_loss: 0.24370) (accu: 0.9259)
[epoch : 14] (l_loss: 0.23926) (t_loss: 0.24221) (accu: 0.9270)
[epoch : 15] (l_loss: 0.23735) (t_loss: 0.24118) (accu: 0.9276)
[epoch : 16] (l_loss: 0.23572) (t_loss: 0.23869) (accu: 0.9295)
[epoch : 17] (l_loss: 0.23428) (t_loss: 0.24002) (accu: 0.9277)
[epoch : 18] (l_loss: 0.23309) (t_loss: 0.23811) (accu: 0.9288)
[epoch : 19] (l_loss: 0.23192) (t_loss: 0.23533) (accu: 0.9293)
[epoch : 20] (l_loss: 0.23069) (t_loss: 0.23580) (accu: 0.9292)
[epoch : 21] (l_loss: 0.22992) (t_loss: 0.23444) (accu: 0.9298)
[epoch : 22] (l_loss: 0.22904) (t_loss: 0.23332) (accu: 0.9297)
[epoch : 23] (l_loss: 0.22799) (t_loss: 0.23270) (accu: 0.9318)
[epoch : 24] (l_loss: 0.22713) (t_loss: 0.23305) (accu: 0.9297)
[epoch : 25] (l_loss: 0.22661) (t_loss: 0.23352) (accu: 0.9299)
[epoch : 26] (l_loss: 0.22565) (t_loss: 0.23104) (accu: 0.9312)
[epoch : 27] (l_loss: 0.22539) (t_loss: 0.23253) (accu: 0.9302)
[epoch : 28] (l_loss: 0.22473) (t_loss: 0.23191) (accu: 0.9298)
[epoch : 29] (l_loss: 0.22413) (t_loss: 0.23082) (accu: 0.9308)
[epoch : 30] (l_loss: 0.22367) (t_loss: 0.22966) (accu: 0.9317)
Finish! (Best accu: 0.9318) (Time taken(sec) : 449.73) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (23095 | 243105)          8.68
fc1.weight   :      235200 (20204 | 214996)          8.59
fc2.weight   :        30000 (2577 | 27423)           8.59
fcout.weight :          1000 (314 | 686)            31.40
------------------------------------------------------------
Learning start! [Prune_iter : (12/21), Remaining weight : 8.68 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32976) (accu: 0.1052)
[epoch : 1] (l_loss: 1.11890) (t_loss: 0.49292) (accu: 0.8501)
[epoch : 2] (l_loss: 0.42597) (t_loss: 0.36657) (accu: 0.8882)
[epoch : 3] (l_loss: 0.35063) (t_loss: 0.32785) (accu: 0.8995)
[epoch : 4] (l_loss: 0.32020) (t_loss: 0.30859) (accu: 0.9063)
[epoch : 5] (l_loss: 0.30201) (t_loss: 0.29387) (accu: 0.9096)
[epoch : 6] (l_loss: 0.28863) (t_loss: 0.28308) (accu: 0.9140)
[epoch : 7] (l_loss: 0.27789) (t_loss: 0.27500) (accu: 0.9181)
[epoch : 8] (l_loss: 0.26965) (t_loss: 0.26694) (accu: 0.9208)
[epoch : 9] (l_loss: 0.26331) (t_loss: 0.26096) (accu: 0.9227)
[epoch : 10] (l_loss: 0.25787) (t_loss: 0.25564) (accu: 0.9231)
[epoch : 11] (l_loss: 0.25364) (t_loss: 0.25310) (accu: 0.9248)
[epoch : 12] (l_loss: 0.25004) (t_loss: 0.24949) (accu: 0.9253)
[epoch : 13] (l_loss: 0.24748) (t_loss: 0.24780) (accu: 0.9266)
[epoch : 14] (l_loss: 0.24508) (t_loss: 0.24454) (accu: 0.9260)
[epoch : 15] (l_loss: 0.24303) (t_loss: 0.24511) (accu: 0.9264)
[epoch : 16] (l_loss: 0.24140) (t_loss: 0.24203) (accu: 0.9269)
[epoch : 17] (l_loss: 0.23948) (t_loss: 0.24444) (accu: 0.9275)
[epoch : 18] (l_loss: 0.23822) (t_loss: 0.24024) (accu: 0.9269)
[epoch : 19] (l_loss: 0.23704) (t_loss: 0.24063) (accu: 0.9268)
[epoch : 20] (l_loss: 0.23605) (t_loss: 0.23862) (accu: 0.9271)
[epoch : 21] (l_loss: 0.23435) (t_loss: 0.23766) (accu: 0.9274)
[epoch : 22] (l_loss: 0.23331) (t_loss: 0.23724) (accu: 0.9272)
[epoch : 23] (l_loss: 0.23201) (t_loss: 0.23538) (accu: 0.9275)
[epoch : 24] (l_loss: 0.23103) (t_loss: 0.23425) (accu: 0.9284)
[epoch : 25] (l_loss: 0.23033) (t_loss: 0.23403) (accu: 0.9281)
[epoch : 26] (l_loss: 0.22979) (t_loss: 0.23352) (accu: 0.9280)
[epoch : 27] (l_loss: 0.22900) (t_loss: 0.23348) (accu: 0.9279)
[epoch : 28] (l_loss: 0.22783) (t_loss: 0.23454) (accu: 0.9277)
[epoch : 29] (l_loss: 0.22741) (t_loss: 0.23413) (accu: 0.9287)
[epoch : 30] (l_loss: 0.22671) (t_loss: 0.23274) (accu: 0.9288)
Finish! (Best accu: 0.9288) (Time taken(sec) : 449.10) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (18507 | 247693)          6.95
fc1.weight   :      235200 (16163 | 219037)          6.87
fc2.weight   :        30000 (2062 | 27938)           6.87
fcout.weight :          1000 (282 | 718)            28.20
------------------------------------------------------------
Learning start! [Prune_iter : (13/21), Remaining weight : 6.95 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30422) (accu: 0.1110)
[epoch : 1] (l_loss: 1.14773) (t_loss: 0.51239) (accu: 0.8493)
[epoch : 2] (l_loss: 0.45156) (t_loss: 0.38912) (accu: 0.8797)
[epoch : 3] (l_loss: 0.37571) (t_loss: 0.34743) (accu: 0.8929)
[epoch : 4] (l_loss: 0.33967) (t_loss: 0.32340) (accu: 0.9022)
[epoch : 5] (l_loss: 0.31747) (t_loss: 0.30713) (accu: 0.9046)
[epoch : 6] (l_loss: 0.30347) (t_loss: 0.29359) (accu: 0.9086)
[epoch : 7] (l_loss: 0.29358) (t_loss: 0.28684) (accu: 0.9125)
[epoch : 8] (l_loss: 0.28597) (t_loss: 0.28113) (accu: 0.9139)
[epoch : 9] (l_loss: 0.28013) (t_loss: 0.27606) (accu: 0.9156)
[epoch : 10] (l_loss: 0.27490) (t_loss: 0.27237) (accu: 0.9173)
[epoch : 11] (l_loss: 0.27114) (t_loss: 0.26848) (accu: 0.9170)
[epoch : 12] (l_loss: 0.26810) (t_loss: 0.26602) (accu: 0.9184)
[epoch : 13] (l_loss: 0.26513) (t_loss: 0.26240) (accu: 0.9196)
[epoch : 14] (l_loss: 0.26283) (t_loss: 0.26130) (accu: 0.9203)
[epoch : 15] (l_loss: 0.26048) (t_loss: 0.25938) (accu: 0.9216)
[epoch : 16] (l_loss: 0.25864) (t_loss: 0.25655) (accu: 0.9227)
[epoch : 17] (l_loss: 0.25697) (t_loss: 0.25617) (accu: 0.9224)
[epoch : 18] (l_loss: 0.25564) (t_loss: 0.25410) (accu: 0.9240)
[epoch : 19] (l_loss: 0.25418) (t_loss: 0.25248) (accu: 0.9235)
[epoch : 20] (l_loss: 0.25275) (t_loss: 0.25367) (accu: 0.9226)
[epoch : 21] (l_loss: 0.25201) (t_loss: 0.25031) (accu: 0.9255)
[epoch : 22] (l_loss: 0.25090) (t_loss: 0.25047) (accu: 0.9229)
[epoch : 23] (l_loss: 0.24991) (t_loss: 0.24933) (accu: 0.9246)
[epoch : 24] (l_loss: 0.24895) (t_loss: 0.24822) (accu: 0.9250)
[epoch : 25] (l_loss: 0.24816) (t_loss: 0.24738) (accu: 0.9258)
[epoch : 26] (l_loss: 0.24725) (t_loss: 0.24686) (accu: 0.9251)
[epoch : 27] (l_loss: 0.24638) (t_loss: 0.24764) (accu: 0.9247)
[epoch : 28] (l_loss: 0.24569) (t_loss: 0.24455) (accu: 0.9257)
[epoch : 29] (l_loss: 0.24467) (t_loss: 0.24422) (accu: 0.9256)
[epoch : 30] (l_loss: 0.24411) (t_loss: 0.24234) (accu: 0.9269)
Finish! (Best accu: 0.9269) (Time taken(sec) : 450.65) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (14833 | 251367)          5.57
fc1.weight   :      235200 (12930 | 222270)          5.50
fc2.weight   :        30000 (1649 | 28351)           5.50
fcout.weight :          1000 (254 | 746)            25.40
------------------------------------------------------------
Learning start! [Prune_iter : (14/21), Remaining weight : 5.57 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.33905) (accu: 0.0996)
[epoch : 1] (l_loss: 1.19487) (t_loss: 0.53636) (accu: 0.8441)
[epoch : 2] (l_loss: 0.46639) (t_loss: 0.40110) (accu: 0.8796)
[epoch : 3] (l_loss: 0.38618) (t_loss: 0.35973) (accu: 0.8895)
[epoch : 4] (l_loss: 0.35399) (t_loss: 0.34046) (accu: 0.8959)
[epoch : 5] (l_loss: 0.33543) (t_loss: 0.32484) (accu: 0.9001)
[epoch : 6] (l_loss: 0.32230) (t_loss: 0.31451) (accu: 0.9021)
[epoch : 7] (l_loss: 0.31230) (t_loss: 0.30657) (accu: 0.9067)
[epoch : 8] (l_loss: 0.30467) (t_loss: 0.30048) (accu: 0.9077)
[epoch : 9] (l_loss: 0.29892) (t_loss: 0.29514) (accu: 0.9093)
[epoch : 10] (l_loss: 0.29411) (t_loss: 0.29089) (accu: 0.9100)
[epoch : 11] (l_loss: 0.28999) (t_loss: 0.28737) (accu: 0.9110)
[epoch : 12] (l_loss: 0.28655) (t_loss: 0.28518) (accu: 0.9127)
[epoch : 13] (l_loss: 0.28393) (t_loss: 0.28329) (accu: 0.9134)
[epoch : 14] (l_loss: 0.28148) (t_loss: 0.28165) (accu: 0.9141)
[epoch : 15] (l_loss: 0.27897) (t_loss: 0.27816) (accu: 0.9142)
[epoch : 16] (l_loss: 0.27697) (t_loss: 0.27681) (accu: 0.9154)
[epoch : 17] (l_loss: 0.27550) (t_loss: 0.27464) (accu: 0.9165)
[epoch : 18] (l_loss: 0.27323) (t_loss: 0.27345) (accu: 0.9175)
[epoch : 19] (l_loss: 0.27211) (t_loss: 0.27164) (accu: 0.9176)
[epoch : 20] (l_loss: 0.27070) (t_loss: 0.27102) (accu: 0.9178)
[epoch : 21] (l_loss: 0.26933) (t_loss: 0.27041) (accu: 0.9179)
[epoch : 22] (l_loss: 0.26829) (t_loss: 0.27105) (accu: 0.9176)
[epoch : 23] (l_loss: 0.26730) (t_loss: 0.26840) (accu: 0.9182)
[epoch : 24] (l_loss: 0.26609) (t_loss: 0.26740) (accu: 0.9195)
[epoch : 25] (l_loss: 0.26514) (t_loss: 0.26688) (accu: 0.9186)
[epoch : 26] (l_loss: 0.26453) (t_loss: 0.26511) (accu: 0.9193)
[epoch : 27] (l_loss: 0.26341) (t_loss: 0.26584) (accu: 0.9189)
[epoch : 28] (l_loss: 0.26245) (t_loss: 0.26519) (accu: 0.9203)
[epoch : 29] (l_loss: 0.26203) (t_loss: 0.26200) (accu: 0.9188)
[epoch : 30] (l_loss: 0.26159) (t_loss: 0.26365) (accu: 0.9194)
Finish! (Best accu: 0.9203) (Time taken(sec) : 442.45) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      266200 (11892 | 254308)          4.47
fc1.weight   :      235200 (10344 | 224856)          4.40
fc2.weight   :        30000 (1319 | 28681)           4.40
fcout.weight :          1000 (229 | 771)            22.90
------------------------------------------------------------
Learning start! [Prune_iter : (15/21), Remaining weight : 4.47 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32726) (accu: 0.0775)
[epoch : 1] (l_loss: 1.18490) (t_loss: 0.53634) (accu: 0.8382)
[epoch : 2] (l_loss: 0.47437) (t_loss: 0.40968) (accu: 0.8740)
[epoch : 3] (l_loss: 0.40053) (t_loss: 0.37108) (accu: 0.8863)
[epoch : 4] (l_loss: 0.36997) (t_loss: 0.35087) (accu: 0.8921)
[epoch : 5] (l_loss: 0.34699) (t_loss: 0.33165) (accu: 0.9002)
[epoch : 6] (l_loss: 0.33095) (t_loss: 0.31939) (accu: 0.9024)
[epoch : 7] (l_loss: 0.32001) (t_loss: 0.31233) (accu: 0.9043)
[epoch : 8] (l_loss: 0.31248) (t_loss: 0.30548) (accu: 0.9059)
[epoch : 9] (l_loss: 0.30667) (t_loss: 0.30111) (accu: 0.9080)
[epoch : 10] (l_loss: 0.30167) (t_loss: 0.29627) (accu: 0.9087)
[epoch : 11] (l_loss: 0.29773) (t_loss: 0.29229) (accu: 0.9114)
[epoch : 12] (l_loss: 0.29392) (t_loss: 0.28926) (accu: 0.9114)
[epoch : 13] (l_loss: 0.29123) (t_loss: 0.28633) (accu: 0.9130)
[epoch : 14] (l_loss: 0.28848) (t_loss: 0.28448) (accu: 0.9139)
[epoch : 15] (l_loss: 0.28617) (t_loss: 0.28329) (accu: 0.9138)
[epoch : 16] (l_loss: 0.28401) (t_loss: 0.28301) (accu: 0.9140)
[epoch : 17] (l_loss: 0.28225) (t_loss: 0.28012) (accu: 0.9149)
[epoch : 18] (l_loss: 0.28070) (t_loss: 0.27773) (accu: 0.9153)
[epoch : 19] (l_loss: 0.27903) (t_loss: 0.27744) (accu: 0.9150)
[epoch : 20] (l_loss: 0.27799) (t_loss: 0.27603) (accu: 0.9152)
[epoch : 21] (l_loss: 0.27662) (t_loss: 0.27510) (accu: 0.9154)
[epoch : 22] (l_loss: 0.27504) (t_loss: 0.27702) (accu: 0.9165)
[epoch : 23] (l_loss: 0.27389) (t_loss: 0.27441) (accu: 0.9166)
[epoch : 24] (l_loss: 0.27338) (t_loss: 0.27347) (accu: 0.9157)
[epoch : 25] (l_loss: 0.27267) (t_loss: 0.27301) (accu: 0.9173)
[epoch : 26] (l_loss: 0.27157) (t_loss: 0.27311) (accu: 0.9165)
[epoch : 27] (l_loss: 0.27123) (t_loss: 0.27391) (accu: 0.9168)
[epoch : 28] (l_loss: 0.26996) (t_loss: 0.27234) (accu: 0.9172)
[epoch : 29] (l_loss: 0.26950) (t_loss: 0.27147) (accu: 0.9171)
[epoch : 30] (l_loss: 0.26880) (t_loss: 0.27245) (accu: 0.9180)
Finish! (Best accu: 0.9180) (Time taken(sec) : 451.49) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (9537 | 256663)          3.58
fc1.weight   :       235200 (8275 | 226925)          3.52
fc2.weight   :        30000 (1056 | 28944)           3.52
fcout.weight :          1000 (206 | 794)            20.60
------------------------------------------------------------
Learning start! [Prune_iter : (16/21), Remaining weight : 3.58 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.31925) (accu: 0.1020)
[epoch : 1] (l_loss: 1.21022) (t_loss: 0.55714) (accu: 0.8330)
[epoch : 2] (l_loss: 0.49036) (t_loss: 0.42276) (accu: 0.8719)
[epoch : 3] (l_loss: 0.40641) (t_loss: 0.37552) (accu: 0.8859)
[epoch : 4] (l_loss: 0.37177) (t_loss: 0.35391) (accu: 0.8925)
[epoch : 5] (l_loss: 0.35227) (t_loss: 0.33818) (accu: 0.8975)
[epoch : 6] (l_loss: 0.33854) (t_loss: 0.32669) (accu: 0.9012)
[epoch : 7] (l_loss: 0.32854) (t_loss: 0.31769) (accu: 0.9038)
[epoch : 8] (l_loss: 0.32089) (t_loss: 0.31179) (accu: 0.9059)
[epoch : 9] (l_loss: 0.31462) (t_loss: 0.30601) (accu: 0.9071)
[epoch : 10] (l_loss: 0.30991) (t_loss: 0.30372) (accu: 0.9080)
[epoch : 11] (l_loss: 0.30405) (t_loss: 0.29719) (accu: 0.9109)
[epoch : 12] (l_loss: 0.29877) (t_loss: 0.29369) (accu: 0.9137)
[epoch : 13] (l_loss: 0.29517) (t_loss: 0.29294) (accu: 0.9137)
[epoch : 14] (l_loss: 0.29203) (t_loss: 0.29115) (accu: 0.9139)
[epoch : 15] (l_loss: 0.28944) (t_loss: 0.28699) (accu: 0.9150)
[epoch : 16] (l_loss: 0.28735) (t_loss: 0.28553) (accu: 0.9158)
[epoch : 17] (l_loss: 0.28533) (t_loss: 0.28370) (accu: 0.9167)
[epoch : 18] (l_loss: 0.28328) (t_loss: 0.28341) (accu: 0.9162)
[epoch : 19] (l_loss: 0.28193) (t_loss: 0.28138) (accu: 0.9173)
[epoch : 20] (l_loss: 0.28049) (t_loss: 0.28114) (accu: 0.9178)
[epoch : 21] (l_loss: 0.27904) (t_loss: 0.28075) (accu: 0.9174)
[epoch : 22] (l_loss: 0.27767) (t_loss: 0.27966) (accu: 0.9170)
[epoch : 23] (l_loss: 0.27662) (t_loss: 0.28105) (accu: 0.9177)
[epoch : 24] (l_loss: 0.27547) (t_loss: 0.27905) (accu: 0.9182)
[epoch : 25] (l_loss: 0.27444) (t_loss: 0.27824) (accu: 0.9189)
[epoch : 26] (l_loss: 0.27352) (t_loss: 0.27789) (accu: 0.9197)
[epoch : 27] (l_loss: 0.27271) (t_loss: 0.27781) (accu: 0.9191)
[epoch : 28] (l_loss: 0.27180) (t_loss: 0.27793) (accu: 0.9186)
[epoch : 29] (l_loss: 0.27127) (t_loss: 0.27838) (accu: 0.9189)
[epoch : 30] (l_loss: 0.27071) (t_loss: 0.27667) (accu: 0.9165)
Finish! (Best accu: 0.9197) (Time taken(sec) : 453.63) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (7649 | 258551)          2.87
fc1.weight   :       235200 (6620 | 228580)          2.81
fc2.weight   :        30000 (844 | 29156)            2.81
fcout.weight :          1000 (185 | 815)            18.50
------------------------------------------------------------
Learning start! [Prune_iter : (17/21), Remaining weight : 2.87 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.32054) (accu: 0.0890)
[epoch : 1] (l_loss: 1.25326) (t_loss: 0.58037) (accu: 0.8325)
[epoch : 2] (l_loss: 0.50576) (t_loss: 0.43483) (accu: 0.8679)
[epoch : 3] (l_loss: 0.41525) (t_loss: 0.38512) (accu: 0.8841)
[epoch : 4] (l_loss: 0.38065) (t_loss: 0.36392) (accu: 0.8887)
[epoch : 5] (l_loss: 0.36183) (t_loss: 0.35061) (accu: 0.8936)
[epoch : 6] (l_loss: 0.34970) (t_loss: 0.34298) (accu: 0.8968)
[epoch : 7] (l_loss: 0.34025) (t_loss: 0.33427) (accu: 0.9000)
[epoch : 8] (l_loss: 0.33298) (t_loss: 0.32751) (accu: 0.9018)
[epoch : 9] (l_loss: 0.32708) (t_loss: 0.32411) (accu: 0.9033)
[epoch : 10] (l_loss: 0.32181) (t_loss: 0.32041) (accu: 0.9043)
[epoch : 11] (l_loss: 0.31780) (t_loss: 0.31806) (accu: 0.9043)
[epoch : 12] (l_loss: 0.31463) (t_loss: 0.31555) (accu: 0.9044)
[epoch : 13] (l_loss: 0.31175) (t_loss: 0.31458) (accu: 0.9042)
[epoch : 14] (l_loss: 0.30956) (t_loss: 0.31776) (accu: 0.9051)
[epoch : 15] (l_loss: 0.30741) (t_loss: 0.31190) (accu: 0.9065)
[epoch : 16] (l_loss: 0.30539) (t_loss: 0.30955) (accu: 0.9074)
[epoch : 17] (l_loss: 0.30356) (t_loss: 0.30943) (accu: 0.9073)
[epoch : 18] (l_loss: 0.30207) (t_loss: 0.30649) (accu: 0.9065)
[epoch : 19] (l_loss: 0.30062) (t_loss: 0.30552) (accu: 0.9062)
[epoch : 20] (l_loss: 0.29900) (t_loss: 0.30654) (accu: 0.9081)
[epoch : 21] (l_loss: 0.29795) (t_loss: 0.30473) (accu: 0.9091)
[epoch : 22] (l_loss: 0.29653) (t_loss: 0.30413) (accu: 0.9076)
[epoch : 23] (l_loss: 0.29582) (t_loss: 0.30247) (accu: 0.9090)
[epoch : 24] (l_loss: 0.29418) (t_loss: 0.30142) (accu: 0.9088)
[epoch : 25] (l_loss: 0.29343) (t_loss: 0.30235) (accu: 0.9091)
[epoch : 26] (l_loss: 0.29265) (t_loss: 0.30234) (accu: 0.9075)
[epoch : 27] (l_loss: 0.29198) (t_loss: 0.30140) (accu: 0.9088)
[epoch : 28] (l_loss: 0.29125) (t_loss: 0.30045) (accu: 0.9082)
[epoch : 29] (l_loss: 0.29023) (t_loss: 0.29823) (accu: 0.9089)
[epoch : 30] (l_loss: 0.28960) (t_loss: 0.29773) (accu: 0.9104)
Finish! (Best accu: 0.9104) (Time taken(sec) : 455.12) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (6139 | 260061)          2.31
fc1.weight   :       235200 (5296 | 229904)          2.25
fc2.weight   :        30000 (676 | 29324)            2.25
fcout.weight :          1000 (167 | 833)            16.70
------------------------------------------------------------
Learning start! [Prune_iter : (18/21), Remaining weight : 2.31 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.31990) (accu: 0.0927)
[epoch : 1] (l_loss: 1.25369) (t_loss: 0.60450) (accu: 0.8276)
[epoch : 2] (l_loss: 0.52992) (t_loss: 0.45830) (accu: 0.8630)
[epoch : 3] (l_loss: 0.43963) (t_loss: 0.40582) (accu: 0.8755)
[epoch : 4] (l_loss: 0.40340) (t_loss: 0.38712) (accu: 0.8822)
[epoch : 5] (l_loss: 0.38231) (t_loss: 0.36792) (accu: 0.8882)
[epoch : 6] (l_loss: 0.36629) (t_loss: 0.35681) (accu: 0.8921)
[epoch : 7] (l_loss: 0.35658) (t_loss: 0.34950) (accu: 0.8940)
[epoch : 8] (l_loss: 0.34928) (t_loss: 0.34452) (accu: 0.8957)
[epoch : 9] (l_loss: 0.34404) (t_loss: 0.33886) (accu: 0.8970)
[epoch : 10] (l_loss: 0.33985) (t_loss: 0.33523) (accu: 0.8973)
[epoch : 11] (l_loss: 0.33637) (t_loss: 0.33279) (accu: 0.8978)
[epoch : 12] (l_loss: 0.33347) (t_loss: 0.33109) (accu: 0.8985)
[epoch : 13] (l_loss: 0.33112) (t_loss: 0.32905) (accu: 0.8990)
[epoch : 14] (l_loss: 0.32880) (t_loss: 0.32816) (accu: 0.9002)
[epoch : 15] (l_loss: 0.32723) (t_loss: 0.32823) (accu: 0.8983)
[epoch : 16] (l_loss: 0.32582) (t_loss: 0.32621) (accu: 0.9012)
[epoch : 17] (l_loss: 0.32431) (t_loss: 0.32777) (accu: 0.9014)
[epoch : 18] (l_loss: 0.32302) (t_loss: 0.32332) (accu: 0.9000)
[epoch : 19] (l_loss: 0.32191) (t_loss: 0.32212) (accu: 0.9008)
[epoch : 20] (l_loss: 0.32050) (t_loss: 0.32118) (accu: 0.9023)
[epoch : 21] (l_loss: 0.31970) (t_loss: 0.32100) (accu: 0.9018)
[epoch : 22] (l_loss: 0.31835) (t_loss: 0.31961) (accu: 0.9007)
[epoch : 23] (l_loss: 0.31741) (t_loss: 0.31922) (accu: 0.9026)
[epoch : 24] (l_loss: 0.31674) (t_loss: 0.31886) (accu: 0.9010)
[epoch : 25] (l_loss: 0.31604) (t_loss: 0.31856) (accu: 0.9025)
[epoch : 26] (l_loss: 0.31497) (t_loss: 0.31652) (accu: 0.9022)
[epoch : 27] (l_loss: 0.31452) (t_loss: 0.31608) (accu: 0.9022)
[epoch : 28] (l_loss: 0.31386) (t_loss: 0.31834) (accu: 0.9014)
[epoch : 29] (l_loss: 0.31320) (t_loss: 0.31755) (accu: 0.9031)
[epoch : 30] (l_loss: 0.31244) (t_loss: 0.31512) (accu: 0.9023)
Finish! (Best accu: 0.9031) (Time taken(sec) : 454.59) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (4927 | 261273)          1.85
fc1.weight   :       235200 (4237 | 230963)          1.80
fc2.weight   :        30000 (540 | 29460)            1.80
fcout.weight :          1000 (150 | 850)            15.00
------------------------------------------------------------
Learning start! [Prune_iter : (19/21), Remaining weight : 1.85 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30193) (accu: 0.0901)
[epoch : 1] (l_loss: 1.24023) (t_loss: 0.61385) (accu: 0.8235)
[epoch : 2] (l_loss: 0.53775) (t_loss: 0.47998) (accu: 0.8555)
[epoch : 3] (l_loss: 0.45709) (t_loss: 0.43202) (accu: 0.8715)
[epoch : 4] (l_loss: 0.42024) (t_loss: 0.40893) (accu: 0.8778)
[epoch : 5] (l_loss: 0.40016) (t_loss: 0.39219) (accu: 0.8812)
[epoch : 6] (l_loss: 0.38760) (t_loss: 0.38388) (accu: 0.8864)
[epoch : 7] (l_loss: 0.37902) (t_loss: 0.37821) (accu: 0.8857)
[epoch : 8] (l_loss: 0.37269) (t_loss: 0.37359) (accu: 0.8884)
[epoch : 9] (l_loss: 0.36788) (t_loss: 0.36801) (accu: 0.8905)
[epoch : 10] (l_loss: 0.36405) (t_loss: 0.36628) (accu: 0.8910)
[epoch : 11] (l_loss: 0.36091) (t_loss: 0.36310) (accu: 0.8932)
[epoch : 12] (l_loss: 0.35828) (t_loss: 0.35970) (accu: 0.8916)
[epoch : 13] (l_loss: 0.35578) (t_loss: 0.35886) (accu: 0.8920)
[epoch : 14] (l_loss: 0.35368) (t_loss: 0.35557) (accu: 0.8930)
[epoch : 15] (l_loss: 0.35193) (t_loss: 0.35513) (accu: 0.8949)
[epoch : 16] (l_loss: 0.35016) (t_loss: 0.35170) (accu: 0.8954)
[epoch : 17] (l_loss: 0.34853) (t_loss: 0.35017) (accu: 0.8955)
[epoch : 18] (l_loss: 0.34702) (t_loss: 0.34843) (accu: 0.8955)
[epoch : 19] (l_loss: 0.34553) (t_loss: 0.34845) (accu: 0.8947)
[epoch : 20] (l_loss: 0.34448) (t_loss: 0.34531) (accu: 0.8969)
[epoch : 21] (l_loss: 0.34296) (t_loss: 0.34632) (accu: 0.8967)
[epoch : 22] (l_loss: 0.34230) (t_loss: 0.34647) (accu: 0.8967)
[epoch : 23] (l_loss: 0.34116) (t_loss: 0.34401) (accu: 0.8964)
[epoch : 24] (l_loss: 0.34036) (t_loss: 0.34283) (accu: 0.8964)
[epoch : 25] (l_loss: 0.33943) (t_loss: 0.34295) (accu: 0.8977)
[epoch : 26] (l_loss: 0.33863) (t_loss: 0.34247) (accu: 0.8982)
[epoch : 27] (l_loss: 0.33793) (t_loss: 0.34066) (accu: 0.8974)
[epoch : 28] (l_loss: 0.33727) (t_loss: 0.33913) (accu: 0.8978)
[epoch : 29] (l_loss: 0.33650) (t_loss: 0.33956) (accu: 0.8983)
[epoch : 30] (l_loss: 0.33586) (t_loss: 0.34057) (accu: 0.8981)
Finish! (Best accu: 0.8983) (Time taken(sec) : 448.40) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3957 | 262243)          1.49
fc1.weight   :       235200 (3390 | 231810)          1.44
fc2.weight   :        30000 (432 | 29568)            1.44
fcout.weight :          1000 (135 | 865)            13.50
------------------------------------------------------------
Learning start! [Prune_iter : (20/21), Remaining weight : 1.49 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30736) (accu: 0.0896)
[epoch : 1] (l_loss: 1.24659) (t_loss: 0.63058) (accu: 0.8093)
[epoch : 2] (l_loss: 0.55773) (t_loss: 0.49727) (accu: 0.8503)
[epoch : 3] (l_loss: 0.47560) (t_loss: 0.45031) (accu: 0.8634)
[epoch : 4] (l_loss: 0.44062) (t_loss: 0.42600) (accu: 0.8691)
[epoch : 5] (l_loss: 0.42042) (t_loss: 0.41155) (accu: 0.8740)
[epoch : 6] (l_loss: 0.40754) (t_loss: 0.40003) (accu: 0.8790)
[epoch : 7] (l_loss: 0.39823) (t_loss: 0.39585) (accu: 0.8814)
[epoch : 8] (l_loss: 0.39201) (t_loss: 0.38859) (accu: 0.8823)
[epoch : 9] (l_loss: 0.38688) (t_loss: 0.38494) (accu: 0.8836)
[epoch : 10] (l_loss: 0.38281) (t_loss: 0.37952) (accu: 0.8860)
[epoch : 11] (l_loss: 0.37952) (t_loss: 0.38012) (accu: 0.8862)
[epoch : 12] (l_loss: 0.37689) (t_loss: 0.37862) (accu: 0.8865)
[epoch : 13] (l_loss: 0.37482) (t_loss: 0.37499) (accu: 0.8873)
[epoch : 14] (l_loss: 0.37272) (t_loss: 0.37415) (accu: 0.8883)
[epoch : 15] (l_loss: 0.37098) (t_loss: 0.37220) (accu: 0.8906)
[epoch : 16] (l_loss: 0.36947) (t_loss: 0.37124) (accu: 0.8893)
[epoch : 17] (l_loss: 0.36814) (t_loss: 0.36996) (accu: 0.8907)
[epoch : 18] (l_loss: 0.36714) (t_loss: 0.36888) (accu: 0.8884)
[epoch : 19] (l_loss: 0.36578) (t_loss: 0.36837) (accu: 0.8915)
[epoch : 20] (l_loss: 0.36487) (t_loss: 0.36706) (accu: 0.8918)
[epoch : 21] (l_loss: 0.36358) (t_loss: 0.36656) (accu: 0.8892)
[epoch : 22] (l_loss: 0.36312) (t_loss: 0.36677) (accu: 0.8902)
[epoch : 23] (l_loss: 0.36215) (t_loss: 0.36455) (accu: 0.8918)
[epoch : 24] (l_loss: 0.36142) (t_loss: 0.36485) (accu: 0.8917)
[epoch : 25] (l_loss: 0.36060) (t_loss: 0.36374) (accu: 0.8908)
[epoch : 26] (l_loss: 0.35999) (t_loss: 0.36310) (accu: 0.8905)
[epoch : 27] (l_loss: 0.35938) (t_loss: 0.36238) (accu: 0.8912)
[epoch : 28] (l_loss: 0.35883) (t_loss: 0.36304) (accu: 0.8912)
[epoch : 29] (l_loss: 0.35800) (t_loss: 0.36346) (accu: 0.8909)
[epoch : 30] (l_loss: 0.35763) (t_loss: 0.36244) (accu: 0.8908)
Finish! (Best accu: 0.8918) (Time taken(sec) : 441.80) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       266200 (3180 | 263020)          1.19
fc1.weight   :       235200 (2712 | 232488)          1.15
fc2.weight   :        30000 (346 | 29654)            1.15
fcout.weight :          1000 (122 | 878)            12.20
------------------------------------------------------------
Learning start! [Prune_iter : (21/21), Remaining weight : 1.19 %]
[epoch : 0] (l_loss: x.xxxxx) (t_loss: 2.30077) (accu: 0.1126)
[epoch : 1] (l_loss: 1.27491) (t_loss: 0.64191) (accu: 0.8089)
[epoch : 2] (l_loss: 0.56742) (t_loss: 0.50802) (accu: 0.8486)
[epoch : 3] (l_loss: 0.48810) (t_loss: 0.46339) (accu: 0.8598)
[epoch : 4] (l_loss: 0.45498) (t_loss: 0.44096) (accu: 0.8645)
[epoch : 5] (l_loss: 0.43615) (t_loss: 0.42599) (accu: 0.8711)
[epoch : 6] (l_loss: 0.42345) (t_loss: 0.41812) (accu: 0.8722)
[epoch : 7] (l_loss: 0.41421) (t_loss: 0.40961) (accu: 0.8738)
[epoch : 8] (l_loss: 0.40806) (t_loss: 0.40254) (accu: 0.8752)
[epoch : 9] (l_loss: 0.40263) (t_loss: 0.39884) (accu: 0.8764)
[epoch : 10] (l_loss: 0.39903) (t_loss: 0.39589) (accu: 0.8764)
[epoch : 11] (l_loss: 0.39560) (t_loss: 0.39324) (accu: 0.8780)
[epoch : 12] (l_loss: 0.39263) (t_loss: 0.39175) (accu: 0.8789)
[epoch : 13] (l_loss: 0.39011) (t_loss: 0.38847) (accu: 0.8797)
[epoch : 14] (l_loss: 0.38801) (t_loss: 0.38678) (accu: 0.8806)
[epoch : 15] (l_loss: 0.38566) (t_loss: 0.38524) (accu: 0.8822)
[epoch : 16] (l_loss: 0.38387) (t_loss: 0.38455) (accu: 0.8817)
[epoch : 17] (l_loss: 0.38234) (t_loss: 0.38043) (accu: 0.8830)
[epoch : 18] (l_loss: 0.38055) (t_loss: 0.38000) (accu: 0.8841)
[epoch : 19] (l_loss: 0.37866) (t_loss: 0.37836) (accu: 0.8835)
[epoch : 20] (l_loss: 0.37725) (t_loss: 0.37727) (accu: 0.8844)
[epoch : 21] (l_loss: 0.37584) (t_loss: 0.37737) (accu: 0.8849)
[epoch : 22] (l_loss: 0.37489) (t_loss: 0.37399) (accu: 0.8858)
[epoch : 23] (l_loss: 0.37398) (t_loss: 0.37571) (accu: 0.8871)
[epoch : 24] (l_loss: 0.37328) (t_loss: 0.37522) (accu: 0.8856)
[epoch : 25] (l_loss: 0.37206) (t_loss: 0.37268) (accu: 0.8871)
[epoch : 26] (l_loss: 0.37176) (t_loss: 0.37368) (accu: 0.8877)
[epoch : 27] (l_loss: 0.37125) (t_loss: 0.37462) (accu: 0.8873)
[epoch : 28] (l_loss: 0.37096) (t_loss: 0.37364) (accu: 0.8875)
[epoch : 29] (l_loss: 0.37024) (t_loss: 0.37359) (accu: 0.8868)
[epoch : 30] (l_loss: 0.36976) (t_loss: 0.37145) (accu: 0.8873)
Finish! (Best accu: 0.8877) (Time taken(sec) : 440.55) 


Maximum accuracy per weight remaining
Remaining weight 100.0 %  Epoch 29 Accu 0.9298
Remaining weight 80.04 %  Epoch 25 Accu 0.9302
Remaining weight 64.06 %  Epoch 24 Accu 0.9283
Remaining weight 51.28 %  Epoch 29 Accu 0.9297
Remaining weight 41.05 %  Epoch 28 Accu 0.9297
Remaining weight 32.87 %  Epoch 29 Accu 0.9320
Remaining weight 26.32 %  Epoch 29 Accu 0.9264
Remaining weight 21.07 %  Epoch 28 Accu 0.9297
Remaining weight 16.88 %  Epoch 28 Accu 0.9293
Remaining weight 13.52 %  Epoch 28 Accu 0.9297
Remaining weight 10.83 %  Epoch 22 Accu 0.9318
Remaining weight 8.68 %  Epoch 29 Accu 0.9288
Remaining weight 6.95 %  Epoch 29 Accu 0.9269
Remaining weight 5.57 %  Epoch 27 Accu 0.9203
Remaining weight 4.47 %  Epoch 29 Accu 0.9180
Remaining weight 3.58 %  Epoch 25 Accu 0.9197
Remaining weight 2.87 %  Epoch 29 Accu 0.9104
Remaining weight 2.31 %  Epoch 28 Accu 0.9031
Remaining weight 1.85 %  Epoch 28 Accu 0.8983
Remaining weight 1.49 %  Epoch 22 Accu 0.8918
Remaining weight 1.19 %  Epoch 25 Accu 0.8877
Average test data
Remaining weight 100.00 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.690954   0.0912
1     0.863590    0.366055   0.8865
2     0.308872    0.242614   0.9240
3     0.231761    0.206887   0.9363
4     0.200267    0.189479   0.9410
5     0.181397    0.182439   0.9439
6     0.168637    0.177626   0.9460
7     0.159048    0.171567   0.9478
8     0.151974    0.166972   0.9505
9     0.146257    0.163580   0.9517
10     0.142322    0.164138   0.9518
11     0.138736    0.163159   0.9519
12     0.135039    0.165149   0.9524
13     0.132524    0.162636   0.9534
14     0.130414    0.168447   0.9522
15     0.128553    0.157771   0.9542
16     0.125912    0.166928   0.9528
17     0.124368    0.162123   0.9539
18     0.123163    0.160565   0.9552
19     0.121295    0.164397   0.9546
20     0.120315    0.163429   0.9551
21     0.119331    0.161161   0.9552
22     0.117916    0.162339   0.9551
23     0.116689    0.160289   0.9560
24     0.115655    0.164967   0.9556
25     0.115469    0.160889   0.9560
26     0.114031    0.166207   0.9557
27     0.113157    0.169749   0.9554
28     0.112959    0.164443   0.9562
29     0.112074    0.164977   0.9561
30     0.110833    0.167984   0.9564
Remaining weight 80.04 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.601714   0.1037
1     0.868759    0.367221   0.8878
2     0.308160    0.245095   0.9238
3     0.231576    0.208652   0.9348
4     0.199738    0.192561   0.9407
5     0.181885    0.183280   0.9438
6     0.169925    0.179324   0.9452
7     0.160920    0.173507   0.9479
8     0.153677    0.169500   0.9497
9     0.147638    0.170677   0.9504
10     0.143459    0.165122   0.9515
11     0.139722    0.163782   0.9531
12     0.135689    0.161415   0.9534
13     0.133284    0.164164   0.9540
14     0.130710    0.165262   0.9536
15     0.128357    0.166414   0.9535
16     0.126709    0.161163   0.9546
17     0.124900    0.165138   0.9549
18     0.123599    0.159449   0.9553
19     0.121361    0.163458   0.9554
20     0.121178    0.160467   0.9553
21     0.119620    0.166685   0.9550
22     0.118090    0.161446   0.9566
23     0.117551    0.165254   0.9564
24     0.116157    0.159992   0.9567
25     0.115480    0.162673   0.9562
26     0.114438    0.163866   0.9559
27     0.114315    0.161729   0.9566
28     0.113067    0.166391   0.9563
29     0.112717    0.168433   0.9561
30     0.111514    0.164832   0.9563
Remaining weight 64.06 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.554903   0.1258
1     0.855887    0.359888   0.8886
2     0.300871    0.246028   0.9237
3     0.227350    0.211513   0.9339
4     0.196361    0.191175   0.9409
5     0.178784    0.181259   0.9445
6     0.166627    0.179761   0.9456
7     0.157332    0.172385   0.9478
8     0.151494    0.168135   0.9498
9     0.146156    0.167589   0.9504
10     0.140932    0.166917   0.9505
11     0.137639    0.161736   0.9522
12     0.134695    0.164208   0.9523
13     0.131644    0.163513   0.9533
14     0.129309    0.163011   0.9528
15     0.127305    0.166370   0.9530
16     0.125764    0.170834   0.9529
17     0.123553    0.159807   0.9553
18     0.122273    0.164820   0.9542
19     0.121356    0.164175   0.9541
20     0.120679    0.165266   0.9543
21     0.118598    0.168372   0.9543
22     0.117873    0.161080   0.9557
23     0.116512    0.166892   0.9546
24     0.116719    0.162901   0.9555
25     0.115035    0.162727   0.9560
26     0.113492    0.165396   0.9559
27     0.113827    0.166205   0.9560
28     0.112764    0.167233   0.9561
29     0.112094    0.167919   0.9556
30     0.111220    0.172389   0.9557
Remaining weight 51.28 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.482668   0.1177
1     0.833781    0.355890   0.8894
2     0.296824    0.241630   0.9234
3     0.224075    0.207404   0.9347
4     0.194222    0.191014   0.9402
5     0.176920    0.182345   0.9431
6     0.165139    0.177705   0.9460
7     0.156800    0.173912   0.9467
8     0.150536    0.168705   0.9494
9     0.145521    0.169920   0.9496
10     0.141513    0.165609   0.9512
11     0.137719    0.164185   0.9520
12     0.135222    0.164466   0.9520
13     0.132744    0.162465   0.9526
14     0.130438    0.162505   0.9533
15     0.128016    0.166885   0.9528
16     0.125929    0.164248   0.9531
17     0.125659    0.163784   0.9536
18     0.123495    0.160202   0.9548
19     0.121649    0.160984   0.9548
20     0.121164    0.161004   0.9549
21     0.120112    0.164319   0.9550
22     0.118642    0.168006   0.9544
23     0.117513    0.163579   0.9554
24     0.117074    0.167535   0.9552
25     0.116350    0.166161   0.9553
26     0.115046    0.164633   0.9559
27     0.114300    0.166204   0.9561
28     0.113963    0.161304   0.9564
29     0.112609    0.166319   0.9560
30     0.112291    0.164047   0.9566
Remaining weight 41.05 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.482061   0.1223
1     0.829395    0.349643   0.8919
2     0.289846    0.240082   0.9242
3     0.220002    0.206961   0.9353
4     0.190530    0.190087   0.9413
5     0.174159    0.181562   0.9439
6     0.162510    0.173818   0.9468
7     0.154575    0.172810   0.9477
8     0.148287    0.167065   0.9486
9     0.143151    0.167082   0.9494
10     0.139444    0.164059   0.9509
11     0.136124    0.162604   0.9520
12     0.133198    0.164426   0.9519
13     0.130713    0.160127   0.9529
14     0.127762    0.159159   0.9534
15     0.126657    0.163950   0.9526
16     0.125122    0.160177   0.9532
17     0.123007    0.164187   0.9543
18     0.122504    0.163302   0.9545
19     0.120550    0.158154   0.9547
20     0.118946    0.156819   0.9554
21     0.117947    0.160367   0.9554
22     0.117850    0.162112   0.9560
23     0.116318    0.161288   0.9560
24     0.115062    0.161626   0.9554
25     0.114599    0.160901   0.9564
26     0.113853    0.161040   0.9564
27     0.112976    0.157457   0.9567
28     0.112044    0.158682   0.9569
29     0.112385    0.160925   0.9568
30     0.110613    0.165970   0.9569
Remaining weight 32.87 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.460859   0.1201
1     0.832608    0.339786   0.8957
2     0.278188    0.232431   0.9275
3     0.211603    0.199191   0.9382
4     0.184824    0.185764   0.9430
5     0.169014    0.176405   0.9461
6     0.159089    0.172624   0.9483
7     0.151596    0.166017   0.9497
8     0.145673    0.163464   0.9505
9     0.141173    0.162661   0.9514
10     0.137909    0.162775   0.9521
11     0.134558    0.160593   0.9528
12     0.132192    0.161635   0.9532
13     0.130269    0.159288   0.9540
14     0.127649    0.161485   0.9535
15     0.126134    0.161129   0.9535
16     0.124046    0.159422   0.9549
17     0.123292    0.159993   0.9545
18     0.121054    0.158159   0.9555
19     0.120658    0.159494   0.9551
20     0.119205    0.157129   0.9555
21     0.117701    0.161697   0.9558
22     0.117625    0.161808   0.9557
23     0.116618    0.164282   0.9558
24     0.115547    0.162779   0.9556
25     0.114566    0.161781   0.9562
26     0.113909    0.163043   0.9564
27     0.113255    0.161717   0.9560
28     0.112522    0.162634   0.9566
29     0.112063    0.159024   0.9571
30     0.111567    0.160358   0.9570
Remaining weight 26.32 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.380440   0.1328
1     0.829747    0.335752   0.8968
2     0.275456    0.230737   0.9276
3     0.211525    0.201698   0.9369
4     0.185150    0.189000   0.9415
5     0.169821    0.179944   0.9440
6     0.160058    0.174192   0.9461
7     0.152176    0.170903   0.9475
8     0.146604    0.167182   0.9498
9     0.141786    0.167411   0.9494
10     0.138212    0.166298   0.9501
11     0.134915    0.163879   0.9516
12     0.131856    0.169003   0.9518
13     0.130265    0.162104   0.9528
14     0.127911    0.162483   0.9525
15     0.125719    0.163878   0.9532
16     0.124819    0.169104   0.9529
17     0.122786    0.161653   0.9538
18     0.121260    0.162643   0.9541
19     0.121715    0.163438   0.9537
20     0.119203    0.166850   0.9541
21     0.118019    0.162644   0.9546
22     0.117697    0.170199   0.9537
23     0.117389    0.162298   0.9550
24     0.115904    0.168260   0.9546
25     0.115522    0.166141   0.9549
26     0.114288    0.166323   0.9552
27     0.113890    0.161348   0.9557
28     0.113393    0.165369   0.9557
29     0.112772    0.166887   0.9558
30     0.112259    0.167356   0.9557
Remaining weight 21.07 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.384696   0.1348
1     0.817911    0.324467   0.9012
2     0.268736    0.227954   0.9281
3     0.207100    0.198727   0.9378
4     0.181771    0.184035   0.9423
5     0.167014    0.177368   0.9450
6     0.157363    0.171849   0.9469
7     0.150264    0.169673   0.9483
8     0.144959    0.168388   0.9495
9     0.140552    0.165570   0.9512
10     0.136967    0.165057   0.9514
11     0.134102    0.162155   0.9522
12     0.132370    0.166389   0.9521
13     0.129652    0.162611   0.9528
14     0.127263    0.163364   0.9530
15     0.126331    0.163356   0.9535
16     0.124379    0.162844   0.9538
17     0.122847    0.163980   0.9538
18     0.122016    0.164325   0.9544
19     0.120298    0.165924   0.9533
20     0.119785    0.161197   0.9547
21     0.117954    0.161786   0.9553
22     0.117296    0.166056   0.9550
23     0.116626    0.162613   0.9552
24     0.115565    0.161061   0.9556
25     0.114370    0.159186   0.9561
26     0.114422    0.163382   0.9562
27     0.113859    0.160275   0.9565
28     0.112820    0.162546   0.9568
29     0.112270    0.160420   0.9571
30     0.111829    0.161021   0.9574
Remaining weight 16.88 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.331778   0.1341
1     0.789174    0.323295   0.9018
2     0.271799    0.235281   0.9281
3     0.216433    0.209080   0.9361
4     0.191633    0.194234   0.9408
5     0.176392    0.184184   0.9439
6     0.166453    0.180928   0.9464
7     0.158580    0.175982   0.9476
8     0.152734    0.178984   0.9479
9     0.147990    0.169027   0.9504
10     0.143988    0.168985   0.9510
11     0.141443    0.171635   0.9512
12     0.138238    0.166468   0.9525
13     0.135348    0.165313   0.9532
14     0.133232    0.163160   0.9538
15     0.131378    0.163328   0.9540
16     0.129849    0.162862   0.9545
17     0.128383    0.161857   0.9551
18     0.127141    0.161927   0.9551
19     0.125899    0.162554   0.9551
20     0.128046    0.162542   0.9550
21     0.124635    0.163313   0.9545
22     0.123306    0.161018   0.9552
23     0.122267    0.161412   0.9562
24     0.121402    0.160862   0.9558
25     0.120640    0.161608   0.9559
26     0.119949    0.160640   0.9558
27     0.119482    0.160700   0.9561
28     0.118915    0.160779   0.9560
29     0.118218    0.162588   0.9565
30     0.117746    0.162406   0.9565
Remaining weight 13.52 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.280749   0.1597
1     0.770529    0.311574   0.9066
2     0.261239    0.230896   0.9284
3     0.207625    0.203904   0.9375
4     0.183686    0.189299   0.9423
5     0.169096    0.181966   0.9445
6     0.159615    0.176311   0.9476
7     0.153120    0.173752   0.9487
8     0.147040    0.171729   0.9499
9     0.142544    0.168510   0.9510
10     0.138732    0.165308   0.9521
11     0.137198    0.168318   0.9516
12     0.133639    0.163770   0.9522
13     0.131318    0.162749   0.9533
14     0.129856    0.167294   0.9532
15     0.128492    0.166526   0.9530
16     0.127063    0.165102   0.9537
17     0.125144    0.161793   0.9539
18     0.123819    0.162746   0.9545
19     0.123267    0.163230   0.9548
20     0.122386    0.162299   0.9550
21     0.121333    0.162754   0.9549
22     0.120107    0.160843   0.9553
23     0.119084    0.159290   0.9555
24     0.119373    0.164132   0.9548
25     0.118326    0.164629   0.9548
26     0.117511    0.163856   0.9555
27     0.116543    0.160632   0.9560
28     0.115991    0.160996   0.9557
29     0.115410    0.160974   0.9561
30     0.114995    0.160888   0.9564
Remaining weight 10.83 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.253558   0.1670
1     0.790508    0.316602   0.9063
2     0.264914    0.231189   0.9290
3     0.208544    0.202024   0.9375
4     0.183887    0.189189   0.9425
5     0.168937    0.180729   0.9449
6     0.159417    0.174595   0.9472
7     0.152551    0.171689   0.9483
8     0.146717    0.168476   0.9492
9     0.142653    0.169015   0.9496
10     0.139641    0.166381   0.9508
11     0.136207    0.167069   0.9519
12     0.133583    0.165991   0.9523
13     0.132723    0.165635   0.9524
14     0.130273    0.164532   0.9532
15     0.128428    0.165501   0.9530
16     0.127229    0.165675   0.9542
17     0.125978    0.166016   0.9538
18     0.124937    0.164392   0.9547
19     0.123955    0.164686   0.9547
20     0.122887    0.163896   0.9548
21     0.122072    0.163320   0.9554
22     0.121568    0.170871   0.9544
23     0.121150    0.164474   0.9557
24     0.119859    0.166169   0.9554
25     0.119453    0.166312   0.9555
26     0.118901    0.167289   0.9553
27     0.118612    0.164913   0.9559
28     0.117914    0.166006   0.9559
29     0.117251    0.168869   0.9557
30     0.117019    0.164563   0.9562
Remaining weight 8.68 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.251523   0.1915
1     0.784585    0.310613   0.9077
2     0.261215    0.228340   0.9304
3     0.208611    0.203497   0.9376
4     0.185965    0.191331   0.9419
5     0.172824    0.183579   0.9436
6     0.163195    0.178261   0.9462
7     0.156398    0.175125   0.9481
8     0.151096    0.171104   0.9495
9     0.146785    0.170636   0.9500
10     0.143006    0.168550   0.9507
11     0.139905    0.167494   0.9519
12     0.137190    0.165448   0.9522
13     0.135513    0.166545   0.9530
14     0.133287    0.165137   0.9527
15     0.131610    0.163667   0.9534
16     0.130101    0.161864   0.9537
17     0.128693    0.161844   0.9545
18     0.127693    0.161397   0.9544
19     0.126574    0.161873   0.9538
20     0.125654    0.161434   0.9540
21     0.124742    0.161514   0.9535
22     0.125820    0.161746   0.9545
23     0.123192    0.160607   0.9548
24     0.122327    0.159229   0.9546
25     0.121610    0.158975   0.9551
26     0.121032    0.159132   0.9550
27     0.120449    0.158657   0.9553
28     0.119919    0.158986   0.9554
29     0.119255    0.159528   0.9553
30     0.118861    0.159171   0.9553
Remaining weight 6.95 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.226576   0.1994
1     0.800928    0.323897   0.9048
2     0.276524    0.239671   0.9261
3     0.221566    0.212361   0.9340
4     0.196645    0.198989   0.9391
5     0.182037    0.189932   0.9415
6     0.172238    0.185253   0.9438
7     0.165591    0.180675   0.9456
8     0.160056    0.177890   0.9466
9     0.156074    0.176551   0.9475
10     0.153126    0.174148   0.9483
11     0.149735    0.172364   0.9490
12     0.147278    0.170665   0.9499
13     0.145170    0.169993   0.9506
14     0.143366    0.168890   0.9511
15     0.141774    0.168278   0.9512
16     0.140448    0.175008   0.9512
17     0.140637    0.169660   0.9518
18     0.138202    0.170025   0.9519
19     0.137041    0.168137   0.9522
20     0.136043    0.167630   0.9524
21     0.135235    0.166220   0.9534
22     0.134346    0.167251   0.9524
23     0.133617    0.166803   0.9531
24     0.133017    0.166989   0.9530
25     0.132288    0.166640   0.9534
26     0.131666    0.166856   0.9533
27     0.131131    0.167568   0.9535
28     0.130550    0.167759   0.9535
29     0.131298    0.173884   0.9532
30     0.129907    0.168069   0.9539
Remaining weight 5.57 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.255328   0.1841
1     0.835782    0.340689   0.9006
2     0.290994    0.253674   0.9239
3     0.234030    0.224299   0.9316
4     0.208601    0.209091   0.9356
5     0.193520    0.199492   0.9385
6     0.183572    0.194099   0.9405
7     0.176244    0.191237   0.9422
8     0.170620    0.185808   0.9431
9     0.166650    0.184100   0.9440
10     0.162743    0.182625   0.9447
11     0.159574    0.180767   0.9458
12     0.156972    0.179089   0.9468
13     0.155454    0.179807   0.9473
14     0.152997    0.178196   0.9480
15     0.151124    0.177441   0.9485
16     0.149507    0.176627   0.9487
17     0.148278    0.175811   0.9494
18     0.146853    0.176113   0.9495
19     0.145831    0.175241   0.9501
20     0.145255    0.183141   0.9491
21     0.145044    0.178136   0.9496
22     0.143067    0.175980   0.9500
23     0.142184    0.174876   0.9506
24     0.141431    0.174732   0.9507
25     0.140698    0.175098   0.9507
26     0.140141    0.174103   0.9510
27     0.139459    0.174576   0.9506
28     0.138893    0.175189   0.9511
29     0.138296    0.174586   0.9511
30     0.137809    0.175807   0.9507
Remaining weight 4.47 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.267019   0.1334
1     0.839352    0.342066   0.8973
2     0.296530    0.255769   0.9212
3     0.240324    0.227087   0.9301
4     0.215099    0.213607   0.9345
5     0.199278    0.203073   0.9379
6     0.188562    0.198247   0.9395
7     0.180713    0.193249   0.9418
8     0.175139    0.191666   0.9427
9     0.171158    0.188149   0.9440
10     0.167334    0.186485   0.9450
11     0.164285    0.183964   0.9454
12     0.161764    0.182907   0.9462
13     0.159577    0.183377   0.9463
14     0.158638    0.184372   0.9464
15     0.156184    0.182085   0.9466
16     0.154527    0.181345   0.9472
17     0.153211    0.180551   0.9473
18     0.152132    0.179839   0.9475
19     0.151045    0.179225   0.9474
20     0.150126    0.179704   0.9479
21     0.150141    0.182653   0.9477
22     0.148398    0.182605   0.9482
23     0.147404    0.180166   0.9485
24     0.146863    0.179846   0.9485
25     0.146190    0.179391   0.9488
26     0.145584    0.179493   0.9486
27     0.145008    0.180656   0.9487
28     0.144389    0.179961   0.9489
29     0.143822    0.179838   0.9490
30     0.143382    0.180706   0.9489
Remaining weight 3.58 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.268625   0.1391
1     0.854133    0.351427   0.8946
2     0.304884    0.263550   0.9195
3     0.246432    0.233697   0.9278
4     0.220438    0.218727   0.9331
5     0.205440    0.209344   0.9358
6     0.195389    0.205116   0.9377
7     0.188242    0.200483   0.9398
8     0.182721    0.197601   0.9400
9     0.178352    0.194413   0.9411
10     0.174856    0.194484   0.9420
11     0.171919    0.193402   0.9433
12     0.168773    0.191082   0.9444
13     0.166518    0.190088   0.9442
14     0.164406    0.189667   0.9447
15     0.162837    0.191796   0.9452
16     0.162089    0.189375   0.9457
17     0.160031    0.189559   0.9460
18     0.158782    0.188985   0.9463
19     0.157677    0.187659   0.9461
20     0.156759    0.187380   0.9470
21     0.155918    0.187852   0.9467
22     0.155097    0.187867   0.9467
23     0.154995    0.189885   0.9464
24     0.153749    0.187486   0.9471
25     0.152828    0.188110   0.9476
26     0.152204    0.187681   0.9480
27     0.151685    0.187526   0.9475
28     0.151159    0.186852   0.9475
29     0.150709    0.187890   0.9479
30     0.150288    0.186969   0.9474
Remaining weight 2.87 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.280508   0.1208
1     0.884347    0.359714   0.8956
2     0.313127    0.272179   0.9174
3     0.255236    0.241318   0.9266
4     0.229714    0.225832   0.9307
5     0.215060    0.217665   0.9337
6     0.205361    0.212106   0.9358
7     0.198441    0.207755   0.9372
8     0.193086    0.205483   0.9381
9     0.188945    0.203432   0.9389
10     0.185435    0.203638   0.9391
11     0.182749    0.201778   0.9396
12     0.180360    0.200654   0.9404
13     0.178429    0.200356   0.9407
14     0.176683    0.201254   0.9408
15     0.175024    0.198771   0.9410
16     0.173530    0.200389   0.9411
17     0.172672    0.201816   0.9409
18     0.171774    0.200723   0.9411
19     0.170250    0.199100   0.9418
20     0.169288    0.199096   0.9419
21     0.168457    0.198818   0.9417
22     0.167567    0.198160   0.9423
23     0.166800    0.198494   0.9428
24     0.166670    0.201272   0.9423
25     0.165635    0.199741   0.9430
26     0.164836    0.200219   0.9427
27     0.164240    0.199620   0.9428
28     0.163796    0.199575   0.9429
29     0.163175    0.198506   0.9428
30     0.162522    0.198733   0.9434
Remaining weight 2.31 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.283832   0.0984
1     0.891837    0.370858   0.8925
2     0.322519    0.278051   0.9161
3     0.263702    0.248171   0.9235
4     0.238607    0.234848   0.9273
5     0.224054    0.225889   0.9303
6     0.213785    0.219619   0.9332
7     0.206520    0.216768   0.9342
8     0.201251    0.214347   0.9351
9     0.197014    0.212293   0.9359
10     0.193679    0.209638   0.9367
11     0.190785    0.210073   0.9373
12     0.188509    0.210095   0.9376
13     0.186568    0.208907   0.9378
14     0.184702    0.209947   0.9381
15     0.183364    0.209987   0.9380
16     0.182054    0.208819   0.9387
17     0.180898    0.210840   0.9391
18     0.179858    0.209485   0.9393
19     0.178832    0.210485   0.9387
20     0.178152    0.210763   0.9395
21     0.177153    0.209816   0.9395
22     0.176244    0.208487   0.9399
23     0.175479    0.208835   0.9400
24     0.174853    0.209514   0.9400
25     0.174974    0.212538   0.9405
26     0.173844    0.209894   0.9399
27     0.173219    0.209353   0.9404
28     0.172644    0.210551   0.9402
29     0.172193    0.210442   0.9407
30     0.171762    0.214492   0.9396
Remaining weight 1.85 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.282908   0.0933
1     0.902448    0.384890   0.8870
2     0.333132    0.292763   0.9111
3     0.276354    0.263459   0.9205
4     0.251178    0.247965   0.9251
5     0.236673    0.237978   0.9271
6     0.227078    0.233371   0.9293
7     0.220446    0.230507   0.9298
8     0.215408    0.227198   0.9310
9     0.211152    0.225692   0.9323
10     0.207798    0.224260   0.9327
11     0.204963    0.222884   0.9336
12     0.202673    0.222154   0.9329
13     0.200595    0.221901   0.9339
14     0.198744    0.222099   0.9337
15     0.197110    0.221845   0.9347
16     0.195805    0.222136   0.9343
17     0.194689    0.222425   0.9344
18     0.193420    0.220118   0.9355
19     0.192295    0.221496   0.9357
20     0.191417    0.221325   0.9355
21     0.190406    0.221509   0.9350
22     0.189771    0.222641   0.9356
23     0.189029    0.221483   0.9359
24     0.188413    0.221679   0.9358
25     0.187718    0.222593   0.9353
26     0.187065    0.223053   0.9362
27     0.186782    0.224162   0.9364
28     0.186093    0.222872   0.9361
29     0.185414    0.223683   0.9362
30     0.184947    0.224880   0.9360
Remaining weight 1.49 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.289257   0.1027
1     0.930489    0.402984   0.8787
2     0.350900    0.309826   0.9053
3     0.293831    0.280323   0.9135
4     0.268992    0.265129   0.9187
5     0.254453    0.255858   0.9213
6     0.244477    0.249217   0.9238
7     0.237194    0.245007   0.9251
8     0.231525    0.241368   0.9258
9     0.227044    0.240162   0.9268
10     0.222576    0.235632   0.9291
11     0.219133    0.235545   0.9290
12     0.216482    0.235332   0.9293
13     0.214338    0.234328   0.9297
14     0.212359    0.233532   0.9304
15     0.210725    0.232728   0.9303
16     0.209137    0.232613   0.9310
17     0.207906    0.233207   0.9307
18     0.206713    0.231777   0.9308
19     0.205630    0.232818   0.9316
20     0.204525    0.232516   0.9318
21     0.203715    0.233866   0.9313
22     0.203067    0.233858   0.9321
23     0.202133    0.233148   0.9324
24     0.201469    0.234100   0.9325
25     0.200903    0.233977   0.9317
26     0.200200    0.234682   0.9320
27     0.199798    0.234836   0.9327
28     0.199318    0.235198   0.9325
29     0.198741    0.235997   0.9316
30     0.198339    0.236093   0.9329
Remaining weight 1.19 %
Epoch Train_loss  Test_loss  Accuracy
0     0.000000    2.290907   0.1120
1     0.953331    0.414232   0.8751
2     0.364738    0.321589   0.9014
3     0.306713    0.290591   0.9109
4     0.281038    0.274601   0.9145
5     0.265930    0.264880   0.9183
6     0.256146    0.258700   0.9200
7     0.249124    0.254447   0.9209
8     0.243946    0.252267   0.9219
9     0.239866    0.249541   0.9227
10     0.236700    0.248663   0.9230
11     0.233876    0.246396   0.9240
12     0.231398    0.245026   0.9247
13     0.229324    0.244488   0.9245
14     0.227184    0.243782   0.9255
15     0.225585    0.242671   0.9260
16     0.224096    0.242898   0.9260
17     0.222816    0.241400   0.9264
18     0.221601    0.241684   0.9268
19     0.220366    0.240726   0.9271
20     0.219299    0.241378   0.9272
21     0.218424    0.241447   0.9271
22     0.217556    0.240825   0.9274
23     0.216838    0.241009   0.9280
24     0.216234    0.241389   0.9277
25     0.215313    0.242509   0.9280
26     0.214823    0.240913   0.9287
27     0.214282    0.240949   0.9280
28     0.213837    0.242330   0.9280
29     0.213276    0.241600   0.9283
30     0.212847    0.242255   0.9285
