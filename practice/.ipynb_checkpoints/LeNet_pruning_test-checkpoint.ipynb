{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import visdom\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def countZeroWeights(model):\n",
    "    zeros = 0\n",
    "    for param in model.parameters():\n",
    "        if param is not None:\n",
    "            zeros += torch.sum((param == 0).int()).data[0]\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")\n",
    "\n",
    "loss_plt = vis.line(Y = torch.Tensor(1).zero_(),\n",
    "                   opts = dict(title = 'LeNet_Pruning_Test',\n",
    "                              legend = ['legend'],\n",
    "                              showlegend = True\n",
    "                              )\n",
    "                   )\n",
    "\n",
    "def loss_tracker(loss_plot, loss_value, num, name):\n",
    "    vis.line(X = num,\n",
    "            Y = loss_value,\n",
    "            win = loss_plot,\n",
    "            name = name,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(555)\n",
    "torch.cuda.manual_seed_all(555)\n",
    "np.random.seed(555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 1\n",
    "device = torch.device(f'cuda:{GPU_NUM}')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "epochs = 3\n",
    "batch_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 전처리\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = dsets.MNIST('../MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform = transform,\n",
    "                         download=False)\n",
    "\n",
    "train_data_mean = trainset.data.float().mean()/255\n",
    "train_data_std = trainset.data.float().std()/255\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5), (0.5))]\n",
    "                             )\n",
    "                               \n",
    "trainset = dsets.MNIST('../MNIST_data/',\n",
    "                      train = True,\n",
    "                      transform = transform,\n",
    "                      download = False)\n",
    "\n",
    "valset = dsets.MNIST('../MNIST_data/',\n",
    "                      train = True,\n",
    "                      transform = transform,\n",
    "                      download = False)\n",
    "\n",
    "testset = dsets.MNIST('../MNIST_data/',\n",
    "                      train = False,\n",
    "                      transform = transform,\n",
    "                      download = False)\n",
    "\n",
    "validation_ratio = 0.1\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = trainset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          sampler = train_sampler,\n",
    "                                          drop_last = True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset = valset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          sampler = val_sampler,\n",
    "                                          drop_last = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = testset,\n",
    "                                          drop_last = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model_base = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinhyuk/anaconda3/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = pickle.loads(pickle.dumps(model_base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_base)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0271,  0.0445,  0.0437,  ...,  0.0244, -0.0405, -0.0107],\n",
       "          [-0.0467, -0.0027,  0.0158,  ..., -0.0051, -0.0212,  0.0045],\n",
       "          [-0.0135, -0.0077,  0.0229,  ...,  0.0289,  0.0204, -0.0473],\n",
       "          ...,\n",
       "          [-0.0167, -0.0093, -0.0275,  ..., -0.0422,  0.0244, -0.0153],\n",
       "          [-0.0449,  0.0292, -0.0194,  ..., -0.0171, -0.0111, -0.0295],\n",
       "          [-0.0386,  0.0079, -0.0364,  ...,  0.0388,  0.0144, -0.0467]],\n",
       "         device='cuda:1', requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0273, -0.0473, -0.0487, -0.0398, -0.0422, -0.0412, -0.0063, -0.0181,\n",
       "          -0.0494,  0.0393, -0.0013, -0.0410,  0.0057,  0.0204,  0.0010,  0.0241,\n",
       "          -0.0050,  0.0010, -0.0007, -0.0439, -0.0090,  0.0193,  0.0293,  0.0158,\n",
       "           0.0065,  0.0072, -0.0386, -0.0012, -0.0025, -0.0433, -0.0129, -0.0440,\n",
       "          -0.0130, -0.0115, -0.0265,  0.0235, -0.0302,  0.0049, -0.0052, -0.0170,\n",
       "          -0.0216,  0.0396, -0.0442,  0.0146, -0.0018, -0.0460, -0.0051, -0.0179,\n",
       "          -0.0046,  0.0322, -0.0261,  0.0402,  0.0026,  0.0023, -0.0039, -0.0193,\n",
       "          -0.0364,  0.0085, -0.0490, -0.0214,  0.0151,  0.0133,  0.0298,  0.0053,\n",
       "           0.0440, -0.0497,  0.0177,  0.0446,  0.0410,  0.0390, -0.0438, -0.0436,\n",
       "           0.0387, -0.0277, -0.0260, -0.0272, -0.0407,  0.0299, -0.0030, -0.0296,\n",
       "          -0.0248,  0.0187, -0.0371,  0.0381,  0.0235, -0.0156,  0.0273,  0.0453,\n",
       "           0.0345,  0.0142,  0.0330, -0.0467,  0.0431, -0.0191,  0.0490, -0.0482,\n",
       "           0.0336,  0.0216, -0.0407, -0.0136, -0.0333, -0.0352, -0.0041, -0.0237,\n",
       "           0.0297, -0.0275,  0.0442,  0.0092,  0.0266, -0.0116, -0.0184,  0.0217,\n",
       "           0.0132,  0.0084,  0.0090,  0.0006, -0.0270, -0.0334, -0.0455, -0.0339,\n",
       "           0.0114,  0.0456, -0.0255, -0.0157,  0.0295,  0.0209,  0.0120, -0.0360,\n",
       "           0.0232, -0.0346, -0.0193,  0.0451, -0.0165, -0.0220, -0.0098,  0.0430,\n",
       "          -0.0110,  0.0078,  0.0001,  0.0314, -0.0409,  0.0427, -0.0444,  0.0190,\n",
       "           0.0444, -0.0368,  0.0256,  0.0139,  0.0002,  0.0415, -0.0233, -0.0045,\n",
       "          -0.0239, -0.0051, -0.0107, -0.0106,  0.0268,  0.0478, -0.0171,  0.0232,\n",
       "           0.0371,  0.0232,  0.0246,  0.0420, -0.0340, -0.0492,  0.0134, -0.0308,\n",
       "           0.0405,  0.0056,  0.0182, -0.0449,  0.0177, -0.0181,  0.0400, -0.0312,\n",
       "           0.0014, -0.0387, -0.0481,  0.0158, -0.0197, -0.0307, -0.0237, -0.0098,\n",
       "           0.0347, -0.0327,  0.0477,  0.0253,  0.0282, -0.0191, -0.0418,  0.0210,\n",
       "           0.0131, -0.0266,  0.0136,  0.0434, -0.0224, -0.0274,  0.0310, -0.0343,\n",
       "          -0.0431,  0.0499, -0.0447, -0.0373,  0.0410, -0.0305, -0.0095,  0.0238,\n",
       "           0.0345, -0.0135, -0.0398, -0.0168, -0.0470, -0.0212, -0.0437, -0.0279,\n",
       "          -0.0111, -0.0326,  0.0007,  0.0267, -0.0058, -0.0372, -0.0476, -0.0431,\n",
       "           0.0404,  0.0324,  0.0013, -0.0364,  0.0134, -0.0124, -0.0480, -0.0044,\n",
       "           0.0143, -0.0180, -0.0127, -0.0448,  0.0113, -0.0479, -0.0462, -0.0463,\n",
       "          -0.0203, -0.0410,  0.0083,  0.0421,  0.0071, -0.0097,  0.0273,  0.0444,\n",
       "          -0.0038,  0.0272, -0.0301,  0.0246, -0.0455, -0.0336, -0.0114, -0.0166,\n",
       "          -0.0478, -0.0431, -0.0069,  0.0458,  0.0096,  0.0407, -0.0116,  0.0485,\n",
       "           0.0484, -0.0273,  0.0306,  0.0432, -0.0035, -0.0420, -0.0123, -0.0281,\n",
       "           0.0015, -0.0417, -0.0135, -0.0433,  0.0245, -0.0296,  0.0147,  0.0286,\n",
       "           0.0001,  0.0038, -0.0066, -0.0169, -0.0362,  0.0136, -0.0332, -0.0236,\n",
       "           0.0156, -0.0205,  0.0048, -0.0353, -0.0459,  0.0372,  0.0354,  0.0155,\n",
       "          -0.0167,  0.0191,  0.0321,  0.0367], device='cuda:1',\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.fc1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, DataLoader, total_batch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for X, Y in DataLoader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss / total_batch\n",
    "        \n",
    "    return running_loss\n",
    "\n",
    "def loss_eval(model, criterion, DataLoader, total_batch):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        for X, Y in DataLoader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, Y)\n",
    "            running_loss += loss / total_batch\n",
    "        return running_loss    \n",
    "\n",
    "def accu_eval(DataLoader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X, Y in DataLoader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            outputs = model(X)\n",
    "            \n",
    "            predicted = torch.argmax(outputs.data, 1)\n",
    "            total += Y.size(0)\n",
    "            correct += (predicted == Y).sum().item()\n",
    "        return correct, total  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = 1.2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(count_parameters(module))\\n#countZeroWeights(model)\\nprint(sum((module.weight == 0).sum(dim=1)))'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(count_parameters(module))\n",
    "#countZeroWeights(model)\n",
    "print(sum((module.weight == 0).sum(dim=1)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Start!\n",
      "[epoch : 1] (T_loss: 0.36205)  (V_loss: 0.247128)  (Val Accuract : 92 %)\n",
      "[epoch : 2] (T_loss: 0.11424)  (V_loss: 0.216839)  (Val Accuract : 93 %)\n",
      "[epoch : 3] (T_loss: 0.08046)  (V_loss: 0.262497)  (Val Accuract : 92 %)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "t_total_batch = len(test_loader)\n",
    "v_total_batch = len(val_loader)\n",
    "print('Learning Start!')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    t_running_loss = train(model, optimizer, criterion, test_loader, t_total_batch)\n",
    "    v_running_loss = loss_eval(model, criterion, val_loader, v_total_batch)\n",
    "    correct, total = accu_eval(val_loader)\n",
    "    \n",
    "        # Plot & print\n",
    "    loss_tracker(loss_plt, torch.Tensor([t_running_loss]), torch.Tensor([epoch]), 'T_loss')\n",
    "    loss_tracker(loss_plt, torch.Tensor([v_running_loss]), torch.Tensor([epoch]), 'V_loss')\n",
    "\n",
    "    print('[epoch : %d] (T_loss: %.5f) ' % (epoch + 1, t_running_loss),\n",
    "          '(V_loss: %5f) ' % (v_running_loss),\n",
    "          '(Val Accuract : %d %%)' % (100 * correct / total)\n",
    "         )\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 4.4947e-04,  2.6580e-03,  7.2403e-04,  ...,  2.7783e-02,\n",
       "           -1.9292e-02,  9.7743e-03],\n",
       "          [ 1.2640e-42, -2.0305e-42,  1.6844e-42,  ..., -3.4077e-04,\n",
       "           -2.4802e-04, -5.3531e-07],\n",
       "          [ 1.1091e-03,  7.8542e-03, -3.1500e-04,  ...,  3.4875e-02,\n",
       "           -1.2314e-02, -1.0835e-02],\n",
       "          ...,\n",
       "          [-4.4604e-03, -3.3680e-03,  1.4998e-03,  ..., -1.7054e-02,\n",
       "            9.4226e-03,  1.9116e-02],\n",
       "          [-5.8429e-22,  1.0883e-22, -1.5724e-25,  ...,  2.9285e-21,\n",
       "           -3.1688e-21, -1.5790e-23],\n",
       "          [ 6.3262e-04,  5.2443e-04,  3.2825e-03,  ...,  1.1836e-02,\n",
       "            2.8429e-02,  1.6337e-02]], device='cuda:1', requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-3.1705e-03, -3.8343e-04, -2.0996e-03, -1.6259e-02, -2.1500e-02,\n",
       "          -1.6925e-02,  8.1173e-03, -1.8872e-02, -4.1448e-02,  6.3339e-43,\n",
       "           2.6328e-03, -5.6169e-04,  1.0667e-02,  6.3632e-03,  2.3396e-02,\n",
       "          -5.7650e-03, -1.0338e-02,  1.5267e-02, -1.9770e-05, -1.4323e-02,\n",
       "           7.7279e-03, -4.0175e-03,  1.6503e-02,  1.3163e-02, -1.4087e-03,\n",
       "           8.4268e-03, -7.0520e-03, -3.1260e-12, -4.4674e-03, -3.2831e-05,\n",
       "           3.8821e-07, -4.7570e-03, -3.3808e-04,  1.7744e-03, -4.2047e-03,\n",
       "          -4.1531e-04, -4.2515e-42, -1.8343e-03,  3.8023e-03, -2.6237e-05,\n",
       "           4.6441e-04,  2.6516e-02, -2.5138e-02,  1.2664e-02,  1.3464e-03,\n",
       "          -2.2363e-02, -8.9933e-03, -1.4260e-02,  2.6632e-02,  2.1137e-02,\n",
       "          -3.9137e-02,  2.5189e-02, -1.3456e-02, -6.4934e-25,  7.5656e-04,\n",
       "           6.2317e-03,  9.7421e-03,  1.8489e-02, -2.4191e-02, -3.2578e-04,\n",
       "           9.2469e-03,  7.6592e-03,  2.8893e-02, -4.1842e-03,  2.4572e-02,\n",
       "          -2.0001e-03,  3.1872e-02,  3.8665e-02,  2.6165e-02, -9.0268e-04,\n",
       "          -2.6710e-02, -3.3352e-02,  1.0909e-02, -7.2483e-03, -1.0065e-03,\n",
       "          -1.8266e-02, -2.4202e-03,  7.3517e-04,  1.1683e-02, -1.2566e-02,\n",
       "          -6.9405e-03,  2.3675e-02,  8.8457e-04,  2.2901e-02,  1.6651e-02,\n",
       "           1.0855e-02,  3.0397e-02,  3.7962e-02,  3.3461e-02,  1.0215e-02,\n",
       "           2.0716e-02, -2.2550e-02,  3.8240e-02, -3.3633e-03,  1.7745e-02,\n",
       "          -3.0598e-14,  2.1439e-02,  8.4401e-03, -1.9185e-02, -4.7344e-03,\n",
       "          -4.4092e-03, -7.8598e-03,  4.7268e-03, -1.9771e-02,  3.4892e-02,\n",
       "          -8.4924e-03, -1.8835e-05,  1.2187e-02, -9.0457e-04, -2.1134e-02,\n",
       "          -4.4404e-04, -3.4197e-04,  1.3125e-02,  6.0229e-03, -2.4483e-03,\n",
       "           3.0386e-03, -2.5386e-02, -2.3513e-02, -1.0868e-02, -5.9546e-05,\n",
       "          -2.2658e-06,  1.3177e-02,  1.5077e-03, -1.6746e-42, -4.6375e-04,\n",
       "           3.7277e-02, -3.2216e-34, -3.0373e-03,  3.4627e-02,  1.8360e-02,\n",
       "           1.2640e-02,  4.1520e-02, -1.4749e-02, -5.4869e-03,  1.3518e-02,\n",
       "           2.7900e-02, -1.1923e-02,  2.9974e-02,  1.9465e-02, -2.9751e-03,\n",
       "          -2.1044e-02, -1.2414e-09, -2.1149e-02,  1.6702e-03,  1.9881e-02,\n",
       "          -1.1459e-02,  8.2241e-03,  1.6637e-02,  1.9816e-02,  2.1772e-02,\n",
       "          -2.5375e-02, -1.5055e-03, -5.4274e-03, -8.2642e-04, -6.9406e-03,\n",
       "          -5.0248e-03,  7.9914e-03,  3.8230e-02, -7.3396e-03,  1.9930e-02,\n",
       "           2.2460e-02, -1.0163e-04,  1.5812e-02,  1.4657e-04, -4.2108e-03,\n",
       "          -1.4751e-04, -3.3640e-06, -5.3909e-06,  4.5814e-02,  8.6382e-03,\n",
       "          -7.2786e-03, -3.4720e-02, -5.1423e-03, -1.8511e-02,  3.0616e-02,\n",
       "          -2.9708e-02, -4.3518e-03,  1.9910e-33, -1.4281e-07,  1.8721e-02,\n",
       "          -2.1400e-04,  6.9104e-03, -1.4544e-02, -6.9133e-03, -6.9592e-06,\n",
       "          -9.9269e-04,  3.4816e-02,  3.5583e-02,  9.0959e-03, -1.3396e-42,\n",
       "           1.1964e-03,  1.0490e-02, -3.8336e-05, -2.9507e-02,  2.7608e-02,\n",
       "          -3.0789e-25, -1.8417e-02, -2.9366e-02,  9.9958e-03, -3.5330e-04,\n",
       "          -2.3064e-16,  3.1116e-02, -1.8495e-02, -1.9674e-02,  1.7358e-02,\n",
       "           6.7182e-03,  4.4791e-03, -2.4905e-03,  1.0750e-02, -6.4606e-04,\n",
       "          -9.7109e-03, -1.9436e-05,  6.4705e-04, -1.6059e-08, -1.2321e-02,\n",
       "          -2.3898e-05,  1.4673e-02, -1.4489e-03, -1.1250e-02,  1.6869e-02,\n",
       "           9.2168e-03, -1.4607e-02, -4.4953e-04,  1.9655e-09,  2.3086e-02,\n",
       "           1.6342e-02, -4.1459e-05, -9.2965e-03,  1.2122e-03, -1.1293e-03,\n",
       "          -1.5340e-02, -5.7145e-42,  7.9070e-03, -1.4442e-03, -1.0456e-02,\n",
       "          -9.9090e-03, -2.6851e-03,  7.4697e-03, -3.8895e-02, -2.7222e-02,\n",
       "          -1.7381e-02, -5.4187e-03,  4.3696e-03, -5.1078e-04,  5.8140e-03,\n",
       "           1.7181e-03,  1.2658e-02,  3.1301e-02,  9.0366e-04,  1.1107e-02,\n",
       "          -1.5811e-02,  1.3244e-02, -1.3577e-12, -1.0228e-12, -4.2841e-03,\n",
       "          -3.7528e-04, -4.0704e-03, -3.8796e-02, -7.8499e-03,  4.8777e-02,\n",
       "           7.9556e-03,  2.2066e-02,  8.3890e-03,  4.4259e-02,  3.5862e-02,\n",
       "          -1.5209e-02,  1.2424e-02, -2.1537e-18, -1.5872e-06, -9.5219e-24,\n",
       "          -8.4261e-03,  5.4120e-03,  3.7993e-03, -1.8893e-02,  5.2166e-03,\n",
       "          -3.0597e-02, -6.8912e-04, -1.2340e-14, -5.6607e-03,  1.7814e-02,\n",
       "           3.4287e-03, -1.3535e-12,  7.6850e-03, -3.6235e-03, -2.1165e-02,\n",
       "           1.4985e-02,  1.3480e-34, -1.6931e-14,  2.4472e-02,  1.3654e-03,\n",
       "           1.6629e-02,  1.6781e-03,  4.7624e-03,  3.4924e-02,  5.2672e-02,\n",
       "           1.6045e-02, -1.6228e-02,  1.3394e-02, -9.4669e-22, -1.0860e-03],\n",
       "         device='cuda:1', requires_grad=True))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.fc1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0271,  0.0445,  0.0437,  ...,  0.0244, -0.0405, -0.0107],\n",
       "          [-0.0467, -0.0027,  0.0158,  ..., -0.0051, -0.0212,  0.0045],\n",
       "          [-0.0135, -0.0077,  0.0229,  ...,  0.0289,  0.0204, -0.0473],\n",
       "          ...,\n",
       "          [-0.0167, -0.0093, -0.0275,  ..., -0.0422,  0.0244, -0.0153],\n",
       "          [-0.0449,  0.0292, -0.0194,  ..., -0.0171, -0.0111, -0.0295],\n",
       "          [-0.0386,  0.0079, -0.0364,  ...,  0.0388,  0.0144, -0.0467]],\n",
       "         device='cuda:1', requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0273, -0.0473, -0.0487, -0.0398, -0.0422, -0.0412, -0.0063, -0.0181,\n",
       "          -0.0494,  0.0393, -0.0013, -0.0410,  0.0057,  0.0204,  0.0010,  0.0241,\n",
       "          -0.0050,  0.0010, -0.0007, -0.0439, -0.0090,  0.0193,  0.0293,  0.0158,\n",
       "           0.0065,  0.0072, -0.0386, -0.0012, -0.0025, -0.0433, -0.0129, -0.0440,\n",
       "          -0.0130, -0.0115, -0.0265,  0.0235, -0.0302,  0.0049, -0.0052, -0.0170,\n",
       "          -0.0216,  0.0396, -0.0442,  0.0146, -0.0018, -0.0460, -0.0051, -0.0179,\n",
       "          -0.0046,  0.0322, -0.0261,  0.0402,  0.0026,  0.0023, -0.0039, -0.0193,\n",
       "          -0.0364,  0.0085, -0.0490, -0.0214,  0.0151,  0.0133,  0.0298,  0.0053,\n",
       "           0.0440, -0.0497,  0.0177,  0.0446,  0.0410,  0.0390, -0.0438, -0.0436,\n",
       "           0.0387, -0.0277, -0.0260, -0.0272, -0.0407,  0.0299, -0.0030, -0.0296,\n",
       "          -0.0248,  0.0187, -0.0371,  0.0381,  0.0235, -0.0156,  0.0273,  0.0453,\n",
       "           0.0345,  0.0142,  0.0330, -0.0467,  0.0431, -0.0191,  0.0490, -0.0482,\n",
       "           0.0336,  0.0216, -0.0407, -0.0136, -0.0333, -0.0352, -0.0041, -0.0237,\n",
       "           0.0297, -0.0275,  0.0442,  0.0092,  0.0266, -0.0116, -0.0184,  0.0217,\n",
       "           0.0132,  0.0084,  0.0090,  0.0006, -0.0270, -0.0334, -0.0455, -0.0339,\n",
       "           0.0114,  0.0456, -0.0255, -0.0157,  0.0295,  0.0209,  0.0120, -0.0360,\n",
       "           0.0232, -0.0346, -0.0193,  0.0451, -0.0165, -0.0220, -0.0098,  0.0430,\n",
       "          -0.0110,  0.0078,  0.0001,  0.0314, -0.0409,  0.0427, -0.0444,  0.0190,\n",
       "           0.0444, -0.0368,  0.0256,  0.0139,  0.0002,  0.0415, -0.0233, -0.0045,\n",
       "          -0.0239, -0.0051, -0.0107, -0.0106,  0.0268,  0.0478, -0.0171,  0.0232,\n",
       "           0.0371,  0.0232,  0.0246,  0.0420, -0.0340, -0.0492,  0.0134, -0.0308,\n",
       "           0.0405,  0.0056,  0.0182, -0.0449,  0.0177, -0.0181,  0.0400, -0.0312,\n",
       "           0.0014, -0.0387, -0.0481,  0.0158, -0.0197, -0.0307, -0.0237, -0.0098,\n",
       "           0.0347, -0.0327,  0.0477,  0.0253,  0.0282, -0.0191, -0.0418,  0.0210,\n",
       "           0.0131, -0.0266,  0.0136,  0.0434, -0.0224, -0.0274,  0.0310, -0.0343,\n",
       "          -0.0431,  0.0499, -0.0447, -0.0373,  0.0410, -0.0305, -0.0095,  0.0238,\n",
       "           0.0345, -0.0135, -0.0398, -0.0168, -0.0470, -0.0212, -0.0437, -0.0279,\n",
       "          -0.0111, -0.0326,  0.0007,  0.0267, -0.0058, -0.0372, -0.0476, -0.0431,\n",
       "           0.0404,  0.0324,  0.0013, -0.0364,  0.0134, -0.0124, -0.0480, -0.0044,\n",
       "           0.0143, -0.0180, -0.0127, -0.0448,  0.0113, -0.0479, -0.0462, -0.0463,\n",
       "          -0.0203, -0.0410,  0.0083,  0.0421,  0.0071, -0.0097,  0.0273,  0.0444,\n",
       "          -0.0038,  0.0272, -0.0301,  0.0246, -0.0455, -0.0336, -0.0114, -0.0166,\n",
       "          -0.0478, -0.0431, -0.0069,  0.0458,  0.0096,  0.0407, -0.0116,  0.0485,\n",
       "           0.0484, -0.0273,  0.0306,  0.0432, -0.0035, -0.0420, -0.0123, -0.0281,\n",
       "           0.0015, -0.0417, -0.0135, -0.0433,  0.0245, -0.0296,  0.0147,  0.0286,\n",
       "           0.0001,  0.0038, -0.0066, -0.0169, -0.0362,  0.0136, -0.0332, -0.0236,\n",
       "           0.0156, -0.0205,  0.0048, -0.0353, -0.0459,  0.0372,  0.0354,  0.0155,\n",
       "          -0.0167,  0.0191,  0.0321,  0.0367], device='cuda:1',\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_base.fc1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.nn.utils.prune.L1Unstructured(amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())\n",
    "print(model_base.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_buffers at 0x7f0e351d8750>\n"
     ]
    }
   ],
   "source": [
    "print(model.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = model.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=400, out_features=300, bias=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name='weight', amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=400, out_features=300, bias=True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name='weight', amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias_mask', tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.fc1.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias_orig', 'fc1.bias_mask', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())\n",
    "print(model_base.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.CustomFromMask(model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LeNet' object has no attribute '_tensor_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-663a10a5391e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Unstructured\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/utils/prune.py\u001b[0m in \u001b[0;36mapply_mask\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# so the pruning method must know what tensor it's operating on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         assert (\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module {} has to be pruned\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LeNet' object has no attribute '_tensor_name'"
     ]
    }
   ],
   "source": [
    "prune.L1Unstructured.apply_mask(model, 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.]], device='cuda:1'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.fc1.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(list(model_base.fc1.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.bias', 'fc1.weight_orig', 'fc1.weight_mask', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())\n",
    "print(model_base.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0491, -0.0845, -0.0874,  0.1131,  0.3536, -0.0558], device='cuda:1',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1476, -0.2033, -0.3068,  0.0978,  0.0971, -0.1217], device='cuda:1',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['bias', 'weight_orig', 'weight_mask'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = prune.l1_unstructured(module, name='weight', amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., -0., 0.],\n",
       "        [0., -0., 0.,  ..., -0., -0., -0.],\n",
       "        [0., 0., -0.,  ..., 0., -0., -0.],\n",
       "        ...,\n",
       "        [-0., -0., 0.,  ..., -0., 0., 0.],\n",
       "        [-0., 0., -0.,  ..., 0., -0., -0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., -0., 0.],\n",
       "        [0., -0., 0.,  ..., -0., -0., -0.],\n",
       "        [0., 0., -0.,  ..., 0., -0., -0.],\n",
       "        ...,\n",
       "        [-0., -0., 0.,  ..., -0., 0., 0.],\n",
       "        [-0., 0., -0.,  ..., 0., -0., -0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'apply_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-ce35464c2aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPruningContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.fc1.weight_mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'apply_mask'"
     ]
    }
   ],
   "source": [
    "prune.PruningContainer(apply_mask=(model_base, \"model.fc1.weight_mask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0271,  0.0445,  0.0437,  ...,  0.0244, -0.0405, -0.0107],\n",
      "        [-0.0467, -0.0027,  0.0158,  ..., -0.0051, -0.0212,  0.0045],\n",
      "        [-0.0135, -0.0077,  0.0229,  ...,  0.0289,  0.0204, -0.0473],\n",
      "        ...,\n",
      "        [-0.0167, -0.0093, -0.0275,  ..., -0.0422,  0.0244, -0.0153],\n",
      "        [-0.0449,  0.0292, -0.0194,  ..., -0.0171, -0.0111, -0.0295],\n",
      "        [-0.0386,  0.0079, -0.0364,  ...,  0.0388,  0.0144, -0.0467]],\n",
      "       device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model_base.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute '_forward_pre_hook'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-2a35ce2c2cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute '_forward_pre_hook'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "class FooBarPruningMethod(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        mask.view(-1)[::2] = 0 \n",
    "        return mask\n",
    "\n",
    "######################################################################\n",
    "# Now, to apply this to a parameter in an ``nn.Module``, you should\n",
    "# also provide a simple function that instantiates the method and\n",
    "# applies it.\n",
    "def foobar_unstructured(module, name):\n",
    "    \"\"\"Prunes tensor corresponding to parameter called `name` in `module`\n",
    "    by removing every other entry in the tensors.\n",
    "    Modifies module in place (and also return the modified module) \n",
    "    by:\n",
    "    1) adding a named buffer called `name+'_mask'` corresponding to the \n",
    "    binary mask applied to the parameter `name` by the pruning method.\n",
    "    The parameter `name` is replaced by its pruned version, while the \n",
    "    original (unpruned) parameter is stored in a new parameter named \n",
    "    `name+'_orig'`.\n",
    "    Args:\n",
    "        module (nn.Module): module containing the tensor to prune\n",
    "        name (string): parameter name within `module` on which pruning\n",
    "                will act.\n",
    "    Returns:\n",
    "        module (nn.Module): modified (i.e. pruned) version of the input\n",
    "            module\n",
    "    \n",
    "    Examples:\n",
    "        >>> m = nn.Linear(3, 4)\n",
    "        >>> foobar_unstructured(m, name='bias')\n",
    "    \"\"\"\n",
    "    FooBarPruningMethod.apply(module, name)\n",
    "    return module\n",
    "\n",
    "######################################################################\n",
    "# Let's try it out!\n",
    "model = LeNet()\n",
    "foobar_unstructured(model.fc1, name='bias')\n",
    "\n",
    "print(model.fc1.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'bias_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-b93ff130f9ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'bias_mask'"
     ]
    }
   ],
   "source": [
    "print(model_base.fc1.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model_base.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = model_basic.fc1\n",
    "\n",
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.l1_unstructured(module, name='bias', amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = model.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_parameters(module))\n",
    "print((module.weight == 0).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.remove(module, 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((module.weight == 0).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.l1_unstructured(module, name='weight', amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum((module.weight == 0).sum(dim=0)))\n",
    "print(sum((module.weight != 0).sum(dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
