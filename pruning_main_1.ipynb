{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import visdom\n",
    "import copy\n",
    "import torch.nn.utils.prune as prune\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "# custom librarys\n",
    "# model, parameters\n",
    "import custom.utils as cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(55)\n",
    "torch.cuda.manual_seed_all(55)\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  2\n",
      "Current cuda device  1\n",
      "GeForce RTX 2080 Ti\n",
      "cpu와 cuda 중 다음 기기로 학습함: cuda:1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 1\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# visdom setting\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")\n",
    "\n",
    "# make plot\n",
    "vis_plt = vis.line(X=torch.Tensor(1).zero_(), Y=torch.Tensor(1).zero_(), \n",
    "                    opts=dict(title = 'LeNet300_Accuracy_Tracker',\n",
    "                              legend=['100.0'],\n",
    "                             showlegend=True,\n",
    "                              xtickmin = 0,\n",
    "                              xtickmax = 20000,\n",
    "                              ytickmin = 0.95,\n",
    "                              ytickmax = 0.99\n",
    "                             )\n",
    "                   )\n",
    "\n",
    "def visdom_plot(loss_plot, loss_value, num, name):\n",
    "    vis.line(X = num,\n",
    "            Y = loss_value,\n",
    "            win = loss_plot,\n",
    "            name = name,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch = 0\n",
    "best_accu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'LeNet300'\n",
    "#model_type = 'Conv6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = cu.parameters()\n",
    "\n",
    "if model_type == 'LeNet300':\n",
    "    model = cu.LeNet300().to(device)\n",
    "elif model_type == 'Conv6':\n",
    "    model = cu.Conv6().to(device)\n",
    "    \n",
    "param.type(model_type)    \n",
    "model_init = copy.deepcopy(model)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0012,\n",
       " 'epochs': 50,\n",
       " 'batch_size': 60,\n",
       " 'weight_decay': 0.0012,\n",
       " 'iteration': 0,\n",
       " 'remaining_weight_c': 'empty',\n",
       " 'remaining_weight_f': 1,\n",
       " 'remaining_weight_o': 1,\n",
       " 'prune_per_c': 'empty',\n",
       " 'prune_per_f': 0.2,\n",
       " 'prune_per_o': 0.1,\n",
       " 'noi': 12,\n",
       " 'trainset': Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ../MNIST_data/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "            ),\n",
       " 'valset': 'empty',\n",
       " 'testset': Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ../MNIST_data/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "            ),\n",
       " 'train_loader': <torch.utils.data.dataloader.DataLoader at 0x7f44736a6150>,\n",
       " 'val_loader': 'empty',\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x7f43fadcae90>,\n",
       " 'transforms': Compose(\n",
       "     ToTensor()\n",
       "     Normalize(mean=(0.1307,), std=(0.3081,))\n",
       " )}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0012,\n",
       " 'epochs': 50,\n",
       " 'batch_size': 60,\n",
       " 'weight_decay': 0.0012,\n",
       " 'iteration': 0,\n",
       " 'remaining_weight_c': 'empty',\n",
       " 'remaining_weight_f': 1,\n",
       " 'remaining_weight_o': 1,\n",
       " 'prune_per_c': 'empty',\n",
       " 'prune_per_f': 0.2,\n",
       " 'prune_per_o': 0.1,\n",
       " 'noi': 12,\n",
       " 'trainset': Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ../MNIST_data/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "            ),\n",
       " 'valset': 'empty',\n",
       " 'testset': Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ../MNIST_data/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "            ),\n",
       " 'train_loader': <torch.utils.data.dataloader.DataLoader at 0x7f44736a6150>,\n",
       " 'val_loader': 'empty',\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x7f43fadcae90>,\n",
       " 'transforms': Compose(\n",
       "     ToTensor()\n",
       "     Normalize(mean=(0.1307,), std=(0.3081,))\n",
       " )}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f43fadcae90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter\n",
    "lr = 0.0012\n",
    "#epochs = 50\n",
    "#epochs = 20\n",
    "epochs = 30\n",
    "batch_size = 60\n",
    "weight_decay = 1.2e-3\n",
    "iteration = 0\n",
    "remaining_weight = 1\n",
    "prune_per = 0.2\n",
    "# number of iteration\n",
    "noi = 11\n",
    "\n",
    "switch = 0\n",
    "best_accu = []\n",
    "# 마지막 layer의 Pruning rate는 기존의 1/2\n",
    "# prune_per_ll = prune_per/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cp_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_train = dsets.MNIST(root='../MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms,\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root='../MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms,\n",
    "                        download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, prune function\n",
    "def train(model, dataloader, optimizer, criterion, cp_mask):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, label) in enumerate(dataloader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        # 0-weight 학습 방지\n",
    "        if cp_mask:\n",
    "            i = 0\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    p.grad.data *= cp_mask[i]\n",
    "                    i += 1\n",
    "        optimizer.step()\n",
    "        running_loss += loss / len(dataloader)\n",
    "    return running_loss\n",
    "\n",
    "def test(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #test_loss += F.nll_loss(outputs, label, reduction='sum').item() # sum up batch loss\n",
    "            loss = criterion(outputs, label)\n",
    "            #predicted = outputs.data.max(1, keepdim=True)[1]\n",
    "            #correct += predicted.eq(label.data.view_as(predicted)).sum().item()\n",
    "            \n",
    "            test_loss += loss / len(dataloader)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "        #accuracy =  correct / len(dataloader)\n",
    "        # 로더 -> 배치 개수 로더.dataset -> 전체 길이, \n",
    "    return (correct/total), test_loss\n",
    "\n",
    "# prune function\n",
    "# pruning mask 생성 -> mask 복사 -> init값 복사 -> prune 진행\n",
    "def weight_init(model1, model2, c_rate, f_rate, o_rate):\n",
    "    # layer별로 지정된 rate만큼 prune mask 생성\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name = 'weight', amount = c_rate)\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if name != 'fc3':\n",
    "                prune.l1_unstructured(module, name = 'weight', amount = f_rate)\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name = 'weight', amount = o_rate)\n",
    "                        \n",
    "    # mask 복사\n",
    "    cp_mask = []\n",
    "    for name, mask in model1.named_buffers():\n",
    "        cp_mask.append(mask)\n",
    "    \n",
    "    # init 값을 model에 복사\n",
    "    for name, p in model1.named_parameters():\n",
    "        if 'weight_orig' in name:\n",
    "            for name2, p2 in model2.named_parameters():\n",
    "                if name[0:len(name) - 5] in name2:\n",
    "                    p.data = copy.deepcopy(p2.data)\n",
    "        if 'bias_orig' in name:\n",
    "            for name2, p2 in model2.named_parameters():\n",
    "                if name[0:len(name) - 5] in name2:\n",
    "                    p.data = copy.deepcopy(p2.data)\n",
    "                    \n",
    "    # prune 진행\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.remove(module, name = 'weight')\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            prune.remove(module, name = 'weight')\n",
    "            \n",
    "    # copy된 mask return\n",
    "    return cp_mask\n",
    "\n",
    "# weight count function\n",
    "# list type[[name, all, non_zero, zero, per]]\n",
    "def weight_counter(model):\n",
    "    layer_weight = []\n",
    "    all_weight = ['All_weight',0 ,0 ,0, 0]\n",
    "    for name, p in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            none_zero_w = (p != 0).sum().item()\n",
    "            zero_w = (p == 0).sum().item()\n",
    "            all_w = none_zero_w + zero_w\n",
    "\n",
    "            all_weight[1] += all_w\n",
    "            all_weight[2] += none_zero_w\n",
    "            all_weight[3] += zero_w\n",
    "\n",
    "            layer_weight.append([name, all_w, none_zero_w, zero_w, round(none_zero_w/all_w, 1)])\n",
    "\n",
    "    all_weight[4] = round((all_weight[2]/all_weight[1]), 3)\n",
    "    layer_weight.insert(0, all_weight)\n",
    "    for i in range(len(layer_weight)):\n",
    "        print(layer_weight[i])\n",
    "    \n",
    "    return layer_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(param.train_loader), len(param.val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            predicted = torch.argmax(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            accuracy = (correct/total)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = 1.2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPS = 1e-6\n",
    "# number of weight\n",
    "a = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "#b = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "b = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "\n",
    "now = (a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def calc_now(model):\n",
    "    fc1_1 = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc1_0 = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc1 = fc1_1 + fc1_0\n",
    "    fc1_p = fc1_0 / fc1_1\n",
    "    fc2_1 = ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc2_0 = ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc2 = fc2_1 + fc2_0\n",
    "    fc3_1 = ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc3_0 = ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc3 = fc3_1 + fc3_0\n",
    "    #print(fc1, fc2, fc3, fc1+fc2+fc3, fc1_1 + fc2_1 + fc3_1 ,fc1_0 + fc2_0 + fc3_0)\n",
    "    print(\"Remaining weight %.1f %%\" %(((fc1_1+fc2_1+fc3_1)/(fc1+fc2+fc3))*100))\n",
    "    print('total weight :',\n",
    "        '%d' % (fc1+fc2+fc3),\n",
    "         '(%d |' % (fc1_1+fc2_1+fc3_1),\n",
    "         '%d)' % (fc1_0+fc2_0+fc3_0)\n",
    "         )\n",
    "    print('fc1 :',\n",
    "        '%d' % fc1,\n",
    "         '(%d |' % fc1_1,\n",
    "         '%d)' % fc1_0\n",
    "         )\n",
    "    print('fc2 :',\n",
    "        '%d' % fc2,\n",
    "         '(%d |' % fc2_1,\n",
    "         '%d)' % fc2_0\n",
    "         )\n",
    "    print('fc3 :',\n",
    "        '%d' % fc3,\n",
    "         '(%d |' % fc3_1,\n",
    "         '%d)' % fc3_0\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_init(model, model_init, 1 - weight_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_init(model, model_init, 1 - weight_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model.fc3.weight_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.l1_unstructured(module, name = 'weight', amount = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # init 값 복사\n",
    "for name, p in model.named_parameters():\n",
    "     if 'weight_orig' in name:\n",
    "        for name2, p2 in model_init.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break\n",
    "    if 'bias_orig' in name:\n",
    "        for name2, p2 in modelinit.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.remove(module, name = 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model.fc3.weight[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model_init.fc3.weight[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 266200, 0, 1.0]\n",
      "['fc1.weight', 235200, 235200, 0, 1.0]\n",
      "['fc2.weight', 30000, 30000, 0, 1.0]\n",
      "['fc3.weight', 1000, 1000, 0, 1.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e19138cebc04769837134f6567bf323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.1053)\n",
      "[epoch : 1] (r_loss: 0.22417) (t_loss: 0.12337) (accu: 0.9617)\n",
      "\n",
      "Finish! (Best accu: 0.9617) (Time taken(sec) : 14.86) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 213060, 53140, 0.8]\n",
      "['fc1.weight', 235200, 188160, 47040, 0.8]\n",
      "['fc2.weight', 30000, 24000, 6000, 0.8]\n",
      "['fc3.weight', 1000, 900, 100, 0.9]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3327e36c93824742be38968c096189be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.1267)\n",
      "[epoch : 1] (r_loss: 0.21979) (t_loss: 0.12898) (accu: 0.9585)\n",
      "\n",
      "Finish! (Best accu: 0.9585) (Time taken(sec) : 14.30) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 170538, 95662, 0.641]\n",
      "['fc1.weight', 235200, 150528, 84672, 0.6]\n",
      "['fc2.weight', 30000, 19200, 10800, 0.6]\n",
      "['fc3.weight', 1000, 810, 190, 0.8]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea560ce6114c4fa4a2e42a1d03ba345a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.1806)\n",
      "[epoch : 1] (r_loss: 0.20324) (t_loss: 0.11282) (accu: 0.9650)\n",
      "\n",
      "Finish! (Best accu: 0.9650) (Time taken(sec) : 14.42) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 136511, 129689, 0.513]\n",
      "['fc1.weight', 235200, 120422, 114778, 0.5]\n",
      "['fc2.weight', 30000, 15360, 14640, 0.5]\n",
      "['fc3.weight', 1000, 729, 271, 0.7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8be824445a04174bac0ddc91b64afcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.1790)\n",
      "[epoch : 1] (r_loss: 0.19153) (t_loss: 0.12398) (accu: 0.9629)\n",
      "\n",
      "Finish! (Best accu: 0.9629) (Time taken(sec) : 14.86) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 109282, 156918, 0.411]\n",
      "['fc1.weight', 235200, 96338, 138862, 0.4]\n",
      "['fc2.weight', 30000, 12288, 17712, 0.4]\n",
      "['fc3.weight', 1000, 656, 344, 0.7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423549b5d985419db5fff0117a66c30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.2020)\n",
      "[epoch : 1] (r_loss: 0.17964) (t_loss: 0.10236) (accu: 0.9712)\n",
      "\n",
      "Finish! (Best accu: 0.9712) (Time taken(sec) : 14.88) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 87490, 178710, 0.329]\n",
      "['fc1.weight', 235200, 77070, 158130, 0.3]\n",
      "['fc2.weight', 30000, 9830, 20170, 0.3]\n",
      "['fc3.weight', 1000, 590, 410, 0.6]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3da556bd8640928a0d1a3fba6df076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.2890)\n",
      "[epoch : 1] (r_loss: 0.16418) (t_loss: 0.09958) (accu: 0.9721)\n",
      "\n",
      "Finish! (Best accu: 0.9721) (Time taken(sec) : 14.86) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 70051, 196149, 0.263]\n",
      "['fc1.weight', 235200, 61656, 173544, 0.3]\n",
      "['fc2.weight', 30000, 7864, 22136, 0.3]\n",
      "['fc3.weight', 1000, 531, 469, 0.5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e3dd97b2b749918f97f64987ae5ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.2959)\n",
      "[epoch : 1] (r_loss: 0.15752) (t_loss: 0.09388) (accu: 0.9699)\n",
      "\n",
      "Finish! (Best accu: 0.9699) (Time taken(sec) : 14.76) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 56094, 210106, 0.211]\n",
      "['fc1.weight', 235200, 49325, 185875, 0.2]\n",
      "['fc2.weight', 30000, 6291, 23709, 0.2]\n",
      "['fc3.weight', 1000, 478, 522, 0.5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a6bf508ab04c4ea89f1cf76d365b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.2299)\n",
      "[epoch : 1] (r_loss: 0.15345) (t_loss: 0.08650) (accu: 0.9732)\n",
      "\n",
      "Finish! (Best accu: 0.9732) (Time taken(sec) : 14.89) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 44923, 221277, 0.169]\n",
      "['fc1.weight', 235200, 39460, 195740, 0.2]\n",
      "['fc2.weight', 30000, 5033, 24967, 0.2]\n",
      "['fc3.weight', 1000, 430, 570, 0.4]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8165be81d2a4a9bb6d062194137be92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.2112)\n",
      "[epoch : 1] (r_loss: 0.15490) (t_loss: 0.08849) (accu: 0.9741)\n",
      "\n",
      "Finish! (Best accu: 0.9741) (Time taken(sec) : 14.54) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning start!\n",
      "\n",
      "['All_weight', 266200, 35982, 230218, 0.135]\n",
      "['fc1.weight', 235200, 31568, 203632, 0.1]\n",
      "['fc2.weight', 30000, 4027, 25973, 0.1]\n",
      "['fc3.weight', 1000, 387, 613, 0.4]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248fb76bd9f54a71a099eb1ae2ef3d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.3336)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5bc862df277d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m              )\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# val_set이 있을 경우 val_set을 통해 loss, accu를 구한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ad29862c891a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, cp_mask)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(param.noi):\n",
    "    best_accu.append(0)\n",
    "    best_accu[i] = [0, 0, 0]\n",
    "    cp_mask = []\n",
    "    \n",
    "    if i != 0:\n",
    "        # x1 = 1 * (1-0.2)\n",
    "        # x2 = 1 * (1-0.2) * (1-0.2)\n",
    "        # ...\n",
    "        # xn = 1 * (1-0.2) ** n -> 남은 weight\n",
    "        # pruning weight 1 - (1-0.2)**n\n",
    "        \n",
    "        # 필요한 값은 pruning weight \n",
    "        # c = conv f = fc o = output layer\n",
    "        if  model_type == 'LeNet300':\n",
    "             param.remaining_weight_c = 1\n",
    "        else:\n",
    "            param.remaining_weight_c = (1-param.prune_per_c) ** i\n",
    "        param.remaining_weight_f = (1-param.prune_per_f) ** i\n",
    "        param.remaining_weight_o = (1-param.prune_per_o) ** i\n",
    "        #remaining_weight = param.remaining_weight_f\n",
    "        #1- 남은 웨이트 -> prune 할 비율\n",
    "        # pruning 및 mask 복사\n",
    "        cp_mask = weight_init(model, model_init,\n",
    "                              1 - param.remaining_weight_c,\n",
    "                              1 - param.remaining_weight_f,\n",
    "                              1 - param.remaining_weight_o\n",
    "                             )\n",
    "        #switch = 1\n",
    "    optimizer = optim.Adam(model.parameters(), lr = param.lr, weight_decay = param.weight_decay)\n",
    "    print(\"Learning start!\\n\")\n",
    "    #calc_now(model)\n",
    "    num_of_weight = weight_counter(model)\n",
    "    #print(model.fc3.weight[0])\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    #pw = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    #print('pruned weight (All | Pruned) %d |' % now,'%d' % pw)\n",
    "    #print(model.fc3.weight[0][0])\n",
    "    #print(model_init.fc3.weight[0][0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(param.epochs)):\n",
    "        # epoch가 0일때 정확도 계산\n",
    "        if epoch == 0:\n",
    "            accuracy, test_loss = test(model, param.test_loader, criterion)\n",
    "            visdom_plot(vis_plt,torch.Tensor([accuracy]), torch.Tensor([0]),\n",
    "                        str(round(num_of_weight[0][4]*100, 1))\n",
    "                       )\n",
    "            print('[epoch : %d]' % (epoch),\n",
    "             '(loss: x.xxxxx)',\n",
    "             '(accu: %.4f)' % (accuracy)\n",
    "             )\n",
    "        # model training    \n",
    "        running_loss = train(model, param.train_loader, optimizer, criterion, cp_mask)\n",
    "        \n",
    "        # val_set이 있을 경우 val_set을 통해 loss, accu를 구한다.\n",
    "        if param.valset == 'empty':\n",
    "            accuracy, test_loss = test(model, param.test_loader, criterion)\n",
    "        else:\n",
    "            accuracy, test_loss = test(model, param.val_loader, criterion)\n",
    "        \n",
    "        # visdom plot\n",
    "        visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([(epoch+1) * 1000]),\n",
    "                    str(round(num_of_weight[0][4]*100, 1))\n",
    "                   )\n",
    "        \n",
    "        # best accuracy list (weight_remain, epoch, accuracy)\n",
    "        if best_accu[i][2] <= accuracy:\n",
    "            best_accu[i] = [round(num_of_weight[0][4]*100, 1), epoch, accuracy]\n",
    "        \n",
    "        print('[epoch : %d]' % (epoch+1),\n",
    "             '(r_loss: %.5f)' % (running_loss),\n",
    "             '(t_loss: %.5f)' % (test_loss),\n",
    "             '(accu: %.4f)' % (accuracy)\n",
    "             )\n",
    "    stop_time = timeit.default_timer()\n",
    "    #print(model.fc3.weight[0][0])\n",
    "    #print(model_init.fc3.weight[0][0])\n",
    "    \n",
    "    #print(model.fc3.weight[0])\n",
    "    \n",
    "    print(\"Finish!\",\n",
    "          \"(Best accu: %.4f)\" % best_accu[i][2],\n",
    "          \"(Time taken(sec) : %.2f)\" % (stop_time - start_time),\n",
    "          \"\\n\\n\\n\\n\\n\\n\\n\")\n",
    "    #calc_now(model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(weight_counter(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = weight_counter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(num_of_weight[0][4]*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_weight[0][4]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2], [10, 20]]\n",
    "\n",
    "#배열이름.inset(위치, 넣을 값)\n",
    "print(a[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#name, all, non_zero, zero, per\n",
    "def weight_counter(model):\n",
    "    layer_weight = []\n",
    "    all_weight = ['All_weight',0 ,0 ,0, 0]\n",
    "    for name, p in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            none_zero_w = (p != 0).sum().item()\n",
    "            zero_w = (p == 0).sum().item()\n",
    "            all_w = none_zero_w + zero_w\n",
    "\n",
    "            all_weight[1] += all_w\n",
    "            all_weight[2] += none_zero_w\n",
    "            all_weight[3] += zero_w\n",
    "\n",
    "            layer_weight.append([name, all_w, none_zero_w, zero_w, round(none_zero_w/all_w,4)])\n",
    "\n",
    "    all_weight[4] = round((all_weight[2]/all_weight[1]), 4)\n",
    "    layer_weight.insert(0, all_weight)\n",
    "    for i in range(len(layer_weight)):\n",
    "        print(layer_weight[i])\n",
    "    \n",
    "    return layer_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_counter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.conv1.weight != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.conv1.weight != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.conv1.weight == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.fc1.weight != 0).sum(dim=1).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.fc1.weight != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def calc_now(model):\n",
    "    fc1_1 = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc1_0 = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc1 = fc1_1 + fc1_0\n",
    "    fc1_p = fc1_0 / fc1_1\n",
    "    fc2_1 = ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc2_0 = ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc2 = fc2_1 + fc2_0\n",
    "    fc3_1 = ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc3_0 = ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc3 = fc3_1 + fc3_0\n",
    "    #print(fc1, fc2, fc3, fc1+fc2+fc3, fc1_1 + fc2_1 + fc3_1 ,fc1_0 + fc2_0 + fc3_0)\n",
    "    print(\"Remaining weight %.1f %%\" %(((fc1_1+fc2_1+fc3_1)/(fc1+fc2+fc3))*100))\n",
    "    print('total weight :',\n",
    "        '%d' % (fc1+fc2+fc3),\n",
    "         '(%d |' % (fc1_1+fc2_1+fc3_1),\n",
    "         '%d)' % (fc1_0+fc2_0+fc3_0)\n",
    "         )\n",
    "    print('fc1 :',\n",
    "        '%d' % fc1,\n",
    "         '(%d |' % fc1_1,\n",
    "         '%d)' % fc1_0\n",
    "         )\n",
    "    print('fc2 :',\n",
    "        '%d' % fc2,\n",
    "         '(%d |' % fc2_1,\n",
    "         '%d)' % fc2_0\n",
    "         )\n",
    "    print('fc3 :',\n",
    "        '%d' % fc3,\n",
    "         '(%d |' % fc3_1,\n",
    "         '%d)' % fc3_0\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model1.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        prune.remove(module, name = 'weight')\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        prune.remove(module, name = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[epoch : 0] (loss: x.xxxxx) (accu: 0.1053)\n",
    "[epoch : 1] (r_loss: 0.00008) (t_loss: -8.30549) (accu: 0.9617)\n",
    "[epoch : 2] (r_loss: 0.00012) (t_loss: -8.05022) (accu: 0.9668)\n",
    "[epoch : 3] (r_loss: 0.00021) (t_loss: -8.19537) (accu: 0.9714)\n",
    "[epoch : 4] (r_loss: 0.00009) (t_loss: -7.94015) (accu: 0.9688)\n",
    "[epoch : 5] (r_loss: 0.00006) (t_loss: -8.75366) (accu: 0.9603)\n",
    "\n",
    "\n",
    "1\n",
    "[epoch : 0] (loss: x.xxxxx) (accu: 0.1053)\n",
    "[epoch : 1] (loss: 0.00008) (accu: 0.9617)\n",
    "[epoch : 2] (loss: 0.00012) (accu: 0.9668)\n",
    "[epoch : 3] (loss: 0.00021) (accu: 0.9714)\n",
    "[epoch : 4] (loss: 0.00009) (accu: 0.9688)\n",
    "[epoch : 5] (loss: 0.00006) (accu: 0.9603)\n",
    "2\n",
    "[epoch : 0] (loss: x.xxxxx) (accu: 0.0980)\n",
    "[epoch : 1] (loss: 0.00002) (accu: 0.9651)\n",
    "[epoch : 2] (loss: 0.00004) (accu: 0.9611)\n",
    "[epoch : 3] (loss: 0.00003) (accu: 0.9703)\n",
    "[epoch : 4] (loss: 0.00007) (accu: 0.9706)\n",
    "[epoch : 5] (loss: 0.00002) (accu: 0.9663)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy per weight remaining\")\n",
    "for i in range(len(best_accu)):\n",
    "    print(\"Remaining weight %.1f %% \" % (best_accu[i][0] * 100),\n",
    "         \"Epoch %d\" % best_accu[i][1],\n",
    "         \"Accu %.4f %%\" % best_accu[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, p in model.named_parameters():\n",
    "    EPS = 1e-6\n",
    "    if 'weight' in name:\n",
    "        tensor = p.data.cpu().numpy()\n",
    "        grad_tensor = p.grad.data.cpu().numpy()\n",
    "        grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "        p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        print(p.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 숫자 60000\n",
    "배치 길이 60\n",
    "배치 개수 1000\n",
    "epoch = 50\n",
    "\n",
    "이터레이션 횟수 50000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
