{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import visdom\n",
    "import copy\n",
    "import torch.nn.utils.prune as prune\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# custom librarys\n",
    "import custom.model as cm # 저장된 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(55)\n",
    "#torch.cuda.manual_seed_all(55)\n",
    "#torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_now(model):\n",
    "    fc1_1 = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "    fc1_0 = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    fc1 = fc1_1 + fc1_0\n",
    "    fc1_p = fc1_0 / fc1_1\n",
    "    fc2_1 = ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "    fc2_0 = ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    fc2 = fc2_1 + fc2_0\n",
    "    fc3_1 = ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "    fc3_0 = ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    fc3 = fc3_1 + fc3_0\n",
    "    #print(fc1, fc2, fc3, fc1+fc2+fc3, fc1_1 + fc2_1 + fc3_1 ,fc1_0 + fc2_0 + fc3_0)\n",
    "    print('%d' % (fc1+fc2+fc3),\n",
    "         '(%d |' % (fc1_1+fc2_1+fc3_1),\n",
    "         '%d)' % (fc1_0+fc2_0+fc3_0)\n",
    "         )\n",
    "    print('%d' % fc1,\n",
    "         '(%d |' % fc1_1,\n",
    "         '%d)' % fc1_0\n",
    "         )\n",
    "    print('%d' % fc2,\n",
    "         '(%d |' % fc2_1,\n",
    "         '%d)' % fc2_0\n",
    "         )\n",
    "    print('%d' % fc3,\n",
    "         '(%d |' % fc3_1,\n",
    "         '%d)' % fc3_0\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144512\n"
     ]
    }
   ],
   "source": [
    "a = 3*64*9\n",
    "b = 64*64*9\n",
    "c = 64*128*9\n",
    "d = 128*128*9\n",
    "e = 128*256*9\n",
    "f = 256*256*9\n",
    "g = 64*64*9\n",
    "h = 64*64*9\n",
    "\n",
    "print(a+b+c+d+e+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv6, self).__init__()\n",
    "        # 32 mp 16 mp 8 mp 4\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1) # i-channel x o-channel x kernel_size = weight 숫자\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*256, 256, bias = True)\n",
    "        self.fc2 = nn.Linear(256, 256, bias = True)\n",
    "        self.fc3 = nn.Linear(256, 10, bias = True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  2\n",
      "Current cuda device  1\n",
      "GeForce RTX 2080 Ti\n",
      "cpu와 cuda 중 다음 기기로 학습함: cuda:1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 1\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116672 (1116671 | 1)\n",
      "1048576 (1048575 | 1)\n",
      "65536 (65536 | 0)\n",
      "2560 (2560 | 0)\n"
     ]
    }
   ],
   "source": [
    "calc_now(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'conv3.weight', 'conv3.bias', 'conv4.weight', 'conv4.bias', 'conv5.weight', 'conv5.bias', 'conv6.weight', 'conv6.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1144512, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "c1 = (((model.conv1.weight != 0).sum(dim=1)).sum(dim=0) + ((model.conv1.weight == 0).sum(dim=1)).sum(dim=0)).sum(dim=0).sum(dim=0)\n",
    "c2 = (((model.conv2.weight != 0).sum(dim=1)).sum(dim=0) + ((model.conv2.weight == 0).sum(dim=1)).sum(dim=0)).sum(dim=0).sum(dim=0)\n",
    "c3 = (((model.conv3.weight != 0).sum(dim=1)).sum(dim=0) + ((model.conv3.weight == 0).sum(dim=1)).sum(dim=0)).sum(dim=0).sum(dim=0)\n",
    "c4 = (((model.conv4.weight != 0).sum(dim=1)).sum(dim=0) + ((model.conv4.weight == 0).sum(dim=1)).sum(dim=0)).sum(dim=0).sum(dim=0)\n",
    "c5 = (((model.conv5.weight != 0).sum(dim=1)).sum(dim=0) + ((model.conv5.weight == 0).sum(dim=1)).sum(dim=0)).sum(dim=0).sum(dim=0)\n",
    "c6 = (((model.conv6.weight != 0).sum(dim=1)).sum(dim=0) + ((model.conv6.weight == 0).sum(dim=1)).sum(dim=0)).sum(dim=0).sum(dim=0)\n",
    "print(c1 + c2 + c3+ c4+c5+c6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1116672, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "f1 = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "f2 = ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "f3 = ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "print(f1+f2+f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv6().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv6(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (9*256 + 256 * 8256  + 256*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2118400"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363008\n"
     ]
    }
   ],
   "source": [
    "print(9*128*256 + 256*256 + 2560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# visdom setting\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")\n",
    "\n",
    "# make plot\n",
    "vis_plt = vis.line(X=torch.Tensor(1).zero_(), Y=torch.Tensor(1).zero_(), \n",
    "                    opts=dict(title = 'LeNet300_Accuracy_Tracker',\n",
    "                              legend=['100'],\n",
    "                             showlegend=True,\n",
    "                              xtickmin = 0,\n",
    "                              xtickmax = 20000,\n",
    "                              ytickmin = 0.9,\n",
    "                              ytickmax = 0.99\n",
    "                             )\n",
    "                   )\n",
    "\n",
    "def visdom_plot(loss_plot, loss_value, num, name):\n",
    "    vis.line(X = num,\n",
    "            Y = loss_value,\n",
    "            win = loss_plot,\n",
    "            name = name,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0012\n",
    "#epochs = 50\n",
    "#epochs = 20\n",
    "epochs = 3\n",
    "batch_size = 60\n",
    "iteration = 0\n",
    "pruned_percent = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_train = dsets.MNIST(root='../MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms,\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root='../MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms,\n",
    "                        download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, switch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    EPS = 1e-6\n",
    "    for data, label in dataloader:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        if switch == 1:\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    tensor = p.data.cpu().numpy()\n",
    "                    grad_tensor = p.grad.data.cpu().numpy()\n",
    "                    grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "                    p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "    \n",
    "        optimizer.step()\n",
    "        running_loss = loss / len(dataloader)\n",
    "    return running_loss\n",
    "\n",
    "\"\"\"def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    iteration = 0\n",
    "    for data, label in dataloader:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iteration += 1\n",
    "        running_loss = loss / len(dataloader)\n",
    "    return running_loss\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            predicted = torch.argmax(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            accuracy = (correct/total)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\"\"\"\n",
    "def weight_init(model1, model2, rate):\n",
    "    # prune mask 생성\n",
    "    prune.l1_unstructured(model1.fc1, name='weight', amount=rate)\n",
    "    #prune.l1_unstructured(model1.fc1, name='bias', amount=rate)\n",
    "    prune.l1_unstructured(model1.fc2, name='weight', amount=rate)\n",
    "    #prune.l1_unstructured(model1.fc2, name='bias', amount=rate)\n",
    "    prune.l1_unstructured(model1.fc3, name='weight', amount=rate)\n",
    "    # layer의 weight, bias를 initial 값으로 변경\n",
    "    # deepcopy 필요한지 확인해볼 것\n",
    "    model1.fc1.weight_orig = copy.deepcopy(model2.fc1.weight)\n",
    "    model1.fc1.bias_orig = copy.deepcopy(model2.fc1.bias)\n",
    "    model1.fc2.weight_orig = copy.deepcopy(model2.fc2.weight)\n",
    "    model1.fc2.bias_orig = copy.deepcopy(model2.fc2.bias)\n",
    "    model1.fc3.weight_orig = copy.deepcopy(model2.fc3.weight)\n",
    "    model1.fc3.bias_orig = copy.deepcopy(model2.fc3.bias)\n",
    "    # prune 진행\n",
    "    prune.remove(model1.fc1, \"weight\")\n",
    "    #prune.remove(model1.fc1, \"bias\")\n",
    "    prune.remove(model1.fc2, \"weight\")\n",
    "    #prune.remove(model1.fc2, \"bias\")\n",
    "    prune.remove(model1.fc3, \"weight\")\n",
    "    #prune.remove(model1.fc3, \"bias\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cm.LeNet300().to(device)\n",
    "model_init = copy.deepcopy(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = 1.2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 8.6343e-02,  2.2677e-02, -4.7661e-02,  1.8855e-02,  1.2614e-02,\n",
       "         -9.1771e-02,  9.5994e-02,  3.7472e-03, -5.5675e-02,  4.2135e-02,\n",
       "         -8.2481e-02,  8.1279e-02,  3.3593e-02,  6.8933e-02,  3.4503e-03,\n",
       "         -6.9401e-02,  4.7753e-02, -1.6106e-02, -4.8963e-02,  9.8462e-02,\n",
       "          7.7872e-03, -1.4528e-02,  8.6890e-02, -1.8431e-02, -9.0947e-02,\n",
       "         -4.9702e-02,  2.8297e-03,  5.7101e-02,  6.9263e-02,  5.4166e-02,\n",
       "          1.4694e-02,  8.2854e-02, -7.6132e-03, -6.4445e-02, -5.7414e-02,\n",
       "          7.8778e-02, -5.7851e-02, -3.3824e-02,  3.3542e-02,  4.5017e-02,\n",
       "         -1.8248e-02,  2.2583e-02,  3.3094e-03, -9.7023e-02,  3.7301e-02,\n",
       "          7.5525e-02,  5.3025e-02, -3.8207e-02,  5.0060e-02, -9.1124e-02,\n",
       "         -7.0831e-02, -2.2198e-02,  1.9828e-02,  6.3643e-02, -7.5319e-02,\n",
       "          2.2189e-02,  1.0544e-02, -9.4123e-02,  5.2022e-02,  7.2223e-02,\n",
       "          2.8765e-02, -9.0098e-02, -7.3193e-02,  2.3185e-02,  7.0516e-02,\n",
       "         -2.3746e-02, -4.2617e-02, -1.7919e-02,  9.8678e-02,  6.7877e-02,\n",
       "          7.7421e-02, -1.8440e-02,  8.5005e-02, -8.0693e-02, -1.8403e-02,\n",
       "         -3.4524e-02, -9.1246e-02,  1.7109e-02, -9.6608e-02,  5.3629e-02,\n",
       "          1.9765e-02, -8.9226e-02,  6.9817e-02,  1.5969e-02, -7.3826e-02,\n",
       "          5.8003e-02, -5.9896e-02,  1.0440e-02, -5.3661e-02, -2.8234e-02,\n",
       "         -3.2824e-02,  1.6111e-02,  7.4770e-02,  1.9609e-02, -7.8515e-02,\n",
       "         -6.5563e-02,  5.6677e-02, -6.3302e-02, -8.2887e-02, -3.2505e-03],\n",
       "        [ 4.1528e-03, -5.0999e-04,  4.7889e-02,  9.9608e-02,  6.5930e-02,\n",
       "          1.2603e-02, -5.2682e-02, -2.0438e-02, -7.8649e-02, -4.7545e-02,\n",
       "         -3.0186e-02,  2.0846e-02,  4.4954e-03, -4.6991e-02, -7.4986e-02,\n",
       "         -7.7584e-02, -7.6817e-02, -2.6010e-02,  2.5692e-02, -1.9591e-02,\n",
       "          3.9720e-02,  6.6772e-02,  1.1513e-02,  2.2705e-02,  9.9643e-02,\n",
       "         -9.2052e-02, -1.3720e-02,  2.7988e-02,  1.0657e-02,  8.1917e-02,\n",
       "          4.9089e-02,  8.5811e-03, -4.6736e-02,  8.4676e-03, -2.9749e-02,\n",
       "          8.4153e-02,  1.7573e-03,  9.0151e-02,  4.0110e-02, -6.8232e-02,\n",
       "         -3.1649e-02, -7.5894e-02, -8.8491e-02, -7.0608e-02,  8.5739e-02,\n",
       "         -5.7996e-02, -3.1761e-02, -5.9893e-02, -5.4090e-02,  1.9082e-02,\n",
       "          8.2661e-02,  4.4332e-02,  7.3294e-02, -1.2014e-02, -1.3561e-02,\n",
       "          5.5646e-02,  1.2545e-02,  4.3497e-02, -1.0592e-02,  4.2127e-02,\n",
       "          6.8960e-02,  9.3093e-02, -2.7970e-02, -3.3585e-02, -9.4778e-02,\n",
       "          1.4174e-02, -9.4552e-02, -2.1529e-02,  4.7088e-03,  7.3967e-02,\n",
       "         -6.4380e-02, -8.0963e-02,  6.5893e-02, -7.5556e-02,  5.8889e-02,\n",
       "         -7.2845e-02, -7.0367e-02,  5.2844e-02, -2.1209e-02,  8.9995e-02,\n",
       "          8.6740e-02,  5.6064e-02, -7.9534e-02, -3.7765e-03,  2.8179e-03,\n",
       "          4.5681e-02,  7.1234e-02, -9.0122e-02,  8.7984e-02,  5.9727e-02,\n",
       "         -9.6097e-02, -6.0146e-02,  7.2155e-03,  4.1201e-02,  2.2552e-03,\n",
       "         -1.6688e-02, -9.5432e-02, -2.9095e-02,  7.6843e-02,  7.4836e-04],\n",
       "        [-2.5500e-03,  2.3274e-03,  7.3384e-02, -8.0204e-04,  9.0274e-02,\n",
       "         -2.8104e-02, -2.2140e-02, -7.7364e-02,  4.8680e-02, -4.5889e-02,\n",
       "         -6.6111e-02,  2.8005e-02,  3.9746e-02,  4.9738e-02, -5.2060e-02,\n",
       "         -1.7594e-02,  1.7409e-02, -1.6960e-02, -3.0478e-02, -1.0121e-03,\n",
       "          7.3673e-02, -9.2437e-02,  9.2866e-02, -8.5163e-02,  6.5988e-02,\n",
       "          4.0207e-03,  2.5145e-02, -1.8225e-02, -6.3483e-02,  1.9956e-03,\n",
       "          9.5636e-02, -5.2204e-02, -8.4442e-02,  2.4041e-02, -7.0409e-02,\n",
       "          8.9973e-02, -4.2703e-02,  1.0772e-02,  9.9668e-03,  4.8437e-02,\n",
       "          3.4002e-02, -2.1566e-02, -3.8276e-02, -1.1650e-02, -7.5659e-03,\n",
       "          3.6031e-02, -4.4493e-03, -4.5334e-02, -1.5439e-02,  3.6833e-02,\n",
       "         -8.1999e-02,  4.0632e-02,  9.2213e-02,  1.9470e-02, -5.7503e-02,\n",
       "          2.5290e-02,  6.7209e-02, -4.3417e-02,  1.8483e-02,  8.7581e-02,\n",
       "          8.6944e-02,  1.2402e-02,  9.0743e-02, -1.3202e-02,  2.4537e-02,\n",
       "         -7.0989e-02,  2.0723e-02, -1.5906e-02, -2.3716e-02, -2.9661e-02,\n",
       "         -1.2390e-02,  1.4766e-02, -2.5465e-04, -9.7442e-02, -7.2802e-03,\n",
       "          4.5010e-02,  1.1450e-02,  4.4475e-04, -2.0048e-03, -5.9728e-02,\n",
       "         -6.9177e-02, -4.5585e-02, -5.9017e-02,  5.9935e-02, -2.1287e-02,\n",
       "         -3.8905e-02,  4.1414e-02,  8.6765e-03, -1.0193e-02,  2.8438e-02,\n",
       "          5.8956e-02,  7.1921e-02, -4.0519e-03,  1.9134e-02,  1.6889e-02,\n",
       "          6.3170e-02, -9.0465e-02,  9.2459e-02,  6.2682e-02,  1.4407e-02],\n",
       "        [-6.4671e-02, -1.9622e-02, -4.1884e-02,  7.2848e-02, -1.3087e-03,\n",
       "          9.2978e-03, -6.2640e-02, -9.5693e-04, -9.7351e-02,  6.4995e-02,\n",
       "         -2.8299e-02,  3.8229e-02, -6.4734e-02, -4.4667e-02, -8.2343e-02,\n",
       "         -2.6142e-02,  5.5340e-02, -7.9140e-02,  9.3099e-02, -4.4264e-02,\n",
       "         -3.9927e-03,  8.9598e-03,  3.1641e-02,  3.8755e-02, -5.4770e-02,\n",
       "          7.3218e-02,  6.9969e-02,  3.5092e-02,  5.9126e-02, -7.3393e-02,\n",
       "          2.7073e-02,  9.8398e-02,  3.0389e-02,  5.2298e-02, -8.8168e-02,\n",
       "         -8.3517e-02, -4.9683e-02,  4.2034e-02, -6.5246e-02,  5.4208e-02,\n",
       "         -8.9553e-02,  5.9553e-02, -6.9454e-02, -2.4570e-02,  4.2015e-02,\n",
       "          1.2895e-03,  6.6123e-02, -1.7651e-02,  7.8748e-02, -7.9327e-02,\n",
       "          1.4061e-02, -7.4886e-02, -4.7078e-02,  4.5722e-02, -7.0716e-02,\n",
       "         -9.4505e-02,  5.1904e-02,  4.5253e-03, -8.1925e-04,  4.9587e-03,\n",
       "          5.3629e-02, -7.3109e-02, -8.5068e-02,  5.4536e-02,  8.1014e-02,\n",
       "          5.5725e-02, -9.4109e-02, -2.8140e-02,  5.1159e-02, -5.8746e-02,\n",
       "         -9.3726e-02,  3.1368e-02, -7.3942e-02,  9.0758e-02, -3.2881e-02,\n",
       "          6.4243e-02,  7.6023e-03,  1.8202e-02, -6.2037e-02,  1.1409e-02,\n",
       "         -5.3912e-02, -3.8634e-02,  5.1748e-02, -3.9598e-02, -5.0872e-02,\n",
       "         -8.2941e-02,  8.8752e-02,  1.6624e-02,  3.8859e-03,  4.2001e-02,\n",
       "         -5.5109e-02,  8.7460e-02, -4.2381e-02, -9.9180e-02, -8.6241e-02,\n",
       "         -8.9850e-02,  4.4762e-02,  4.5963e-02,  8.2411e-02,  9.2800e-03],\n",
       "        [ 4.3601e-02, -3.4494e-02, -5.7787e-02, -1.4136e-02, -4.3939e-02,\n",
       "          3.2256e-02, -7.5373e-02,  9.1316e-02, -3.7707e-03, -5.5445e-02,\n",
       "         -6.6390e-02,  4.1525e-02, -3.4794e-02,  6.8138e-02,  4.7879e-03,\n",
       "          5.9857e-02, -7.1180e-02,  6.7177e-02, -8.3874e-02,  7.0709e-02,\n",
       "         -4.9262e-02,  7.5635e-02,  9.9538e-02,  1.5865e-02, -1.8727e-02,\n",
       "         -9.3624e-02, -8.5000e-02, -9.2178e-03,  2.8803e-02,  9.3594e-02,\n",
       "          2.0650e-02,  8.9347e-02,  6.6293e-02, -9.7868e-02,  2.3316e-02,\n",
       "          1.6505e-02,  8.9273e-02,  8.2533e-02, -7.8808e-02,  5.2512e-02,\n",
       "          3.3913e-02, -8.1112e-02,  2.2472e-02, -1.7950e-02,  2.6129e-02,\n",
       "          8.4983e-02, -5.4338e-02, -4.3629e-02,  7.6526e-02,  3.9182e-02,\n",
       "         -9.3896e-02, -8.3411e-02,  1.1320e-02, -6.2531e-02, -6.2071e-02,\n",
       "         -2.9819e-02,  3.9089e-02, -6.1120e-02,  2.3641e-02,  9.9605e-02,\n",
       "          3.4316e-02,  6.3897e-02, -7.1780e-03,  4.9769e-03, -1.4503e-02,\n",
       "          7.0034e-02, -8.1194e-02, -7.0706e-03,  6.6244e-02,  2.1536e-02,\n",
       "         -1.5054e-02, -1.4042e-02,  3.8608e-02,  9.1832e-03,  8.1986e-03,\n",
       "          1.1235e-02,  5.3728e-02, -6.8584e-02,  5.6557e-02, -5.7709e-02,\n",
       "          9.3063e-03,  7.9759e-02, -4.1170e-02, -4.1482e-02, -8.5165e-02,\n",
       "          7.9161e-02, -9.2639e-02, -5.4367e-02, -2.8281e-02, -2.1363e-02,\n",
       "          9.3371e-02,  1.7236e-02, -1.1385e-02, -6.1794e-02,  4.2132e-02,\n",
       "         -5.7499e-02, -1.7752e-02,  6.1594e-02,  9.0768e-02, -3.5583e-02],\n",
       "        [-8.0562e-02,  5.2788e-02, -5.9207e-02,  5.2153e-02, -4.9190e-02,\n",
       "         -1.2815e-02,  9.7013e-02, -7.4623e-02, -6.2269e-02, -5.4922e-02,\n",
       "          1.5724e-02, -3.4340e-02,  7.7623e-02, -4.8620e-02,  2.4162e-02,\n",
       "         -2.5834e-02,  7.6896e-02, -4.0405e-02,  1.3451e-03, -8.1941e-02,\n",
       "         -4.3111e-02, -4.5878e-02,  1.5949e-02, -7.5751e-02, -9.5916e-02,\n",
       "         -8.5443e-02, -2.0578e-02,  8.0032e-02, -9.4383e-02, -8.0177e-03,\n",
       "          8.0198e-02,  7.5688e-02, -8.2508e-02,  2.5497e-02, -4.0375e-02,\n",
       "          1.7961e-02, -3.2565e-03,  2.8614e-02, -8.0333e-02,  9.3072e-02,\n",
       "         -5.8048e-02, -2.4315e-02, -2.7922e-02,  8.7350e-02, -7.9492e-02,\n",
       "          9.4581e-02,  2.2760e-02,  1.3166e-02, -8.3920e-02, -6.2117e-02,\n",
       "          4.9298e-02,  8.8655e-02,  6.3035e-02, -5.6876e-02, -6.4902e-03,\n",
       "         -2.5933e-02,  2.4289e-02, -7.7747e-02,  2.9593e-02,  1.2707e-02,\n",
       "         -6.5622e-02, -2.0439e-02, -6.9101e-02, -2.3490e-02, -7.8613e-02,\n",
       "         -3.9565e-02, -8.5401e-02,  5.5246e-02,  2.4987e-02, -4.7975e-02,\n",
       "          8.8521e-02,  3.0851e-02,  1.4754e-03,  3.0287e-02,  5.7004e-02,\n",
       "         -1.2508e-02, -3.6943e-02,  2.5958e-02, -5.0604e-02, -3.8234e-02,\n",
       "          6.3907e-02, -1.6487e-02,  1.4253e-02,  5.3643e-02, -2.3923e-02,\n",
       "         -8.9125e-02, -3.7334e-03,  7.1785e-02, -6.4289e-02, -7.1369e-03,\n",
       "         -6.3484e-02,  3.2469e-02, -9.9547e-03, -5.3241e-02,  1.8564e-02,\n",
       "          2.5148e-02,  9.8486e-03,  3.2055e-02, -8.9040e-02,  1.4824e-02],\n",
       "        [ 5.9026e-02, -5.0621e-02, -3.2696e-02,  4.4960e-02,  1.6684e-02,\n",
       "          1.4792e-03,  1.8295e-02,  2.6417e-02,  2.1001e-02, -4.8455e-02,\n",
       "         -9.6928e-02,  2.9257e-02, -9.3454e-02,  7.3738e-02,  3.0534e-02,\n",
       "          6.5924e-02,  2.3422e-02, -8.6882e-02, -4.0743e-02, -2.6556e-02,\n",
       "         -1.3885e-02,  7.7824e-02,  4.6027e-02,  3.2260e-02, -1.7540e-02,\n",
       "          7.3648e-03,  4.5031e-02, -2.8448e-02, -7.2320e-03,  5.1744e-02,\n",
       "          6.9604e-02,  8.1851e-02,  2.7918e-03, -9.8251e-02, -1.2639e-02,\n",
       "          5.3265e-02, -4.2813e-02, -6.8331e-02,  1.5010e-02, -5.8569e-02,\n",
       "         -2.2219e-02, -2.4114e-02, -1.4530e-02, -1.7364e-02, -9.1941e-03,\n",
       "         -1.0603e-02,  7.4305e-02, -1.5893e-02, -2.0449e-02, -3.5320e-02,\n",
       "          4.0753e-02, -2.1353e-03, -4.6640e-02, -6.6990e-02, -7.0215e-02,\n",
       "          6.6001e-02,  2.1142e-02, -7.5543e-02,  4.6400e-02, -2.4217e-02,\n",
       "          5.0202e-02, -6.1302e-02, -1.2170e-02,  7.8400e-02, -3.4096e-02,\n",
       "          9.8906e-02,  4.9788e-02, -1.3564e-02, -4.4159e-02, -5.6083e-02,\n",
       "         -5.0064e-02,  2.6566e-03, -8.5770e-04,  4.5537e-02, -7.7143e-02,\n",
       "          3.1669e-02,  3.7224e-03, -3.7081e-03, -2.5075e-02,  7.3677e-02,\n",
       "         -8.5969e-02, -4.6309e-02,  2.2035e-02, -8.6429e-02, -2.9284e-02,\n",
       "         -1.5355e-02, -8.6934e-02, -5.5548e-02,  5.5799e-02,  8.2205e-02,\n",
       "         -2.9939e-02, -1.2084e-02, -7.4241e-02, -8.6183e-02, -4.3200e-03,\n",
       "         -7.6398e-02, -9.6096e-02,  7.1425e-02,  8.2157e-02,  9.5446e-02],\n",
       "        [-8.9403e-02,  4.0506e-02,  1.3439e-02,  9.0280e-02, -2.7822e-02,\n",
       "          9.7970e-02,  1.4020e-02,  7.7287e-02,  7.3067e-02, -5.8740e-02,\n",
       "         -8.4600e-02,  3.3242e-02, -4.2847e-03,  1.3826e-02,  2.3941e-02,\n",
       "         -5.4344e-02,  6.4043e-02,  9.7476e-02, -4.2760e-02,  3.4561e-02,\n",
       "         -6.3089e-02, -6.8214e-02,  8.4022e-02, -5.2991e-02,  9.0282e-02,\n",
       "          6.2587e-02,  4.0697e-02, -4.4998e-02, -2.9477e-02,  2.4943e-02,\n",
       "         -3.9199e-02,  6.5424e-05, -4.2814e-02,  8.2109e-03, -5.4878e-02,\n",
       "         -2.8676e-02, -8.9987e-02,  2.8043e-02,  2.9140e-02,  2.2242e-02,\n",
       "          6.9026e-02,  9.6716e-02, -6.1381e-02,  8.5053e-02,  6.4341e-03,\n",
       "         -3.6801e-02, -5.1950e-02,  5.4700e-02,  2.7304e-02, -2.5956e-02,\n",
       "          9.7227e-02, -4.3543e-02,  8.4096e-02, -3.2012e-02, -9.6544e-02,\n",
       "         -3.6465e-02, -2.7663e-03, -8.8177e-02, -3.8632e-02,  3.0295e-02,\n",
       "          8.5585e-02, -9.6268e-02, -7.9988e-02, -3.9222e-02,  2.1567e-02,\n",
       "         -9.7983e-02,  5.5646e-02,  4.8819e-02, -3.9640e-03, -3.4109e-02,\n",
       "         -2.5943e-02, -1.0594e-02, -9.9471e-03, -2.8234e-02, -7.4283e-02,\n",
       "          3.9268e-02,  7.9887e-02,  8.7643e-02,  9.5134e-02, -1.0928e-02,\n",
       "         -3.4155e-02, -9.3886e-02, -9.1365e-03, -4.5802e-02, -1.0208e-02,\n",
       "          5.4826e-02,  8.7284e-02, -2.2323e-02, -7.2347e-02,  1.7180e-02,\n",
       "         -7.2511e-02, -8.3457e-02, -8.6285e-03, -5.8778e-02,  7.2705e-02,\n",
       "          9.1806e-02, -5.2112e-02, -3.5617e-03,  5.7661e-03, -4.0118e-02],\n",
       "        [-4.3570e-03,  2.4893e-02,  6.8747e-02, -9.3909e-02, -3.2646e-02,\n",
       "          2.3233e-02,  6.4983e-02, -3.1407e-02,  7.2274e-02, -6.7775e-02,\n",
       "          7.8958e-02,  6.7058e-02,  2.3296e-02,  1.7273e-02,  9.6637e-02,\n",
       "          7.2483e-02, -3.2463e-04,  9.3890e-02,  2.9703e-02, -5.6024e-02,\n",
       "         -3.4558e-02, -7.6397e-02,  9.7206e-02,  6.5830e-03, -5.1011e-03,\n",
       "         -6.4176e-02,  6.3541e-02,  9.9010e-02, -5.7466e-02, -5.5288e-02,\n",
       "         -8.9334e-03, -5.0751e-02, -7.8354e-02, -2.8980e-02, -8.9608e-02,\n",
       "          5.4440e-02,  9.0201e-03, -3.9748e-02,  1.6316e-02, -8.5962e-02,\n",
       "          1.1889e-02, -7.1450e-02,  1.8487e-04,  6.5266e-02,  6.5553e-02,\n",
       "          7.5997e-02, -7.8502e-02,  9.1629e-03,  5.9026e-02, -5.7573e-02,\n",
       "         -8.0473e-02, -4.3077e-02,  8.0421e-02,  1.1084e-02,  6.4332e-03,\n",
       "         -1.4917e-02, -5.4373e-03, -9.5556e-02,  3.9003e-02, -3.5526e-02,\n",
       "         -9.4698e-02,  5.3025e-02, -2.4968e-02,  4.5203e-02, -1.0653e-03,\n",
       "         -7.1493e-03, -8.6810e-02,  9.0136e-02,  8.1275e-02,  8.8943e-03,\n",
       "         -3.3584e-02,  9.8136e-02, -1.9258e-02,  2.1157e-03,  7.9153e-02,\n",
       "         -9.0267e-02,  3.4507e-03, -4.7046e-02,  9.6603e-02,  7.0081e-02,\n",
       "         -7.6956e-02, -4.2076e-03,  4.3450e-02,  4.6727e-02, -7.8136e-02,\n",
       "          8.0338e-03, -7.4346e-03, -2.9151e-02,  8.6913e-02,  8.0780e-02,\n",
       "         -8.7140e-04,  3.7287e-02,  4.9385e-02,  3.3062e-02,  7.4214e-02,\n",
       "         -7.3472e-03,  3.5766e-02,  5.9207e-02, -8.3441e-02,  6.7270e-02],\n",
       "        [ 9.4200e-02,  6.8145e-02,  6.2540e-02, -3.1562e-02,  9.6986e-02,\n",
       "         -3.1815e-02,  5.9731e-02, -4.9975e-03, -5.5222e-02, -3.3059e-02,\n",
       "         -5.4803e-02,  6.9262e-02,  8.9559e-03, -2.4500e-02,  1.4373e-04,\n",
       "          2.7972e-02, -2.7735e-02,  1.4423e-02, -3.3158e-02, -3.8355e-02,\n",
       "         -7.4027e-02, -3.2170e-02, -5.9092e-02,  5.0811e-02, -9.2681e-02,\n",
       "          6.3145e-02, -3.1374e-03,  3.3152e-02,  7.9955e-03, -8.5179e-03,\n",
       "          8.6924e-02,  5.1679e-02,  7.5106e-03,  9.4907e-02,  1.4119e-02,\n",
       "         -9.9382e-02,  6.9623e-03, -1.8123e-03, -1.5565e-02, -9.4022e-02,\n",
       "          7.6084e-02,  9.2810e-02, -2.9924e-02,  4.5483e-04, -5.4411e-02,\n",
       "          7.4701e-02,  7.7844e-02,  8.0866e-02, -9.6821e-02, -9.6581e-02,\n",
       "         -8.6109e-02, -6.0333e-02, -6.3632e-02, -9.0926e-02, -4.0633e-02,\n",
       "          1.1208e-02,  9.1663e-02,  5.4924e-02, -5.5600e-02,  9.7539e-02,\n",
       "          1.2901e-02,  5.7531e-02,  6.5117e-02,  9.1056e-02,  8.3216e-02,\n",
       "         -1.6184e-02,  8.8581e-02,  3.3894e-02, -4.4587e-02,  6.4554e-02,\n",
       "         -9.7076e-03, -7.7806e-03,  8.5596e-02, -9.9204e-02,  6.9508e-02,\n",
       "          2.2285e-02,  7.1212e-03, -4.4236e-02, -3.3658e-02, -8.4797e-02,\n",
       "         -4.0756e-03,  5.8306e-02, -5.8387e-02,  8.6262e-02, -8.2355e-02,\n",
       "          8.5821e-02,  3.1430e-03,  9.5859e-02,  9.9203e-02,  7.2328e-02,\n",
       "          8.0080e-02,  5.8242e-02,  2.0763e-02, -6.8113e-02, -4.8255e-02,\n",
       "         -8.3045e-02, -7.4706e-02,  9.1431e-02, -9.7327e-02, -8.4262e-02]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 8.6343e-02,  2.2677e-02, -4.7661e-02,  1.8855e-02,  1.2614e-02,\n",
       "         -9.1771e-02,  9.5994e-02,  3.7472e-03, -5.5675e-02,  4.2135e-02,\n",
       "         -8.2481e-02,  8.1279e-02,  3.3593e-02,  6.8933e-02,  3.4503e-03,\n",
       "         -6.9401e-02,  4.7753e-02, -1.6106e-02, -4.8963e-02,  9.8462e-02,\n",
       "          7.7872e-03, -1.4528e-02,  8.6890e-02, -1.8431e-02, -9.0947e-02,\n",
       "         -4.9702e-02,  2.8297e-03,  5.7101e-02,  6.9263e-02,  5.4166e-02,\n",
       "          1.4694e-02,  8.2854e-02, -7.6132e-03, -6.4445e-02, -5.7414e-02,\n",
       "          7.8778e-02, -5.7851e-02, -3.3824e-02,  3.3542e-02,  4.5017e-02,\n",
       "         -1.8248e-02,  2.2583e-02,  3.3094e-03, -9.7023e-02,  3.7301e-02,\n",
       "          7.5525e-02,  5.3025e-02, -3.8207e-02,  5.0060e-02, -9.1124e-02,\n",
       "         -7.0831e-02, -2.2198e-02,  1.9828e-02,  6.3643e-02, -7.5319e-02,\n",
       "          2.2189e-02,  1.0544e-02, -9.4123e-02,  5.2022e-02,  7.2223e-02,\n",
       "          2.8765e-02, -9.0098e-02, -7.3193e-02,  2.3185e-02,  7.0516e-02,\n",
       "         -2.3746e-02, -4.2617e-02, -1.7919e-02,  9.8678e-02,  6.7877e-02,\n",
       "          7.7421e-02, -1.8440e-02,  8.5005e-02, -8.0693e-02, -1.8403e-02,\n",
       "         -3.4524e-02, -9.1246e-02,  1.7109e-02, -9.6608e-02,  5.3629e-02,\n",
       "          1.9765e-02, -8.9226e-02,  6.9817e-02,  1.5969e-02, -7.3826e-02,\n",
       "          5.8003e-02, -5.9896e-02,  1.0440e-02, -5.3661e-02, -2.8234e-02,\n",
       "         -3.2824e-02,  1.6111e-02,  7.4770e-02,  1.9609e-02, -7.8515e-02,\n",
       "         -6.5563e-02,  5.6677e-02, -6.3302e-02, -8.2887e-02, -3.2505e-03],\n",
       "        [ 4.1528e-03, -5.0999e-04,  4.7889e-02,  9.9608e-02,  6.5930e-02,\n",
       "          1.2603e-02, -5.2682e-02, -2.0438e-02, -7.8649e-02, -4.7545e-02,\n",
       "         -3.0186e-02,  2.0846e-02,  4.4954e-03, -4.6991e-02, -7.4986e-02,\n",
       "         -7.7584e-02, -7.6817e-02, -2.6010e-02,  2.5692e-02, -1.9591e-02,\n",
       "          3.9720e-02,  6.6772e-02,  1.1513e-02,  2.2705e-02,  9.9643e-02,\n",
       "         -9.2052e-02, -1.3720e-02,  2.7988e-02,  1.0657e-02,  8.1917e-02,\n",
       "          4.9089e-02,  8.5811e-03, -4.6736e-02,  8.4676e-03, -2.9749e-02,\n",
       "          8.4153e-02,  1.7573e-03,  9.0151e-02,  4.0110e-02, -6.8232e-02,\n",
       "         -3.1649e-02, -7.5894e-02, -8.8491e-02, -7.0608e-02,  8.5739e-02,\n",
       "         -5.7996e-02, -3.1761e-02, -5.9893e-02, -5.4090e-02,  1.9082e-02,\n",
       "          8.2661e-02,  4.4332e-02,  7.3294e-02, -1.2014e-02, -1.3561e-02,\n",
       "          5.5646e-02,  1.2545e-02,  4.3497e-02, -1.0592e-02,  4.2127e-02,\n",
       "          6.8960e-02,  9.3093e-02, -2.7970e-02, -3.3585e-02, -9.4778e-02,\n",
       "          1.4174e-02, -9.4552e-02, -2.1529e-02,  4.7088e-03,  7.3967e-02,\n",
       "         -6.4380e-02, -8.0963e-02,  6.5893e-02, -7.5556e-02,  5.8889e-02,\n",
       "         -7.2845e-02, -7.0367e-02,  5.2844e-02, -2.1209e-02,  8.9995e-02,\n",
       "          8.6740e-02,  5.6064e-02, -7.9534e-02, -3.7765e-03,  2.8179e-03,\n",
       "          4.5681e-02,  7.1234e-02, -9.0122e-02,  8.7984e-02,  5.9727e-02,\n",
       "         -9.6097e-02, -6.0146e-02,  7.2155e-03,  4.1201e-02,  2.2552e-03,\n",
       "         -1.6688e-02, -9.5432e-02, -2.9095e-02,  7.6843e-02,  7.4836e-04],\n",
       "        [-2.5500e-03,  2.3274e-03,  7.3384e-02, -8.0204e-04,  9.0274e-02,\n",
       "         -2.8104e-02, -2.2140e-02, -7.7364e-02,  4.8680e-02, -4.5889e-02,\n",
       "         -6.6111e-02,  2.8005e-02,  3.9746e-02,  4.9738e-02, -5.2060e-02,\n",
       "         -1.7594e-02,  1.7409e-02, -1.6960e-02, -3.0478e-02, -1.0121e-03,\n",
       "          7.3673e-02, -9.2437e-02,  9.2866e-02, -8.5163e-02,  6.5988e-02,\n",
       "          4.0207e-03,  2.5145e-02, -1.8225e-02, -6.3483e-02,  1.9956e-03,\n",
       "          9.5636e-02, -5.2204e-02, -8.4442e-02,  2.4041e-02, -7.0409e-02,\n",
       "          8.9973e-02, -4.2703e-02,  1.0772e-02,  9.9668e-03,  4.8437e-02,\n",
       "          3.4002e-02, -2.1566e-02, -3.8276e-02, -1.1650e-02, -7.5659e-03,\n",
       "          3.6031e-02, -4.4493e-03, -4.5334e-02, -1.5439e-02,  3.6833e-02,\n",
       "         -8.1999e-02,  4.0632e-02,  9.2213e-02,  1.9470e-02, -5.7503e-02,\n",
       "          2.5290e-02,  6.7209e-02, -4.3417e-02,  1.8483e-02,  8.7581e-02,\n",
       "          8.6944e-02,  1.2402e-02,  9.0743e-02, -1.3202e-02,  2.4537e-02,\n",
       "         -7.0989e-02,  2.0723e-02, -1.5906e-02, -2.3716e-02, -2.9661e-02,\n",
       "         -1.2390e-02,  1.4766e-02, -2.5465e-04, -9.7442e-02, -7.2802e-03,\n",
       "          4.5010e-02,  1.1450e-02,  4.4475e-04, -2.0048e-03, -5.9728e-02,\n",
       "         -6.9177e-02, -4.5585e-02, -5.9017e-02,  5.9935e-02, -2.1287e-02,\n",
       "         -3.8905e-02,  4.1414e-02,  8.6765e-03, -1.0193e-02,  2.8438e-02,\n",
       "          5.8956e-02,  7.1921e-02, -4.0519e-03,  1.9134e-02,  1.6889e-02,\n",
       "          6.3170e-02, -9.0465e-02,  9.2459e-02,  6.2682e-02,  1.4407e-02],\n",
       "        [-6.4671e-02, -1.9622e-02, -4.1884e-02,  7.2848e-02, -1.3087e-03,\n",
       "          9.2978e-03, -6.2640e-02, -9.5693e-04, -9.7351e-02,  6.4995e-02,\n",
       "         -2.8299e-02,  3.8229e-02, -6.4734e-02, -4.4667e-02, -8.2343e-02,\n",
       "         -2.6142e-02,  5.5340e-02, -7.9140e-02,  9.3099e-02, -4.4264e-02,\n",
       "         -3.9927e-03,  8.9598e-03,  3.1641e-02,  3.8755e-02, -5.4770e-02,\n",
       "          7.3218e-02,  6.9969e-02,  3.5092e-02,  5.9126e-02, -7.3393e-02,\n",
       "          2.7073e-02,  9.8398e-02,  3.0389e-02,  5.2298e-02, -8.8168e-02,\n",
       "         -8.3517e-02, -4.9683e-02,  4.2034e-02, -6.5246e-02,  5.4208e-02,\n",
       "         -8.9553e-02,  5.9553e-02, -6.9454e-02, -2.4570e-02,  4.2015e-02,\n",
       "          1.2895e-03,  6.6123e-02, -1.7651e-02,  7.8748e-02, -7.9327e-02,\n",
       "          1.4061e-02, -7.4886e-02, -4.7078e-02,  4.5722e-02, -7.0716e-02,\n",
       "         -9.4505e-02,  5.1904e-02,  4.5253e-03, -8.1925e-04,  4.9587e-03,\n",
       "          5.3629e-02, -7.3109e-02, -8.5068e-02,  5.4536e-02,  8.1014e-02,\n",
       "          5.5725e-02, -9.4109e-02, -2.8140e-02,  5.1159e-02, -5.8746e-02,\n",
       "         -9.3726e-02,  3.1368e-02, -7.3942e-02,  9.0758e-02, -3.2881e-02,\n",
       "          6.4243e-02,  7.6023e-03,  1.8202e-02, -6.2037e-02,  1.1409e-02,\n",
       "         -5.3912e-02, -3.8634e-02,  5.1748e-02, -3.9598e-02, -5.0872e-02,\n",
       "         -8.2941e-02,  8.8752e-02,  1.6624e-02,  3.8859e-03,  4.2001e-02,\n",
       "         -5.5109e-02,  8.7460e-02, -4.2381e-02, -9.9180e-02, -8.6241e-02,\n",
       "         -8.9850e-02,  4.4762e-02,  4.5963e-02,  8.2411e-02,  9.2800e-03],\n",
       "        [ 4.3601e-02, -3.4494e-02, -5.7787e-02, -1.4136e-02, -4.3939e-02,\n",
       "          3.2256e-02, -7.5373e-02,  9.1316e-02, -3.7707e-03, -5.5445e-02,\n",
       "         -6.6390e-02,  4.1525e-02, -3.4794e-02,  6.8138e-02,  4.7879e-03,\n",
       "          5.9857e-02, -7.1180e-02,  6.7177e-02, -8.3874e-02,  7.0709e-02,\n",
       "         -4.9262e-02,  7.5635e-02,  9.9538e-02,  1.5865e-02, -1.8727e-02,\n",
       "         -9.3624e-02, -8.5000e-02, -9.2178e-03,  2.8803e-02,  9.3594e-02,\n",
       "          2.0650e-02,  8.9347e-02,  6.6293e-02, -9.7868e-02,  2.3316e-02,\n",
       "          1.6505e-02,  8.9273e-02,  8.2533e-02, -7.8808e-02,  5.2512e-02,\n",
       "          3.3913e-02, -8.1112e-02,  2.2472e-02, -1.7950e-02,  2.6129e-02,\n",
       "          8.4983e-02, -5.4338e-02, -4.3629e-02,  7.6526e-02,  3.9182e-02,\n",
       "         -9.3896e-02, -8.3411e-02,  1.1320e-02, -6.2531e-02, -6.2071e-02,\n",
       "         -2.9819e-02,  3.9089e-02, -6.1120e-02,  2.3641e-02,  9.9605e-02,\n",
       "          3.4316e-02,  6.3897e-02, -7.1780e-03,  4.9769e-03, -1.4503e-02,\n",
       "          7.0034e-02, -8.1194e-02, -7.0706e-03,  6.6244e-02,  2.1536e-02,\n",
       "         -1.5054e-02, -1.4042e-02,  3.8608e-02,  9.1832e-03,  8.1986e-03,\n",
       "          1.1235e-02,  5.3728e-02, -6.8584e-02,  5.6557e-02, -5.7709e-02,\n",
       "          9.3063e-03,  7.9759e-02, -4.1170e-02, -4.1482e-02, -8.5165e-02,\n",
       "          7.9161e-02, -9.2639e-02, -5.4367e-02, -2.8281e-02, -2.1363e-02,\n",
       "          9.3371e-02,  1.7236e-02, -1.1385e-02, -6.1794e-02,  4.2132e-02,\n",
       "         -5.7499e-02, -1.7752e-02,  6.1594e-02,  9.0768e-02, -3.5583e-02],\n",
       "        [-8.0562e-02,  5.2788e-02, -5.9207e-02,  5.2153e-02, -4.9190e-02,\n",
       "         -1.2815e-02,  9.7013e-02, -7.4623e-02, -6.2269e-02, -5.4922e-02,\n",
       "          1.5724e-02, -3.4340e-02,  7.7623e-02, -4.8620e-02,  2.4162e-02,\n",
       "         -2.5834e-02,  7.6896e-02, -4.0405e-02,  1.3451e-03, -8.1941e-02,\n",
       "         -4.3111e-02, -4.5878e-02,  1.5949e-02, -7.5751e-02, -9.5916e-02,\n",
       "         -8.5443e-02, -2.0578e-02,  8.0032e-02, -9.4383e-02, -8.0177e-03,\n",
       "          8.0198e-02,  7.5688e-02, -8.2508e-02,  2.5497e-02, -4.0375e-02,\n",
       "          1.7961e-02, -3.2565e-03,  2.8614e-02, -8.0333e-02,  9.3072e-02,\n",
       "         -5.8048e-02, -2.4315e-02, -2.7922e-02,  8.7350e-02, -7.9492e-02,\n",
       "          9.4581e-02,  2.2760e-02,  1.3166e-02, -8.3920e-02, -6.2117e-02,\n",
       "          4.9298e-02,  8.8655e-02,  6.3035e-02, -5.6876e-02, -6.4902e-03,\n",
       "         -2.5933e-02,  2.4289e-02, -7.7747e-02,  2.9593e-02,  1.2707e-02,\n",
       "         -6.5622e-02, -2.0439e-02, -6.9101e-02, -2.3490e-02, -7.8613e-02,\n",
       "         -3.9565e-02, -8.5401e-02,  5.5246e-02,  2.4987e-02, -4.7975e-02,\n",
       "          8.8521e-02,  3.0851e-02,  1.4754e-03,  3.0287e-02,  5.7004e-02,\n",
       "         -1.2508e-02, -3.6943e-02,  2.5958e-02, -5.0604e-02, -3.8234e-02,\n",
       "          6.3907e-02, -1.6487e-02,  1.4253e-02,  5.3643e-02, -2.3923e-02,\n",
       "         -8.9125e-02, -3.7334e-03,  7.1785e-02, -6.4289e-02, -7.1369e-03,\n",
       "         -6.3484e-02,  3.2469e-02, -9.9547e-03, -5.3241e-02,  1.8564e-02,\n",
       "          2.5148e-02,  9.8486e-03,  3.2055e-02, -8.9040e-02,  1.4824e-02],\n",
       "        [ 5.9026e-02, -5.0621e-02, -3.2696e-02,  4.4960e-02,  1.6684e-02,\n",
       "          1.4792e-03,  1.8295e-02,  2.6417e-02,  2.1001e-02, -4.8455e-02,\n",
       "         -9.6928e-02,  2.9257e-02, -9.3454e-02,  7.3738e-02,  3.0534e-02,\n",
       "          6.5924e-02,  2.3422e-02, -8.6882e-02, -4.0743e-02, -2.6556e-02,\n",
       "         -1.3885e-02,  7.7824e-02,  4.6027e-02,  3.2260e-02, -1.7540e-02,\n",
       "          7.3648e-03,  4.5031e-02, -2.8448e-02, -7.2320e-03,  5.1744e-02,\n",
       "          6.9604e-02,  8.1851e-02,  2.7918e-03, -9.8251e-02, -1.2639e-02,\n",
       "          5.3265e-02, -4.2813e-02, -6.8331e-02,  1.5010e-02, -5.8569e-02,\n",
       "         -2.2219e-02, -2.4114e-02, -1.4530e-02, -1.7364e-02, -9.1941e-03,\n",
       "         -1.0603e-02,  7.4305e-02, -1.5893e-02, -2.0449e-02, -3.5320e-02,\n",
       "          4.0753e-02, -2.1353e-03, -4.6640e-02, -6.6990e-02, -7.0215e-02,\n",
       "          6.6001e-02,  2.1142e-02, -7.5543e-02,  4.6400e-02, -2.4217e-02,\n",
       "          5.0202e-02, -6.1302e-02, -1.2170e-02,  7.8400e-02, -3.4096e-02,\n",
       "          9.8906e-02,  4.9788e-02, -1.3564e-02, -4.4159e-02, -5.6083e-02,\n",
       "         -5.0064e-02,  2.6566e-03, -8.5770e-04,  4.5537e-02, -7.7143e-02,\n",
       "          3.1669e-02,  3.7224e-03, -3.7081e-03, -2.5075e-02,  7.3677e-02,\n",
       "         -8.5969e-02, -4.6309e-02,  2.2035e-02, -8.6429e-02, -2.9284e-02,\n",
       "         -1.5355e-02, -8.6934e-02, -5.5548e-02,  5.5799e-02,  8.2205e-02,\n",
       "         -2.9939e-02, -1.2084e-02, -7.4241e-02, -8.6183e-02, -4.3200e-03,\n",
       "         -7.6398e-02, -9.6096e-02,  7.1425e-02,  8.2157e-02,  9.5446e-02],\n",
       "        [-8.9403e-02,  4.0506e-02,  1.3439e-02,  9.0280e-02, -2.7822e-02,\n",
       "          9.7970e-02,  1.4020e-02,  7.7287e-02,  7.3067e-02, -5.8740e-02,\n",
       "         -8.4600e-02,  3.3242e-02, -4.2847e-03,  1.3826e-02,  2.3941e-02,\n",
       "         -5.4344e-02,  6.4043e-02,  9.7476e-02, -4.2760e-02,  3.4561e-02,\n",
       "         -6.3089e-02, -6.8214e-02,  8.4022e-02, -5.2991e-02,  9.0282e-02,\n",
       "          6.2587e-02,  4.0697e-02, -4.4998e-02, -2.9477e-02,  2.4943e-02,\n",
       "         -3.9199e-02,  6.5424e-05, -4.2814e-02,  8.2109e-03, -5.4878e-02,\n",
       "         -2.8676e-02, -8.9987e-02,  2.8043e-02,  2.9140e-02,  2.2242e-02,\n",
       "          6.9026e-02,  9.6716e-02, -6.1381e-02,  8.5053e-02,  6.4341e-03,\n",
       "         -3.6801e-02, -5.1950e-02,  5.4700e-02,  2.7304e-02, -2.5956e-02,\n",
       "          9.7227e-02, -4.3543e-02,  8.4096e-02, -3.2012e-02, -9.6544e-02,\n",
       "         -3.6465e-02, -2.7663e-03, -8.8177e-02, -3.8632e-02,  3.0295e-02,\n",
       "          8.5585e-02, -9.6268e-02, -7.9988e-02, -3.9222e-02,  2.1567e-02,\n",
       "         -9.7983e-02,  5.5646e-02,  4.8819e-02, -3.9640e-03, -3.4109e-02,\n",
       "         -2.5943e-02, -1.0594e-02, -9.9471e-03, -2.8234e-02, -7.4283e-02,\n",
       "          3.9268e-02,  7.9887e-02,  8.7643e-02,  9.5134e-02, -1.0928e-02,\n",
       "         -3.4155e-02, -9.3886e-02, -9.1365e-03, -4.5802e-02, -1.0208e-02,\n",
       "          5.4826e-02,  8.7284e-02, -2.2323e-02, -7.2347e-02,  1.7180e-02,\n",
       "         -7.2511e-02, -8.3457e-02, -8.6285e-03, -5.8778e-02,  7.2705e-02,\n",
       "          9.1806e-02, -5.2112e-02, -3.5617e-03,  5.7661e-03, -4.0118e-02],\n",
       "        [-4.3570e-03,  2.4893e-02,  6.8747e-02, -9.3909e-02, -3.2646e-02,\n",
       "          2.3233e-02,  6.4983e-02, -3.1407e-02,  7.2274e-02, -6.7775e-02,\n",
       "          7.8958e-02,  6.7058e-02,  2.3296e-02,  1.7273e-02,  9.6637e-02,\n",
       "          7.2483e-02, -3.2463e-04,  9.3890e-02,  2.9703e-02, -5.6024e-02,\n",
       "         -3.4558e-02, -7.6397e-02,  9.7206e-02,  6.5830e-03, -5.1011e-03,\n",
       "         -6.4176e-02,  6.3541e-02,  9.9010e-02, -5.7466e-02, -5.5288e-02,\n",
       "         -8.9334e-03, -5.0751e-02, -7.8354e-02, -2.8980e-02, -8.9608e-02,\n",
       "          5.4440e-02,  9.0201e-03, -3.9748e-02,  1.6316e-02, -8.5962e-02,\n",
       "          1.1889e-02, -7.1450e-02,  1.8487e-04,  6.5266e-02,  6.5553e-02,\n",
       "          7.5997e-02, -7.8502e-02,  9.1629e-03,  5.9026e-02, -5.7573e-02,\n",
       "         -8.0473e-02, -4.3077e-02,  8.0421e-02,  1.1084e-02,  6.4332e-03,\n",
       "         -1.4917e-02, -5.4373e-03, -9.5556e-02,  3.9003e-02, -3.5526e-02,\n",
       "         -9.4698e-02,  5.3025e-02, -2.4968e-02,  4.5203e-02, -1.0653e-03,\n",
       "         -7.1493e-03, -8.6810e-02,  9.0136e-02,  8.1275e-02,  8.8943e-03,\n",
       "         -3.3584e-02,  9.8136e-02, -1.9258e-02,  2.1157e-03,  7.9153e-02,\n",
       "         -9.0267e-02,  3.4507e-03, -4.7046e-02,  9.6603e-02,  7.0081e-02,\n",
       "         -7.6956e-02, -4.2076e-03,  4.3450e-02,  4.6727e-02, -7.8136e-02,\n",
       "          8.0338e-03, -7.4346e-03, -2.9151e-02,  8.6913e-02,  8.0780e-02,\n",
       "         -8.7140e-04,  3.7287e-02,  4.9385e-02,  3.3062e-02,  7.4214e-02,\n",
       "         -7.3472e-03,  3.5766e-02,  5.9207e-02, -8.3441e-02,  6.7270e-02],\n",
       "        [ 9.4200e-02,  6.8145e-02,  6.2540e-02, -3.1562e-02,  9.6986e-02,\n",
       "         -3.1815e-02,  5.9731e-02, -4.9975e-03, -5.5222e-02, -3.3059e-02,\n",
       "         -5.4803e-02,  6.9262e-02,  8.9559e-03, -2.4500e-02,  1.4373e-04,\n",
       "          2.7972e-02, -2.7735e-02,  1.4423e-02, -3.3158e-02, -3.8355e-02,\n",
       "         -7.4027e-02, -3.2170e-02, -5.9092e-02,  5.0811e-02, -9.2681e-02,\n",
       "          6.3145e-02, -3.1374e-03,  3.3152e-02,  7.9955e-03, -8.5179e-03,\n",
       "          8.6924e-02,  5.1679e-02,  7.5106e-03,  9.4907e-02,  1.4119e-02,\n",
       "         -9.9382e-02,  6.9623e-03, -1.8123e-03, -1.5565e-02, -9.4022e-02,\n",
       "          7.6084e-02,  9.2810e-02, -2.9924e-02,  4.5483e-04, -5.4411e-02,\n",
       "          7.4701e-02,  7.7844e-02,  8.0866e-02, -9.6821e-02, -9.6581e-02,\n",
       "         -8.6109e-02, -6.0333e-02, -6.3632e-02, -9.0926e-02, -4.0633e-02,\n",
       "          1.1208e-02,  9.1663e-02,  5.4924e-02, -5.5600e-02,  9.7539e-02,\n",
       "          1.2901e-02,  5.7531e-02,  6.5117e-02,  9.1056e-02,  8.3216e-02,\n",
       "         -1.6184e-02,  8.8581e-02,  3.3894e-02, -4.4587e-02,  6.4554e-02,\n",
       "         -9.7076e-03, -7.7806e-03,  8.5596e-02, -9.9204e-02,  6.9508e-02,\n",
       "          2.2285e-02,  7.1212e-03, -4.4236e-02, -3.3658e-02, -8.4797e-02,\n",
       "         -4.0756e-03,  5.8306e-02, -5.8387e-02,  8.6262e-02, -8.2355e-02,\n",
       "          8.5821e-02,  3.1430e-03,  9.5859e-02,  9.9203e-02,  7.2328e-02,\n",
       "          8.0080e-02,  5.8242e-02,  2.0763e-02, -6.8113e-02, -4.8255e-02,\n",
       "         -8.3045e-02, -7.4706e-02,  9.1431e-02, -9.7327e-02, -8.4262e-02]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_init.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0f6f5d5db641a9a48b4dfbaa22c887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 1] (loss: 0.00008) (accu: 0.9621)\n",
      "[epoch : 2] (loss: 0.00016) (accu: 0.9698)\n",
      "[epoch : 3] (loss: 0.00025) (accu: 0.9716)\n",
      "\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning start!\")\n",
    "pruned_percent = pruned_percent\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    if epoch == 0:\n",
    "        accuracy = test(model, test_loader, criterion)\n",
    "        visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([epoch]), str(pruned_percent))\n",
    "    \n",
    "    running_loss = train(model, train_loader, optimizer, criterion, 0)\n",
    "    accuracy = test(model, test_loader, criterion)\n",
    "    visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([((epoch+1)) * 1000]), str(pruned_percent))\n",
    "\n",
    "    \"\"\" \n",
    "    for data, label in train_loader:\n",
    "        model.train()\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iteration += 1\n",
    "        running_loss = loss / len(train_loader)\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            accuracy = test(model, test_loader, criterion)\n",
    "            visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([(iteration)]), str(pruned_percent))        \n",
    "        #accuracy = test(model, test_loader, criterion)   \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    print('[epoch : %d]' % (epoch+1),\n",
    "         '(loss: %.5f)' % (running_loss),\n",
    "         '(accu: %.4f)' % (accuracy)\n",
    "         )\n",
    "print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.l1_unstructured(model.fc1, name='weight', amount=0.5)\n",
    "prune.l1_unstructured(model.fc2, name='weight', amount=0.5)\n",
    "prune.l1_unstructured(model.fc3, name='weight', amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0914, -0.0000, -0.0699,  0.0000, -0.0000,  0.1390, -0.0000,\n",
       "         -0.0844,  0.0000, -0.1586,  0.1734,  0.0000,  0.1183, -0.0000, -0.1046,\n",
       "          0.0000, -0.0000, -0.0000,  0.1893,  0.0000, -0.0899,  0.1244,  0.0000,\n",
       "         -0.1780, -0.1437, -0.0000, -0.0000,  0.1270,  0.0000, -0.1566, -0.0000,\n",
       "          0.0000, -0.1644, -0.1531, -0.0000, -0.0000, -0.2097,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.2016, -0.0000,  0.0000,  0.0886, -0.1023,\n",
       "          0.1411, -0.1892, -0.0000, -0.0731, -0.0000,  0.0999,  0.0000,  0.0729,\n",
       "         -0.0000, -0.1140,  0.0705,  0.0809,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.1214, -0.0000, -0.0000, -0.1389,  0.0928,  0.1456,  0.1213, -0.0000,\n",
       "         -0.0000, -0.1693, -0.1453, -0.0754, -0.1931,  0.0000, -0.1925,  0.0954,\n",
       "         -0.0000, -0.0000,  0.0882,  0.0000, -0.0726,  0.1015, -0.1880,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000,  0.1564,  0.0000, -0.1160, -0.0879,\n",
       "          0.0000, -0.0000, -0.1510,  0.0000],\n",
       "        [-0.0000, -0.1381,  0.0000,  0.0745,  0.0000,  0.0000, -0.1770, -0.0000,\n",
       "         -0.1266, -0.0000, -0.0000,  0.0000, -0.0000, -0.1412,  0.0000, -0.1455,\n",
       "         -0.1366, -0.0000,  0.0000, -0.0000,  0.0797,  0.1472, -0.0000,  0.0000,\n",
       "          0.1637, -0.1831, -0.0000,  0.0000, -0.0000,  0.1244,  0.1262, -0.0000,\n",
       "         -0.0984,  0.0000, -0.1027, -0.0000,  0.0000,  0.0751,  0.0000,  0.0000,\n",
       "         -0.1104, -0.1576, -0.1402, -0.1471,  0.1195, -0.1447, -0.0831, -0.1376,\n",
       "         -0.0732,  0.0000,  0.0000,  0.0889,  0.1005, -0.0701,  0.0000,  0.0000,\n",
       "          0.0000,  0.1026, -0.0777,  0.0000,  0.1175,  0.0000, -0.1083, -0.1119,\n",
       "         -0.1876,  0.1183, -0.1422, -0.1296, -0.0000,  0.1859, -0.1459, -0.1495,\n",
       "          0.0000, -0.0967,  0.0712, -0.1699, -0.1134,  0.0988,  0.0000, -0.0000,\n",
       "          0.1419,  0.1623, -0.1365, -0.1228,  0.0000,  0.1009,  0.0992, -0.0000,\n",
       "          0.0807, -0.0000, -0.1576, -0.1273, -0.0000,  0.0821,  0.0000,  0.0000,\n",
       "         -0.1691, -0.1651,  0.0842, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000,  0.1602, -0.0000, -0.0807, -0.1111,\n",
       "          0.1063, -0.0000, -0.1293,  0.0000,  0.0782,  0.0820, -0.0000, -0.1032,\n",
       "          0.0000, -0.0762, -0.0000,  0.0000,  0.1338, -0.1968,  0.1640, -0.1950,\n",
       "          0.1181,  0.0000,  0.0000, -0.1233, -0.1077, -0.0763, -0.0000, -0.0000,\n",
       "         -0.1456,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0742, -0.0000,\n",
       "          0.0000, -0.0000, -0.1576, -0.0939, -0.0000, -0.0000, -0.0000, -0.1434,\n",
       "         -0.1055,  0.1427, -0.1545,  0.0721,  0.1379,  0.0869, -0.0000,  0.0000,\n",
       "          0.0000, -0.1896,  0.0000,  0.1511,  0.1284, -0.0000,  0.1924, -0.1012,\n",
       "          0.0000, -0.0000, -0.0000, -0.1183, -0.0000, -0.1513, -0.0000,  0.0000,\n",
       "         -0.0000, -0.1420, -0.1039,  0.0800, -0.0000,  0.0000, -0.0856, -0.2515,\n",
       "         -0.1898, -0.2001, -0.0848,  0.0812, -0.0000, -0.1505,  0.0000, -0.0000,\n",
       "         -0.0795,  0.0000,  0.1340,  0.0824, -0.0000,  0.0853, -0.0000,  0.1428,\n",
       "         -0.1090,  0.1563,  0.1419,  0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  0.1033,  0.0000,  0.0000, -0.1605, -0.1362,\n",
       "         -0.0906,  0.1186,  0.0000, -0.0000, -0.0000, -0.1317,  0.0000, -0.1431,\n",
       "          0.0698, -0.0763, -0.0000, -0.2129, -0.0000, -0.1128,  0.0000,  0.0000,\n",
       "         -0.0852,  0.1730,  0.1331,  0.0951,  0.0000, -0.1473, -0.0000,  0.0000,\n",
       "          0.0000,  0.1194, -0.1084, -0.0000,  0.0000,  0.0770, -0.1213, -0.0000,\n",
       "         -0.1241,  0.0818, -0.1894,  0.0000,  0.1008, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0962,  0.0000, -0.0855,  0.0000,  0.0869, -0.0000, -0.1637,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000,  0.0858, -0.0000, -0.1170,  0.0000,\n",
       "          0.1187, -0.1070, -0.0000,  0.0000,  0.0000, -0.2190, -0.1817,  0.0000,\n",
       "          0.0000,  0.1398, -0.0000,  0.0938,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.2763,  0.0785, -0.0000, -0.0000, -0.1748,  0.1595,  0.0000,\n",
       "         -0.0870,  0.0000, -0.1047,  0.1341, -0.0000, -0.0832, -0.1378, -0.1016,\n",
       "          0.1001,  0.0000,  0.0794,  0.0000],\n",
       "        [ 0.0000, -0.1233, -0.0000, -0.0774, -0.1232,  0.0000, -0.1561,  0.1574,\n",
       "         -0.0000, -0.1311, -0.0745,  0.0000, -0.0994,  0.0000, -0.0000,  0.1132,\n",
       "         -0.1790,  0.0889, -0.0000,  0.1085, -0.1302,  0.1412,  0.0000,  0.0767,\n",
       "         -0.0000, -0.0848, -0.2182, -0.0000,  0.0000,  0.1328, -0.1058, -0.0000,\n",
       "          0.1358, -0.1636,  0.0824, -0.0000,  0.0000,  0.1179, -0.1595,  0.0000,\n",
       "          0.0000, -0.1660,  0.0000, -0.0000,  0.0000,  0.1207, -0.1009, -0.0000,\n",
       "          0.0000,  0.0000, -0.1690, -0.1210, -0.0956, -0.1261, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.1204,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.1727,  0.1982, -0.1853,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000,  0.0804, -0.1766,  0.0914, -0.1368,\n",
       "          0.0000,  0.1655, -0.1358, -0.1115, -0.1265,  0.1235, -0.1648, -0.0000,\n",
       "         -0.0000, -0.0000,  0.1889, -0.0000, -0.0000, -0.1757,  0.0712, -0.1215,\n",
       "         -0.0000,  0.0000,  0.1373, -0.0000],\n",
       "        [-0.0000,  0.1165, -0.0000,  0.1112, -0.1018, -0.0000,  0.1761, -0.0854,\n",
       "         -0.1311, -0.0000,  0.0000, -0.1166,  0.0835, -0.0000,  0.0000, -0.0000,\n",
       "          0.1533, -0.1124,  0.0000, -0.1914, -0.0736, -0.0000, -0.0844, -0.1906,\n",
       "         -0.1679, -0.1362, -0.0000,  0.1090, -0.0964,  0.0000,  0.1362,  0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.1460,  0.0000,\n",
       "         -0.1722, -0.0000,  0.0000,  0.1779, -0.2314,  0.1413,  0.0826,  0.0000,\n",
       "         -0.1834, -0.1055,  0.1500,  0.1585,  0.0000, -0.0942,  0.0000, -0.0000,\n",
       "         -0.0000, -0.1580,  0.0000,  0.0000, -0.1612,  0.0000, -0.0000,  0.0000,\n",
       "         -0.1757, -0.0000, -0.2090,  0.1071, -0.0000, -0.0741,  0.1828,  0.0000,\n",
       "          0.0000,  0.0915,  0.0921,  0.0000, -0.0831,  0.0000, -0.1542, -0.0000,\n",
       "          0.1455, -0.0984,  0.0732,  0.0873,  0.0000, -0.1352, -0.0000,  0.0000,\n",
       "         -0.1193, -0.0000, -0.0000,  0.0000, -0.1074, -0.1392,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0898,  0.0000],\n",
       "        [-0.0000, -0.1679, -0.0000,  0.1432, -0.0000, -0.0000,  0.1152,  0.0000,\n",
       "          0.0747, -0.1512, -0.0771,  0.0000, -0.0831,  0.1373, -0.0000,  0.1285,\n",
       "          0.0000, -0.2407,  0.0000, -0.0000, -0.0000,  0.2129,  0.0000, -0.0000,\n",
       "         -0.1143, -0.2168, -0.0000, -0.0000, -0.1402,  0.1191,  0.1636,  0.0000,\n",
       "          0.0000, -0.3261,  0.0000,  0.0000, -0.0000, -0.2334,  0.1106, -0.0000,\n",
       "         -0.1016, -0.1724,  0.0726, -0.0997, -0.0000,  0.0000,  0.1217, -0.0841,\n",
       "          0.0000, -0.0000,  0.0817,  0.0000, -0.0000, -0.1283,  0.0000,  0.1492,\n",
       "          0.0000, -0.0943,  0.1214, -0.1908, -0.0723, -0.0000,  0.0000,  0.1118,\n",
       "         -0.1782,  0.0000,  0.1182, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0784,  0.0000, -0.1457, -0.0000, -0.0840,  0.2478,\n",
       "         -0.1509, -0.0000,  0.0938, -0.1055,  0.0000, -0.1117, -0.2997, -0.0000,\n",
       "          0.1100, -0.0000, -0.1411, -0.1060, -0.0000, -0.0000, -0.0000, -0.1268,\n",
       "         -0.0000,  0.0000,  0.1151,  0.0000],\n",
       "        [ 0.0000,  0.0780,  0.0000,  0.0822,  0.0000,  0.0000, -0.0000,  0.1201,\n",
       "          0.0000, -0.0000, -0.1769, -0.0000, -0.0000, -0.0000, -0.0000, -0.1497,\n",
       "          0.0000,  0.1288,  0.0000,  0.1073, -0.0000, -0.1666,  0.0000, -0.0805,\n",
       "          0.1576,  0.0765,  0.0000, -0.1593, -0.0000,  0.0000, -0.1753, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0789, -0.0000, -0.0000,  0.0900,  0.0000,  0.0000,\n",
       "          0.0961,  0.1519, -0.0000,  0.0772,  0.0000, -0.1313, -0.1753,  0.1054,\n",
       "          0.1722,  0.0000,  0.0000, -0.1544,  0.1063, -0.0000, -0.0000, -0.1653,\n",
       "         -0.0000, -0.0000, -0.1464,  0.0751,  0.1489, -0.0000, -0.2195, -0.1961,\n",
       "          0.0000, -0.1600,  0.1284, -0.0811, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0703, -0.1426,  0.0000,  0.1483,  0.1215,  0.1365,  0.0000,\n",
       "         -0.0000, -0.1251, -0.1496, -0.1168,  0.0000,  0.0755,  0.1090,  0.0000,\n",
       "         -0.1408, -0.0000, -0.1683, -0.1980,  0.0000, -0.0000,  0.0000,  0.1392,\n",
       "         -0.1499, -0.1320,  0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0741, -0.1487,\n",
       "          0.1408, -0.0000,  0.1240,  0.0000,  0.0000, -0.0000,  0.0000,  0.1141,\n",
       "         -0.0000,  0.1263,  0.0000, -0.0841, -0.0000, -0.0914,  0.1243,  0.0000,\n",
       "         -0.0000, -0.0000,  0.1069,  0.1221, -0.0968, -0.1191, -0.0000,  0.0000,\n",
       "         -0.1087, -0.0000, -0.2205,  0.0000, -0.0000, -0.1184,  0.0000, -0.0000,\n",
       "         -0.0000, -0.1246,  0.0000,  0.0714,  0.1337,  0.0786, -0.1010, -0.0000,\n",
       "         -0.0000, -0.0000, -0.1066, -0.0869,  0.0976,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.1230,  0.0000, -0.1455, -0.2257,  0.0000, -0.0874,  0.0891,\n",
       "          0.0000, -0.1466, -0.1270,  0.1512,  0.1199,  0.0000, -0.0913,  0.1474,\n",
       "         -0.0000,  0.0000,  0.1138, -0.1739, -0.0000, -0.1511,  0.1083, -0.0000,\n",
       "         -0.1640,  0.0000,  0.0697,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.1488,  0.0000, -0.1293,  0.0000, -0.0000,  0.0774,  0.1203, -0.0000,\n",
       "          0.0000,  0.0000, -0.1072,  0.0000],\n",
       "        [-0.0000,  0.0987,  0.0000, -0.2268,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.1541, -0.0000, -0.0000,  0.0749, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0713, -0.1917, -0.1140, -0.2308,  0.0998,\n",
       "         -0.1438,  0.0000, -0.0000,  0.0000,  0.0707, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.1387,  0.0000,  0.0000, -0.0000,  0.0000, -0.1043,  0.0000,\n",
       "          0.1251,  0.1602, -0.0000,  0.0000, -0.1380,  0.0983,  0.0000,  0.1399,\n",
       "         -0.1248, -0.2671, -0.1252, -0.0873, -0.3013, -0.1717, -0.0000, -0.0000,\n",
       "          0.0000,  0.1218, -0.1546,  0.0975, -0.0000,  0.0000,  0.0704,  0.1521,\n",
       "          0.1343, -0.0000,  0.1526,  0.0000, -0.0000,  0.0000, -0.0000, -0.0998,\n",
       "          0.0000, -0.1122,  0.0928,  0.0000,  0.0000, -0.1162,  0.0000, -0.1158,\n",
       "         -0.0000,  0.0812, -0.1387,  0.1207, -0.1361,  0.1365,  0.0000,  0.0000,\n",
       "          0.0968,  0.0000,  0.1305,  0.0941,  0.0000, -0.1694, -0.0000, -0.1551,\n",
       "         -0.0814,  0.1437, -0.3281, -0.0000]], device='cuda:1',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0223, -0.0350,  0.0280,  ...,  0.0078, -0.0322,  0.0111],\n",
       "        [-0.0130,  0.0037, -0.0165,  ..., -0.0151, -0.0281,  0.0235],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-0.0234,  0.0161, -0.0082,  ...,  0.0281,  0.0005, -0.0298],\n",
       "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "        [-0.0229, -0.0160,  0.0066,  ..., -0.0047, -0.0076,  0.0054]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0223, -0.0350,  0.0280,  ...,  0.0078, -0.0322,  0.0111],\n",
       "        [-0.0130,  0.0037, -0.0165,  ..., -0.0151, -0.0281,  0.0235],\n",
       "        [ 0.0128,  0.0135,  0.0014,  ...,  0.0197,  0.0046,  0.0020],\n",
       "        ...,\n",
       "        [-0.0234,  0.0161, -0.0082,  ...,  0.0281,  0.0005, -0.0298],\n",
       "        [ 0.0031, -0.0031,  0.0014,  ..., -0.0074, -0.0103,  0.0002],\n",
       "        [-0.0229, -0.0160,  0.0066,  ..., -0.0047, -0.0076,  0.0054]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0223, -0.0350,  0.0280,  ...,  0.0078, -0.0322,  0.0111],\n",
       "        [-0.0130,  0.0037, -0.0165,  ..., -0.0151, -0.0281,  0.0235],\n",
       "        [ 0.0128,  0.0135,  0.0014,  ...,  0.0197,  0.0046,  0.0020],\n",
       "        ...,\n",
       "        [-0.0234,  0.0161, -0.0082,  ...,  0.0281,  0.0005, -0.0298],\n",
       "        [ 0.0031, -0.0031,  0.0014,  ..., -0.0074, -0.0103,  0.0002],\n",
       "        [-0.0229, -0.0160,  0.0066,  ..., -0.0047, -0.0076,  0.0054]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_init.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0302, -0.1240, -0.0000,  ..., -0.0000,  0.0271, -0.0329],\n",
       "        [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-0.0373, -0.0512, -0.0000,  ..., -0.0141, -0.0435,  0.0000],\n",
       "        [-0.0252,  0.1998,  0.0000,  ...,  0.0203, -0.0000,  0.0414],\n",
       "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
       "       device='cuda:1', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0491,  0.0513,  0.0141,  ...,  0.0035,  0.0569, -0.0283],\n",
       "        [ 0.0508, -0.0542,  0.0294,  ..., -0.0455,  0.0561, -0.0015],\n",
       "        [-0.0142, -0.0327, -0.0007,  ...,  0.0577, -0.0259, -0.0153],\n",
       "        ...,\n",
       "        [-0.0114, -0.0065, -0.0085,  ...,  0.0361,  0.0414,  0.0333],\n",
       "        [-0.0493, -0.0280,  0.0286,  ...,  0.0179,  0.0050,  0.0105],\n",
       "        [-0.0452,  0.0042, -0.0133,  ...,  0.0435,  0.0233, -0.0402]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0491,  0.0513,  0.0141,  ...,  0.0035,  0.0569, -0.0283],\n",
       "        [ 0.0508, -0.0542,  0.0294,  ..., -0.0455,  0.0561, -0.0015],\n",
       "        [-0.0142, -0.0327, -0.0007,  ...,  0.0577, -0.0259, -0.0153],\n",
       "        ...,\n",
       "        [-0.0114, -0.0065, -0.0085,  ...,  0.0361,  0.0414,  0.0333],\n",
       "        [-0.0493, -0.0280,  0.0286,  ...,  0.0179,  0.0050,  0.0105],\n",
       "        [-0.0452,  0.0042, -0.0133,  ...,  0.0435,  0.0233, -0.0402]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_init.fc2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0914, -0.0000, -0.0699,  0.0000, -0.0000,  0.1390, -0.0000,\n",
       "         -0.0844,  0.0000, -0.1586,  0.1734,  0.0000,  0.1183, -0.0000, -0.1046,\n",
       "          0.0000, -0.0000, -0.0000,  0.1893,  0.0000, -0.0899,  0.1244,  0.0000,\n",
       "         -0.1780, -0.1437, -0.0000, -0.0000,  0.1270,  0.0000, -0.1566, -0.0000,\n",
       "          0.0000, -0.1644, -0.1531, -0.0000, -0.0000, -0.2097,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.2016, -0.0000,  0.0000,  0.0886, -0.1023,\n",
       "          0.1411, -0.1892, -0.0000, -0.0731, -0.0000,  0.0999,  0.0000,  0.0729,\n",
       "         -0.0000, -0.1140,  0.0705,  0.0809,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.1214, -0.0000, -0.0000, -0.1389,  0.0928,  0.1456,  0.1213, -0.0000,\n",
       "         -0.0000, -0.1693, -0.1453, -0.0754, -0.1931,  0.0000, -0.1925,  0.0954,\n",
       "         -0.0000, -0.0000,  0.0882,  0.0000, -0.0726,  0.1015, -0.1880,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000,  0.1564,  0.0000, -0.1160, -0.0879,\n",
       "          0.0000, -0.0000, -0.1510,  0.0000],\n",
       "        [-0.0000, -0.1381,  0.0000,  0.0745,  0.0000,  0.0000, -0.1770, -0.0000,\n",
       "         -0.1266, -0.0000, -0.0000,  0.0000, -0.0000, -0.1412,  0.0000, -0.1455,\n",
       "         -0.1366, -0.0000,  0.0000, -0.0000,  0.0797,  0.1472, -0.0000,  0.0000,\n",
       "          0.1637, -0.1831, -0.0000,  0.0000, -0.0000,  0.1244,  0.1262, -0.0000,\n",
       "         -0.0984,  0.0000, -0.1027, -0.0000,  0.0000,  0.0751,  0.0000,  0.0000,\n",
       "         -0.1104, -0.1576, -0.1402, -0.1471,  0.1195, -0.1447, -0.0831, -0.1376,\n",
       "         -0.0732,  0.0000,  0.0000,  0.0889,  0.1005, -0.0701,  0.0000,  0.0000,\n",
       "          0.0000,  0.1026, -0.0777,  0.0000,  0.1175,  0.0000, -0.1083, -0.1119,\n",
       "         -0.1876,  0.1183, -0.1422, -0.1296, -0.0000,  0.1859, -0.1459, -0.1495,\n",
       "          0.0000, -0.0967,  0.0712, -0.1699, -0.1134,  0.0988,  0.0000, -0.0000,\n",
       "          0.1419,  0.1623, -0.1365, -0.1228,  0.0000,  0.1009,  0.0992, -0.0000,\n",
       "          0.0807, -0.0000, -0.1576, -0.1273, -0.0000,  0.0821,  0.0000,  0.0000,\n",
       "         -0.1691, -0.1651,  0.0842, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000,  0.1602, -0.0000, -0.0807, -0.1111,\n",
       "          0.1063, -0.0000, -0.1293,  0.0000,  0.0782,  0.0820, -0.0000, -0.1032,\n",
       "          0.0000, -0.0762, -0.0000,  0.0000,  0.1338, -0.1968,  0.1640, -0.1950,\n",
       "          0.1181,  0.0000,  0.0000, -0.1233, -0.1077, -0.0763, -0.0000, -0.0000,\n",
       "         -0.1456,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0742, -0.0000,\n",
       "          0.0000, -0.0000, -0.1576, -0.0939, -0.0000, -0.0000, -0.0000, -0.1434,\n",
       "         -0.1055,  0.1427, -0.1545,  0.0721,  0.1379,  0.0869, -0.0000,  0.0000,\n",
       "          0.0000, -0.1896,  0.0000,  0.1511,  0.1284, -0.0000,  0.1924, -0.1012,\n",
       "          0.0000, -0.0000, -0.0000, -0.1183, -0.0000, -0.1513, -0.0000,  0.0000,\n",
       "         -0.0000, -0.1420, -0.1039,  0.0800, -0.0000,  0.0000, -0.0856, -0.2515,\n",
       "         -0.1898, -0.2001, -0.0848,  0.0812, -0.0000, -0.1505,  0.0000, -0.0000,\n",
       "         -0.0795,  0.0000,  0.1340,  0.0824, -0.0000,  0.0853, -0.0000,  0.1428,\n",
       "         -0.1090,  0.1563,  0.1419,  0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  0.1033,  0.0000,  0.0000, -0.1605, -0.1362,\n",
       "         -0.0906,  0.1186,  0.0000, -0.0000, -0.0000, -0.1317,  0.0000, -0.1431,\n",
       "          0.0698, -0.0763, -0.0000, -0.2129, -0.0000, -0.1128,  0.0000,  0.0000,\n",
       "         -0.0852,  0.1730,  0.1331,  0.0951,  0.0000, -0.1473, -0.0000,  0.0000,\n",
       "          0.0000,  0.1194, -0.1084, -0.0000,  0.0000,  0.0770, -0.1213, -0.0000,\n",
       "         -0.1241,  0.0818, -0.1894,  0.0000,  0.1008, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0962,  0.0000, -0.0855,  0.0000,  0.0869, -0.0000, -0.1637,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000,  0.0858, -0.0000, -0.1170,  0.0000,\n",
       "          0.1187, -0.1070, -0.0000,  0.0000,  0.0000, -0.2190, -0.1817,  0.0000,\n",
       "          0.0000,  0.1398, -0.0000,  0.0938,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.2763,  0.0785, -0.0000, -0.0000, -0.1748,  0.1595,  0.0000,\n",
       "         -0.0870,  0.0000, -0.1047,  0.1341, -0.0000, -0.0832, -0.1378, -0.1016,\n",
       "          0.1001,  0.0000,  0.0794,  0.0000],\n",
       "        [ 0.0000, -0.1233, -0.0000, -0.0774, -0.1232,  0.0000, -0.1561,  0.1574,\n",
       "         -0.0000, -0.1311, -0.0745,  0.0000, -0.0994,  0.0000, -0.0000,  0.1132,\n",
       "         -0.1790,  0.0889, -0.0000,  0.1085, -0.1302,  0.1412,  0.0000,  0.0767,\n",
       "         -0.0000, -0.0848, -0.2182, -0.0000,  0.0000,  0.1328, -0.1058, -0.0000,\n",
       "          0.1358, -0.1636,  0.0824, -0.0000,  0.0000,  0.1179, -0.1595,  0.0000,\n",
       "          0.0000, -0.1660,  0.0000, -0.0000,  0.0000,  0.1207, -0.1009, -0.0000,\n",
       "          0.0000,  0.0000, -0.1690, -0.1210, -0.0956, -0.1261, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.1204,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.1727,  0.1982, -0.1853,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000,  0.0804, -0.1766,  0.0914, -0.1368,\n",
       "          0.0000,  0.1655, -0.1358, -0.1115, -0.1265,  0.1235, -0.1648, -0.0000,\n",
       "         -0.0000, -0.0000,  0.1889, -0.0000, -0.0000, -0.1757,  0.0712, -0.1215,\n",
       "         -0.0000,  0.0000,  0.1373, -0.0000],\n",
       "        [-0.0000,  0.1165, -0.0000,  0.1112, -0.1018, -0.0000,  0.1761, -0.0854,\n",
       "         -0.1311, -0.0000,  0.0000, -0.1166,  0.0835, -0.0000,  0.0000, -0.0000,\n",
       "          0.1533, -0.1124,  0.0000, -0.1914, -0.0736, -0.0000, -0.0844, -0.1906,\n",
       "         -0.1679, -0.1362, -0.0000,  0.1090, -0.0964,  0.0000,  0.1362,  0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.1460,  0.0000,\n",
       "         -0.1722, -0.0000,  0.0000,  0.1779, -0.2314,  0.1413,  0.0826,  0.0000,\n",
       "         -0.1834, -0.1055,  0.1500,  0.1585,  0.0000, -0.0942,  0.0000, -0.0000,\n",
       "         -0.0000, -0.1580,  0.0000,  0.0000, -0.1612,  0.0000, -0.0000,  0.0000,\n",
       "         -0.1757, -0.0000, -0.2090,  0.1071, -0.0000, -0.0741,  0.1828,  0.0000,\n",
       "          0.0000,  0.0915,  0.0921,  0.0000, -0.0831,  0.0000, -0.1542, -0.0000,\n",
       "          0.1455, -0.0984,  0.0732,  0.0873,  0.0000, -0.1352, -0.0000,  0.0000,\n",
       "         -0.1193, -0.0000, -0.0000,  0.0000, -0.1074, -0.1392,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0898,  0.0000],\n",
       "        [-0.0000, -0.1679, -0.0000,  0.1432, -0.0000, -0.0000,  0.1152,  0.0000,\n",
       "          0.0747, -0.1512, -0.0771,  0.0000, -0.0831,  0.1373, -0.0000,  0.1285,\n",
       "          0.0000, -0.2407,  0.0000, -0.0000, -0.0000,  0.2129,  0.0000, -0.0000,\n",
       "         -0.1143, -0.2168, -0.0000, -0.0000, -0.1402,  0.1191,  0.1636,  0.0000,\n",
       "          0.0000, -0.3261,  0.0000,  0.0000, -0.0000, -0.2334,  0.1106, -0.0000,\n",
       "         -0.1016, -0.1724,  0.0726, -0.0997, -0.0000,  0.0000,  0.1217, -0.0841,\n",
       "          0.0000, -0.0000,  0.0817,  0.0000, -0.0000, -0.1283,  0.0000,  0.1492,\n",
       "          0.0000, -0.0943,  0.1214, -0.1908, -0.0723, -0.0000,  0.0000,  0.1118,\n",
       "         -0.1782,  0.0000,  0.1182, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0784,  0.0000, -0.1457, -0.0000, -0.0840,  0.2478,\n",
       "         -0.1509, -0.0000,  0.0938, -0.1055,  0.0000, -0.1117, -0.2997, -0.0000,\n",
       "          0.1100, -0.0000, -0.1411, -0.1060, -0.0000, -0.0000, -0.0000, -0.1268,\n",
       "         -0.0000,  0.0000,  0.1151,  0.0000],\n",
       "        [ 0.0000,  0.0780,  0.0000,  0.0822,  0.0000,  0.0000, -0.0000,  0.1201,\n",
       "          0.0000, -0.0000, -0.1769, -0.0000, -0.0000, -0.0000, -0.0000, -0.1497,\n",
       "          0.0000,  0.1288,  0.0000,  0.1073, -0.0000, -0.1666,  0.0000, -0.0805,\n",
       "          0.1576,  0.0765,  0.0000, -0.1593, -0.0000,  0.0000, -0.1753, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0789, -0.0000, -0.0000,  0.0900,  0.0000,  0.0000,\n",
       "          0.0961,  0.1519, -0.0000,  0.0772,  0.0000, -0.1313, -0.1753,  0.1054,\n",
       "          0.1722,  0.0000,  0.0000, -0.1544,  0.1063, -0.0000, -0.0000, -0.1653,\n",
       "         -0.0000, -0.0000, -0.1464,  0.0751,  0.1489, -0.0000, -0.2195, -0.1961,\n",
       "          0.0000, -0.1600,  0.1284, -0.0811, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0703, -0.1426,  0.0000,  0.1483,  0.1215,  0.1365,  0.0000,\n",
       "         -0.0000, -0.1251, -0.1496, -0.1168,  0.0000,  0.0755,  0.1090,  0.0000,\n",
       "         -0.1408, -0.0000, -0.1683, -0.1980,  0.0000, -0.0000,  0.0000,  0.1392,\n",
       "         -0.1499, -0.1320,  0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0741, -0.1487,\n",
       "          0.1408, -0.0000,  0.1240,  0.0000,  0.0000, -0.0000,  0.0000,  0.1141,\n",
       "         -0.0000,  0.1263,  0.0000, -0.0841, -0.0000, -0.0914,  0.1243,  0.0000,\n",
       "         -0.0000, -0.0000,  0.1069,  0.1221, -0.0968, -0.1191, -0.0000,  0.0000,\n",
       "         -0.1087, -0.0000, -0.2205,  0.0000, -0.0000, -0.1184,  0.0000, -0.0000,\n",
       "         -0.0000, -0.1246,  0.0000,  0.0714,  0.1337,  0.0786, -0.1010, -0.0000,\n",
       "         -0.0000, -0.0000, -0.1066, -0.0869,  0.0976,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.1230,  0.0000, -0.1455, -0.2257,  0.0000, -0.0874,  0.0891,\n",
       "          0.0000, -0.1466, -0.1270,  0.1512,  0.1199,  0.0000, -0.0913,  0.1474,\n",
       "         -0.0000,  0.0000,  0.1138, -0.1739, -0.0000, -0.1511,  0.1083, -0.0000,\n",
       "         -0.1640,  0.0000,  0.0697,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.1488,  0.0000, -0.1293,  0.0000, -0.0000,  0.0774,  0.1203, -0.0000,\n",
       "          0.0000,  0.0000, -0.1072,  0.0000],\n",
       "        [-0.0000,  0.0987,  0.0000, -0.2268,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.1541, -0.0000, -0.0000,  0.0749, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0713, -0.1917, -0.1140, -0.2308,  0.0998,\n",
       "         -0.1438,  0.0000, -0.0000,  0.0000,  0.0707, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.1387,  0.0000,  0.0000, -0.0000,  0.0000, -0.1043,  0.0000,\n",
       "          0.1251,  0.1602, -0.0000,  0.0000, -0.1380,  0.0983,  0.0000,  0.1399,\n",
       "         -0.1248, -0.2671, -0.1252, -0.0873, -0.3013, -0.1717, -0.0000, -0.0000,\n",
       "          0.0000,  0.1218, -0.1546,  0.0975, -0.0000,  0.0000,  0.0704,  0.1521,\n",
       "          0.1343, -0.0000,  0.1526,  0.0000, -0.0000,  0.0000, -0.0000, -0.0998,\n",
       "          0.0000, -0.1122,  0.0928,  0.0000,  0.0000, -0.1162,  0.0000, -0.1158,\n",
       "         -0.0000,  0.0812, -0.1387,  0.1207, -0.1361,  0.1365,  0.0000,  0.0000,\n",
       "          0.0968,  0.0000,  0.1305,  0.0941,  0.0000, -0.1694, -0.0000, -0.1551,\n",
       "         -0.0814,  0.1437, -0.3281, -0.0000]], device='cuda:1',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 8.6343e-02,  2.2677e-02, -4.7661e-02,  1.8855e-02,  1.2614e-02,\n",
       "         -9.1771e-02,  9.5994e-02,  3.7472e-03, -5.5675e-02,  4.2135e-02,\n",
       "         -8.2481e-02,  8.1279e-02,  3.3593e-02,  6.8933e-02,  3.4503e-03,\n",
       "         -6.9401e-02,  4.7753e-02, -1.6106e-02, -4.8963e-02,  9.8462e-02,\n",
       "          7.7872e-03, -1.4528e-02,  8.6890e-02, -1.8431e-02, -9.0947e-02,\n",
       "         -4.9702e-02,  2.8297e-03,  5.7101e-02,  6.9263e-02,  5.4166e-02,\n",
       "          1.4694e-02,  8.2854e-02, -7.6132e-03, -6.4445e-02, -5.7414e-02,\n",
       "          7.8778e-02, -5.7851e-02, -3.3824e-02,  3.3542e-02,  4.5017e-02,\n",
       "         -1.8248e-02,  2.2583e-02,  3.3094e-03, -9.7023e-02,  3.7301e-02,\n",
       "          7.5525e-02,  5.3025e-02, -3.8207e-02,  5.0060e-02, -9.1124e-02,\n",
       "         -7.0831e-02, -2.2198e-02,  1.9828e-02,  6.3643e-02, -7.5319e-02,\n",
       "          2.2189e-02,  1.0544e-02, -9.4123e-02,  5.2022e-02,  7.2223e-02,\n",
       "          2.8765e-02, -9.0098e-02, -7.3193e-02,  2.3185e-02,  7.0516e-02,\n",
       "         -2.3746e-02, -4.2617e-02, -1.7919e-02,  9.8678e-02,  6.7877e-02,\n",
       "          7.7421e-02, -1.8440e-02,  8.5005e-02, -8.0693e-02, -1.8403e-02,\n",
       "         -3.4524e-02, -9.1246e-02,  1.7109e-02, -9.6608e-02,  5.3629e-02,\n",
       "          1.9765e-02, -8.9226e-02,  6.9817e-02,  1.5969e-02, -7.3826e-02,\n",
       "          5.8003e-02, -5.9896e-02,  1.0440e-02, -5.3661e-02, -2.8234e-02,\n",
       "         -3.2824e-02,  1.6111e-02,  7.4770e-02,  1.9609e-02, -7.8515e-02,\n",
       "         -6.5563e-02,  5.6677e-02, -6.3302e-02, -8.2887e-02, -3.2505e-03],\n",
       "        [ 4.1528e-03, -5.0999e-04,  4.7889e-02,  9.9608e-02,  6.5930e-02,\n",
       "          1.2603e-02, -5.2682e-02, -2.0438e-02, -7.8649e-02, -4.7545e-02,\n",
       "         -3.0186e-02,  2.0846e-02,  4.4954e-03, -4.6991e-02, -7.4986e-02,\n",
       "         -7.7584e-02, -7.6817e-02, -2.6010e-02,  2.5692e-02, -1.9591e-02,\n",
       "          3.9720e-02,  6.6772e-02,  1.1513e-02,  2.2705e-02,  9.9643e-02,\n",
       "         -9.2052e-02, -1.3720e-02,  2.7988e-02,  1.0657e-02,  8.1917e-02,\n",
       "          4.9089e-02,  8.5811e-03, -4.6736e-02,  8.4676e-03, -2.9749e-02,\n",
       "          8.4153e-02,  1.7573e-03,  9.0151e-02,  4.0110e-02, -6.8232e-02,\n",
       "         -3.1649e-02, -7.5894e-02, -8.8491e-02, -7.0608e-02,  8.5739e-02,\n",
       "         -5.7996e-02, -3.1761e-02, -5.9893e-02, -5.4090e-02,  1.9082e-02,\n",
       "          8.2661e-02,  4.4332e-02,  7.3294e-02, -1.2014e-02, -1.3561e-02,\n",
       "          5.5646e-02,  1.2545e-02,  4.3497e-02, -1.0592e-02,  4.2127e-02,\n",
       "          6.8960e-02,  9.3093e-02, -2.7970e-02, -3.3585e-02, -9.4778e-02,\n",
       "          1.4174e-02, -9.4552e-02, -2.1529e-02,  4.7088e-03,  7.3967e-02,\n",
       "         -6.4380e-02, -8.0963e-02,  6.5893e-02, -7.5556e-02,  5.8889e-02,\n",
       "         -7.2845e-02, -7.0367e-02,  5.2844e-02, -2.1209e-02,  8.9995e-02,\n",
       "          8.6740e-02,  5.6064e-02, -7.9534e-02, -3.7765e-03,  2.8179e-03,\n",
       "          4.5681e-02,  7.1234e-02, -9.0122e-02,  8.7984e-02,  5.9727e-02,\n",
       "         -9.6097e-02, -6.0146e-02,  7.2155e-03,  4.1201e-02,  2.2552e-03,\n",
       "         -1.6688e-02, -9.5432e-02, -2.9095e-02,  7.6843e-02,  7.4836e-04],\n",
       "        [-2.5500e-03,  2.3274e-03,  7.3384e-02, -8.0204e-04,  9.0274e-02,\n",
       "         -2.8104e-02, -2.2140e-02, -7.7364e-02,  4.8680e-02, -4.5889e-02,\n",
       "         -6.6111e-02,  2.8005e-02,  3.9746e-02,  4.9738e-02, -5.2060e-02,\n",
       "         -1.7594e-02,  1.7409e-02, -1.6960e-02, -3.0478e-02, -1.0121e-03,\n",
       "          7.3673e-02, -9.2437e-02,  9.2866e-02, -8.5163e-02,  6.5988e-02,\n",
       "          4.0207e-03,  2.5145e-02, -1.8225e-02, -6.3483e-02,  1.9956e-03,\n",
       "          9.5636e-02, -5.2204e-02, -8.4442e-02,  2.4041e-02, -7.0409e-02,\n",
       "          8.9973e-02, -4.2703e-02,  1.0772e-02,  9.9668e-03,  4.8437e-02,\n",
       "          3.4002e-02, -2.1566e-02, -3.8276e-02, -1.1650e-02, -7.5659e-03,\n",
       "          3.6031e-02, -4.4493e-03, -4.5334e-02, -1.5439e-02,  3.6833e-02,\n",
       "         -8.1999e-02,  4.0632e-02,  9.2213e-02,  1.9470e-02, -5.7503e-02,\n",
       "          2.5290e-02,  6.7209e-02, -4.3417e-02,  1.8483e-02,  8.7581e-02,\n",
       "          8.6944e-02,  1.2402e-02,  9.0743e-02, -1.3202e-02,  2.4537e-02,\n",
       "         -7.0989e-02,  2.0723e-02, -1.5906e-02, -2.3716e-02, -2.9661e-02,\n",
       "         -1.2390e-02,  1.4766e-02, -2.5465e-04, -9.7442e-02, -7.2802e-03,\n",
       "          4.5010e-02,  1.1450e-02,  4.4475e-04, -2.0048e-03, -5.9728e-02,\n",
       "         -6.9177e-02, -4.5585e-02, -5.9017e-02,  5.9935e-02, -2.1287e-02,\n",
       "         -3.8905e-02,  4.1414e-02,  8.6765e-03, -1.0193e-02,  2.8438e-02,\n",
       "          5.8956e-02,  7.1921e-02, -4.0519e-03,  1.9134e-02,  1.6889e-02,\n",
       "          6.3170e-02, -9.0465e-02,  9.2459e-02,  6.2682e-02,  1.4407e-02],\n",
       "        [-6.4671e-02, -1.9622e-02, -4.1884e-02,  7.2848e-02, -1.3087e-03,\n",
       "          9.2978e-03, -6.2640e-02, -9.5693e-04, -9.7351e-02,  6.4995e-02,\n",
       "         -2.8299e-02,  3.8229e-02, -6.4734e-02, -4.4667e-02, -8.2343e-02,\n",
       "         -2.6142e-02,  5.5340e-02, -7.9140e-02,  9.3099e-02, -4.4264e-02,\n",
       "         -3.9927e-03,  8.9598e-03,  3.1641e-02,  3.8755e-02, -5.4770e-02,\n",
       "          7.3218e-02,  6.9969e-02,  3.5092e-02,  5.9126e-02, -7.3393e-02,\n",
       "          2.7073e-02,  9.8398e-02,  3.0389e-02,  5.2298e-02, -8.8168e-02,\n",
       "         -8.3517e-02, -4.9683e-02,  4.2034e-02, -6.5246e-02,  5.4208e-02,\n",
       "         -8.9553e-02,  5.9553e-02, -6.9454e-02, -2.4570e-02,  4.2015e-02,\n",
       "          1.2895e-03,  6.6123e-02, -1.7651e-02,  7.8748e-02, -7.9327e-02,\n",
       "          1.4061e-02, -7.4886e-02, -4.7078e-02,  4.5722e-02, -7.0716e-02,\n",
       "         -9.4505e-02,  5.1904e-02,  4.5253e-03, -8.1925e-04,  4.9587e-03,\n",
       "          5.3629e-02, -7.3109e-02, -8.5068e-02,  5.4536e-02,  8.1014e-02,\n",
       "          5.5725e-02, -9.4109e-02, -2.8140e-02,  5.1159e-02, -5.8746e-02,\n",
       "         -9.3726e-02,  3.1368e-02, -7.3942e-02,  9.0758e-02, -3.2881e-02,\n",
       "          6.4243e-02,  7.6023e-03,  1.8202e-02, -6.2037e-02,  1.1409e-02,\n",
       "         -5.3912e-02, -3.8634e-02,  5.1748e-02, -3.9598e-02, -5.0872e-02,\n",
       "         -8.2941e-02,  8.8752e-02,  1.6624e-02,  3.8859e-03,  4.2001e-02,\n",
       "         -5.5109e-02,  8.7460e-02, -4.2381e-02, -9.9180e-02, -8.6241e-02,\n",
       "         -8.9850e-02,  4.4762e-02,  4.5963e-02,  8.2411e-02,  9.2800e-03],\n",
       "        [ 4.3601e-02, -3.4494e-02, -5.7787e-02, -1.4136e-02, -4.3939e-02,\n",
       "          3.2256e-02, -7.5373e-02,  9.1316e-02, -3.7707e-03, -5.5445e-02,\n",
       "         -6.6390e-02,  4.1525e-02, -3.4794e-02,  6.8138e-02,  4.7879e-03,\n",
       "          5.9857e-02, -7.1180e-02,  6.7177e-02, -8.3874e-02,  7.0709e-02,\n",
       "         -4.9262e-02,  7.5635e-02,  9.9538e-02,  1.5865e-02, -1.8727e-02,\n",
       "         -9.3624e-02, -8.5000e-02, -9.2178e-03,  2.8803e-02,  9.3594e-02,\n",
       "          2.0650e-02,  8.9347e-02,  6.6293e-02, -9.7868e-02,  2.3316e-02,\n",
       "          1.6505e-02,  8.9273e-02,  8.2533e-02, -7.8808e-02,  5.2512e-02,\n",
       "          3.3913e-02, -8.1112e-02,  2.2472e-02, -1.7950e-02,  2.6129e-02,\n",
       "          8.4983e-02, -5.4338e-02, -4.3629e-02,  7.6526e-02,  3.9182e-02,\n",
       "         -9.3896e-02, -8.3411e-02,  1.1320e-02, -6.2531e-02, -6.2071e-02,\n",
       "         -2.9819e-02,  3.9089e-02, -6.1120e-02,  2.3641e-02,  9.9605e-02,\n",
       "          3.4316e-02,  6.3897e-02, -7.1780e-03,  4.9769e-03, -1.4503e-02,\n",
       "          7.0034e-02, -8.1194e-02, -7.0706e-03,  6.6244e-02,  2.1536e-02,\n",
       "         -1.5054e-02, -1.4042e-02,  3.8608e-02,  9.1832e-03,  8.1986e-03,\n",
       "          1.1235e-02,  5.3728e-02, -6.8584e-02,  5.6557e-02, -5.7709e-02,\n",
       "          9.3063e-03,  7.9759e-02, -4.1170e-02, -4.1482e-02, -8.5165e-02,\n",
       "          7.9161e-02, -9.2639e-02, -5.4367e-02, -2.8281e-02, -2.1363e-02,\n",
       "          9.3371e-02,  1.7236e-02, -1.1385e-02, -6.1794e-02,  4.2132e-02,\n",
       "         -5.7499e-02, -1.7752e-02,  6.1594e-02,  9.0768e-02, -3.5583e-02],\n",
       "        [-8.0562e-02,  5.2788e-02, -5.9207e-02,  5.2153e-02, -4.9190e-02,\n",
       "         -1.2815e-02,  9.7013e-02, -7.4623e-02, -6.2269e-02, -5.4922e-02,\n",
       "          1.5724e-02, -3.4340e-02,  7.7623e-02, -4.8620e-02,  2.4162e-02,\n",
       "         -2.5834e-02,  7.6896e-02, -4.0405e-02,  1.3451e-03, -8.1941e-02,\n",
       "         -4.3111e-02, -4.5878e-02,  1.5949e-02, -7.5751e-02, -9.5916e-02,\n",
       "         -8.5443e-02, -2.0578e-02,  8.0032e-02, -9.4383e-02, -8.0177e-03,\n",
       "          8.0198e-02,  7.5688e-02, -8.2508e-02,  2.5497e-02, -4.0375e-02,\n",
       "          1.7961e-02, -3.2565e-03,  2.8614e-02, -8.0333e-02,  9.3072e-02,\n",
       "         -5.8048e-02, -2.4315e-02, -2.7922e-02,  8.7350e-02, -7.9492e-02,\n",
       "          9.4581e-02,  2.2760e-02,  1.3166e-02, -8.3920e-02, -6.2117e-02,\n",
       "          4.9298e-02,  8.8655e-02,  6.3035e-02, -5.6876e-02, -6.4902e-03,\n",
       "         -2.5933e-02,  2.4289e-02, -7.7747e-02,  2.9593e-02,  1.2707e-02,\n",
       "         -6.5622e-02, -2.0439e-02, -6.9101e-02, -2.3490e-02, -7.8613e-02,\n",
       "         -3.9565e-02, -8.5401e-02,  5.5246e-02,  2.4987e-02, -4.7975e-02,\n",
       "          8.8521e-02,  3.0851e-02,  1.4754e-03,  3.0287e-02,  5.7004e-02,\n",
       "         -1.2508e-02, -3.6943e-02,  2.5958e-02, -5.0604e-02, -3.8234e-02,\n",
       "          6.3907e-02, -1.6487e-02,  1.4253e-02,  5.3643e-02, -2.3923e-02,\n",
       "         -8.9125e-02, -3.7334e-03,  7.1785e-02, -6.4289e-02, -7.1369e-03,\n",
       "         -6.3484e-02,  3.2469e-02, -9.9547e-03, -5.3241e-02,  1.8564e-02,\n",
       "          2.5148e-02,  9.8486e-03,  3.2055e-02, -8.9040e-02,  1.4824e-02],\n",
       "        [ 5.9026e-02, -5.0621e-02, -3.2696e-02,  4.4960e-02,  1.6684e-02,\n",
       "          1.4792e-03,  1.8295e-02,  2.6417e-02,  2.1001e-02, -4.8455e-02,\n",
       "         -9.6928e-02,  2.9257e-02, -9.3454e-02,  7.3738e-02,  3.0534e-02,\n",
       "          6.5924e-02,  2.3422e-02, -8.6882e-02, -4.0743e-02, -2.6556e-02,\n",
       "         -1.3885e-02,  7.7824e-02,  4.6027e-02,  3.2260e-02, -1.7540e-02,\n",
       "          7.3648e-03,  4.5031e-02, -2.8448e-02, -7.2320e-03,  5.1744e-02,\n",
       "          6.9604e-02,  8.1851e-02,  2.7918e-03, -9.8251e-02, -1.2639e-02,\n",
       "          5.3265e-02, -4.2813e-02, -6.8331e-02,  1.5010e-02, -5.8569e-02,\n",
       "         -2.2219e-02, -2.4114e-02, -1.4530e-02, -1.7364e-02, -9.1941e-03,\n",
       "         -1.0603e-02,  7.4305e-02, -1.5893e-02, -2.0449e-02, -3.5320e-02,\n",
       "          4.0753e-02, -2.1353e-03, -4.6640e-02, -6.6990e-02, -7.0215e-02,\n",
       "          6.6001e-02,  2.1142e-02, -7.5543e-02,  4.6400e-02, -2.4217e-02,\n",
       "          5.0202e-02, -6.1302e-02, -1.2170e-02,  7.8400e-02, -3.4096e-02,\n",
       "          9.8906e-02,  4.9788e-02, -1.3564e-02, -4.4159e-02, -5.6083e-02,\n",
       "         -5.0064e-02,  2.6566e-03, -8.5770e-04,  4.5537e-02, -7.7143e-02,\n",
       "          3.1669e-02,  3.7224e-03, -3.7081e-03, -2.5075e-02,  7.3677e-02,\n",
       "         -8.5969e-02, -4.6309e-02,  2.2035e-02, -8.6429e-02, -2.9284e-02,\n",
       "         -1.5355e-02, -8.6934e-02, -5.5548e-02,  5.5799e-02,  8.2205e-02,\n",
       "         -2.9939e-02, -1.2084e-02, -7.4241e-02, -8.6183e-02, -4.3200e-03,\n",
       "         -7.6398e-02, -9.6096e-02,  7.1425e-02,  8.2157e-02,  9.5446e-02],\n",
       "        [-8.9403e-02,  4.0506e-02,  1.3439e-02,  9.0280e-02, -2.7822e-02,\n",
       "          9.7970e-02,  1.4020e-02,  7.7287e-02,  7.3067e-02, -5.8740e-02,\n",
       "         -8.4600e-02,  3.3242e-02, -4.2847e-03,  1.3826e-02,  2.3941e-02,\n",
       "         -5.4344e-02,  6.4043e-02,  9.7476e-02, -4.2760e-02,  3.4561e-02,\n",
       "         -6.3089e-02, -6.8214e-02,  8.4022e-02, -5.2991e-02,  9.0282e-02,\n",
       "          6.2587e-02,  4.0697e-02, -4.4998e-02, -2.9477e-02,  2.4943e-02,\n",
       "         -3.9199e-02,  6.5424e-05, -4.2814e-02,  8.2109e-03, -5.4878e-02,\n",
       "         -2.8676e-02, -8.9987e-02,  2.8043e-02,  2.9140e-02,  2.2242e-02,\n",
       "          6.9026e-02,  9.6716e-02, -6.1381e-02,  8.5053e-02,  6.4341e-03,\n",
       "         -3.6801e-02, -5.1950e-02,  5.4700e-02,  2.7304e-02, -2.5956e-02,\n",
       "          9.7227e-02, -4.3543e-02,  8.4096e-02, -3.2012e-02, -9.6544e-02,\n",
       "         -3.6465e-02, -2.7663e-03, -8.8177e-02, -3.8632e-02,  3.0295e-02,\n",
       "          8.5585e-02, -9.6268e-02, -7.9988e-02, -3.9222e-02,  2.1567e-02,\n",
       "         -9.7983e-02,  5.5646e-02,  4.8819e-02, -3.9640e-03, -3.4109e-02,\n",
       "         -2.5943e-02, -1.0594e-02, -9.9471e-03, -2.8234e-02, -7.4283e-02,\n",
       "          3.9268e-02,  7.9887e-02,  8.7643e-02,  9.5134e-02, -1.0928e-02,\n",
       "         -3.4155e-02, -9.3886e-02, -9.1365e-03, -4.5802e-02, -1.0208e-02,\n",
       "          5.4826e-02,  8.7284e-02, -2.2323e-02, -7.2347e-02,  1.7180e-02,\n",
       "         -7.2511e-02, -8.3457e-02, -8.6285e-03, -5.8778e-02,  7.2705e-02,\n",
       "          9.1806e-02, -5.2112e-02, -3.5617e-03,  5.7661e-03, -4.0118e-02],\n",
       "        [-4.3570e-03,  2.4893e-02,  6.8747e-02, -9.3909e-02, -3.2646e-02,\n",
       "          2.3233e-02,  6.4983e-02, -3.1407e-02,  7.2274e-02, -6.7775e-02,\n",
       "          7.8958e-02,  6.7058e-02,  2.3296e-02,  1.7273e-02,  9.6637e-02,\n",
       "          7.2483e-02, -3.2463e-04,  9.3890e-02,  2.9703e-02, -5.6024e-02,\n",
       "         -3.4558e-02, -7.6397e-02,  9.7206e-02,  6.5830e-03, -5.1011e-03,\n",
       "         -6.4176e-02,  6.3541e-02,  9.9010e-02, -5.7466e-02, -5.5288e-02,\n",
       "         -8.9334e-03, -5.0751e-02, -7.8354e-02, -2.8980e-02, -8.9608e-02,\n",
       "          5.4440e-02,  9.0201e-03, -3.9748e-02,  1.6316e-02, -8.5962e-02,\n",
       "          1.1889e-02, -7.1450e-02,  1.8487e-04,  6.5266e-02,  6.5553e-02,\n",
       "          7.5997e-02, -7.8502e-02,  9.1629e-03,  5.9026e-02, -5.7573e-02,\n",
       "         -8.0473e-02, -4.3077e-02,  8.0421e-02,  1.1084e-02,  6.4332e-03,\n",
       "         -1.4917e-02, -5.4373e-03, -9.5556e-02,  3.9003e-02, -3.5526e-02,\n",
       "         -9.4698e-02,  5.3025e-02, -2.4968e-02,  4.5203e-02, -1.0653e-03,\n",
       "         -7.1493e-03, -8.6810e-02,  9.0136e-02,  8.1275e-02,  8.8943e-03,\n",
       "         -3.3584e-02,  9.8136e-02, -1.9258e-02,  2.1157e-03,  7.9153e-02,\n",
       "         -9.0267e-02,  3.4507e-03, -4.7046e-02,  9.6603e-02,  7.0081e-02,\n",
       "         -7.6956e-02, -4.2076e-03,  4.3450e-02,  4.6727e-02, -7.8136e-02,\n",
       "          8.0338e-03, -7.4346e-03, -2.9151e-02,  8.6913e-02,  8.0780e-02,\n",
       "         -8.7140e-04,  3.7287e-02,  4.9385e-02,  3.3062e-02,  7.4214e-02,\n",
       "         -7.3472e-03,  3.5766e-02,  5.9207e-02, -8.3441e-02,  6.7270e-02],\n",
       "        [ 9.4200e-02,  6.8145e-02,  6.2540e-02, -3.1562e-02,  9.6986e-02,\n",
       "         -3.1815e-02,  5.9731e-02, -4.9975e-03, -5.5222e-02, -3.3059e-02,\n",
       "         -5.4803e-02,  6.9262e-02,  8.9559e-03, -2.4500e-02,  1.4373e-04,\n",
       "          2.7972e-02, -2.7735e-02,  1.4423e-02, -3.3158e-02, -3.8355e-02,\n",
       "         -7.4027e-02, -3.2170e-02, -5.9092e-02,  5.0811e-02, -9.2681e-02,\n",
       "          6.3145e-02, -3.1374e-03,  3.3152e-02,  7.9955e-03, -8.5179e-03,\n",
       "          8.6924e-02,  5.1679e-02,  7.5106e-03,  9.4907e-02,  1.4119e-02,\n",
       "         -9.9382e-02,  6.9623e-03, -1.8123e-03, -1.5565e-02, -9.4022e-02,\n",
       "          7.6084e-02,  9.2810e-02, -2.9924e-02,  4.5483e-04, -5.4411e-02,\n",
       "          7.4701e-02,  7.7844e-02,  8.0866e-02, -9.6821e-02, -9.6581e-02,\n",
       "         -8.6109e-02, -6.0333e-02, -6.3632e-02, -9.0926e-02, -4.0633e-02,\n",
       "          1.1208e-02,  9.1663e-02,  5.4924e-02, -5.5600e-02,  9.7539e-02,\n",
       "          1.2901e-02,  5.7531e-02,  6.5117e-02,  9.1056e-02,  8.3216e-02,\n",
       "         -1.6184e-02,  8.8581e-02,  3.3894e-02, -4.4587e-02,  6.4554e-02,\n",
       "         -9.7076e-03, -7.7806e-03,  8.5596e-02, -9.9204e-02,  6.9508e-02,\n",
       "          2.2285e-02,  7.1212e-03, -4.4236e-02, -3.3658e-02, -8.4797e-02,\n",
       "         -4.0756e-03,  5.8306e-02, -5.8387e-02,  8.6262e-02, -8.2355e-02,\n",
       "          8.5821e-02,  3.1430e-03,  9.5859e-02,  9.9203e-02,  7.2328e-02,\n",
       "          8.0080e-02,  5.8242e-02,  2.0763e-02, -6.8113e-02, -4.8255e-02,\n",
       "         -8.3045e-02, -7.4706e-02,  9.1431e-02, -9.7327e-02, -8.4262e-02]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc3.weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 8.6343e-02,  2.2677e-02, -4.7661e-02,  1.8855e-02,  1.2614e-02,\n",
       "         -9.1771e-02,  9.5994e-02,  3.7472e-03, -5.5675e-02,  4.2135e-02,\n",
       "         -8.2481e-02,  8.1279e-02,  3.3593e-02,  6.8933e-02,  3.4503e-03,\n",
       "         -6.9401e-02,  4.7753e-02, -1.6106e-02, -4.8963e-02,  9.8462e-02,\n",
       "          7.7872e-03, -1.4528e-02,  8.6890e-02, -1.8431e-02, -9.0947e-02,\n",
       "         -4.9702e-02,  2.8297e-03,  5.7101e-02,  6.9263e-02,  5.4166e-02,\n",
       "          1.4694e-02,  8.2854e-02, -7.6132e-03, -6.4445e-02, -5.7414e-02,\n",
       "          7.8778e-02, -5.7851e-02, -3.3824e-02,  3.3542e-02,  4.5017e-02,\n",
       "         -1.8248e-02,  2.2583e-02,  3.3094e-03, -9.7023e-02,  3.7301e-02,\n",
       "          7.5525e-02,  5.3025e-02, -3.8207e-02,  5.0060e-02, -9.1124e-02,\n",
       "         -7.0831e-02, -2.2198e-02,  1.9828e-02,  6.3643e-02, -7.5319e-02,\n",
       "          2.2189e-02,  1.0544e-02, -9.4123e-02,  5.2022e-02,  7.2223e-02,\n",
       "          2.8765e-02, -9.0098e-02, -7.3193e-02,  2.3185e-02,  7.0516e-02,\n",
       "         -2.3746e-02, -4.2617e-02, -1.7919e-02,  9.8678e-02,  6.7877e-02,\n",
       "          7.7421e-02, -1.8440e-02,  8.5005e-02, -8.0693e-02, -1.8403e-02,\n",
       "         -3.4524e-02, -9.1246e-02,  1.7109e-02, -9.6608e-02,  5.3629e-02,\n",
       "          1.9765e-02, -8.9226e-02,  6.9817e-02,  1.5969e-02, -7.3826e-02,\n",
       "          5.8003e-02, -5.9896e-02,  1.0440e-02, -5.3661e-02, -2.8234e-02,\n",
       "         -3.2824e-02,  1.6111e-02,  7.4770e-02,  1.9609e-02, -7.8515e-02,\n",
       "         -6.5563e-02,  5.6677e-02, -6.3302e-02, -8.2887e-02, -3.2505e-03],\n",
       "        [ 4.1528e-03, -5.0999e-04,  4.7889e-02,  9.9608e-02,  6.5930e-02,\n",
       "          1.2603e-02, -5.2682e-02, -2.0438e-02, -7.8649e-02, -4.7545e-02,\n",
       "         -3.0186e-02,  2.0846e-02,  4.4954e-03, -4.6991e-02, -7.4986e-02,\n",
       "         -7.7584e-02, -7.6817e-02, -2.6010e-02,  2.5692e-02, -1.9591e-02,\n",
       "          3.9720e-02,  6.6772e-02,  1.1513e-02,  2.2705e-02,  9.9643e-02,\n",
       "         -9.2052e-02, -1.3720e-02,  2.7988e-02,  1.0657e-02,  8.1917e-02,\n",
       "          4.9089e-02,  8.5811e-03, -4.6736e-02,  8.4676e-03, -2.9749e-02,\n",
       "          8.4153e-02,  1.7573e-03,  9.0151e-02,  4.0110e-02, -6.8232e-02,\n",
       "         -3.1649e-02, -7.5894e-02, -8.8491e-02, -7.0608e-02,  8.5739e-02,\n",
       "         -5.7996e-02, -3.1761e-02, -5.9893e-02, -5.4090e-02,  1.9082e-02,\n",
       "          8.2661e-02,  4.4332e-02,  7.3294e-02, -1.2014e-02, -1.3561e-02,\n",
       "          5.5646e-02,  1.2545e-02,  4.3497e-02, -1.0592e-02,  4.2127e-02,\n",
       "          6.8960e-02,  9.3093e-02, -2.7970e-02, -3.3585e-02, -9.4778e-02,\n",
       "          1.4174e-02, -9.4552e-02, -2.1529e-02,  4.7088e-03,  7.3967e-02,\n",
       "         -6.4380e-02, -8.0963e-02,  6.5893e-02, -7.5556e-02,  5.8889e-02,\n",
       "         -7.2845e-02, -7.0367e-02,  5.2844e-02, -2.1209e-02,  8.9995e-02,\n",
       "          8.6740e-02,  5.6064e-02, -7.9534e-02, -3.7765e-03,  2.8179e-03,\n",
       "          4.5681e-02,  7.1234e-02, -9.0122e-02,  8.7984e-02,  5.9727e-02,\n",
       "         -9.6097e-02, -6.0146e-02,  7.2155e-03,  4.1201e-02,  2.2552e-03,\n",
       "         -1.6688e-02, -9.5432e-02, -2.9095e-02,  7.6843e-02,  7.4836e-04],\n",
       "        [-2.5500e-03,  2.3274e-03,  7.3384e-02, -8.0204e-04,  9.0274e-02,\n",
       "         -2.8104e-02, -2.2140e-02, -7.7364e-02,  4.8680e-02, -4.5889e-02,\n",
       "         -6.6111e-02,  2.8005e-02,  3.9746e-02,  4.9738e-02, -5.2060e-02,\n",
       "         -1.7594e-02,  1.7409e-02, -1.6960e-02, -3.0478e-02, -1.0121e-03,\n",
       "          7.3673e-02, -9.2437e-02,  9.2866e-02, -8.5163e-02,  6.5988e-02,\n",
       "          4.0207e-03,  2.5145e-02, -1.8225e-02, -6.3483e-02,  1.9956e-03,\n",
       "          9.5636e-02, -5.2204e-02, -8.4442e-02,  2.4041e-02, -7.0409e-02,\n",
       "          8.9973e-02, -4.2703e-02,  1.0772e-02,  9.9668e-03,  4.8437e-02,\n",
       "          3.4002e-02, -2.1566e-02, -3.8276e-02, -1.1650e-02, -7.5659e-03,\n",
       "          3.6031e-02, -4.4493e-03, -4.5334e-02, -1.5439e-02,  3.6833e-02,\n",
       "         -8.1999e-02,  4.0632e-02,  9.2213e-02,  1.9470e-02, -5.7503e-02,\n",
       "          2.5290e-02,  6.7209e-02, -4.3417e-02,  1.8483e-02,  8.7581e-02,\n",
       "          8.6944e-02,  1.2402e-02,  9.0743e-02, -1.3202e-02,  2.4537e-02,\n",
       "         -7.0989e-02,  2.0723e-02, -1.5906e-02, -2.3716e-02, -2.9661e-02,\n",
       "         -1.2390e-02,  1.4766e-02, -2.5465e-04, -9.7442e-02, -7.2802e-03,\n",
       "          4.5010e-02,  1.1450e-02,  4.4475e-04, -2.0048e-03, -5.9728e-02,\n",
       "         -6.9177e-02, -4.5585e-02, -5.9017e-02,  5.9935e-02, -2.1287e-02,\n",
       "         -3.8905e-02,  4.1414e-02,  8.6765e-03, -1.0193e-02,  2.8438e-02,\n",
       "          5.8956e-02,  7.1921e-02, -4.0519e-03,  1.9134e-02,  1.6889e-02,\n",
       "          6.3170e-02, -9.0465e-02,  9.2459e-02,  6.2682e-02,  1.4407e-02],\n",
       "        [-6.4671e-02, -1.9622e-02, -4.1884e-02,  7.2848e-02, -1.3087e-03,\n",
       "          9.2978e-03, -6.2640e-02, -9.5693e-04, -9.7351e-02,  6.4995e-02,\n",
       "         -2.8299e-02,  3.8229e-02, -6.4734e-02, -4.4667e-02, -8.2343e-02,\n",
       "         -2.6142e-02,  5.5340e-02, -7.9140e-02,  9.3099e-02, -4.4264e-02,\n",
       "         -3.9927e-03,  8.9598e-03,  3.1641e-02,  3.8755e-02, -5.4770e-02,\n",
       "          7.3218e-02,  6.9969e-02,  3.5092e-02,  5.9126e-02, -7.3393e-02,\n",
       "          2.7073e-02,  9.8398e-02,  3.0389e-02,  5.2298e-02, -8.8168e-02,\n",
       "         -8.3517e-02, -4.9683e-02,  4.2034e-02, -6.5246e-02,  5.4208e-02,\n",
       "         -8.9553e-02,  5.9553e-02, -6.9454e-02, -2.4570e-02,  4.2015e-02,\n",
       "          1.2895e-03,  6.6123e-02, -1.7651e-02,  7.8748e-02, -7.9327e-02,\n",
       "          1.4061e-02, -7.4886e-02, -4.7078e-02,  4.5722e-02, -7.0716e-02,\n",
       "         -9.4505e-02,  5.1904e-02,  4.5253e-03, -8.1925e-04,  4.9587e-03,\n",
       "          5.3629e-02, -7.3109e-02, -8.5068e-02,  5.4536e-02,  8.1014e-02,\n",
       "          5.5725e-02, -9.4109e-02, -2.8140e-02,  5.1159e-02, -5.8746e-02,\n",
       "         -9.3726e-02,  3.1368e-02, -7.3942e-02,  9.0758e-02, -3.2881e-02,\n",
       "          6.4243e-02,  7.6023e-03,  1.8202e-02, -6.2037e-02,  1.1409e-02,\n",
       "         -5.3912e-02, -3.8634e-02,  5.1748e-02, -3.9598e-02, -5.0872e-02,\n",
       "         -8.2941e-02,  8.8752e-02,  1.6624e-02,  3.8859e-03,  4.2001e-02,\n",
       "         -5.5109e-02,  8.7460e-02, -4.2381e-02, -9.9180e-02, -8.6241e-02,\n",
       "         -8.9850e-02,  4.4762e-02,  4.5963e-02,  8.2411e-02,  9.2800e-03],\n",
       "        [ 4.3601e-02, -3.4494e-02, -5.7787e-02, -1.4136e-02, -4.3939e-02,\n",
       "          3.2256e-02, -7.5373e-02,  9.1316e-02, -3.7707e-03, -5.5445e-02,\n",
       "         -6.6390e-02,  4.1525e-02, -3.4794e-02,  6.8138e-02,  4.7879e-03,\n",
       "          5.9857e-02, -7.1180e-02,  6.7177e-02, -8.3874e-02,  7.0709e-02,\n",
       "         -4.9262e-02,  7.5635e-02,  9.9538e-02,  1.5865e-02, -1.8727e-02,\n",
       "         -9.3624e-02, -8.5000e-02, -9.2178e-03,  2.8803e-02,  9.3594e-02,\n",
       "          2.0650e-02,  8.9347e-02,  6.6293e-02, -9.7868e-02,  2.3316e-02,\n",
       "          1.6505e-02,  8.9273e-02,  8.2533e-02, -7.8808e-02,  5.2512e-02,\n",
       "          3.3913e-02, -8.1112e-02,  2.2472e-02, -1.7950e-02,  2.6129e-02,\n",
       "          8.4983e-02, -5.4338e-02, -4.3629e-02,  7.6526e-02,  3.9182e-02,\n",
       "         -9.3896e-02, -8.3411e-02,  1.1320e-02, -6.2531e-02, -6.2071e-02,\n",
       "         -2.9819e-02,  3.9089e-02, -6.1120e-02,  2.3641e-02,  9.9605e-02,\n",
       "          3.4316e-02,  6.3897e-02, -7.1780e-03,  4.9769e-03, -1.4503e-02,\n",
       "          7.0034e-02, -8.1194e-02, -7.0706e-03,  6.6244e-02,  2.1536e-02,\n",
       "         -1.5054e-02, -1.4042e-02,  3.8608e-02,  9.1832e-03,  8.1986e-03,\n",
       "          1.1235e-02,  5.3728e-02, -6.8584e-02,  5.6557e-02, -5.7709e-02,\n",
       "          9.3063e-03,  7.9759e-02, -4.1170e-02, -4.1482e-02, -8.5165e-02,\n",
       "          7.9161e-02, -9.2639e-02, -5.4367e-02, -2.8281e-02, -2.1363e-02,\n",
       "          9.3371e-02,  1.7236e-02, -1.1385e-02, -6.1794e-02,  4.2132e-02,\n",
       "         -5.7499e-02, -1.7752e-02,  6.1594e-02,  9.0768e-02, -3.5583e-02],\n",
       "        [-8.0562e-02,  5.2788e-02, -5.9207e-02,  5.2153e-02, -4.9190e-02,\n",
       "         -1.2815e-02,  9.7013e-02, -7.4623e-02, -6.2269e-02, -5.4922e-02,\n",
       "          1.5724e-02, -3.4340e-02,  7.7623e-02, -4.8620e-02,  2.4162e-02,\n",
       "         -2.5834e-02,  7.6896e-02, -4.0405e-02,  1.3451e-03, -8.1941e-02,\n",
       "         -4.3111e-02, -4.5878e-02,  1.5949e-02, -7.5751e-02, -9.5916e-02,\n",
       "         -8.5443e-02, -2.0578e-02,  8.0032e-02, -9.4383e-02, -8.0177e-03,\n",
       "          8.0198e-02,  7.5688e-02, -8.2508e-02,  2.5497e-02, -4.0375e-02,\n",
       "          1.7961e-02, -3.2565e-03,  2.8614e-02, -8.0333e-02,  9.3072e-02,\n",
       "         -5.8048e-02, -2.4315e-02, -2.7922e-02,  8.7350e-02, -7.9492e-02,\n",
       "          9.4581e-02,  2.2760e-02,  1.3166e-02, -8.3920e-02, -6.2117e-02,\n",
       "          4.9298e-02,  8.8655e-02,  6.3035e-02, -5.6876e-02, -6.4902e-03,\n",
       "         -2.5933e-02,  2.4289e-02, -7.7747e-02,  2.9593e-02,  1.2707e-02,\n",
       "         -6.5622e-02, -2.0439e-02, -6.9101e-02, -2.3490e-02, -7.8613e-02,\n",
       "         -3.9565e-02, -8.5401e-02,  5.5246e-02,  2.4987e-02, -4.7975e-02,\n",
       "          8.8521e-02,  3.0851e-02,  1.4754e-03,  3.0287e-02,  5.7004e-02,\n",
       "         -1.2508e-02, -3.6943e-02,  2.5958e-02, -5.0604e-02, -3.8234e-02,\n",
       "          6.3907e-02, -1.6487e-02,  1.4253e-02,  5.3643e-02, -2.3923e-02,\n",
       "         -8.9125e-02, -3.7334e-03,  7.1785e-02, -6.4289e-02, -7.1369e-03,\n",
       "         -6.3484e-02,  3.2469e-02, -9.9547e-03, -5.3241e-02,  1.8564e-02,\n",
       "          2.5148e-02,  9.8486e-03,  3.2055e-02, -8.9040e-02,  1.4824e-02],\n",
       "        [ 5.9026e-02, -5.0621e-02, -3.2696e-02,  4.4960e-02,  1.6684e-02,\n",
       "          1.4792e-03,  1.8295e-02,  2.6417e-02,  2.1001e-02, -4.8455e-02,\n",
       "         -9.6928e-02,  2.9257e-02, -9.3454e-02,  7.3738e-02,  3.0534e-02,\n",
       "          6.5924e-02,  2.3422e-02, -8.6882e-02, -4.0743e-02, -2.6556e-02,\n",
       "         -1.3885e-02,  7.7824e-02,  4.6027e-02,  3.2260e-02, -1.7540e-02,\n",
       "          7.3648e-03,  4.5031e-02, -2.8448e-02, -7.2320e-03,  5.1744e-02,\n",
       "          6.9604e-02,  8.1851e-02,  2.7918e-03, -9.8251e-02, -1.2639e-02,\n",
       "          5.3265e-02, -4.2813e-02, -6.8331e-02,  1.5010e-02, -5.8569e-02,\n",
       "         -2.2219e-02, -2.4114e-02, -1.4530e-02, -1.7364e-02, -9.1941e-03,\n",
       "         -1.0603e-02,  7.4305e-02, -1.5893e-02, -2.0449e-02, -3.5320e-02,\n",
       "          4.0753e-02, -2.1353e-03, -4.6640e-02, -6.6990e-02, -7.0215e-02,\n",
       "          6.6001e-02,  2.1142e-02, -7.5543e-02,  4.6400e-02, -2.4217e-02,\n",
       "          5.0202e-02, -6.1302e-02, -1.2170e-02,  7.8400e-02, -3.4096e-02,\n",
       "          9.8906e-02,  4.9788e-02, -1.3564e-02, -4.4159e-02, -5.6083e-02,\n",
       "         -5.0064e-02,  2.6566e-03, -8.5770e-04,  4.5537e-02, -7.7143e-02,\n",
       "          3.1669e-02,  3.7224e-03, -3.7081e-03, -2.5075e-02,  7.3677e-02,\n",
       "         -8.5969e-02, -4.6309e-02,  2.2035e-02, -8.6429e-02, -2.9284e-02,\n",
       "         -1.5355e-02, -8.6934e-02, -5.5548e-02,  5.5799e-02,  8.2205e-02,\n",
       "         -2.9939e-02, -1.2084e-02, -7.4241e-02, -8.6183e-02, -4.3200e-03,\n",
       "         -7.6398e-02, -9.6096e-02,  7.1425e-02,  8.2157e-02,  9.5446e-02],\n",
       "        [-8.9403e-02,  4.0506e-02,  1.3439e-02,  9.0280e-02, -2.7822e-02,\n",
       "          9.7970e-02,  1.4020e-02,  7.7287e-02,  7.3067e-02, -5.8740e-02,\n",
       "         -8.4600e-02,  3.3242e-02, -4.2847e-03,  1.3826e-02,  2.3941e-02,\n",
       "         -5.4344e-02,  6.4043e-02,  9.7476e-02, -4.2760e-02,  3.4561e-02,\n",
       "         -6.3089e-02, -6.8214e-02,  8.4022e-02, -5.2991e-02,  9.0282e-02,\n",
       "          6.2587e-02,  4.0697e-02, -4.4998e-02, -2.9477e-02,  2.4943e-02,\n",
       "         -3.9199e-02,  6.5424e-05, -4.2814e-02,  8.2109e-03, -5.4878e-02,\n",
       "         -2.8676e-02, -8.9987e-02,  2.8043e-02,  2.9140e-02,  2.2242e-02,\n",
       "          6.9026e-02,  9.6716e-02, -6.1381e-02,  8.5053e-02,  6.4341e-03,\n",
       "         -3.6801e-02, -5.1950e-02,  5.4700e-02,  2.7304e-02, -2.5956e-02,\n",
       "          9.7227e-02, -4.3543e-02,  8.4096e-02, -3.2012e-02, -9.6544e-02,\n",
       "         -3.6465e-02, -2.7663e-03, -8.8177e-02, -3.8632e-02,  3.0295e-02,\n",
       "          8.5585e-02, -9.6268e-02, -7.9988e-02, -3.9222e-02,  2.1567e-02,\n",
       "         -9.7983e-02,  5.5646e-02,  4.8819e-02, -3.9640e-03, -3.4109e-02,\n",
       "         -2.5943e-02, -1.0594e-02, -9.9471e-03, -2.8234e-02, -7.4283e-02,\n",
       "          3.9268e-02,  7.9887e-02,  8.7643e-02,  9.5134e-02, -1.0928e-02,\n",
       "         -3.4155e-02, -9.3886e-02, -9.1365e-03, -4.5802e-02, -1.0208e-02,\n",
       "          5.4826e-02,  8.7284e-02, -2.2323e-02, -7.2347e-02,  1.7180e-02,\n",
       "         -7.2511e-02, -8.3457e-02, -8.6285e-03, -5.8778e-02,  7.2705e-02,\n",
       "          9.1806e-02, -5.2112e-02, -3.5617e-03,  5.7661e-03, -4.0118e-02],\n",
       "        [-4.3570e-03,  2.4893e-02,  6.8747e-02, -9.3909e-02, -3.2646e-02,\n",
       "          2.3233e-02,  6.4983e-02, -3.1407e-02,  7.2274e-02, -6.7775e-02,\n",
       "          7.8958e-02,  6.7058e-02,  2.3296e-02,  1.7273e-02,  9.6637e-02,\n",
       "          7.2483e-02, -3.2463e-04,  9.3890e-02,  2.9703e-02, -5.6024e-02,\n",
       "         -3.4558e-02, -7.6397e-02,  9.7206e-02,  6.5830e-03, -5.1011e-03,\n",
       "         -6.4176e-02,  6.3541e-02,  9.9010e-02, -5.7466e-02, -5.5288e-02,\n",
       "         -8.9334e-03, -5.0751e-02, -7.8354e-02, -2.8980e-02, -8.9608e-02,\n",
       "          5.4440e-02,  9.0201e-03, -3.9748e-02,  1.6316e-02, -8.5962e-02,\n",
       "          1.1889e-02, -7.1450e-02,  1.8487e-04,  6.5266e-02,  6.5553e-02,\n",
       "          7.5997e-02, -7.8502e-02,  9.1629e-03,  5.9026e-02, -5.7573e-02,\n",
       "         -8.0473e-02, -4.3077e-02,  8.0421e-02,  1.1084e-02,  6.4332e-03,\n",
       "         -1.4917e-02, -5.4373e-03, -9.5556e-02,  3.9003e-02, -3.5526e-02,\n",
       "         -9.4698e-02,  5.3025e-02, -2.4968e-02,  4.5203e-02, -1.0653e-03,\n",
       "         -7.1493e-03, -8.6810e-02,  9.0136e-02,  8.1275e-02,  8.8943e-03,\n",
       "         -3.3584e-02,  9.8136e-02, -1.9258e-02,  2.1157e-03,  7.9153e-02,\n",
       "         -9.0267e-02,  3.4507e-03, -4.7046e-02,  9.6603e-02,  7.0081e-02,\n",
       "         -7.6956e-02, -4.2076e-03,  4.3450e-02,  4.6727e-02, -7.8136e-02,\n",
       "          8.0338e-03, -7.4346e-03, -2.9151e-02,  8.6913e-02,  8.0780e-02,\n",
       "         -8.7140e-04,  3.7287e-02,  4.9385e-02,  3.3062e-02,  7.4214e-02,\n",
       "         -7.3472e-03,  3.5766e-02,  5.9207e-02, -8.3441e-02,  6.7270e-02],\n",
       "        [ 9.4200e-02,  6.8145e-02,  6.2540e-02, -3.1562e-02,  9.6986e-02,\n",
       "         -3.1815e-02,  5.9731e-02, -4.9975e-03, -5.5222e-02, -3.3059e-02,\n",
       "         -5.4803e-02,  6.9262e-02,  8.9559e-03, -2.4500e-02,  1.4373e-04,\n",
       "          2.7972e-02, -2.7735e-02,  1.4423e-02, -3.3158e-02, -3.8355e-02,\n",
       "         -7.4027e-02, -3.2170e-02, -5.9092e-02,  5.0811e-02, -9.2681e-02,\n",
       "          6.3145e-02, -3.1374e-03,  3.3152e-02,  7.9955e-03, -8.5179e-03,\n",
       "          8.6924e-02,  5.1679e-02,  7.5106e-03,  9.4907e-02,  1.4119e-02,\n",
       "         -9.9382e-02,  6.9623e-03, -1.8123e-03, -1.5565e-02, -9.4022e-02,\n",
       "          7.6084e-02,  9.2810e-02, -2.9924e-02,  4.5483e-04, -5.4411e-02,\n",
       "          7.4701e-02,  7.7844e-02,  8.0866e-02, -9.6821e-02, -9.6581e-02,\n",
       "         -8.6109e-02, -6.0333e-02, -6.3632e-02, -9.0926e-02, -4.0633e-02,\n",
       "          1.1208e-02,  9.1663e-02,  5.4924e-02, -5.5600e-02,  9.7539e-02,\n",
       "          1.2901e-02,  5.7531e-02,  6.5117e-02,  9.1056e-02,  8.3216e-02,\n",
       "         -1.6184e-02,  8.8581e-02,  3.3894e-02, -4.4587e-02,  6.4554e-02,\n",
       "         -9.7076e-03, -7.7806e-03,  8.5596e-02, -9.9204e-02,  6.9508e-02,\n",
       "          2.2285e-02,  7.1212e-03, -4.4236e-02, -3.3658e-02, -8.4797e-02,\n",
       "         -4.0756e-03,  5.8306e-02, -5.8387e-02,  8.6262e-02, -8.2355e-02,\n",
       "          8.5821e-02,  3.1430e-03,  9.5859e-02,  9.9203e-02,  7.2328e-02,\n",
       "          8.0080e-02,  5.8242e-02,  2.0763e-02, -6.8113e-02, -4.8255e-02,\n",
       "         -8.3045e-02, -7.4706e-02,  9.1431e-02, -9.7327e-02, -8.4262e-02]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_init.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(117600, device='cuda:1')\n",
      "tensor(117600, device='cuda:1')\n",
      "tensor(15000, device='cuda:1')\n",
      "tensor(15000, device='cuda:1')\n",
      "tensor(500, device='cuda:1')\n",
      "tensor(500, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(((model.fc1.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print(((model.fc1.weight == 0).sum(dim=1)).sum(dim=0))\n",
    "\n",
    "print(((model.fc2.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print(((model.fc2.weight == 0).sum(dim=1)).sum(dim=0))\n",
    "\n",
    "print(((model.fc3.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print(((model.fc3.weight == 0).sum(dim=1)).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    if 'weight_orig' in name:\n",
    "        for name2, p2 in model_init.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.remove(module, name='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruning mask 생성 -> init값 복사 -> prune 진행\n",
    "# mask 생성\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.5)\n",
    "\n",
    "# init 값 복사\n",
    "for name, p in model.named_parameters():\n",
    "    if 'weight_orig' in name:\n",
    "        for name2, p2 in model_init.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break\n",
    "#prune 진행\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.remove(module, name='weight')\n",
    "\n",
    "\n",
    "\n",
    "    # prune 진행\n",
    "    #prune.remove(model1.fc1, \"weight\")\n",
    "    #prune.remove(model1.fc1, \"bias\")\n",
    "    #prune.remove(model1.fc2, \"weight\")\n",
    "    #prune.remove(model1.fc2, \"bias\")\n",
    "    #prune.remove(model1.fc3, \"weight\")\n",
    "    #prune.remove(model1.fc3, \"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.remove(module, name='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)\n",
    "\n",
    "for name, p in model.named_parameters():\n",
    "    if 'weight_orig' in name:\n",
    "        print(name[0:len(name)-5])\n",
    "        print(model.name[0:len(name)-5])\n",
    "        #prune.l1_unstructured(model.fc1, name='weight', amount=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((model.fc1.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print(((model.fc1.weight == 0).sum(dim=1)).sum(dim=0))\n",
    "\n",
    "print(((model.fc2.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print(((model.fc2.weight == 0).sum(dim=1)).sum(dim=0))\n",
    "\n",
    "print(((model.fc3.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print(((model.fc3.weight == 0).sum(dim=1)).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.l1_unstructured(model.fc1, name='weight', amount=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_init.fc3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.parameters(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    \n",
    "    if 'weight_orig' in name:\n",
    "        print(model.parameters('fc3.weight'))\n",
    "        #print(module._parameters[self.name])\n",
    "        #module._parameters[self._tensor_name + \"_orig\"]\n",
    "        #print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_init.fc3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"asd1234_135\"\n",
    "b = \"asd1234\"\n",
    "print(len(a)-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if a[0:len(a)-4] == b:\n",
    "    print('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fc3.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((model.fc3.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print(((model.fc3.weight == 0).sum(dim=1)).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = 1.2e-3)\n",
    "pruned_percent = 80\n",
    "print(\"Learning start!\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    if epoch == 0:\n",
    "        accuracy = test(model, test_loader, criterion)\n",
    "        visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([epoch]), str(pruned_percent))\n",
    "    \n",
    "    running_loss = train(model, train_loader, optimizer, criterion, 1)\n",
    "    accuracy = test(model, test_loader, criterion)\n",
    "    visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([((epoch+1)) * 1000]), str(pruned_percent))\n",
    "\n",
    "\n",
    "    print('[epoch : %d]' % (epoch+1),\n",
    "         '(loss: %.5f)' % (running_loss),\n",
    "         '(accu: %.4f)' % (accuracy)\n",
    "         )\n",
    "print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_init(model, model_init, 0.5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc3.weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((model.fc3.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print(((model.fc3.weight == 0).sum(dim=1)).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('남은 weight %d' % ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0))\n",
    "print('제거된 weight %d' % ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "b = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a, b)\n",
    "print (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = 1.2e-3)\n",
    "pruned_percent = 50\n",
    "print(\"Learning start!\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    if epoch == 0:\n",
    "        accuracy = test(model, test_loader, criterion)\n",
    "        visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([epoch]), str(pruned_percent))\n",
    "    \n",
    "    running_loss = train(model, train_loader, optimizer, criterion, 1)\n",
    "    accuracy = test(model, test_loader, criterion)\n",
    "    visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([((epoch+1)) * 1000]), str(pruned_percent))\n",
    "\n",
    "\n",
    "    print('[epoch : %d]' % (epoch+1),\n",
    "         '(loss: %.5f)' % (running_loss),\n",
    "         '(accu: %.4f)' % (accuracy)\n",
    "         )\n",
    "print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight)\n",
    "model_test = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_init.fc3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.l1_unstructured(model.fc1, name='weight', amount=0.5)\n",
    "    #prune.l1_unstructured(model1.fc1, name='bias', amount=rate)\n",
    "prune.l1_unstructured(model.fc2, name='weight', amount=0.5)\n",
    "    #prune.l1_unstructured(model1.fc2, name='bias', amount=rate)\n",
    "prune.l1_unstructured(model.fc3, name='weight', amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc3.weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_test.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc3.weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    #print(name, name)\n",
    "    if 'weight_orig' in name:\n",
    "        print(name)\n",
    "            for name2, p2 in model_init.named_parameters():\n",
    "                if 'weight' in name2:\n",
    "                    p = copy.deepcopy(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    EPS = 1e-6\n",
    "    if 'weight' in name:\n",
    "        tensor = p.data.cpu().numpy()\n",
    "        grad_tensor = p.grad.data.cpu().numpy()\n",
    "        grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "        p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        print(p.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n",
      "[4, 4]\n",
      "[4, 4, 4]\n",
      "[4, 4, 4, 4]\n",
      "[4, 4, 4, 4, 4]\n",
      "[4, 4, 4, 4, 4, 4]\n",
      "[4, 4, 4, 4, 4, 4, 4]\n",
      "[4, 4, 4, 4, 4, 4, 4, 4]\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "best_accu = []\n",
    "for i in range(10):\n",
    "    best_accu.append(0)\n",
    "    for j in range(5):\n",
    "        if best_accu[i] <= j:\n",
    "            best_accu[i] = j\n",
    "    print(best_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 숫자 60000\n",
    "배치 길이 60\n",
    "배치 개수 1000\n",
    "epoch = 50\n",
    "\n",
    "이터레이션 횟수 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5874010519681994\n"
     ]
    }
   ],
   "source": [
    "a = 4\n",
    "print(a**(1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4096000000000001\n",
      "100.0\n",
      "80.0\n",
      "64.00000000000001\n",
      "51.20000000000001\n",
      "40.96000000000001\n",
      "32.76800000000001\n",
      "26.21440000000001\n",
      "20.97152000000001\n",
      "16.77721600000001\n",
      "13.421772800000006\n",
      "10.737418240000006\n",
      "8.589934592000006\n",
      "6.871947673600004\n",
      "5.497558138880003\n",
      "4.3980465111040035\n",
      "3.518437208883203\n",
      "2.814749767106562\n",
      "2.2517998136852504\n",
      "1.8014398509482004\n",
      "1.4411518807585602\n"
     ]
    }
   ],
   "source": [
    "print(0.8**4)\n",
    "i = 1\n",
    "for i in range(20):\n",
    "    print((0.8**i)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0\n",
      "8.94427190999916\n",
      "4.308869380063767\n",
      "2.990697562442441\n",
      "2.4022488679628626\n",
      "2.075781631112427\n",
      "1.8701222535385968\n",
      "1.7293633402042616\n",
      "1.6272506099369242\n"
     ]
    }
   ],
   "source": [
    "aaa = 100\n",
    "a = 80\n",
    "b = 0\n",
    "i = 1\n",
    "for i in range(1,10):\n",
    "    print(a**(1/i))\n",
    "    #b += a**(1/i)\n",
    "    #print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "print(math.sqrt(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72192\n",
      "45.58234307272938\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(math.sqrt((600000-(256*256)-(2560))/256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2287872 453888 294912 657920\n",
      "1038438.599168\n",
      "1769472\n"
     ]
    }
   ],
   "source": [
    "\"\"\"a\n",
    "input conv1\n",
    "conv1 conv2\"\"\"\n",
    "\n",
    "a = (\n",
    "32 * 32 * 9 * 3 * 64 *2\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"b\n",
    "maxpool conv3\n",
    "conv3 conv4\"\"\"\n",
    "\n",
    "b = (\n",
    "16 * 16 * 9 * 128\n",
    "    +\n",
    "12 * 16 * 9 * 128\n",
    ")\n",
    "\n",
    "\"\"\"c\n",
    "maxpool conv5\n",
    "conv5 conv6\"\"\"\n",
    "\n",
    "c = (\n",
    "6 * 6 * 9 * 256\n",
    "    +\n",
    "6 * 6 * 9 * 256\n",
    ")\n",
    "\n",
    "\"\"\"d\n",
    "maxpool fc1\n",
    "fc1 fc2\n",
    "fc2 fc3\"\"\"\n",
    "\n",
    "d = (\n",
    "3 * 3 * 256 * 256\n",
    "    +\n",
    "256 * 256\n",
    "    +\n",
    "256 * 10\n",
    ")\n",
    "\n",
    "print(a, b, c, d)\n",
    "print((a * b + c + d)/1000000)\n",
    "\n",
    "print(32 * 32 * 9 * 3 * 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262602\n",
      "266610\n",
      "266610\n"
     ]
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "aaa = get_n_params(model)\n",
    "print(aaa)\n",
    "model2 = cm.LeNet300().to(device)\n",
    "bbb = get_n_params(model2)\n",
    "print(bbb)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "ccc = count_parameters(model2)\n",
    "print(ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cm.LeNet300().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266610\n"
     ]
    }
   ],
   "source": [
    "ccc = count_parameters(model)\n",
    "print(ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(266200, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a1 = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "a2 = ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "a3 = ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "#b = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "b1 = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "b2 = ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "b3 = ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "a = a1 + a2 + a3\n",
    "b = b1 + b2 + b3\n",
    "now = (a + b)\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(235200, device='cuda:1') tensor(30000, device='cuda:1') tensor(1000, device='cuda:1')\n",
      "tensor(266200, device='cuda:1')\n",
      "tensor(50.0939, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(a1, a2, a3)\n",
    "print(a1+a2+a3)\n",
    "c = a1*0.5 + a2*0.5 + a3*0.25\n",
    "print((1-c/a) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 32 x 32\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266200\n"
     ]
    }
   ],
   "source": [
    "print(28*28*300 + 300*100 + 1000\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cm.Conv6().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv6(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=16, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0455, -0.0406, -0.0592,  ...,  0.0585, -0.0041, -0.0250],\n",
       "        [-0.0024, -0.0130, -0.0269,  ...,  0.0070, -0.0051,  0.0027],\n",
       "        [-0.0575, -0.0074, -0.0327,  ..., -0.0477, -0.0497, -0.0344],\n",
       "        ...,\n",
       "        [ 0.0163,  0.0377,  0.0065,  ..., -0.0129,  0.0354, -0.0239],\n",
       "        [-0.0486,  0.0486,  0.0557,  ..., -0.0125, -0.0036,  0.0047],\n",
       "        [-0.0559,  0.0169,  0.0586,  ...,  0.0439,  0.0203, -0.0097]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.1486, -0.0442, -0.0365],\n",
       "          [-0.0562, -0.0325,  0.0443],\n",
       "          [ 0.1403, -0.0946,  0.0781]],\n",
       "\n",
       "         [[-0.1103, -0.0503,  0.0996],\n",
       "          [ 0.1142, -0.0693, -0.0993],\n",
       "          [ 0.1661, -0.0026,  0.0063]],\n",
       "\n",
       "         [[-0.0869,  0.1282,  0.0807],\n",
       "          [ 0.1125,  0.1241, -0.0864],\n",
       "          [-0.0099,  0.1881, -0.1751]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1741,  0.0773, -0.0903],\n",
       "          [-0.1281,  0.0681, -0.0430],\n",
       "          [-0.1694,  0.0712, -0.1070]],\n",
       "\n",
       "         [[-0.0287, -0.1786,  0.1704],\n",
       "          [ 0.1334,  0.1260,  0.0487],\n",
       "          [-0.0669, -0.0455, -0.1257]],\n",
       "\n",
       "         [[ 0.1815,  0.0757,  0.1919],\n",
       "          [-0.0916, -0.0176, -0.1097],\n",
       "          [ 0.0836,  0.1768,  0.1537]]],\n",
       "\n",
       "\n",
       "        [[[-0.0297, -0.1147, -0.0710],\n",
       "          [ 0.1633, -0.0419, -0.1316],\n",
       "          [ 0.1886,  0.0357, -0.0097]],\n",
       "\n",
       "         [[-0.0446,  0.1223, -0.1393],\n",
       "          [ 0.0510,  0.0159,  0.1564],\n",
       "          [ 0.1476,  0.0074, -0.1458]],\n",
       "\n",
       "         [[-0.1112, -0.0586,  0.0589],\n",
       "          [-0.1183,  0.0145,  0.1848],\n",
       "          [-0.0397, -0.1491, -0.1473]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.1474,  0.1342, -0.0632],\n",
       "          [ 0.0607, -0.1818, -0.0530],\n",
       "          [-0.1006, -0.0991,  0.0171]],\n",
       "\n",
       "         [[ 0.0057, -0.0159, -0.1851],\n",
       "          [-0.1491, -0.0294, -0.1216],\n",
       "          [ 0.0464, -0.0956,  0.1076]],\n",
       "\n",
       "         [[-0.1131,  0.1765,  0.0014],\n",
       "          [-0.0088,  0.1806, -0.1123],\n",
       "          [ 0.0304, -0.1192,  0.0631]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0376,  0.1004, -0.1843],\n",
       "          [ 0.1708,  0.1380,  0.0270],\n",
       "          [ 0.0698,  0.0054, -0.0117]],\n",
       "\n",
       "         [[ 0.1632,  0.1469,  0.1508],\n",
       "          [-0.0622,  0.1526,  0.1268],\n",
       "          [ 0.1568, -0.1513, -0.0163]],\n",
       "\n",
       "         [[-0.0116,  0.0609, -0.0096],\n",
       "          [ 0.0950,  0.0675, -0.0257],\n",
       "          [ 0.0381, -0.1840,  0.1374]]],\n",
       "\n",
       "\n",
       "        [[[-0.1645,  0.0834,  0.0064],\n",
       "          [-0.0003,  0.0497, -0.1094],\n",
       "          [-0.0682, -0.1094, -0.1235]],\n",
       "\n",
       "         [[ 0.0299, -0.1476,  0.0411],\n",
       "          [-0.0581,  0.0685, -0.0826],\n",
       "          [ 0.1652,  0.0584,  0.1366]],\n",
       "\n",
       "         [[-0.0960, -0.0940,  0.1089],\n",
       "          [-0.0820, -0.0159, -0.0933],\n",
       "          [-0.0690, -0.1920, -0.0318]]]], device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv.0.weight', 'conv.0.bias', 'conv.2.weight', 'conv.2.bias', 'conv.5.weight', 'conv.5.bias', 'conv.7.weight', 'conv.7.bias', 'conv.10.weight', 'conv.10.bias', 'conv.12.weight', 'conv.12.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['fc1.bias', 'fc1.weight_orig', 'fc1.weight_mask', 'fc2.bias', 'fc2.weight_orig', 'fc2.weight_mask', 'fc3.bias', 'fc3.weight_orig', 'fc3.weight_mask'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = cm.LeNet300().to(device)\n",
    "model2 = cm.LeNet300().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(model1, model2, rate):\n",
    "    # prune mask 생성\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.l1_unstructured(module, name = 'weight', amount = rate)\n",
    "\n",
    "    # init 값 복사\n",
    "    \n",
    "    cp_mask = []\n",
    "    for name, p in model1.named_parameters():\n",
    "        if 'weight_orig' in name:\n",
    "            for name2, p2 in model2.named_parameters():\n",
    "                if name[0:len(name) - 5] in name2:\n",
    "                    p.data = copy.deepcopy(p2.data)\n",
    "                    break\n",
    "        if 'bias_orig' in name:\n",
    "            for name2, p2 in model2.named_parameters():\n",
    "                if name[0:len(name) - 5] in name2:\n",
    "                    p.data = copy.deepcopy(p2.data)\n",
    "                    break\n",
    "        if '_mask' in name:\n",
    "            cp_mask.append(p.data)\n",
    "    # mask copy\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # prune 진행\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.remove(module, name = 'weight')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=100, out_features=10, bias=True)\n",
      "Linear(in_features=100, out_features=10, bias=True)\n",
      "fc1\n",
      "Linear(in_features=100, out_features=10, bias=True)\n",
      "fc2\n",
      "Linear(in_features=100, out_features=10, bias=True)\n",
      "fc3\n"
     ]
    }
   ],
   "source": [
    "for name, module in model1.named_modules():\n",
    "    print(model)\n",
    "    if isinstance(module, nn.Linear):\n",
    "        print(name)\n",
    "        prune.l1_unstructured(module, name = 'weight', amount = 0.5)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.bias\n",
      "fc1.weight_orig\n",
      "fc2.bias\n",
      "fc2.weight_orig\n",
      "fc3.bias\n",
      "fc3.weight_orig\n"
     ]
    }
   ],
   "source": [
    "cp_mask = []\n",
    "for name, p in model1.named_parameters():\n",
    "    print(name)\n",
    "    if 'weight_orig' in name:\n",
    "        for name2, p2 in model2.named_parameters():\n",
    "             if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break\n",
    "    if 'bias_orig' in name:\n",
    "        for name2, p2 in model2.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break\n",
    "    if '_mask' in name:\n",
    "        cp_mask.append(p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(cp_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-0d977d8b3ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for name, p in model1.parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[1., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 0., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [0., 1., 1.,  ..., 1., 0., 0.]], device='cuda:1'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(model1.fc1.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [1., 1., 0.,  ..., 1., 0., 1.],\n",
       "        [1., 1., 0.,  ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 1.,  ..., 1., 1., 0.],\n",
       "        [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "        [0., 1., 1.,  ..., 1., 0., 0.]], device='cuda:1')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fc1.weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight_mask\n",
      "fc2.weight_mask\n",
      "fc3.weight_mask\n"
     ]
    }
   ],
   "source": [
    "for name, module in model1.named_buffers():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_mask = []\n",
    "\n",
    "for name, mask in model1.named_buffers():\n",
    "    cp_mask.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 1., 0.,  ..., 1., 0., 1.],\n",
       "         [1., 1., 0.,  ..., 1., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 1.,  ..., 1., 1., 0.],\n",
       "         [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 1., 1.,  ..., 1., 0., 0.]], device='cuda:1'),\n",
       " tensor([[0., 1., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         [1., 0., 0.,  ..., 1., 1., 0.],\n",
       "         [1., 0., 1.,  ..., 0., 1., 0.]], device='cuda:1'),\n",
       " tensor([[1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
       "         [1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "          1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 1., 0., 1., 1.],\n",
       "         [0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "          1., 0., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "         [0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "          1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "          1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "          0., 0., 0., 1., 1., 0., 0., 0., 1., 1.],\n",
       "         [1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "          1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
       "         [1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "          0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "          1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 0., 1., 1., 1.],\n",
       "         [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "          1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "          1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 1., 1., 1.]], device='cuda:1')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model1.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.remove(module, name = 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 1., 0.,  ..., 1., 0., 1.],\n",
       "         [1., 1., 0.,  ..., 1., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 1.,  ..., 1., 1., 0.],\n",
       "         [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 1., 1.,  ..., 1., 0., 0.]], device='cuda:1'),\n",
       " tensor([[0., 1., 0.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         [1., 0., 0.,  ..., 1., 1., 0.],\n",
       "         [1., 0., 1.,  ..., 0., 1., 0.]], device='cuda:1'),\n",
       " tensor([[1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
       "         [1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "          1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 1., 0., 1., 1.],\n",
       "         [0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "          1., 0., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "         [0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "          1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "          1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "          0., 0., 0., 1., 1., 0., 0., 0., 1., 1.],\n",
       "         [1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "          1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
       "         [1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "          0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "          1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 0., 1., 1., 1.],\n",
       "         [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "          1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "          1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 1., 1., 1.]], device='cuda:1')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0055,  0.0045, -0.0229,  ..., -0.0064,  0.0346, -0.0280],\n",
      "        [-0.0253,  0.0169,  0.0269,  ...,  0.0142, -0.0163,  0.0041],\n",
      "        [-0.0003,  0.0040, -0.0136,  ...,  0.0205,  0.0091,  0.0144],\n",
      "        ...,\n",
      "        [-0.0320, -0.0213, -0.0003,  ..., -0.0050,  0.0115,  0.0200],\n",
      "        [-0.0019,  0.0120,  0.0064,  ...,  0.0303, -0.0193,  0.0258],\n",
      "        [-0.0263,  0.0074, -0.0007,  ..., -0.0009,  0.0092,  0.0243]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0055,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0280],\n",
      "        [-0.0253,  0.0169,  0.0000,  ...,  0.0142, -0.0000,  0.0041],\n",
      "        [-0.0003,  0.0040, -0.0000,  ...,  0.0205,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0320, -0.0000, -0.0003,  ..., -0.0050,  0.0115,  0.0000],\n",
      "        [-0.0019,  0.0000,  0.0064,  ...,  0.0303, -0.0193,  0.0258],\n",
      "        [-0.0000,  0.0074, -0.0007,  ..., -0.0009,  0.0000,  0.0000]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0284,  0.0486, -0.0248,  ...,  0.0474, -0.0186, -0.0017],\n",
      "        [-0.0457, -0.0192, -0.0189,  ...,  0.0372, -0.0192,  0.0370],\n",
      "        [ 0.0259,  0.0047, -0.0329,  ...,  0.0512, -0.0481, -0.0239],\n",
      "        ...,\n",
      "        [ 0.0004,  0.0425,  0.0418,  ..., -0.0015,  0.0102, -0.0244],\n",
      "        [-0.0334, -0.0520,  0.0087,  ...,  0.0251, -0.0535,  0.0089],\n",
      "        [ 0.0305,  0.0273,  0.0350,  ...,  0.0402, -0.0458,  0.0016]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0000,  0.0486, -0.0000,  ...,  0.0000, -0.0000, -0.0017],\n",
      "        [-0.0457, -0.0000, -0.0189,  ...,  0.0372, -0.0000,  0.0000],\n",
      "        [ 0.0259,  0.0000, -0.0000,  ...,  0.0512, -0.0481, -0.0239],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0015,  0.0102, -0.0244],\n",
      "        [-0.0334, -0.0000,  0.0000,  ...,  0.0251, -0.0535,  0.0000],\n",
      "        [ 0.0305,  0.0000,  0.0350,  ...,  0.0000, -0.0458,  0.0000]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.6692e-02,  5.7925e-02,  4.5212e-02,  6.4826e-02, -9.5745e-02,\n",
      "         -6.2176e-02, -4.5858e-02,  9.6519e-02, -8.6475e-02,  6.7853e-02,\n",
      "          1.0981e-02,  9.5673e-02,  7.1501e-02, -9.2763e-02,  6.2817e-02,\n",
      "          3.9868e-02, -4.9081e-03, -7.7878e-02, -6.1584e-02,  1.0491e-02,\n",
      "          1.3399e-03, -7.5753e-02,  4.5084e-02,  2.5436e-02, -1.7517e-02,\n",
      "         -1.7332e-02, -1.6423e-02,  5.0592e-02, -7.8457e-02, -3.7362e-03,\n",
      "          4.3777e-02,  7.4791e-02,  3.9920e-02, -8.6131e-02, -8.1334e-02,\n",
      "          4.6452e-02,  4.6495e-02, -3.0082e-02,  5.7108e-02,  4.8580e-02,\n",
      "         -3.5659e-02, -8.2428e-02,  4.0949e-02, -1.1595e-02,  1.9747e-02,\n",
      "          1.6504e-02,  5.5454e-02, -1.2951e-02,  1.1087e-02,  2.4257e-02,\n",
      "          4.6752e-02,  5.2298e-02,  6.4416e-02,  3.4870e-02, -3.0989e-03,\n",
      "         -6.1354e-02,  2.7242e-02,  3.4082e-02,  8.4272e-02, -2.9060e-02,\n",
      "         -2.8845e-02, -9.6239e-02, -9.1525e-02,  7.4917e-02,  5.5532e-02,\n",
      "          8.7430e-02, -8.6140e-02,  6.5790e-02, -7.0273e-02, -1.0466e-02,\n",
      "          5.5283e-02, -4.2525e-02, -8.2337e-03,  6.1603e-02, -5.4025e-02,\n",
      "          8.8637e-02, -2.3852e-04, -7.3754e-02,  7.1040e-02, -5.5382e-02,\n",
      "          4.9078e-02,  1.8757e-02, -2.6649e-02,  9.0515e-02, -1.7237e-02,\n",
      "          9.2411e-02,  6.4577e-02,  3.6299e-02, -5.7074e-02,  6.1109e-02,\n",
      "         -1.1569e-02,  7.6618e-02,  7.2033e-02,  5.8756e-02,  9.9133e-02,\n",
      "         -8.1024e-03,  1.6966e-02, -1.9704e-02,  8.9779e-03,  7.2970e-02],\n",
      "        [-9.3794e-02,  5.1942e-02,  7.3212e-02, -4.9622e-03, -3.9302e-02,\n",
      "          8.2285e-02,  8.5943e-02,  7.5636e-02, -7.1011e-02, -5.7157e-02,\n",
      "         -3.1040e-02,  5.0364e-02, -8.9209e-02,  7.6172e-02,  8.0127e-02,\n",
      "          6.6943e-02,  4.5740e-02, -1.8982e-02, -8.5589e-02,  5.1171e-02,\n",
      "         -8.1939e-02,  5.0262e-03,  3.0659e-02, -4.7461e-02, -5.4333e-02,\n",
      "          7.8699e-02, -6.7464e-02,  5.0289e-02, -8.8277e-02, -6.8736e-02,\n",
      "          1.8646e-02, -7.5811e-02, -1.8128e-02,  5.4371e-02, -3.4004e-02,\n",
      "          4.0953e-02,  1.5429e-02, -9.7400e-02, -4.4734e-02,  4.0939e-02,\n",
      "         -2.7567e-02, -5.7234e-02, -6.4809e-02, -6.1892e-02,  4.3271e-02,\n",
      "         -6.6245e-02,  6.7766e-02,  5.8137e-02, -7.4272e-02, -3.7806e-02,\n",
      "          7.7461e-02, -5.0000e-02,  3.3480e-02, -7.3739e-02, -2.3944e-02,\n",
      "         -6.3307e-02, -5.9568e-02,  7.7786e-02, -5.7522e-02,  8.1034e-02,\n",
      "          6.4803e-03,  5.9194e-02, -3.0676e-02,  6.7138e-02,  9.2717e-02,\n",
      "          1.9978e-02, -3.4371e-02,  1.8549e-02, -6.1912e-02, -1.7387e-03,\n",
      "         -8.2557e-02,  1.8133e-02,  8.0828e-02,  8.9130e-02,  4.4984e-02,\n",
      "          4.9327e-03,  9.9791e-02,  9.9065e-02,  4.5120e-02,  6.4039e-02,\n",
      "         -4.0586e-02,  8.1406e-02,  2.1659e-02, -5.5567e-02, -1.8441e-02,\n",
      "          1.7244e-04, -4.8946e-02, -7.0051e-03,  4.8154e-03, -2.7805e-02,\n",
      "          4.0608e-02, -7.0885e-02,  3.7619e-02, -1.7281e-02,  4.3392e-03,\n",
      "          7.2656e-03,  6.4268e-02,  3.7916e-02, -1.3791e-02,  8.5840e-02],\n",
      "        [-6.8799e-02,  4.9778e-02, -6.9064e-02, -6.9134e-02,  1.4304e-02,\n",
      "         -8.1182e-03,  3.7288e-02,  3.3075e-02,  6.6688e-02, -4.9183e-03,\n",
      "          1.5444e-02,  5.7820e-02, -4.4141e-02,  5.8129e-05, -6.0334e-02,\n",
      "         -5.0240e-02, -2.6216e-02,  8.0576e-02, -6.4849e-02,  5.7880e-02,\n",
      "          5.0649e-03,  2.5900e-02, -4.8343e-02,  8.6915e-02, -1.0181e-02,\n",
      "          6.3736e-02,  1.2909e-02, -2.2463e-02,  8.6474e-02, -2.3477e-03,\n",
      "         -9.7632e-02,  9.1415e-03,  6.0833e-02, -9.6934e-02, -5.2665e-02,\n",
      "          9.1026e-02,  4.2798e-02,  2.1979e-02, -6.1097e-02, -7.4378e-03,\n",
      "         -1.6972e-02, -6.7518e-02,  2.8879e-02, -1.7146e-02, -7.4872e-02,\n",
      "         -1.2834e-03, -4.9028e-02,  2.1689e-02,  3.8495e-02,  2.8725e-02,\n",
      "          8.1732e-02,  8.8806e-04,  7.7047e-02, -1.9401e-02,  6.5992e-02,\n",
      "          4.1548e-02,  7.9542e-02, -1.9139e-02, -2.4295e-02,  1.1732e-02,\n",
      "          2.0522e-02, -7.5288e-02, -8.8597e-02,  9.6905e-03, -7.4073e-02,\n",
      "         -6.0378e-03, -3.2623e-02,  5.5654e-02,  2.6211e-02, -3.9630e-02,\n",
      "         -1.0643e-02, -1.9607e-02,  9.9156e-02,  6.5165e-02,  8.7195e-02,\n",
      "         -2.9111e-02, -8.2422e-02,  3.9261e-02,  5.0854e-02,  7.1820e-02,\n",
      "          1.7418e-02,  8.2435e-02,  3.5467e-02, -1.1321e-02, -5.5916e-02,\n",
      "          1.4649e-02, -2.9082e-02,  1.2693e-02, -5.2362e-02, -8.2601e-02,\n",
      "         -4.4147e-02, -1.5573e-02,  9.4360e-02, -5.3549e-02,  2.1901e-02,\n",
      "          7.5325e-03, -3.9686e-02,  9.5483e-02,  6.7259e-02,  3.8146e-02],\n",
      "        [-6.4021e-03, -1.3843e-02, -3.6514e-02, -1.3154e-03, -2.3969e-03,\n",
      "         -6.5856e-02, -1.9231e-02,  5.5470e-02,  2.3900e-02, -9.7609e-02,\n",
      "          7.1225e-02, -8.3026e-02, -7.6449e-02, -8.3475e-02, -1.9494e-02,\n",
      "          6.5039e-02,  2.8724e-02,  6.6696e-02, -8.4417e-02,  1.8453e-02,\n",
      "          2.4622e-02,  4.2548e-02, -4.3826e-02,  2.9898e-03,  5.3253e-03,\n",
      "         -1.7339e-02, -7.4687e-02,  4.8552e-03, -1.8751e-03, -4.2650e-02,\n",
      "         -3.3265e-03,  3.0659e-02,  4.8537e-02, -1.3044e-02,  3.7254e-02,\n",
      "          7.9007e-03,  9.1483e-02,  9.9795e-03,  1.8308e-03,  3.3119e-02,\n",
      "         -1.0055e-02,  7.9463e-02, -5.7138e-02, -7.2923e-02, -4.6275e-02,\n",
      "         -6.3530e-02, -5.6681e-02,  2.5638e-02,  6.5301e-02,  5.5501e-02,\n",
      "          7.2347e-02, -2.0690e-02, -5.4259e-02, -4.6744e-02, -5.5244e-02,\n",
      "          3.0710e-02, -7.7237e-02, -6.6797e-02, -9.9516e-02, -9.2181e-02,\n",
      "         -5.3830e-03,  3.7303e-02, -1.2136e-02, -9.6921e-02, -4.8364e-03,\n",
      "         -9.4379e-02, -1.5331e-02, -5.7863e-02,  2.6744e-02,  3.0934e-02,\n",
      "          7.5350e-02, -2.1979e-02, -3.8155e-02,  4.7724e-02, -8.1157e-02,\n",
      "         -7.5868e-02,  2.8712e-02, -9.0937e-03,  1.4119e-02,  5.4359e-02,\n",
      "          9.2719e-02,  8.1802e-02, -5.8689e-02,  3.3277e-02, -2.2549e-02,\n",
      "          5.9969e-02,  5.5784e-02,  1.3582e-02, -4.4366e-02,  4.4309e-02,\n",
      "          3.5695e-02,  7.0455e-02, -9.5670e-02, -4.6881e-02,  6.3655e-02,\n",
      "          2.7921e-02,  8.5864e-02, -1.4763e-02,  2.1263e-02,  5.8117e-02],\n",
      "        [ 1.6603e-02, -4.4854e-02,  9.6824e-02, -3.3924e-02,  7.7945e-02,\n",
      "          2.1251e-02, -7.2939e-03,  1.5282e-03, -8.3026e-02, -8.4352e-02,\n",
      "          1.6041e-02,  5.9697e-02,  2.4671e-02, -4.6497e-03,  9.0584e-02,\n",
      "         -9.0578e-02, -7.8434e-02, -5.9853e-02,  8.3700e-03,  3.9910e-02,\n",
      "          7.9187e-02,  8.9718e-02, -7.1330e-03, -7.7369e-02,  1.5570e-02,\n",
      "          4.0138e-02, -2.9807e-02, -3.3084e-03, -2.9153e-02, -7.4433e-02,\n",
      "         -1.9677e-02, -4.6059e-02, -3.7503e-02, -7.7351e-02,  3.0114e-02,\n",
      "          7.6769e-02, -7.4407e-02,  9.4665e-02, -5.8893e-02, -4.1678e-03,\n",
      "         -3.5371e-02,  1.6038e-02, -7.7105e-02,  7.6782e-02, -2.7887e-03,\n",
      "         -6.7774e-02,  6.0478e-02, -1.8768e-02,  3.2500e-02,  6.0286e-02,\n",
      "         -6.5043e-02, -5.2742e-02,  2.4787e-02,  5.1383e-02, -1.3607e-02,\n",
      "          4.8275e-02, -7.9600e-02, -5.6171e-02, -7.4809e-02, -1.4265e-03,\n",
      "          6.3271e-02, -4.7323e-02,  8.2209e-02, -2.1183e-02,  8.1873e-02,\n",
      "          6.1512e-02,  5.0360e-02,  3.2144e-02, -6.2285e-02, -1.1857e-02,\n",
      "          5.6103e-02, -1.0272e-02, -8.9094e-02,  2.4624e-02, -6.4950e-02,\n",
      "         -4.7130e-02,  3.5679e-02, -3.0894e-02, -3.2767e-03, -7.9674e-02,\n",
      "         -9.2719e-02, -8.4342e-02, -9.3168e-02,  1.3611e-02, -9.3257e-02,\n",
      "          4.7689e-02,  5.7823e-02, -3.0199e-03,  6.0111e-03, -7.8295e-02,\n",
      "          2.6703e-02,  8.0346e-02, -6.5152e-02,  5.8233e-02, -4.3593e-02,\n",
      "          8.4632e-02,  3.7673e-03, -3.7159e-03,  5.9913e-02, -1.1855e-02],\n",
      "        [ 4.0780e-02, -9.5082e-02, -4.9745e-03,  2.8423e-02, -9.7846e-02,\n",
      "          5.2777e-02, -8.4105e-02, -7.9209e-02,  6.5670e-02, -5.7431e-02,\n",
      "         -5.9341e-02, -8.8354e-02, -3.6787e-02, -1.6880e-02, -8.5559e-02,\n",
      "         -6.3188e-02, -2.6201e-02, -7.0612e-02, -9.9033e-02, -5.9081e-02,\n",
      "          6.8273e-02, -5.3745e-02, -5.2385e-03, -2.4467e-02,  9.3852e-02,\n",
      "          5.6104e-02,  4.2078e-02,  7.7700e-02, -4.5953e-02,  3.7290e-02,\n",
      "          4.9539e-02, -2.0191e-02, -2.0255e-02, -7.5215e-02, -1.8150e-02,\n",
      "         -6.5916e-02, -6.8860e-02, -4.4360e-02,  9.0985e-02,  3.7494e-02,\n",
      "          2.6578e-02, -4.7113e-02, -1.2582e-03,  4.0875e-02,  6.5697e-02,\n",
      "          8.9702e-02,  8.8323e-02,  5.8087e-02,  2.5215e-02,  8.8047e-02,\n",
      "          7.2891e-02, -7.9757e-02, -2.8243e-02, -8.4648e-02,  2.1113e-02,\n",
      "         -4.9253e-02, -4.2786e-02,  1.2603e-02,  1.2403e-02, -2.3150e-03,\n",
      "         -3.8106e-02, -4.7856e-02, -1.6805e-02,  7.0025e-02, -5.9742e-04,\n",
      "          8.9759e-02, -2.7146e-02,  4.4691e-02,  4.6966e-02, -9.1019e-02,\n",
      "         -3.9214e-02,  6.2108e-02, -9.5156e-02,  4.5351e-03,  4.2242e-02,\n",
      "          2.2391e-02, -5.4819e-02, -4.6013e-02, -8.5395e-03, -5.2488e-02,\n",
      "          2.4777e-02,  7.2822e-02, -8.2814e-02, -6.6310e-02,  3.9560e-02,\n",
      "         -6.9088e-02, -4.3204e-02, -2.8493e-02, -7.5615e-02,  3.1211e-02,\n",
      "          1.7620e-02, -3.7710e-02, -7.4887e-02, -3.4169e-03, -3.7937e-02,\n",
      "          3.3240e-02, -9.4882e-02, -3.2908e-02,  1.3374e-02,  1.1385e-02],\n",
      "        [-8.1650e-02,  2.9992e-02, -1.7305e-02,  9.1377e-03, -5.6171e-02,\n",
      "          7.7774e-02, -5.0894e-02, -6.4478e-02,  8.0603e-02,  6.9717e-02,\n",
      "          6.1985e-02,  7.7271e-02,  2.8090e-02, -8.9560e-02, -9.3352e-02,\n",
      "         -7.7785e-02, -6.0535e-02, -2.3904e-02, -8.5145e-02,  4.4948e-03,\n",
      "         -2.9703e-02, -8.1917e-02, -3.7124e-02, -5.2287e-03,  6.4782e-02,\n",
      "          8.9775e-02,  7.2980e-02, -7.1637e-02,  1.5007e-02,  7.6354e-02,\n",
      "         -9.8192e-02,  1.7021e-02, -7.5987e-02,  7.0055e-02, -9.0927e-02,\n",
      "         -1.4727e-02, -4.8645e-02, -1.1318e-02, -7.2787e-02, -8.5809e-02,\n",
      "         -8.3830e-02, -4.4416e-02, -7.9056e-02,  4.8269e-02,  8.2191e-02,\n",
      "         -8.5115e-02, -3.4233e-02,  2.6600e-02, -5.1138e-02, -8.9734e-02,\n",
      "         -2.9848e-02, -1.0080e-02, -1.1596e-02, -6.4174e-02,  8.0746e-04,\n",
      "         -7.1274e-02,  1.3251e-03, -6.1382e-02,  1.0620e-02, -9.7202e-02,\n",
      "         -8.2233e-02, -8.8451e-02, -3.0182e-02, -5.3512e-02, -2.1481e-02,\n",
      "          3.2529e-02, -8.6115e-02, -2.4411e-02,  1.7425e-02, -4.4729e-02,\n",
      "         -1.7872e-02, -7.5608e-03, -6.9140e-02,  1.4602e-02, -6.9063e-02,\n",
      "          2.7695e-02,  5.6199e-02, -6.8562e-02, -9.3859e-02, -8.3471e-02,\n",
      "         -3.0951e-02,  9.8157e-02, -9.3558e-02, -6.4456e-02,  7.8868e-02,\n",
      "          4.6024e-02,  5.9729e-02,  9.2653e-02,  2.3326e-02, -5.0957e-02,\n",
      "          8.5772e-02,  2.1751e-02,  6.9225e-02,  8.3843e-02,  1.7385e-02,\n",
      "          6.2939e-02, -9.0154e-02, -1.5319e-02, -4.2511e-02, -9.5626e-02],\n",
      "        [ 7.8881e-02,  1.2666e-03,  1.6894e-02, -7.9764e-02, -5.3924e-02,\n",
      "         -6.6157e-02,  7.2621e-02, -2.9528e-02, -6.3925e-02,  5.2094e-02,\n",
      "          6.9484e-02, -1.1263e-02,  9.6584e-02, -4.1696e-02,  1.6008e-02,\n",
      "         -3.8552e-02,  7.4023e-02, -6.2297e-02,  4.6383e-02,  6.5969e-02,\n",
      "          6.0524e-02,  6.6041e-02, -1.5302e-02, -9.9914e-02,  9.4316e-02,\n",
      "         -7.6911e-02,  4.7871e-02,  9.3331e-02,  4.5810e-02, -4.1017e-02,\n",
      "         -3.0417e-02, -2.3329e-02,  1.9004e-02,  6.4725e-02, -3.1405e-02,\n",
      "          4.7388e-02, -6.5945e-05,  9.3190e-03, -6.1622e-02,  9.6880e-02,\n",
      "          4.6607e-02, -8.0105e-02,  3.9859e-02,  3.7394e-02, -5.9521e-02,\n",
      "         -1.7060e-02,  8.4782e-02,  7.1240e-02,  8.1821e-02,  6.1279e-02,\n",
      "          9.2856e-02,  7.6665e-03,  1.1751e-02, -8.5920e-03, -4.3526e-05,\n",
      "         -5.3320e-02, -2.8135e-02, -6.6119e-02,  5.7224e-02,  4.5682e-02,\n",
      "          4.6887e-02, -4.2407e-02,  7.0880e-02, -7.6668e-02, -7.2633e-03,\n",
      "         -9.6783e-02, -5.4306e-02, -1.7328e-02, -3.8658e-02,  6.0320e-02,\n",
      "         -8.9051e-02, -3.4464e-02, -6.2654e-02,  3.7427e-02, -2.7871e-03,\n",
      "         -8.1861e-02,  3.0379e-02,  8.9745e-02, -9.5049e-02,  1.3889e-02,\n",
      "          7.5331e-02, -6.2991e-02,  7.3851e-02,  4.9856e-02,  3.7491e-02,\n",
      "         -2.7186e-02, -8.5364e-02, -6.7741e-02,  9.9076e-02,  9.4130e-02,\n",
      "         -5.9844e-02, -9.0887e-02, -2.9406e-02, -1.3082e-02,  8.4844e-02,\n",
      "          8.3589e-03,  8.6860e-02,  2.6495e-02, -9.5367e-02, -6.4183e-02],\n",
      "        [-7.8338e-02, -7.4601e-02,  5.7509e-02,  7.5886e-02,  5.8323e-02,\n",
      "         -6.9728e-02, -3.6763e-02,  8.0206e-02, -5.2056e-02, -3.0118e-02,\n",
      "         -7.4478e-02,  9.6065e-03,  1.1888e-02, -8.7803e-02,  9.0699e-02,\n",
      "          2.3977e-02, -5.4344e-02, -2.5875e-02,  1.7173e-02,  1.7512e-02,\n",
      "          1.6100e-02, -8.3441e-03,  3.0734e-02,  8.5510e-02,  6.9067e-02,\n",
      "         -5.8034e-02, -7.4331e-02,  1.3580e-02,  3.3061e-02, -1.6427e-02,\n",
      "          4.3160e-02,  3.4852e-02, -6.9334e-02,  3.2650e-02,  1.0842e-02,\n",
      "         -8.4125e-03, -5.6560e-02, -1.6997e-02,  6.6951e-03,  2.1755e-02,\n",
      "         -4.4834e-02,  7.1404e-02, -2.6809e-02, -8.5630e-03,  2.9169e-02,\n",
      "         -2.0407e-02,  4.2543e-02,  3.0676e-02,  4.1652e-03, -2.5133e-02,\n",
      "          8.8116e-02, -1.5254e-02,  4.4061e-02,  9.8357e-02, -6.4804e-03,\n",
      "         -9.8260e-03, -9.8061e-02, -7.3401e-02, -8.1234e-02,  3.6335e-02,\n",
      "          1.5767e-02,  1.1276e-02, -1.7506e-03,  3.7977e-02, -8.0587e-02,\n",
      "          7.6529e-02,  4.8764e-02,  2.4218e-02,  3.5778e-02, -5.9490e-02,\n",
      "          7.7778e-02,  4.9090e-02,  3.1905e-02, -4.5310e-02,  6.9461e-02,\n",
      "         -8.5196e-02, -9.0953e-02,  6.7919e-02,  9.1619e-02, -6.8707e-02,\n",
      "         -1.3871e-02, -5.0938e-02, -6.1695e-02, -2.6290e-02,  6.9604e-02,\n",
      "          9.5036e-02, -1.6632e-03,  3.5742e-02, -8.6495e-02,  1.5543e-02,\n",
      "         -1.1181e-02, -2.2639e-02, -7.5351e-02, -4.4257e-02, -5.2250e-03,\n",
      "         -5.7966e-02, -9.5150e-02,  8.8747e-02,  3.6030e-02,  1.7441e-02],\n",
      "        [-8.4042e-02,  9.2409e-02, -7.8661e-02,  4.2020e-02, -4.4422e-02,\n",
      "         -7.5612e-02,  8.0404e-02, -3.3398e-02, -8.8737e-02, -7.0961e-02,\n",
      "         -1.8483e-02, -2.5634e-03, -2.7238e-02,  4.1945e-03,  7.5894e-02,\n",
      "         -2.5077e-02,  2.0555e-02, -9.0282e-02,  2.5322e-02,  3.2935e-02,\n",
      "          7.8025e-03, -8.6148e-02, -3.2427e-02, -5.7887e-02, -9.0793e-02,\n",
      "          2.2144e-03, -1.0372e-02,  3.6089e-02, -4.8606e-02,  5.3730e-02,\n",
      "          1.5483e-02, -1.8805e-03,  8.1210e-02, -4.5909e-02, -1.4640e-02,\n",
      "          4.0908e-03,  9.8743e-02, -6.5339e-02,  5.6720e-02, -6.0650e-02,\n",
      "         -1.8590e-02,  2.1692e-02,  1.2410e-02,  3.6039e-02, -1.0680e-02,\n",
      "          2.0341e-03,  4.7951e-02,  6.5015e-02,  7.1451e-02, -4.9610e-02,\n",
      "         -1.3952e-02, -1.8956e-02,  5.9925e-02,  4.8457e-02,  9.5723e-02,\n",
      "          8.5953e-02, -1.9816e-02,  7.8910e-02, -1.0409e-02,  2.5153e-03,\n",
      "         -8.5261e-02, -7.3957e-02,  7.4401e-02, -8.5661e-02, -2.3012e-02,\n",
      "          7.5791e-02, -4.0358e-02, -3.7015e-02, -3.0954e-02, -9.9673e-03,\n",
      "          1.3787e-02,  5.6664e-02,  5.9673e-02,  4.4587e-02, -5.4984e-02,\n",
      "         -8.3971e-02, -4.5159e-02, -4.0845e-02,  4.7795e-03,  4.0649e-02,\n",
      "          3.6992e-03,  3.3166e-02,  2.4974e-02, -7.2218e-02,  8.6616e-04,\n",
      "         -9.4219e-02,  9.8193e-02, -9.4529e-02, -9.3341e-02,  2.6795e-03,\n",
      "          9.8082e-02, -6.3336e-02,  3.4947e-02, -5.2271e-02,  3.4959e-02,\n",
      "          9.0560e-02, -2.5018e-02, -5.2818e-02, -5.0812e-03, -1.8184e-02]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.6692e-02,  5.7925e-02,  0.0000e+00,  6.4826e-02, -9.5745e-02,\n",
      "         -0.0000e+00, -4.5858e-02,  9.6519e-02, -0.0000e+00,  0.0000e+00,\n",
      "          1.0981e-02,  0.0000e+00,  7.1501e-02, -9.2763e-02,  0.0000e+00,\n",
      "          0.0000e+00, -4.9081e-03, -7.7878e-02, -0.0000e+00,  0.0000e+00,\n",
      "          1.3399e-03, -0.0000e+00,  4.5084e-02,  2.5436e-02, -0.0000e+00,\n",
      "         -0.0000e+00, -1.6423e-02,  5.0592e-02, -7.8457e-02, -0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.9920e-02, -0.0000e+00, -8.1334e-02,\n",
      "          0.0000e+00,  4.6495e-02, -3.0082e-02,  5.7108e-02,  4.8580e-02,\n",
      "         -3.5659e-02, -8.2428e-02,  4.0949e-02, -1.1595e-02,  1.9747e-02,\n",
      "          1.6504e-02,  0.0000e+00, -1.2951e-02,  1.1087e-02,  2.4257e-02,\n",
      "          4.6752e-02,  0.0000e+00,  6.4416e-02,  3.4870e-02, -3.0989e-03,\n",
      "         -6.1354e-02,  2.7242e-02,  0.0000e+00,  0.0000e+00, -2.9060e-02,\n",
      "         -2.8845e-02, -0.0000e+00, -9.1525e-02,  7.4917e-02,  5.5532e-02,\n",
      "          0.0000e+00, -8.6140e-02,  0.0000e+00, -7.0273e-02, -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -0.0000e+00,  9.0515e-02, -1.7237e-02,\n",
      "          0.0000e+00,  6.4577e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "         -1.1569e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00,  1.6966e-02, -0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-0.0000e+00,  0.0000e+00,  7.3212e-02, -0.0000e+00, -3.9302e-02,\n",
      "          8.2285e-02,  0.0000e+00,  0.0000e+00, -7.1011e-02, -5.7157e-02,\n",
      "         -0.0000e+00,  0.0000e+00, -0.0000e+00,  7.6172e-02,  0.0000e+00,\n",
      "          6.6943e-02,  0.0000e+00, -0.0000e+00, -0.0000e+00,  5.1171e-02,\n",
      "         -0.0000e+00,  5.0262e-03,  3.0659e-02, -4.7461e-02, -5.4333e-02,\n",
      "          7.8699e-02, -6.7464e-02,  5.0289e-02, -0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00, -7.5811e-02, -0.0000e+00,  5.4371e-02, -3.4004e-02,\n",
      "          4.0953e-02,  0.0000e+00, -0.0000e+00, -0.0000e+00,  4.0939e-02,\n",
      "         -2.7567e-02, -5.7234e-02, -6.4809e-02, -6.1892e-02,  0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00,  5.8137e-02, -7.4272e-02, -3.7806e-02,\n",
      "          0.0000e+00, -5.0000e-02,  0.0000e+00, -7.3739e-02, -2.3944e-02,\n",
      "         -0.0000e+00, -5.9568e-02,  0.0000e+00, -5.7522e-02,  0.0000e+00,\n",
      "          0.0000e+00,  5.9194e-02, -0.0000e+00,  6.7138e-02,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00,  0.0000e+00, -6.1912e-02, -0.0000e+00,\n",
      "         -8.2557e-02,  0.0000e+00,  8.0828e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4039e-02,\n",
      "         -4.0586e-02,  8.1406e-02,  2.1659e-02, -0.0000e+00, -1.8441e-02,\n",
      "          0.0000e+00, -0.0000e+00, -7.0051e-03,  4.8154e-03, -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00,  3.7619e-02, -1.7281e-02,  0.0000e+00,\n",
      "          0.0000e+00,  6.4268e-02,  0.0000e+00, -0.0000e+00,  8.5840e-02],\n",
      "        [-6.8799e-02,  0.0000e+00, -6.9064e-02, -6.9134e-02,  1.4304e-02,\n",
      "         -0.0000e+00,  3.7288e-02,  0.0000e+00,  6.6688e-02, -0.0000e+00,\n",
      "          0.0000e+00,  5.7820e-02, -0.0000e+00,  5.8129e-05, -6.0334e-02,\n",
      "         -0.0000e+00, -2.6216e-02,  0.0000e+00, -6.4849e-02,  5.7880e-02,\n",
      "          5.0649e-03,  2.5900e-02, -4.8343e-02,  0.0000e+00, -0.0000e+00,\n",
      "          6.3736e-02,  1.2909e-02, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00,  0.0000e+00, -9.6934e-02, -5.2665e-02,\n",
      "          0.0000e+00,  4.2798e-02,  2.1979e-02, -6.1097e-02, -7.4378e-03,\n",
      "         -1.6972e-02, -6.7518e-02,  0.0000e+00, -0.0000e+00, -7.4872e-02,\n",
      "         -1.2834e-03, -0.0000e+00,  2.1689e-02,  0.0000e+00,  2.8725e-02,\n",
      "          0.0000e+00,  0.0000e+00,  7.7047e-02, -1.9401e-02,  6.5992e-02,\n",
      "          0.0000e+00,  0.0000e+00, -1.9139e-02, -0.0000e+00,  1.1732e-02,\n",
      "          2.0522e-02, -0.0000e+00, -0.0000e+00,  9.6905e-03, -7.4073e-02,\n",
      "         -6.0378e-03, -0.0000e+00,  0.0000e+00,  0.0000e+00, -3.9630e-02,\n",
      "         -1.0643e-02, -1.9607e-02,  0.0000e+00,  6.5165e-02,  8.7195e-02,\n",
      "         -2.9111e-02, -8.2422e-02,  3.9261e-02,  5.0854e-02,  7.1820e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -5.5916e-02,\n",
      "          0.0000e+00, -2.9082e-02,  1.2693e-02, -5.2362e-02, -8.2601e-02,\n",
      "         -0.0000e+00, -0.0000e+00,  9.4360e-02, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.9686e-02,  0.0000e+00,  6.7259e-02,  3.8146e-02],\n",
      "        [-0.0000e+00, -0.0000e+00, -3.6514e-02, -1.3154e-03, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -9.7609e-02,\n",
      "          7.1225e-02, -8.3026e-02, -0.0000e+00, -0.0000e+00, -1.9494e-02,\n",
      "          0.0000e+00,  2.8724e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "          2.4622e-02,  0.0000e+00, -4.3826e-02,  0.0000e+00,  5.3253e-03,\n",
      "         -1.7339e-02, -0.0000e+00,  4.8552e-03, -1.8751e-03, -4.2650e-02,\n",
      "         -0.0000e+00,  3.0659e-02,  4.8537e-02, -0.0000e+00,  3.7254e-02,\n",
      "          7.9007e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0055e-02,  7.9463e-02, -5.7138e-02, -7.2923e-02, -4.6275e-02,\n",
      "         -6.3530e-02, -5.6681e-02,  0.0000e+00,  6.5301e-02,  0.0000e+00,\n",
      "          0.0000e+00, -2.0690e-02, -5.4259e-02, -4.6744e-02, -5.5244e-02,\n",
      "          0.0000e+00, -7.7237e-02, -0.0000e+00, -0.0000e+00, -9.2181e-02,\n",
      "         -0.0000e+00,  3.7303e-02, -0.0000e+00, -9.6921e-02, -4.8364e-03,\n",
      "         -9.4379e-02, -0.0000e+00, -5.7863e-02,  0.0000e+00,  3.0934e-02,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          9.2719e-02,  0.0000e+00, -5.8689e-02,  3.3277e-02, -0.0000e+00,\n",
      "          0.0000e+00,  5.5784e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "          3.5695e-02,  0.0000e+00, -9.5670e-02, -0.0000e+00,  6.3655e-02,\n",
      "          2.7921e-02,  0.0000e+00, -1.4763e-02,  2.1263e-02,  0.0000e+00],\n",
      "        [ 0.0000e+00, -4.4854e-02,  0.0000e+00, -0.0000e+00,  7.7945e-02,\n",
      "          2.1251e-02, -0.0000e+00,  1.5282e-03, -8.3026e-02, -0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  2.4671e-02, -4.6497e-03,  0.0000e+00,\n",
      "         -9.0578e-02, -0.0000e+00, -0.0000e+00,  8.3700e-03,  0.0000e+00,\n",
      "          0.0000e+00,  8.9718e-02, -7.1330e-03, -0.0000e+00,  0.0000e+00,\n",
      "          4.0138e-02, -2.9807e-02, -0.0000e+00, -0.0000e+00, -7.4433e-02,\n",
      "         -1.9677e-02, -0.0000e+00, -3.7503e-02, -0.0000e+00,  0.0000e+00,\n",
      "          7.6769e-02, -0.0000e+00,  0.0000e+00, -5.8893e-02, -4.1678e-03,\n",
      "         -0.0000e+00,  0.0000e+00, -0.0000e+00,  7.6782e-02, -0.0000e+00,\n",
      "         -6.7774e-02,  0.0000e+00, -0.0000e+00,  3.2500e-02,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  2.4787e-02,  0.0000e+00, -0.0000e+00,\n",
      "          4.8275e-02, -7.9600e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00, -4.7323e-02,  8.2209e-02, -2.1183e-02,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.2144e-02, -6.2285e-02, -1.1857e-02,\n",
      "          0.0000e+00, -0.0000e+00, -8.9094e-02,  2.4624e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  3.5679e-02, -0.0000e+00, -3.2767e-03, -0.0000e+00,\n",
      "         -9.2719e-02, -0.0000e+00, -0.0000e+00,  1.3611e-02, -9.3257e-02,\n",
      "          4.7689e-02,  5.7823e-02, -3.0199e-03,  0.0000e+00, -7.8295e-02,\n",
      "          0.0000e+00,  0.0000e+00, -0.0000e+00,  5.8233e-02, -4.3593e-02,\n",
      "          0.0000e+00,  0.0000e+00, -0.0000e+00,  5.9913e-02, -1.1855e-02],\n",
      "        [ 4.0780e-02, -0.0000e+00, -0.0000e+00,  0.0000e+00, -9.7846e-02,\n",
      "          5.2777e-02, -0.0000e+00, -0.0000e+00,  6.5670e-02, -5.7431e-02,\n",
      "         -5.9341e-02, -0.0000e+00, -3.6787e-02, -0.0000e+00, -8.5559e-02,\n",
      "         -0.0000e+00, -0.0000e+00, -7.0612e-02, -0.0000e+00, -0.0000e+00,\n",
      "          6.8273e-02, -0.0000e+00, -5.2385e-03, -0.0000e+00,  9.3852e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  3.7290e-02,\n",
      "          4.9539e-02, -0.0000e+00, -2.0255e-02, -7.5215e-02, -0.0000e+00,\n",
      "         -6.5916e-02, -6.8860e-02, -4.4360e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -1.2582e-03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  5.8087e-02,  0.0000e+00,  8.8047e-02,\n",
      "          7.2891e-02, -7.9757e-02, -2.8243e-02, -0.0000e+00,  2.1113e-02,\n",
      "         -0.0000e+00, -4.2786e-02,  1.2603e-02,  0.0000e+00, -2.3150e-03,\n",
      "         -3.8106e-02, -0.0000e+00, -1.6805e-02,  0.0000e+00, -0.0000e+00,\n",
      "          8.9759e-02, -2.7146e-02,  4.4691e-02,  4.6966e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  6.2108e-02, -0.0000e+00,  4.5351e-03,  4.2242e-02,\n",
      "          2.2391e-02, -5.4819e-02, -4.6013e-02, -8.5395e-03, -5.2488e-02,\n",
      "          0.0000e+00,  0.0000e+00, -8.2814e-02, -0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -4.3204e-02, -0.0000e+00, -7.5615e-02,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.7937e-02,\n",
      "          0.0000e+00, -9.4882e-02, -0.0000e+00,  0.0000e+00,  1.1385e-02],\n",
      "        [-0.0000e+00,  0.0000e+00, -1.7305e-02,  0.0000e+00, -5.6171e-02,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00,  8.0603e-02,  0.0000e+00,\n",
      "          6.1985e-02,  0.0000e+00,  0.0000e+00, -8.9560e-02, -0.0000e+00,\n",
      "         -0.0000e+00, -6.0535e-02, -0.0000e+00, -0.0000e+00,  4.4948e-03,\n",
      "         -2.9703e-02, -0.0000e+00, -3.7124e-02, -5.2287e-03,  0.0000e+00,\n",
      "          0.0000e+00,  7.2980e-02, -7.1637e-02,  1.5007e-02,  7.6354e-02,\n",
      "         -0.0000e+00,  0.0000e+00, -7.5987e-02,  7.0055e-02, -0.0000e+00,\n",
      "         -1.4727e-02, -4.8645e-02, -1.1318e-02, -7.2787e-02, -8.5809e-02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -8.5115e-02, -3.4233e-02,  2.6600e-02, -0.0000e+00, -8.9734e-02,\n",
      "         -2.9848e-02, -0.0000e+00, -0.0000e+00, -6.4174e-02,  0.0000e+00,\n",
      "         -0.0000e+00,  1.3251e-03, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -8.2233e-02, -8.8451e-02, -3.0182e-02, -5.3512e-02, -2.1481e-02,\n",
      "          3.2529e-02, -0.0000e+00, -2.4411e-02,  1.7425e-02, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -6.9140e-02,  0.0000e+00, -0.0000e+00,\n",
      "          2.7695e-02,  5.6199e-02, -0.0000e+00, -9.3859e-02, -8.3471e-02,\n",
      "         -3.0951e-02,  0.0000e+00, -9.3558e-02, -6.4456e-02,  7.8868e-02,\n",
      "          0.0000e+00,  5.9729e-02,  9.2653e-02,  2.3326e-02, -5.0957e-02,\n",
      "          8.5772e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7385e-02,\n",
      "          6.2939e-02, -9.0154e-02, -0.0000e+00, -4.2511e-02, -0.0000e+00],\n",
      "        [ 7.8881e-02,  0.0000e+00,  0.0000e+00, -7.9764e-02, -5.3924e-02,\n",
      "         -6.6157e-02,  0.0000e+00, -2.9528e-02, -0.0000e+00,  0.0000e+00,\n",
      "          6.9484e-02, -1.1263e-02,  0.0000e+00, -4.1696e-02,  1.6008e-02,\n",
      "         -3.8552e-02,  7.4023e-02, -6.2297e-02,  0.0000e+00,  6.5969e-02,\n",
      "          6.0524e-02,  0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "         -7.6911e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -2.3329e-02,  0.0000e+00,  0.0000e+00, -3.1405e-02,\n",
      "          4.7388e-02, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -8.0105e-02,  3.9859e-02,  3.7394e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  8.4782e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          9.2856e-02,  7.6665e-03,  1.1751e-02, -8.5920e-03, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  4.5682e-02,\n",
      "          0.0000e+00, -4.2407e-02,  0.0000e+00, -7.6668e-02, -7.2633e-03,\n",
      "         -9.6783e-02, -5.4306e-02, -0.0000e+00, -3.8658e-02,  0.0000e+00,\n",
      "         -8.9051e-02, -3.4464e-02, -6.2654e-02,  3.7427e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  3.0379e-02,  8.9745e-02, -0.0000e+00,  0.0000e+00,\n",
      "          7.5331e-02, -0.0000e+00,  7.3851e-02,  0.0000e+00,  3.7491e-02,\n",
      "         -0.0000e+00, -8.5364e-02, -6.7741e-02,  9.9076e-02,  9.4130e-02,\n",
      "         -5.9844e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00,  8.4844e-02,\n",
      "          8.3589e-03,  0.0000e+00,  2.6495e-02, -9.5367e-02, -6.4183e-02],\n",
      "        [-7.8338e-02, -0.0000e+00,  5.7509e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00, -5.2056e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  9.6065e-03,  1.1888e-02, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -5.4344e-02, -2.5875e-02,  1.7173e-02,  1.7512e-02,\n",
      "          0.0000e+00, -8.3441e-03,  0.0000e+00,  8.5510e-02,  6.9067e-02,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00,  3.3061e-02, -1.6427e-02,\n",
      "          0.0000e+00,  0.0000e+00, -6.9334e-02,  3.2650e-02,  1.0842e-02,\n",
      "         -8.4125e-03, -0.0000e+00, -1.6997e-02,  0.0000e+00,  2.1755e-02,\n",
      "         -0.0000e+00,  7.1404e-02, -2.6809e-02, -0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00,  3.0676e-02,  0.0000e+00, -0.0000e+00,\n",
      "          8.8116e-02, -1.5254e-02,  0.0000e+00,  9.8357e-02, -0.0000e+00,\n",
      "         -9.8260e-03, -0.0000e+00, -0.0000e+00, -8.1234e-02,  0.0000e+00,\n",
      "          1.5767e-02,  1.1276e-02, -0.0000e+00,  3.7977e-02, -0.0000e+00,\n",
      "          0.0000e+00,  4.8764e-02,  0.0000e+00,  0.0000e+00, -5.9490e-02,\n",
      "          0.0000e+00,  0.0000e+00,  3.1905e-02, -4.5310e-02,  6.9461e-02,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -1.3871e-02, -5.0938e-02, -6.1695e-02, -0.0000e+00,  6.9604e-02,\n",
      "          9.5036e-02, -1.6632e-03,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "         -1.1181e-02, -2.2639e-02, -7.5351e-02, -4.4257e-02, -0.0000e+00,\n",
      "         -5.7966e-02, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.4042e-02,  9.2409e-02, -0.0000e+00,  4.2020e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00, -3.3398e-02, -0.0000e+00, -0.0000e+00,\n",
      "         -1.8483e-02, -2.5634e-03, -2.7238e-02,  0.0000e+00,  7.5894e-02,\n",
      "         -2.5077e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          7.8025e-03, -0.0000e+00, -0.0000e+00, -5.7887e-02, -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00,  3.6089e-02, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.8805e-03,  0.0000e+00, -0.0000e+00, -1.4640e-02,\n",
      "          4.0908e-03,  0.0000e+00, -6.5339e-02,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00,  1.2410e-02,  3.6039e-02, -0.0000e+00,\n",
      "          0.0000e+00,  4.7951e-02,  6.5015e-02,  7.1451e-02, -4.9610e-02,\n",
      "         -0.0000e+00, -0.0000e+00,  5.9925e-02,  0.0000e+00,  9.5723e-02,\n",
      "          8.5953e-02, -0.0000e+00,  7.8910e-02, -0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -7.3957e-02,  7.4401e-02, -8.5661e-02, -0.0000e+00,\n",
      "          7.5791e-02, -4.0358e-02, -3.7015e-02, -0.0000e+00, -9.9673e-03,\n",
      "          0.0000e+00,  5.6664e-02,  5.9673e-02,  0.0000e+00, -5.4984e-02,\n",
      "         -8.3971e-02, -0.0000e+00, -0.0000e+00,  4.7795e-03,  4.0649e-02,\n",
      "          0.0000e+00,  3.3166e-02,  0.0000e+00, -7.2218e-02,  0.0000e+00,\n",
      "         -9.4219e-02,  9.8193e-02, -9.4529e-02, -9.3341e-02,  0.0000e+00,\n",
      "          0.0000e+00, -6.3336e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -5.2818e-02, -5.0812e-03, -1.8184e-02]],\n",
      "       device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, p in model1.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(p)\n",
    "        p.data *= cp_mask[i]\n",
    "        i += 1\n",
    "        print(p)\n",
    "        #tensor = p.data.cpu().numpy()\n",
    "        #grad_tensor = p.grad.data.cpu().numpy()\n",
    "        #grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "        #p.grad.data = torch.from_numpy(grad_tensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0055,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0280],\n",
      "        [-0.0253,  0.0169,  0.0000,  ...,  0.0142, -0.0000,  0.0041],\n",
      "        [-0.0003,  0.0040, -0.0000,  ...,  0.0205,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0320, -0.0000, -0.0003,  ..., -0.0050,  0.0115,  0.0000],\n",
      "        [-0.0019,  0.0000,  0.0064,  ...,  0.0303, -0.0193,  0.0258],\n",
      "        [-0.0000,  0.0074, -0.0007,  ..., -0.0009,  0.0000,  0.0000]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0169, -0.0199, -0.0328,  0.0191,  0.0172,  0.0355,  0.0088, -0.0141,\n",
      "         0.0308,  0.0025, -0.0344, -0.0273,  0.0210, -0.0240, -0.0250, -0.0049,\n",
      "        -0.0070,  0.0016, -0.0011, -0.0342, -0.0324,  0.0204, -0.0126, -0.0167,\n",
      "         0.0272, -0.0043, -0.0271, -0.0038,  0.0315,  0.0349,  0.0049,  0.0242,\n",
      "        -0.0203, -0.0336, -0.0171,  0.0137, -0.0049,  0.0161,  0.0032, -0.0012,\n",
      "        -0.0185, -0.0222,  0.0306, -0.0319,  0.0255, -0.0293,  0.0043,  0.0262,\n",
      "         0.0164, -0.0260,  0.0175, -0.0307,  0.0078,  0.0159, -0.0272,  0.0069,\n",
      "         0.0216,  0.0067,  0.0083,  0.0292, -0.0117, -0.0093, -0.0264,  0.0203,\n",
      "        -0.0098,  0.0258,  0.0254, -0.0243, -0.0111, -0.0052,  0.0312,  0.0065,\n",
      "         0.0148,  0.0080, -0.0030,  0.0085, -0.0266,  0.0087, -0.0018, -0.0087,\n",
      "        -0.0201, -0.0016,  0.0256, -0.0069,  0.0012,  0.0278,  0.0263, -0.0199,\n",
      "         0.0098, -0.0048, -0.0034,  0.0022, -0.0085, -0.0341, -0.0079,  0.0127,\n",
      "        -0.0234, -0.0050,  0.0193,  0.0016,  0.0223, -0.0074, -0.0340,  0.0219,\n",
      "         0.0168, -0.0314, -0.0316,  0.0070,  0.0075, -0.0090,  0.0255, -0.0093,\n",
      "         0.0327, -0.0137,  0.0238, -0.0063, -0.0010,  0.0176, -0.0016, -0.0177,\n",
      "         0.0315, -0.0140, -0.0138,  0.0051,  0.0333, -0.0244, -0.0341, -0.0099,\n",
      "        -0.0161, -0.0088,  0.0230, -0.0034,  0.0177, -0.0089,  0.0005, -0.0103,\n",
      "         0.0225,  0.0319, -0.0130,  0.0038,  0.0147,  0.0267, -0.0351,  0.0197,\n",
      "         0.0261, -0.0254,  0.0040,  0.0112,  0.0006, -0.0277, -0.0271, -0.0273,\n",
      "        -0.0326,  0.0153, -0.0296, -0.0133,  0.0203, -0.0125,  0.0117, -0.0092,\n",
      "         0.0259, -0.0148,  0.0246,  0.0041,  0.0132,  0.0338,  0.0223, -0.0097,\n",
      "         0.0189, -0.0330,  0.0259, -0.0131, -0.0348, -0.0239,  0.0183, -0.0282,\n",
      "         0.0290, -0.0231,  0.0269,  0.0193, -0.0120, -0.0123,  0.0157,  0.0237,\n",
      "         0.0089,  0.0090,  0.0099,  0.0139,  0.0104, -0.0267,  0.0005,  0.0341,\n",
      "         0.0056,  0.0027,  0.0119, -0.0189,  0.0292, -0.0232, -0.0171, -0.0157,\n",
      "        -0.0098, -0.0282, -0.0200,  0.0138,  0.0320,  0.0162, -0.0321,  0.0313,\n",
      "        -0.0128, -0.0325,  0.0084, -0.0194, -0.0268, -0.0117, -0.0308, -0.0047,\n",
      "        -0.0112, -0.0096,  0.0211, -0.0111,  0.0314, -0.0167, -0.0348, -0.0300,\n",
      "         0.0081,  0.0285, -0.0154,  0.0212, -0.0141, -0.0044,  0.0031,  0.0111,\n",
      "         0.0315, -0.0174, -0.0215, -0.0301,  0.0185, -0.0305, -0.0325, -0.0275,\n",
      "         0.0117, -0.0101, -0.0316,  0.0293, -0.0310,  0.0051,  0.0067,  0.0237,\n",
      "        -0.0154,  0.0027,  0.0150, -0.0081, -0.0026, -0.0275,  0.0064,  0.0111,\n",
      "         0.0035,  0.0016, -0.0114,  0.0326, -0.0304,  0.0128,  0.0106,  0.0209,\n",
      "         0.0010, -0.0248, -0.0333, -0.0046,  0.0252, -0.0270,  0.0283,  0.0153,\n",
      "         0.0087,  0.0264,  0.0183, -0.0341,  0.0303, -0.0253, -0.0068,  0.0143,\n",
      "         0.0199,  0.0155, -0.0306,  0.0144, -0.0288,  0.0341,  0.0002,  0.0273,\n",
      "         0.0027,  0.0193,  0.0332,  0.0309,  0.0281, -0.0222,  0.0264,  0.0154,\n",
      "         0.0042, -0.0082,  0.0166, -0.0004], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0000,  0.0486, -0.0000,  ...,  0.0000, -0.0000, -0.0017],\n",
      "        [-0.0457, -0.0000, -0.0189,  ...,  0.0372, -0.0000,  0.0000],\n",
      "        [ 0.0259,  0.0000, -0.0000,  ...,  0.0512, -0.0481, -0.0239],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0015,  0.0102, -0.0244],\n",
      "        [-0.0334, -0.0000,  0.0000,  ...,  0.0251, -0.0535,  0.0000],\n",
      "        [ 0.0305,  0.0000,  0.0350,  ...,  0.0000, -0.0458,  0.0000]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0320, -0.0445,  0.0324, -0.0119, -0.0435, -0.0009, -0.0244, -0.0482,\n",
      "        -0.0286,  0.0134, -0.0373, -0.0239,  0.0422, -0.0010, -0.0379, -0.0453,\n",
      "         0.0098,  0.0431, -0.0576,  0.0148, -0.0507,  0.0305, -0.0301, -0.0049,\n",
      "        -0.0546,  0.0458,  0.0313,  0.0512, -0.0129, -0.0204,  0.0309, -0.0339,\n",
      "        -0.0031, -0.0359,  0.0380,  0.0057,  0.0285, -0.0287, -0.0190, -0.0568,\n",
      "        -0.0048,  0.0295, -0.0336, -0.0359,  0.0052, -0.0190,  0.0374, -0.0084,\n",
      "        -0.0507,  0.0112, -0.0502,  0.0482,  0.0007,  0.0536,  0.0399,  0.0307,\n",
      "        -0.0241, -0.0459,  0.0455, -0.0402,  0.0062, -0.0200,  0.0289, -0.0400,\n",
      "         0.0570, -0.0370, -0.0081, -0.0150, -0.0102,  0.0526, -0.0521,  0.0533,\n",
      "         0.0181,  0.0109,  0.0197,  0.0545, -0.0553, -0.0092, -0.0177, -0.0400,\n",
      "        -0.0172, -0.0447,  0.0434,  0.0221, -0.0103, -0.0203,  0.0041, -0.0573,\n",
      "        -0.0131,  0.0179, -0.0400, -0.0062,  0.0318, -0.0252,  0.0434, -0.0173,\n",
      "         0.0015, -0.0126, -0.0238,  0.0323], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.6692e-02,  5.7925e-02,  0.0000e+00,  6.4826e-02, -9.5745e-02,\n",
      "         -0.0000e+00, -4.5858e-02,  9.6519e-02, -0.0000e+00,  0.0000e+00,\n",
      "          1.0981e-02,  0.0000e+00,  7.1501e-02, -9.2763e-02,  0.0000e+00,\n",
      "          0.0000e+00, -4.9081e-03, -7.7878e-02, -0.0000e+00,  0.0000e+00,\n",
      "          1.3399e-03, -0.0000e+00,  4.5084e-02,  2.5436e-02, -0.0000e+00,\n",
      "         -0.0000e+00, -1.6423e-02,  5.0592e-02, -7.8457e-02, -0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.9920e-02, -0.0000e+00, -8.1334e-02,\n",
      "          0.0000e+00,  4.6495e-02, -3.0082e-02,  5.7108e-02,  4.8580e-02,\n",
      "         -3.5659e-02, -8.2428e-02,  4.0949e-02, -1.1595e-02,  1.9747e-02,\n",
      "          1.6504e-02,  0.0000e+00, -1.2951e-02,  1.1087e-02,  2.4257e-02,\n",
      "          4.6752e-02,  0.0000e+00,  6.4416e-02,  3.4870e-02, -3.0989e-03,\n",
      "         -6.1354e-02,  2.7242e-02,  0.0000e+00,  0.0000e+00, -2.9060e-02,\n",
      "         -2.8845e-02, -0.0000e+00, -9.1525e-02,  7.4917e-02,  5.5532e-02,\n",
      "          0.0000e+00, -8.6140e-02,  0.0000e+00, -7.0273e-02, -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -0.0000e+00,  9.0515e-02, -1.7237e-02,\n",
      "          0.0000e+00,  6.4577e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "         -1.1569e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00,  1.6966e-02, -0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-0.0000e+00,  0.0000e+00,  7.3212e-02, -0.0000e+00, -3.9302e-02,\n",
      "          8.2285e-02,  0.0000e+00,  0.0000e+00, -7.1011e-02, -5.7157e-02,\n",
      "         -0.0000e+00,  0.0000e+00, -0.0000e+00,  7.6172e-02,  0.0000e+00,\n",
      "          6.6943e-02,  0.0000e+00, -0.0000e+00, -0.0000e+00,  5.1171e-02,\n",
      "         -0.0000e+00,  5.0262e-03,  3.0659e-02, -4.7461e-02, -5.4333e-02,\n",
      "          7.8699e-02, -6.7464e-02,  5.0289e-02, -0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00, -7.5811e-02, -0.0000e+00,  5.4371e-02, -3.4004e-02,\n",
      "          4.0953e-02,  0.0000e+00, -0.0000e+00, -0.0000e+00,  4.0939e-02,\n",
      "         -2.7567e-02, -5.7234e-02, -6.4809e-02, -6.1892e-02,  0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00,  5.8137e-02, -7.4272e-02, -3.7806e-02,\n",
      "          0.0000e+00, -5.0000e-02,  0.0000e+00, -7.3739e-02, -2.3944e-02,\n",
      "         -0.0000e+00, -5.9568e-02,  0.0000e+00, -5.7522e-02,  0.0000e+00,\n",
      "          0.0000e+00,  5.9194e-02, -0.0000e+00,  6.7138e-02,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00,  0.0000e+00, -6.1912e-02, -0.0000e+00,\n",
      "         -8.2557e-02,  0.0000e+00,  8.0828e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4039e-02,\n",
      "         -4.0586e-02,  8.1406e-02,  2.1659e-02, -0.0000e+00, -1.8441e-02,\n",
      "          0.0000e+00, -0.0000e+00, -7.0051e-03,  4.8154e-03, -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00,  3.7619e-02, -1.7281e-02,  0.0000e+00,\n",
      "          0.0000e+00,  6.4268e-02,  0.0000e+00, -0.0000e+00,  8.5840e-02],\n",
      "        [-6.8799e-02,  0.0000e+00, -6.9064e-02, -6.9134e-02,  1.4304e-02,\n",
      "         -0.0000e+00,  3.7288e-02,  0.0000e+00,  6.6688e-02, -0.0000e+00,\n",
      "          0.0000e+00,  5.7820e-02, -0.0000e+00,  5.8129e-05, -6.0334e-02,\n",
      "         -0.0000e+00, -2.6216e-02,  0.0000e+00, -6.4849e-02,  5.7880e-02,\n",
      "          5.0649e-03,  2.5900e-02, -4.8343e-02,  0.0000e+00, -0.0000e+00,\n",
      "          6.3736e-02,  1.2909e-02, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00,  0.0000e+00, -9.6934e-02, -5.2665e-02,\n",
      "          0.0000e+00,  4.2798e-02,  2.1979e-02, -6.1097e-02, -7.4378e-03,\n",
      "         -1.6972e-02, -6.7518e-02,  0.0000e+00, -0.0000e+00, -7.4872e-02,\n",
      "         -1.2834e-03, -0.0000e+00,  2.1689e-02,  0.0000e+00,  2.8725e-02,\n",
      "          0.0000e+00,  0.0000e+00,  7.7047e-02, -1.9401e-02,  6.5992e-02,\n",
      "          0.0000e+00,  0.0000e+00, -1.9139e-02, -0.0000e+00,  1.1732e-02,\n",
      "          2.0522e-02, -0.0000e+00, -0.0000e+00,  9.6905e-03, -7.4073e-02,\n",
      "         -6.0378e-03, -0.0000e+00,  0.0000e+00,  0.0000e+00, -3.9630e-02,\n",
      "         -1.0643e-02, -1.9607e-02,  0.0000e+00,  6.5165e-02,  8.7195e-02,\n",
      "         -2.9111e-02, -8.2422e-02,  3.9261e-02,  5.0854e-02,  7.1820e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -5.5916e-02,\n",
      "          0.0000e+00, -2.9082e-02,  1.2693e-02, -5.2362e-02, -8.2601e-02,\n",
      "         -0.0000e+00, -0.0000e+00,  9.4360e-02, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -3.9686e-02,  0.0000e+00,  6.7259e-02,  3.8146e-02],\n",
      "        [-0.0000e+00, -0.0000e+00, -3.6514e-02, -1.3154e-03, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -9.7609e-02,\n",
      "          7.1225e-02, -8.3026e-02, -0.0000e+00, -0.0000e+00, -1.9494e-02,\n",
      "          0.0000e+00,  2.8724e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "          2.4622e-02,  0.0000e+00, -4.3826e-02,  0.0000e+00,  5.3253e-03,\n",
      "         -1.7339e-02, -0.0000e+00,  4.8552e-03, -1.8751e-03, -4.2650e-02,\n",
      "         -0.0000e+00,  3.0659e-02,  4.8537e-02, -0.0000e+00,  3.7254e-02,\n",
      "          7.9007e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0055e-02,  7.9463e-02, -5.7138e-02, -7.2923e-02, -4.6275e-02,\n",
      "         -6.3530e-02, -5.6681e-02,  0.0000e+00,  6.5301e-02,  0.0000e+00,\n",
      "          0.0000e+00, -2.0690e-02, -5.4259e-02, -4.6744e-02, -5.5244e-02,\n",
      "          0.0000e+00, -7.7237e-02, -0.0000e+00, -0.0000e+00, -9.2181e-02,\n",
      "         -0.0000e+00,  3.7303e-02, -0.0000e+00, -9.6921e-02, -4.8364e-03,\n",
      "         -9.4379e-02, -0.0000e+00, -5.7863e-02,  0.0000e+00,  3.0934e-02,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          9.2719e-02,  0.0000e+00, -5.8689e-02,  3.3277e-02, -0.0000e+00,\n",
      "          0.0000e+00,  5.5784e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "          3.5695e-02,  0.0000e+00, -9.5670e-02, -0.0000e+00,  6.3655e-02,\n",
      "          2.7921e-02,  0.0000e+00, -1.4763e-02,  2.1263e-02,  0.0000e+00],\n",
      "        [ 0.0000e+00, -4.4854e-02,  0.0000e+00, -0.0000e+00,  7.7945e-02,\n",
      "          2.1251e-02, -0.0000e+00,  1.5282e-03, -8.3026e-02, -0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  2.4671e-02, -4.6497e-03,  0.0000e+00,\n",
      "         -9.0578e-02, -0.0000e+00, -0.0000e+00,  8.3700e-03,  0.0000e+00,\n",
      "          0.0000e+00,  8.9718e-02, -7.1330e-03, -0.0000e+00,  0.0000e+00,\n",
      "          4.0138e-02, -2.9807e-02, -0.0000e+00, -0.0000e+00, -7.4433e-02,\n",
      "         -1.9677e-02, -0.0000e+00, -3.7503e-02, -0.0000e+00,  0.0000e+00,\n",
      "          7.6769e-02, -0.0000e+00,  0.0000e+00, -5.8893e-02, -4.1678e-03,\n",
      "         -0.0000e+00,  0.0000e+00, -0.0000e+00,  7.6782e-02, -0.0000e+00,\n",
      "         -6.7774e-02,  0.0000e+00, -0.0000e+00,  3.2500e-02,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  2.4787e-02,  0.0000e+00, -0.0000e+00,\n",
      "          4.8275e-02, -7.9600e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          0.0000e+00, -4.7323e-02,  8.2209e-02, -2.1183e-02,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.2144e-02, -6.2285e-02, -1.1857e-02,\n",
      "          0.0000e+00, -0.0000e+00, -8.9094e-02,  2.4624e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  3.5679e-02, -0.0000e+00, -3.2767e-03, -0.0000e+00,\n",
      "         -9.2719e-02, -0.0000e+00, -0.0000e+00,  1.3611e-02, -9.3257e-02,\n",
      "          4.7689e-02,  5.7823e-02, -3.0199e-03,  0.0000e+00, -7.8295e-02,\n",
      "          0.0000e+00,  0.0000e+00, -0.0000e+00,  5.8233e-02, -4.3593e-02,\n",
      "          0.0000e+00,  0.0000e+00, -0.0000e+00,  5.9913e-02, -1.1855e-02],\n",
      "        [ 4.0780e-02, -0.0000e+00, -0.0000e+00,  0.0000e+00, -9.7846e-02,\n",
      "          5.2777e-02, -0.0000e+00, -0.0000e+00,  6.5670e-02, -5.7431e-02,\n",
      "         -5.9341e-02, -0.0000e+00, -3.6787e-02, -0.0000e+00, -8.5559e-02,\n",
      "         -0.0000e+00, -0.0000e+00, -7.0612e-02, -0.0000e+00, -0.0000e+00,\n",
      "          6.8273e-02, -0.0000e+00, -5.2385e-03, -0.0000e+00,  9.3852e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  3.7290e-02,\n",
      "          4.9539e-02, -0.0000e+00, -2.0255e-02, -7.5215e-02, -0.0000e+00,\n",
      "         -6.5916e-02, -6.8860e-02, -4.4360e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -1.2582e-03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  5.8087e-02,  0.0000e+00,  8.8047e-02,\n",
      "          7.2891e-02, -7.9757e-02, -2.8243e-02, -0.0000e+00,  2.1113e-02,\n",
      "         -0.0000e+00, -4.2786e-02,  1.2603e-02,  0.0000e+00, -2.3150e-03,\n",
      "         -3.8106e-02, -0.0000e+00, -1.6805e-02,  0.0000e+00, -0.0000e+00,\n",
      "          8.9759e-02, -2.7146e-02,  4.4691e-02,  4.6966e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  6.2108e-02, -0.0000e+00,  4.5351e-03,  4.2242e-02,\n",
      "          2.2391e-02, -5.4819e-02, -4.6013e-02, -8.5395e-03, -5.2488e-02,\n",
      "          0.0000e+00,  0.0000e+00, -8.2814e-02, -0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -4.3204e-02, -0.0000e+00, -7.5615e-02,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.7937e-02,\n",
      "          0.0000e+00, -9.4882e-02, -0.0000e+00,  0.0000e+00,  1.1385e-02],\n",
      "        [-0.0000e+00,  0.0000e+00, -1.7305e-02,  0.0000e+00, -5.6171e-02,\n",
      "          0.0000e+00, -0.0000e+00, -0.0000e+00,  8.0603e-02,  0.0000e+00,\n",
      "          6.1985e-02,  0.0000e+00,  0.0000e+00, -8.9560e-02, -0.0000e+00,\n",
      "         -0.0000e+00, -6.0535e-02, -0.0000e+00, -0.0000e+00,  4.4948e-03,\n",
      "         -2.9703e-02, -0.0000e+00, -3.7124e-02, -5.2287e-03,  0.0000e+00,\n",
      "          0.0000e+00,  7.2980e-02, -7.1637e-02,  1.5007e-02,  7.6354e-02,\n",
      "         -0.0000e+00,  0.0000e+00, -7.5987e-02,  7.0055e-02, -0.0000e+00,\n",
      "         -1.4727e-02, -4.8645e-02, -1.1318e-02, -7.2787e-02, -8.5809e-02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -8.5115e-02, -3.4233e-02,  2.6600e-02, -0.0000e+00, -8.9734e-02,\n",
      "         -2.9848e-02, -0.0000e+00, -0.0000e+00, -6.4174e-02,  0.0000e+00,\n",
      "         -0.0000e+00,  1.3251e-03, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -8.2233e-02, -8.8451e-02, -3.0182e-02, -5.3512e-02, -2.1481e-02,\n",
      "          3.2529e-02, -0.0000e+00, -2.4411e-02,  1.7425e-02, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -6.9140e-02,  0.0000e+00, -0.0000e+00,\n",
      "          2.7695e-02,  5.6199e-02, -0.0000e+00, -9.3859e-02, -8.3471e-02,\n",
      "         -3.0951e-02,  0.0000e+00, -9.3558e-02, -6.4456e-02,  7.8868e-02,\n",
      "          0.0000e+00,  5.9729e-02,  9.2653e-02,  2.3326e-02, -5.0957e-02,\n",
      "          8.5772e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7385e-02,\n",
      "          6.2939e-02, -9.0154e-02, -0.0000e+00, -4.2511e-02, -0.0000e+00],\n",
      "        [ 7.8881e-02,  0.0000e+00,  0.0000e+00, -7.9764e-02, -5.3924e-02,\n",
      "         -6.6157e-02,  0.0000e+00, -2.9528e-02, -0.0000e+00,  0.0000e+00,\n",
      "          6.9484e-02, -1.1263e-02,  0.0000e+00, -4.1696e-02,  1.6008e-02,\n",
      "         -3.8552e-02,  7.4023e-02, -6.2297e-02,  0.0000e+00,  6.5969e-02,\n",
      "          6.0524e-02,  0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "         -7.6911e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -2.3329e-02,  0.0000e+00,  0.0000e+00, -3.1405e-02,\n",
      "          4.7388e-02, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -8.0105e-02,  3.9859e-02,  3.7394e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  8.4782e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          9.2856e-02,  7.6665e-03,  1.1751e-02, -8.5920e-03, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  4.5682e-02,\n",
      "          0.0000e+00, -4.2407e-02,  0.0000e+00, -7.6668e-02, -7.2633e-03,\n",
      "         -9.6783e-02, -5.4306e-02, -0.0000e+00, -3.8658e-02,  0.0000e+00,\n",
      "         -8.9051e-02, -3.4464e-02, -6.2654e-02,  3.7427e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  3.0379e-02,  8.9745e-02, -0.0000e+00,  0.0000e+00,\n",
      "          7.5331e-02, -0.0000e+00,  7.3851e-02,  0.0000e+00,  3.7491e-02,\n",
      "         -0.0000e+00, -8.5364e-02, -6.7741e-02,  9.9076e-02,  9.4130e-02,\n",
      "         -5.9844e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00,  8.4844e-02,\n",
      "          8.3589e-03,  0.0000e+00,  2.6495e-02, -9.5367e-02, -6.4183e-02],\n",
      "        [-7.8338e-02, -0.0000e+00,  5.7509e-02,  0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00, -5.2056e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  9.6065e-03,  1.1888e-02, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -5.4344e-02, -2.5875e-02,  1.7173e-02,  1.7512e-02,\n",
      "          0.0000e+00, -8.3441e-03,  0.0000e+00,  8.5510e-02,  6.9067e-02,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00,  3.3061e-02, -1.6427e-02,\n",
      "          0.0000e+00,  0.0000e+00, -6.9334e-02,  3.2650e-02,  1.0842e-02,\n",
      "         -8.4125e-03, -0.0000e+00, -1.6997e-02,  0.0000e+00,  2.1755e-02,\n",
      "         -0.0000e+00,  7.1404e-02, -2.6809e-02, -0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00,  3.0676e-02,  0.0000e+00, -0.0000e+00,\n",
      "          8.8116e-02, -1.5254e-02,  0.0000e+00,  9.8357e-02, -0.0000e+00,\n",
      "         -9.8260e-03, -0.0000e+00, -0.0000e+00, -8.1234e-02,  0.0000e+00,\n",
      "          1.5767e-02,  1.1276e-02, -0.0000e+00,  3.7977e-02, -0.0000e+00,\n",
      "          0.0000e+00,  4.8764e-02,  0.0000e+00,  0.0000e+00, -5.9490e-02,\n",
      "          0.0000e+00,  0.0000e+00,  3.1905e-02, -4.5310e-02,  6.9461e-02,\n",
      "         -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         -1.3871e-02, -5.0938e-02, -6.1695e-02, -0.0000e+00,  6.9604e-02,\n",
      "          9.5036e-02, -1.6632e-03,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "         -1.1181e-02, -2.2639e-02, -7.5351e-02, -4.4257e-02, -0.0000e+00,\n",
      "         -5.7966e-02, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.4042e-02,  9.2409e-02, -0.0000e+00,  4.2020e-02, -0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00, -3.3398e-02, -0.0000e+00, -0.0000e+00,\n",
      "         -1.8483e-02, -2.5634e-03, -2.7238e-02,  0.0000e+00,  7.5894e-02,\n",
      "         -2.5077e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          7.8025e-03, -0.0000e+00, -0.0000e+00, -5.7887e-02, -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00,  3.6089e-02, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.8805e-03,  0.0000e+00, -0.0000e+00, -1.4640e-02,\n",
      "          4.0908e-03,  0.0000e+00, -6.5339e-02,  0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  0.0000e+00,  1.2410e-02,  3.6039e-02, -0.0000e+00,\n",
      "          0.0000e+00,  4.7951e-02,  6.5015e-02,  7.1451e-02, -4.9610e-02,\n",
      "         -0.0000e+00, -0.0000e+00,  5.9925e-02,  0.0000e+00,  9.5723e-02,\n",
      "          8.5953e-02, -0.0000e+00,  7.8910e-02, -0.0000e+00,  0.0000e+00,\n",
      "         -0.0000e+00, -7.3957e-02,  7.4401e-02, -8.5661e-02, -0.0000e+00,\n",
      "          7.5791e-02, -4.0358e-02, -3.7015e-02, -0.0000e+00, -9.9673e-03,\n",
      "          0.0000e+00,  5.6664e-02,  5.9673e-02,  0.0000e+00, -5.4984e-02,\n",
      "         -8.3971e-02, -0.0000e+00, -0.0000e+00,  4.7795e-03,  4.0649e-02,\n",
      "          0.0000e+00,  3.3166e-02,  0.0000e+00, -7.2218e-02,  0.0000e+00,\n",
      "         -9.4219e-02,  9.8193e-02, -9.4529e-02, -9.3341e-02,  0.0000e+00,\n",
      "          0.0000e+00, -6.3336e-02,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00, -5.2818e-02, -5.0812e-03, -1.8184e-02]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0847,  0.0326,  0.0793, -0.0956, -0.0551, -0.0741,  0.0840,  0.0447,\n",
      "         0.0342, -0.0456], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, p in model1.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = cm.LeNet300().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc3\n"
     ]
    }
   ],
   "source": [
    "for name, module in model1.named_modules():\n",
    "    \n",
    "    if isinstance(module, nn.Linear):\n",
    "        #print(module)\n",
    "        if name == 'fc3':\n",
    "            print(name)\n",
    "            prune.l1_unstructured(module, name = 'weight', amount = 0.1)\n",
    "        else:\n",
    "            prune.l1_unstructured(module, name = 'weight', amount = 0.99)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fc1.weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1\n",
      "fc2\n",
      "fc3\n"
     ]
    }
   ],
   "source": [
    "for name, module in model1.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        print(name)\n",
    "    #if isinstance(module, nn.Linear):\n",
    "       # print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "         0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 0., 1., 1., 0., 1.],\n",
       "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "         1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 0., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "         0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "         1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 0., 1., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 0., 0., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "         1., 0., 0., 1., 1., 0., 1., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "         0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 0., 1., 0., 0.]], device='cuda:1')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fc3.weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
