{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import visdom\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# visdom setting\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")\n",
    "\n",
    "# make plot\n",
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),\n",
    "                    opts=dict(title = 'VGG_Loss_Tracker',\n",
    "                              legend=['T_loss', 'V_loss'],\n",
    "                             showlegend=True\n",
    "                             )\n",
    "                   )\n",
    "\n",
    "def loss_tracker(loss_plot, loss_value, num, name):\n",
    "    vis.line(X = num,\n",
    "            Y = loss_value,\n",
    "            win = loss_plot,\n",
    "            name = name,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "torch.manual_seed(555)\n",
    "torch.cuda.manual_seed_all(555)\n",
    "np.random.seed(555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정된 학습용 기기 : cuda:1\n"
     ]
    }
   ],
   "source": [
    "# CUDA 설정\n",
    "\n",
    "GPU_NUM = 1\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#device = torch.device('cuda')\n",
    "print(\"설정된 학습용 기기 :\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "lr = 0.01\n",
    "epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 전처리\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                               ])\n",
    "\n",
    "# Data load\n",
    "trainsets = dsets.CIFAR10('../CIFAR10/',\n",
    "                         train=True,\n",
    "                         transform = transform,\n",
    "                         download=False)\n",
    "\n",
    "valsets = dsets.CIFAR10('../CIFAR10/',\n",
    "                         train=True,\n",
    "                         transform = transform,\n",
    "                         download=False)\n",
    "\n",
    "testsets = dsets.CIFAR10('../CIFAR10/',\n",
    "                         train=False,\n",
    "                         transform = transform,\n",
    "                         download=False)\n",
    "\n",
    "# validation set 분류\n",
    "validation_ratio = 0.15\n",
    "num_train = len(trainsets)\n",
    "indices = list(range(num_train))\n",
    "# 설정한 비율만큼 분할 시의 data 갯수\n",
    "split = int(np.floor(validation_ratio * num_train))\n",
    "# shuffle\n",
    "np.random.shuffle(indices)\n",
    "# data 분할\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = trainsets,\n",
    "                                          batch_size = batch_size,\n",
    "                                          sampler = train_sampler,\n",
    "                                          drop_last = True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset = valsets,\n",
    "                                          batch_size = batch_size,\n",
    "                                          sampler = val_sampler,\n",
    "                                          drop_last = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = testsets,\n",
    "                                          batch_size = 4,\n",
    "                                          shuffle = False,\n",
    "                                          drop_last = True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog',\n",
    "           'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model output channel 수를 맞춰준다\n",
    "model = models.vgg16()\n",
    "model.classifier._modules['6'] = nn.Linear(4096, 10)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.1265e+19, -2.8121e+20,  3.5264e+20,  3.0976e+19,  5.5099e+19,\n",
      "          2.5883e+20, -1.1299e+20,  7.2047e+19,  1.6618e+20,  2.8962e+20]],\n",
      "       device='cuda:1', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# model's output channel check\n",
    "a = torch.Tensor(1,3,32,32).to(device)\n",
    "out = model(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 훈련 함수\n",
    "def train(model, optimizer, criterion, DataLoader, total_batch):\n",
    "    model.train()    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(DataLoader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss / total_batch\n",
    "    return running_loss \n",
    "    \n",
    "# validation loss 함수\n",
    "def loss_eval(model, criterion, DataLoader, total_batch):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(DataLoader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) \n",
    "            running_loss += loss / total_batch\n",
    "        return running_loss    \n",
    "        \n",
    "# accuracy 계산 함수\n",
    "def accu_eval(DataLoader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(DataLoader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr = lr, momentum=0.9)\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinhyuk/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 1] (T_loss: 2.03288)  (V_loss: 1.667965)  (Val Accuract : 35 %)\n",
      "[epoch : 2] (T_loss: 1.47457)  (V_loss: 1.308382)  (Val Accuract : 53 %)\n",
      "[epoch : 3] (T_loss: 1.16635)  (V_loss: 1.051434)  (Val Accuract : 61 %)\n",
      "[epoch : 4] (T_loss: 0.97139)  (V_loss: 0.940961)  (Val Accuract : 66 %)\n",
      "[epoch : 5] (T_loss: 0.79252)  (V_loss: 0.827494)  (Val Accuract : 71 %)\n",
      "[epoch : 6] (T_loss: 0.66125)  (V_loss: 0.764848)  (Val Accuract : 74 %)\n",
      "[epoch : 7] (T_loss: 0.56624)  (V_loss: 0.751325)  (Val Accuract : 74 %)\n",
      "[epoch : 8] (T_loss: 0.47545)  (V_loss: 0.787173)  (Val Accuract : 74 %)\n",
      "[epoch : 9] (T_loss: 0.39664)  (V_loss: 0.709259)  (Val Accuract : 77 %)\n",
      "[epoch : 10] (T_loss: 0.30656)  (V_loss: 0.747706)  (Val Accuract : 77 %)\n",
      "[epoch : 11] (T_loss: 0.24318)  (V_loss: 0.814971)  (Val Accuract : 77 %)\n",
      "[epoch : 12] (T_loss: 0.21494)  (V_loss: 0.932902)  (Val Accuract : 74 %)\n",
      "[epoch : 13] (T_loss: 0.17160)  (V_loss: 0.840778)  (Val Accuract : 77 %)\n",
      "[epoch : 14] (T_loss: 0.15878)  (V_loss: 0.910184)  (Val Accuract : 76 %)\n",
      "[epoch : 15] (T_loss: 0.10292)  (V_loss: 0.923411)  (Val Accuract : 78 %)\n",
      "[epoch : 16] (T_loss: 0.09166)  (V_loss: 0.906706)  (Val Accuract : 78 %)\n",
      "[epoch : 17] (T_loss: 0.07964)  (V_loss: 1.006570)  (Val Accuract : 78 %)\n",
      "[epoch : 18] (T_loss: 0.06818)  (V_loss: 1.025795)  (Val Accuract : 77 %)\n",
      "[epoch : 19] (T_loss: 0.06100)  (V_loss: 1.130236)  (Val Accuract : 77 %)\n",
      "[epoch : 20] (T_loss: 0.04604)  (V_loss: 1.176101)  (Val Accuract : 77 %)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "t_batch = len(train_loader)\n",
    "v_batch = len(val_loader)\n",
    "print('Learning Start!')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lr_sche.step()\n",
    "    # model training\n",
    "    t_running_loss = train(model, optimizer, criterion, train_loader, t_batch)\n",
    "\n",
    "    # validation loss\n",
    "    v_running_loss = loss_eval(model, criterion, val_loader, v_batch)\n",
    "\n",
    "    # validation accuracy\n",
    "    correct, total = accu_eval(val_loader)\n",
    "\n",
    "    # Plot & print\n",
    "    loss_tracker(loss_plt, torch.Tensor([t_running_loss]), torch.Tensor([epoch]), 'T_loss')\n",
    "    loss_tracker(loss_plt, torch.Tensor([v_running_loss]), torch.Tensor([epoch]), 'V_loss')\n",
    "\n",
    "    print('[epoch : %d] (T_loss: %.5f) ' % (epoch + 1, t_running_loss),\n",
    "          '(V_loss: %5f) ' % (v_running_loss),\n",
    "          '(Val Accuract : %d %%)' % (100 * correct / total)\n",
    "         )\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (testset) : 77.730 %\n"
     ]
    }
   ],
   "source": [
    "# model test\n",
    "correct, total = accu_eval(test_loader)\n",
    "print('Accuracy (testset) : %.3f %%' % (100*correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
