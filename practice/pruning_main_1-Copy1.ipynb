{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import visdom\n",
    "import copy\n",
    "import torch.nn.utils.prune as prune\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "# custom librarys\n",
    "# model, parameters\n",
    "import custom.utils as cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(55)\n",
    "torch.cuda.manual_seed_all(55)\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  2\n",
      "Current cuda device  1\n",
      "GeForce RTX 2080 Ti\n",
      "cpu와 cuda 중 다음 기기로 학습함: cuda:1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 1\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# visdom setting\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")\n",
    "\n",
    "# make plot\n",
    "vis_plt = vis.line(X=torch.Tensor(1).zero_(), Y=torch.Tensor(1).zero_(), \n",
    "                    opts=dict(title = 'LeNet300_Accuracy_Tracker',\n",
    "                              legend=['100'],\n",
    "                             showlegend=True,\n",
    "                              xtickmin = 0,\n",
    "                              xtickmax = 20000,\n",
    "                              ytickmin = 0.95,\n",
    "                              ytickmax = 0.99\n",
    "                             )\n",
    "                   )\n",
    "\n",
    "def visdom_plot(loss_plot, loss_value, num, name):\n",
    "    vis.line(X = num,\n",
    "            Y = loss_value,\n",
    "            win = loss_plot,\n",
    "            name = name,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1.0)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 10\n",
    "x = torch.randn(batch_size, 2)\n",
    "target = torch.randint(0, 2, (batch_size,))\n",
    "\n",
    "# Get weight before training\n",
    "w0 = model[0].weight.detach().clone()\n",
    "\n",
    "# Single training iteration\n",
    "optimizer.zero_grad()\n",
    "output = model(x)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "print('Gradient: ', model[0].weight.grad)\n",
    "optimizer.step()\n",
    "\n",
    "# Compare weight update\n",
    "w1 = model[0].weight.detach().clone()\n",
    "print('Weights updated ', w0!=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f3696e5e5d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Gradient mask\n",
    "gradient_mask = torch.zeros(2, 2)\n",
    "gradient_mask[0, 0] = 1.0\n",
    "model[0].weight.register_hook(lambda grad: grad.mul_(gradient_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.weight', '0.bias', '2.weight', '2.bias'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient:  tensor([[-0.0006, -0.0000],\n",
      "        [-0.0000,  0.0000]])\n",
      "Weights updated  tensor([[ True, False],\n",
      "        [False, False]])\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1.0)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 10\n",
    "x = torch.randn(batch_size, 2)\n",
    "target = torch.randint(0, 2, (batch_size,))\n",
    "\n",
    "# Get weight before training\n",
    "w0 = model[0].weight.detach().clone()\n",
    "\n",
    "# Single training iteration\n",
    "optimizer.zero_grad()\n",
    "output = model(x)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "print('Gradient: ', model[0].weight.grad)\n",
    "optimizer.step()\n",
    "\n",
    "# Compare weight update\n",
    "w1 = model[0].weight.detach().clone()\n",
    "print('Weights updated ', w0!=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-94ce8845a031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "model[2].weight.grad[0] * [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'Conv6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch = 0\n",
    "best_accu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = cu.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 'empty',\n",
       " 'epochs': 'empty',\n",
       " 'batch_size': 'empty',\n",
       " 'weight_decay': 'empty',\n",
       " 'iteration': 'empty',\n",
       " 'remaining_weight_conv': 'empty',\n",
       " 'remaining_weight_fc': 'empty',\n",
       " 'remaining_weight_ffc': 'empty',\n",
       " 'prune_per_c': 'empty',\n",
       " 'prune_per_f': 'empty',\n",
       " 'prune_per_o': 'empty',\n",
       " 'noi': 'empty',\n",
       " 'trainset': 'empty',\n",
       " 'valset': 'empty',\n",
       " 'testset': 'empty',\n",
       " 'train_loader': 'empty',\n",
       " 'val_loader': 'empty',\n",
       " 'test_loader': 'empty'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.type(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0003,\n",
       " 'epochs': 50,\n",
       " 'batch_size': 60,\n",
       " 'weight_decay': 0.003,\n",
       " 'iteration': 0,\n",
       " 'remaining_weight_conv': 'empty',\n",
       " 'remaining_weight_fc': 'empty',\n",
       " 'remaining_weight_ffc': 'empty',\n",
       " 'prune_per_c': 0.15,\n",
       " 'prune_per_f': 0.2,\n",
       " 'prune_per_o': 0.1,\n",
       " 'noi': 12,\n",
       " 'trainset': Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: ../CIFAR10/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
       "            ),\n",
       " 'valset': Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: ../CIFAR10/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
       "            ),\n",
       " 'testset': Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ../CIFAR10/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
       "            ),\n",
       " 'train_loader': <torch.utils.data.dataloader.DataLoader at 0x7f4470cbd550>,\n",
       " 'val_loader': <torch.utils.data.dataloader.DataLoader at 0x7f4470cc7c10>,\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x7f4470cb5750>,\n",
       " 'remaining_weight_c': 1,\n",
       " 'remaining_weight_f': 1,\n",
       " 'remaining_weight_o': 1,\n",
       " 'transform': Compose(\n",
       "     ToTensor()\n",
       "     Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
       " ),\n",
       " 'validation_ratio': 0.1,\n",
       " 'num_train': 50000,\n",
       " 'indices': [35592,\n",
       "  37476,\n",
       "  1757,\n",
       "  29610,\n",
       "  48912,\n",
       "  28994,\n",
       "  36458,\n",
       "  14631,\n",
       "  10937,\n",
       "  79,\n",
       "  33564,\n",
       "  20633,\n",
       "  28627,\n",
       "  19605,\n",
       "  20508,\n",
       "  22401,\n",
       "  2471,\n",
       "  29782,\n",
       "  49964,\n",
       "  21867,\n",
       "  30706,\n",
       "  21599,\n",
       "  33265,\n",
       "  39759,\n",
       "  40857,\n",
       "  47313,\n",
       "  18104,\n",
       "  15270,\n",
       "  17433,\n",
       "  27444,\n",
       "  37965,\n",
       "  37959,\n",
       "  32825,\n",
       "  35741,\n",
       "  34923,\n",
       "  29394,\n",
       "  43284,\n",
       "  13253,\n",
       "  27292,\n",
       "  11176,\n",
       "  16417,\n",
       "  33321,\n",
       "  42463,\n",
       "  2038,\n",
       "  11830,\n",
       "  41797,\n",
       "  34305,\n",
       "  32279,\n",
       "  33034,\n",
       "  17645,\n",
       "  4874,\n",
       "  39367,\n",
       "  33311,\n",
       "  46895,\n",
       "  24038,\n",
       "  33496,\n",
       "  17923,\n",
       "  3367,\n",
       "  10484,\n",
       "  32996,\n",
       "  49582,\n",
       "  36896,\n",
       "  23046,\n",
       "  42937,\n",
       "  37804,\n",
       "  37642,\n",
       "  43959,\n",
       "  31196,\n",
       "  45847,\n",
       "  19270,\n",
       "  13211,\n",
       "  8079,\n",
       "  39737,\n",
       "  37453,\n",
       "  20267,\n",
       "  49108,\n",
       "  33088,\n",
       "  28196,\n",
       "  30620,\n",
       "  45839,\n",
       "  11424,\n",
       "  19137,\n",
       "  10991,\n",
       "  13756,\n",
       "  21206,\n",
       "  9824,\n",
       "  19962,\n",
       "  27528,\n",
       "  43179,\n",
       "  37065,\n",
       "  20037,\n",
       "  29513,\n",
       "  38319,\n",
       "  29292,\n",
       "  42146,\n",
       "  15456,\n",
       "  49035,\n",
       "  28761,\n",
       "  32423,\n",
       "  30982,\n",
       "  15993,\n",
       "  33710,\n",
       "  32122,\n",
       "  36730,\n",
       "  5869,\n",
       "  25810,\n",
       "  16728,\n",
       "  2503,\n",
       "  34643,\n",
       "  40692,\n",
       "  32023,\n",
       "  46669,\n",
       "  3768,\n",
       "  45877,\n",
       "  19870,\n",
       "  20469,\n",
       "  37308,\n",
       "  30878,\n",
       "  48012,\n",
       "  11155,\n",
       "  44885,\n",
       "  11627,\n",
       "  32277,\n",
       "  24344,\n",
       "  36882,\n",
       "  19128,\n",
       "  32943,\n",
       "  647,\n",
       "  9706,\n",
       "  17894,\n",
       "  15935,\n",
       "  16958,\n",
       "  3756,\n",
       "  5341,\n",
       "  23643,\n",
       "  1226,\n",
       "  1342,\n",
       "  15483,\n",
       "  34174,\n",
       "  33837,\n",
       "  27366,\n",
       "  15869,\n",
       "  41267,\n",
       "  48227,\n",
       "  44502,\n",
       "  37029,\n",
       "  32999,\n",
       "  10570,\n",
       "  9012,\n",
       "  16900,\n",
       "  29319,\n",
       "  27440,\n",
       "  17169,\n",
       "  16582,\n",
       "  36373,\n",
       "  44322,\n",
       "  2653,\n",
       "  16834,\n",
       "  1108,\n",
       "  42108,\n",
       "  48670,\n",
       "  28827,\n",
       "  48361,\n",
       "  23740,\n",
       "  23255,\n",
       "  21262,\n",
       "  38782,\n",
       "  10367,\n",
       "  14708,\n",
       "  3309,\n",
       "  45505,\n",
       "  28757,\n",
       "  11060,\n",
       "  24741,\n",
       "  22984,\n",
       "  47210,\n",
       "  1304,\n",
       "  12029,\n",
       "  40826,\n",
       "  36794,\n",
       "  46468,\n",
       "  48212,\n",
       "  38437,\n",
       "  120,\n",
       "  23331,\n",
       "  11867,\n",
       "  5456,\n",
       "  23403,\n",
       "  5843,\n",
       "  44140,\n",
       "  9252,\n",
       "  46099,\n",
       "  49666,\n",
       "  40843,\n",
       "  32139,\n",
       "  20675,\n",
       "  34442,\n",
       "  48597,\n",
       "  21975,\n",
       "  34586,\n",
       "  12173,\n",
       "  8004,\n",
       "  16936,\n",
       "  11660,\n",
       "  31720,\n",
       "  45320,\n",
       "  11370,\n",
       "  10375,\n",
       "  15118,\n",
       "  25499,\n",
       "  49356,\n",
       "  8318,\n",
       "  48998,\n",
       "  26060,\n",
       "  30476,\n",
       "  33633,\n",
       "  36557,\n",
       "  24855,\n",
       "  1933,\n",
       "  32479,\n",
       "  39913,\n",
       "  16743,\n",
       "  30629,\n",
       "  18757,\n",
       "  29922,\n",
       "  36339,\n",
       "  34622,\n",
       "  31312,\n",
       "  12877,\n",
       "  34231,\n",
       "  18388,\n",
       "  2202,\n",
       "  18086,\n",
       "  31541,\n",
       "  48145,\n",
       "  2346,\n",
       "  15213,\n",
       "  26688,\n",
       "  46629,\n",
       "  43502,\n",
       "  41801,\n",
       "  18362,\n",
       "  26553,\n",
       "  27264,\n",
       "  19111,\n",
       "  13585,\n",
       "  8303,\n",
       "  25310,\n",
       "  18139,\n",
       "  23760,\n",
       "  38243,\n",
       "  32368,\n",
       "  32787,\n",
       "  32492,\n",
       "  21557,\n",
       "  25734,\n",
       "  19644,\n",
       "  25445,\n",
       "  44467,\n",
       "  6249,\n",
       "  36515,\n",
       "  17893,\n",
       "  41581,\n",
       "  2500,\n",
       "  29577,\n",
       "  30195,\n",
       "  6993,\n",
       "  32151,\n",
       "  23429,\n",
       "  44439,\n",
       "  47264,\n",
       "  7709,\n",
       "  34116,\n",
       "  25641,\n",
       "  16720,\n",
       "  49173,\n",
       "  7122,\n",
       "  45135,\n",
       "  27750,\n",
       "  27220,\n",
       "  37844,\n",
       "  40982,\n",
       "  8514,\n",
       "  35238,\n",
       "  1109,\n",
       "  38,\n",
       "  12154,\n",
       "  35786,\n",
       "  44101,\n",
       "  13982,\n",
       "  24766,\n",
       "  37336,\n",
       "  25701,\n",
       "  47336,\n",
       "  24257,\n",
       "  34037,\n",
       "  20967,\n",
       "  40634,\n",
       "  19329,\n",
       "  42296,\n",
       "  1427,\n",
       "  751,\n",
       "  10436,\n",
       "  24270,\n",
       "  14910,\n",
       "  2888,\n",
       "  37992,\n",
       "  18206,\n",
       "  37018,\n",
       "  27906,\n",
       "  22556,\n",
       "  1410,\n",
       "  45529,\n",
       "  48665,\n",
       "  15428,\n",
       "  14648,\n",
       "  47688,\n",
       "  17793,\n",
       "  11862,\n",
       "  33619,\n",
       "  23555,\n",
       "  17748,\n",
       "  20150,\n",
       "  48237,\n",
       "  38099,\n",
       "  24806,\n",
       "  20493,\n",
       "  8501,\n",
       "  3925,\n",
       "  31676,\n",
       "  25861,\n",
       "  20028,\n",
       "  14990,\n",
       "  2243,\n",
       "  5268,\n",
       "  36865,\n",
       "  17436,\n",
       "  32194,\n",
       "  31826,\n",
       "  22484,\n",
       "  29859,\n",
       "  8048,\n",
       "  11848,\n",
       "  12020,\n",
       "  17250,\n",
       "  233,\n",
       "  25425,\n",
       "  16876,\n",
       "  17273,\n",
       "  2647,\n",
       "  9943,\n",
       "  48747,\n",
       "  42849,\n",
       "  27877,\n",
       "  36420,\n",
       "  8032,\n",
       "  33452,\n",
       "  42960,\n",
       "  13998,\n",
       "  12559,\n",
       "  49898,\n",
       "  29088,\n",
       "  42487,\n",
       "  10666,\n",
       "  21644,\n",
       "  8624,\n",
       "  10892,\n",
       "  45264,\n",
       "  16527,\n",
       "  31188,\n",
       "  5852,\n",
       "  41813,\n",
       "  31700,\n",
       "  7494,\n",
       "  21072,\n",
       "  22523,\n",
       "  42471,\n",
       "  18866,\n",
       "  26499,\n",
       "  34769,\n",
       "  46800,\n",
       "  11199,\n",
       "  31670,\n",
       "  36682,\n",
       "  26396,\n",
       "  19900,\n",
       "  23767,\n",
       "  22066,\n",
       "  15223,\n",
       "  5717,\n",
       "  14085,\n",
       "  44772,\n",
       "  2465,\n",
       "  6693,\n",
       "  12570,\n",
       "  30609,\n",
       "  34075,\n",
       "  19085,\n",
       "  42841,\n",
       "  15368,\n",
       "  20844,\n",
       "  48885,\n",
       "  7560,\n",
       "  48676,\n",
       "  15911,\n",
       "  15224,\n",
       "  15094,\n",
       "  9913,\n",
       "  7584,\n",
       "  37799,\n",
       "  17028,\n",
       "  33142,\n",
       "  15061,\n",
       "  7147,\n",
       "  45195,\n",
       "  8256,\n",
       "  20708,\n",
       "  24364,\n",
       "  32633,\n",
       "  49149,\n",
       "  6978,\n",
       "  12018,\n",
       "  42402,\n",
       "  20087,\n",
       "  16632,\n",
       "  26560,\n",
       "  40968,\n",
       "  44091,\n",
       "  6670,\n",
       "  970,\n",
       "  46535,\n",
       "  21803,\n",
       "  39772,\n",
       "  11649,\n",
       "  43614,\n",
       "  43667,\n",
       "  12703,\n",
       "  10978,\n",
       "  40983,\n",
       "  7212,\n",
       "  31172,\n",
       "  47377,\n",
       "  45840,\n",
       "  18608,\n",
       "  3212,\n",
       "  19483,\n",
       "  34481,\n",
       "  40172,\n",
       "  48537,\n",
       "  6879,\n",
       "  17840,\n",
       "  13005,\n",
       "  39545,\n",
       "  13636,\n",
       "  27989,\n",
       "  46256,\n",
       "  46533,\n",
       "  31005,\n",
       "  4864,\n",
       "  41837,\n",
       "  2592,\n",
       "  46941,\n",
       "  3161,\n",
       "  48198,\n",
       "  43390,\n",
       "  2798,\n",
       "  12870,\n",
       "  18558,\n",
       "  30628,\n",
       "  38857,\n",
       "  38953,\n",
       "  14364,\n",
       "  14698,\n",
       "  10241,\n",
       "  27538,\n",
       "  21064,\n",
       "  642,\n",
       "  46539,\n",
       "  30698,\n",
       "  47252,\n",
       "  10207,\n",
       "  34968,\n",
       "  32489,\n",
       "  243,\n",
       "  43045,\n",
       "  12219,\n",
       "  9712,\n",
       "  25774,\n",
       "  13354,\n",
       "  40674,\n",
       "  36259,\n",
       "  9312,\n",
       "  37191,\n",
       "  16021,\n",
       "  22048,\n",
       "  1430,\n",
       "  2172,\n",
       "  44247,\n",
       "  30135,\n",
       "  11833,\n",
       "  7055,\n",
       "  38086,\n",
       "  12899,\n",
       "  32255,\n",
       "  18835,\n",
       "  22893,\n",
       "  34073,\n",
       "  15166,\n",
       "  26769,\n",
       "  30729,\n",
       "  30442,\n",
       "  22099,\n",
       "  46075,\n",
       "  14041,\n",
       "  6205,\n",
       "  43078,\n",
       "  10193,\n",
       "  9954,\n",
       "  9505,\n",
       "  6618,\n",
       "  21639,\n",
       "  3434,\n",
       "  2168,\n",
       "  8990,\n",
       "  34558,\n",
       "  19827,\n",
       "  13329,\n",
       "  26970,\n",
       "  20455,\n",
       "  36792,\n",
       "  17268,\n",
       "  24531,\n",
       "  37473,\n",
       "  12089,\n",
       "  3785,\n",
       "  16168,\n",
       "  21678,\n",
       "  23325,\n",
       "  44674,\n",
       "  26887,\n",
       "  6374,\n",
       "  14958,\n",
       "  40520,\n",
       "  32871,\n",
       "  33925,\n",
       "  17527,\n",
       "  19449,\n",
       "  32112,\n",
       "  44842,\n",
       "  46701,\n",
       "  10058,\n",
       "  31429,\n",
       "  30931,\n",
       "  38615,\n",
       "  14289,\n",
       "  31927,\n",
       "  8365,\n",
       "  40607,\n",
       "  39153,\n",
       "  16694,\n",
       "  20878,\n",
       "  10272,\n",
       "  24063,\n",
       "  39411,\n",
       "  48939,\n",
       "  4789,\n",
       "  22427,\n",
       "  28829,\n",
       "  37977,\n",
       "  32567,\n",
       "  27532,\n",
       "  2100,\n",
       "  47631,\n",
       "  31938,\n",
       "  17468,\n",
       "  19252,\n",
       "  20509,\n",
       "  37660,\n",
       "  32136,\n",
       "  13927,\n",
       "  10850,\n",
       "  34332,\n",
       "  22400,\n",
       "  844,\n",
       "  41642,\n",
       "  16811,\n",
       "  36217,\n",
       "  40632,\n",
       "  20335,\n",
       "  20127,\n",
       "  16837,\n",
       "  47224,\n",
       "  17467,\n",
       "  38907,\n",
       "  22287,\n",
       "  35107,\n",
       "  25623,\n",
       "  41176,\n",
       "  3828,\n",
       "  5246,\n",
       "  49216,\n",
       "  47545,\n",
       "  34897,\n",
       "  32523,\n",
       "  24536,\n",
       "  47864,\n",
       "  27261,\n",
       "  21699,\n",
       "  17195,\n",
       "  9645,\n",
       "  19647,\n",
       "  18343,\n",
       "  29864,\n",
       "  31937,\n",
       "  23107,\n",
       "  3603,\n",
       "  40060,\n",
       "  40041,\n",
       "  24401,\n",
       "  28390,\n",
       "  31461,\n",
       "  16428,\n",
       "  3176,\n",
       "  32673,\n",
       "  42172,\n",
       "  9695,\n",
       "  39678,\n",
       "  42256,\n",
       "  33123,\n",
       "  1860,\n",
       "  13154,\n",
       "  6641,\n",
       "  33026,\n",
       "  21353,\n",
       "  570,\n",
       "  38252,\n",
       "  1779,\n",
       "  1909,\n",
       "  18389,\n",
       "  7958,\n",
       "  5252,\n",
       "  5037,\n",
       "  13858,\n",
       "  47132,\n",
       "  46233,\n",
       "  32066,\n",
       "  29779,\n",
       "  35921,\n",
       "  13996,\n",
       "  41411,\n",
       "  40475,\n",
       "  4334,\n",
       "  35923,\n",
       "  11625,\n",
       "  9582,\n",
       "  10748,\n",
       "  18111,\n",
       "  34390,\n",
       "  12797,\n",
       "  11234,\n",
       "  8180,\n",
       "  31663,\n",
       "  27615,\n",
       "  13353,\n",
       "  7228,\n",
       "  2760,\n",
       "  12312,\n",
       "  43092,\n",
       "  44896,\n",
       "  6109,\n",
       "  49197,\n",
       "  6828,\n",
       "  9267,\n",
       "  35384,\n",
       "  42579,\n",
       "  45573,\n",
       "  21963,\n",
       "  30583,\n",
       "  39962,\n",
       "  49917,\n",
       "  24156,\n",
       "  49372,\n",
       "  12578,\n",
       "  968,\n",
       "  33776,\n",
       "  43096,\n",
       "  29976,\n",
       "  37548,\n",
       "  5612,\n",
       "  16431,\n",
       "  25752,\n",
       "  24503,\n",
       "  42315,\n",
       "  19313,\n",
       "  3124,\n",
       "  30504,\n",
       "  40651,\n",
       "  35644,\n",
       "  26315,\n",
       "  31078,\n",
       "  40950,\n",
       "  36164,\n",
       "  18524,\n",
       "  35529,\n",
       "  10935,\n",
       "  48103,\n",
       "  37171,\n",
       "  18281,\n",
       "  10995,\n",
       "  4103,\n",
       "  30010,\n",
       "  14487,\n",
       "  20443,\n",
       "  34182,\n",
       "  34537,\n",
       "  22208,\n",
       "  49946,\n",
       "  9108,\n",
       "  21779,\n",
       "  33841,\n",
       "  43677,\n",
       "  25874,\n",
       "  6010,\n",
       "  31166,\n",
       "  17742,\n",
       "  13598,\n",
       "  36855,\n",
       "  9053,\n",
       "  41751,\n",
       "  9631,\n",
       "  39340,\n",
       "  7616,\n",
       "  48925,\n",
       "  39051,\n",
       "  3412,\n",
       "  1669,\n",
       "  9579,\n",
       "  36332,\n",
       "  40981,\n",
       "  33556,\n",
       "  17205,\n",
       "  32497,\n",
       "  46035,\n",
       "  36773,\n",
       "  29266,\n",
       "  22537,\n",
       "  4056,\n",
       "  18279,\n",
       "  42826,\n",
       "  2759,\n",
       "  17553,\n",
       "  16800,\n",
       "  9058,\n",
       "  25524,\n",
       "  27347,\n",
       "  30968,\n",
       "  48293,\n",
       "  6726,\n",
       "  8640,\n",
       "  35260,\n",
       "  9753,\n",
       "  15271,\n",
       "  15723,\n",
       "  9427,\n",
       "  31348,\n",
       "  19040,\n",
       "  38486,\n",
       "  31903,\n",
       "  18583,\n",
       "  7038,\n",
       "  3343,\n",
       "  35231,\n",
       "  49265,\n",
       "  32045,\n",
       "  15298,\n",
       "  22106,\n",
       "  17531,\n",
       "  5026,\n",
       "  49584,\n",
       "  6309,\n",
       "  20501,\n",
       "  36544,\n",
       "  9091,\n",
       "  23032,\n",
       "  27689,\n",
       "  48582,\n",
       "  16602,\n",
       "  48615,\n",
       "  47055,\n",
       "  10177,\n",
       "  5004,\n",
       "  40160,\n",
       "  26936,\n",
       "  15921,\n",
       "  45178,\n",
       "  41103,\n",
       "  12930,\n",
       "  41035,\n",
       "  20682,\n",
       "  8154,\n",
       "  34276,\n",
       "  39548,\n",
       "  34423,\n",
       "  5316,\n",
       "  2297,\n",
       "  23747,\n",
       "  36103,\n",
       "  17604,\n",
       "  4431,\n",
       "  8730,\n",
       "  43564,\n",
       "  21796,\n",
       "  49374,\n",
       "  25184,\n",
       "  28927,\n",
       "  1545,\n",
       "  46653,\n",
       "  6169,\n",
       "  21972,\n",
       "  21933,\n",
       "  1559,\n",
       "  35169,\n",
       "  45734,\n",
       "  5228,\n",
       "  28722,\n",
       "  5669,\n",
       "  2806,\n",
       "  42198,\n",
       "  26691,\n",
       "  43824,\n",
       "  13373,\n",
       "  29093,\n",
       "  41948,\n",
       "  4365,\n",
       "  46655,\n",
       "  16680,\n",
       "  40562,\n",
       "  28373,\n",
       "  31269,\n",
       "  45696,\n",
       "  19879,\n",
       "  43407,\n",
       "  3172,\n",
       "  34894,\n",
       "  21625,\n",
       "  2989,\n",
       "  6853,\n",
       "  45930,\n",
       "  9249,\n",
       "  38396,\n",
       "  4636,\n",
       "  31694,\n",
       "  40936,\n",
       "  33671,\n",
       "  17910,\n",
       "  25847,\n",
       "  6403,\n",
       "  12192,\n",
       "  47213,\n",
       "  21701,\n",
       "  10346,\n",
       "  21579,\n",
       "  35180,\n",
       "  38483,\n",
       "  23943,\n",
       "  5871,\n",
       "  1582,\n",
       "  16202,\n",
       "  28732,\n",
       "  36583,\n",
       "  5758,\n",
       "  2774,\n",
       "  33838,\n",
       "  7438,\n",
       "  9268,\n",
       "  33195,\n",
       "  44021,\n",
       "  49447,\n",
       "  27275,\n",
       "  31122,\n",
       "  32004,\n",
       "  45812,\n",
       "  11388,\n",
       "  44746,\n",
       "  42955,\n",
       "  26103,\n",
       "  46043,\n",
       "  7104,\n",
       "  15366,\n",
       "  28102,\n",
       "  37897,\n",
       "  49843,\n",
       "  49632,\n",
       "  1953,\n",
       "  42884,\n",
       "  13725,\n",
       "  17216,\n",
       "  15914,\n",
       "  44020,\n",
       "  15881,\n",
       "  47428,\n",
       "  8378,\n",
       "  29439,\n",
       "  17649,\n",
       "  18034,\n",
       "  4069,\n",
       "  43347,\n",
       "  43900,\n",
       "  40062,\n",
       "  34886,\n",
       "  35658,\n",
       "  11832,\n",
       "  29933,\n",
       "  5666,\n",
       "  13559,\n",
       "  28178,\n",
       "  24495,\n",
       "  23354,\n",
       "  5520,\n",
       "  27294,\n",
       "  37887,\n",
       "  29927,\n",
       "  1618,\n",
       "  47777,\n",
       "  1206,\n",
       "  4612,\n",
       "  17242,\n",
       "  38545,\n",
       "  33113,\n",
       "  5814,\n",
       "  10275,\n",
       "  29777,\n",
       "  37540,\n",
       "  35578,\n",
       "  17155,\n",
       "  27964,\n",
       "  23260,\n",
       "  37663,\n",
       "  23351,\n",
       "  23991,\n",
       "  38020,\n",
       "  39964,\n",
       "  32530,\n",
       "  1396,\n",
       "  20703,\n",
       "  43775,\n",
       "  22784,\n",
       "  12963,\n",
       "  46145,\n",
       "  27336,\n",
       "  37693,\n",
       "  37024,\n",
       "  30289,\n",
       "  44565,\n",
       "  10472,\n",
       "  35790,\n",
       "  19955,\n",
       "  18341,\n",
       "  9602,\n",
       "  23667,\n",
       "  29609,\n",
       "  44596,\n",
       "  17412,\n",
       "  27412,\n",
       "  1725,\n",
       "  13508,\n",
       "  13576,\n",
       "  45716,\n",
       "  3189,\n",
       "  7354,\n",
       "  24059,\n",
       "  47644,\n",
       "  452,\n",
       "  16186,\n",
       "  28983,\n",
       "  34212,\n",
       "  25028,\n",
       "  6525,\n",
       "  888,\n",
       "  826,\n",
       "  17730,\n",
       "  6338,\n",
       "  34970,\n",
       "  22272,\n",
       "  1842,\n",
       "  48977,\n",
       "  38092,\n",
       "  1299,\n",
       "  5730,\n",
       "  32757,\n",
       "  6860,\n",
       "  22562,\n",
       "  17895,\n",
       "  35542,\n",
       "  529,\n",
       "  48090,\n",
       "  49556,\n",
       "  41730,\n",
       "  12755,\n",
       "  41949,\n",
       "  ...],\n",
       " 'split': 5000,\n",
       " 'train_idx': [30903,\n",
       "  18784,\n",
       "  29692,\n",
       "  15588,\n",
       "  2394,\n",
       "  15694,\n",
       "  11993,\n",
       "  9895,\n",
       "  45246,\n",
       "  30305,\n",
       "  26755,\n",
       "  7943,\n",
       "  26552,\n",
       "  46250,\n",
       "  44518,\n",
       "  1519,\n",
       "  23500,\n",
       "  8176,\n",
       "  33800,\n",
       "  43855,\n",
       "  29004,\n",
       "  10613,\n",
       "  16579,\n",
       "  27636,\n",
       "  45238,\n",
       "  18846,\n",
       "  17707,\n",
       "  32636,\n",
       "  8844,\n",
       "  47745,\n",
       "  32000,\n",
       "  3342,\n",
       "  28034,\n",
       "  33667,\n",
       "  29580,\n",
       "  32262,\n",
       "  38683,\n",
       "  25750,\n",
       "  4778,\n",
       "  12898,\n",
       "  32706,\n",
       "  32986,\n",
       "  36875,\n",
       "  29753,\n",
       "  2696,\n",
       "  15304,\n",
       "  34344,\n",
       "  16555,\n",
       "  13279,\n",
       "  34604,\n",
       "  272,\n",
       "  32088,\n",
       "  24180,\n",
       "  42324,\n",
       "  43916,\n",
       "  15423,\n",
       "  42501,\n",
       "  46711,\n",
       "  37185,\n",
       "  33799,\n",
       "  47190,\n",
       "  33147,\n",
       "  18079,\n",
       "  29446,\n",
       "  48319,\n",
       "  18615,\n",
       "  5821,\n",
       "  35604,\n",
       "  18264,\n",
       "  38032,\n",
       "  14755,\n",
       "  35996,\n",
       "  45407,\n",
       "  13308,\n",
       "  2809,\n",
       "  19074,\n",
       "  46121,\n",
       "  41344,\n",
       "  22041,\n",
       "  37690,\n",
       "  38978,\n",
       "  14119,\n",
       "  5501,\n",
       "  15780,\n",
       "  45900,\n",
       "  25072,\n",
       "  7464,\n",
       "  33786,\n",
       "  32208,\n",
       "  40385,\n",
       "  44224,\n",
       "  33621,\n",
       "  49342,\n",
       "  16605,\n",
       "  45854,\n",
       "  29913,\n",
       "  11214,\n",
       "  3793,\n",
       "  5009,\n",
       "  37823,\n",
       "  27087,\n",
       "  27357,\n",
       "  3579,\n",
       "  34506,\n",
       "  24040,\n",
       "  14891,\n",
       "  26506,\n",
       "  10963,\n",
       "  11413,\n",
       "  18526,\n",
       "  19546,\n",
       "  5727,\n",
       "  31458,\n",
       "  34696,\n",
       "  31619,\n",
       "  31952,\n",
       "  20462,\n",
       "  36958,\n",
       "  33511,\n",
       "  7269,\n",
       "  15496,\n",
       "  34318,\n",
       "  41824,\n",
       "  22760,\n",
       "  23869,\n",
       "  46026,\n",
       "  47696,\n",
       "  25393,\n",
       "  38223,\n",
       "  43546,\n",
       "  5820,\n",
       "  24849,\n",
       "  1577,\n",
       "  27638,\n",
       "  48263,\n",
       "  7974,\n",
       "  28202,\n",
       "  45311,\n",
       "  15264,\n",
       "  46913,\n",
       "  30376,\n",
       "  30218,\n",
       "  26220,\n",
       "  22381,\n",
       "  37930,\n",
       "  15258,\n",
       "  14946,\n",
       "  29418,\n",
       "  41805,\n",
       "  49317,\n",
       "  20397,\n",
       "  29526,\n",
       "  47112,\n",
       "  30954,\n",
       "  39877,\n",
       "  42253,\n",
       "  20313,\n",
       "  42188,\n",
       "  4086,\n",
       "  14944,\n",
       "  43128,\n",
       "  40695,\n",
       "  3826,\n",
       "  71,\n",
       "  5391,\n",
       "  29501,\n",
       "  44506,\n",
       "  29617,\n",
       "  10253,\n",
       "  2982,\n",
       "  17194,\n",
       "  9448,\n",
       "  47039,\n",
       "  47697,\n",
       "  23478,\n",
       "  3588,\n",
       "  24299,\n",
       "  30826,\n",
       "  35048,\n",
       "  39823,\n",
       "  23917,\n",
       "  24669,\n",
       "  39291,\n",
       "  9750,\n",
       "  2277,\n",
       "  11143,\n",
       "  2861,\n",
       "  4529,\n",
       "  28518,\n",
       "  23978,\n",
       "  44542,\n",
       "  22836,\n",
       "  15442,\n",
       "  8759,\n",
       "  19564,\n",
       "  12722,\n",
       "  3081,\n",
       "  15355,\n",
       "  4289,\n",
       "  368,\n",
       "  6499,\n",
       "  23514,\n",
       "  29063,\n",
       "  18920,\n",
       "  10173,\n",
       "  26849,\n",
       "  49902,\n",
       "  31718,\n",
       "  29001,\n",
       "  14998,\n",
       "  18155,\n",
       "  20503,\n",
       "  29095,\n",
       "  45578,\n",
       "  4936,\n",
       "  14245,\n",
       "  48468,\n",
       "  3714,\n",
       "  40563,\n",
       "  46042,\n",
       "  47532,\n",
       "  23314,\n",
       "  44618,\n",
       "  455,\n",
       "  35817,\n",
       "  38135,\n",
       "  43890,\n",
       "  47712,\n",
       "  13853,\n",
       "  43567,\n",
       "  27281,\n",
       "  36198,\n",
       "  30801,\n",
       "  49664,\n",
       "  26044,\n",
       "  39488,\n",
       "  12128,\n",
       "  37831,\n",
       "  6329,\n",
       "  21247,\n",
       "  2121,\n",
       "  49503,\n",
       "  19994,\n",
       "  15829,\n",
       "  11027,\n",
       "  24717,\n",
       "  2596,\n",
       "  45781,\n",
       "  16744,\n",
       "  3206,\n",
       "  35379,\n",
       "  26987,\n",
       "  1749,\n",
       "  40105,\n",
       "  13526,\n",
       "  18331,\n",
       "  6587,\n",
       "  19079,\n",
       "  40095,\n",
       "  5441,\n",
       "  371,\n",
       "  12859,\n",
       "  25304,\n",
       "  42360,\n",
       "  29639,\n",
       "  30309,\n",
       "  26668,\n",
       "  18,\n",
       "  14798,\n",
       "  10142,\n",
       "  28857,\n",
       "  21546,\n",
       "  39568,\n",
       "  36632,\n",
       "  35965,\n",
       "  26486,\n",
       "  15671,\n",
       "  18030,\n",
       "  9710,\n",
       "  42110,\n",
       "  33415,\n",
       "  46933,\n",
       "  45269,\n",
       "  12856,\n",
       "  40648,\n",
       "  48775,\n",
       "  43435,\n",
       "  32224,\n",
       "  38234,\n",
       "  3402,\n",
       "  18870,\n",
       "  45052,\n",
       "  27063,\n",
       "  44188,\n",
       "  18173,\n",
       "  15251,\n",
       "  21553,\n",
       "  39212,\n",
       "  47384,\n",
       "  41033,\n",
       "  1152,\n",
       "  4447,\n",
       "  6260,\n",
       "  1305,\n",
       "  8544,\n",
       "  10276,\n",
       "  38346,\n",
       "  7657,\n",
       "  22688,\n",
       "  45597,\n",
       "  38874,\n",
       "  47780,\n",
       "  46415,\n",
       "  16052,\n",
       "  9211,\n",
       "  35991,\n",
       "  3463,\n",
       "  49270,\n",
       "  20202,\n",
       "  19767,\n",
       "  41782,\n",
       "  6320,\n",
       "  33807,\n",
       "  8454,\n",
       "  33273,\n",
       "  38284,\n",
       "  7532,\n",
       "  18190,\n",
       "  44631,\n",
       "  31786,\n",
       "  34099,\n",
       "  47437,\n",
       "  32209,\n",
       "  21431,\n",
       "  47281,\n",
       "  20698,\n",
       "  21481,\n",
       "  11820,\n",
       "  25931,\n",
       "  28611,\n",
       "  29634,\n",
       "  5184,\n",
       "  5386,\n",
       "  43364,\n",
       "  8389,\n",
       "  30615,\n",
       "  13093,\n",
       "  20310,\n",
       "  12494,\n",
       "  1263,\n",
       "  35448,\n",
       "  42875,\n",
       "  3197,\n",
       "  24776,\n",
       "  24525,\n",
       "  38166,\n",
       "  37871,\n",
       "  35256,\n",
       "  1790,\n",
       "  44193,\n",
       "  14225,\n",
       "  45156,\n",
       "  45232,\n",
       "  22945,\n",
       "  34483,\n",
       "  44802,\n",
       "  10151,\n",
       "  36724,\n",
       "  16505,\n",
       "  23324,\n",
       "  16210,\n",
       "  12118,\n",
       "  6842,\n",
       "  49100,\n",
       "  31606,\n",
       "  36580,\n",
       "  48689,\n",
       "  15616,\n",
       "  1783,\n",
       "  29608,\n",
       "  18512,\n",
       "  46902,\n",
       "  19723,\n",
       "  29714,\n",
       "  12355,\n",
       "  6428,\n",
       "  25287,\n",
       "  8542,\n",
       "  6005,\n",
       "  39847,\n",
       "  47203,\n",
       "  37559,\n",
       "  16669,\n",
       "  16132,\n",
       "  7314,\n",
       "  39669,\n",
       "  38938,\n",
       "  13267,\n",
       "  3049,\n",
       "  23344,\n",
       "  45985,\n",
       "  39552,\n",
       "  47160,\n",
       "  894,\n",
       "  29721,\n",
       "  10560,\n",
       "  36746,\n",
       "  7637,\n",
       "  28558,\n",
       "  49764,\n",
       "  12485,\n",
       "  20329,\n",
       "  18884,\n",
       "  13457,\n",
       "  27047,\n",
       "  11944,\n",
       "  18220,\n",
       "  11961,\n",
       "  47358,\n",
       "  22813,\n",
       "  10051,\n",
       "  47431,\n",
       "  42798,\n",
       "  27740,\n",
       "  17462,\n",
       "  7988,\n",
       "  36305,\n",
       "  11817,\n",
       "  4845,\n",
       "  42945,\n",
       "  12544,\n",
       "  33570,\n",
       "  22985,\n",
       "  11463,\n",
       "  21036,\n",
       "  14906,\n",
       "  31444,\n",
       "  8165,\n",
       "  34485,\n",
       "  15145,\n",
       "  11014,\n",
       "  32032,\n",
       "  24092,\n",
       "  9843,\n",
       "  29959,\n",
       "  30208,\n",
       "  14518,\n",
       "  3741,\n",
       "  11670,\n",
       "  2223,\n",
       "  10469,\n",
       "  29073,\n",
       "  1433,\n",
       "  32662,\n",
       "  36457,\n",
       "  19739,\n",
       "  10889,\n",
       "  21855,\n",
       "  36973,\n",
       "  29604,\n",
       "  10907,\n",
       "  27682,\n",
       "  7882,\n",
       "  13513,\n",
       "  33268,\n",
       "  45471,\n",
       "  36728,\n",
       "  47196,\n",
       "  32949,\n",
       "  25042,\n",
       "  42499,\n",
       "  10927,\n",
       "  30556,\n",
       "  33883,\n",
       "  26339,\n",
       "  1782,\n",
       "  24709,\n",
       "  10776,\n",
       "  48393,\n",
       "  17727,\n",
       "  32914,\n",
       "  2442,\n",
       "  35280,\n",
       "  19613,\n",
       "  9713,\n",
       "  9366,\n",
       "  36051,\n",
       "  10740,\n",
       "  31230,\n",
       "  36285,\n",
       "  38774,\n",
       "  17274,\n",
       "  19365,\n",
       "  46006,\n",
       "  23702,\n",
       "  3469,\n",
       "  6701,\n",
       "  387,\n",
       "  4040,\n",
       "  46213,\n",
       "  38285,\n",
       "  22152,\n",
       "  40067,\n",
       "  13671,\n",
       "  26767,\n",
       "  37451,\n",
       "  4759,\n",
       "  18445,\n",
       "  40568,\n",
       "  18979,\n",
       "  41316,\n",
       "  10140,\n",
       "  46825,\n",
       "  211,\n",
       "  46555,\n",
       "  40557,\n",
       "  31769,\n",
       "  3853,\n",
       "  42140,\n",
       "  37469,\n",
       "  24821,\n",
       "  37334,\n",
       "  16715,\n",
       "  361,\n",
       "  31519,\n",
       "  19433,\n",
       "  21848,\n",
       "  28546,\n",
       "  30946,\n",
       "  2146,\n",
       "  18819,\n",
       "  7698,\n",
       "  19371,\n",
       "  18932,\n",
       "  19036,\n",
       "  2436,\n",
       "  39327,\n",
       "  6790,\n",
       "  31268,\n",
       "  47869,\n",
       "  10931,\n",
       "  5467,\n",
       "  19395,\n",
       "  32707,\n",
       "  14295,\n",
       "  23381,\n",
       "  32391,\n",
       "  10345,\n",
       "  31491,\n",
       "  12536,\n",
       "  14250,\n",
       "  35043,\n",
       "  10388,\n",
       "  21141,\n",
       "  8866,\n",
       "  40947,\n",
       "  40712,\n",
       "  17841,\n",
       "  10586,\n",
       "  21833,\n",
       "  49806,\n",
       "  42972,\n",
       "  10623,\n",
       "  40205,\n",
       "  38446,\n",
       "  1400,\n",
       "  42538,\n",
       "  14058,\n",
       "  40973,\n",
       "  20586,\n",
       "  24979,\n",
       "  39389,\n",
       "  21095,\n",
       "  24867,\n",
       "  15316,\n",
       "  42225,\n",
       "  16295,\n",
       "  6410,\n",
       "  16595,\n",
       "  37583,\n",
       "  16308,\n",
       "  8452,\n",
       "  26289,\n",
       "  21603,\n",
       "  42016,\n",
       "  8290,\n",
       "  46573,\n",
       "  14715,\n",
       "  37117,\n",
       "  29623,\n",
       "  684,\n",
       "  37365,\n",
       "  25171,\n",
       "  14353,\n",
       "  20475,\n",
       "  38068,\n",
       "  35896,\n",
       "  17511,\n",
       "  27224,\n",
       "  19464,\n",
       "  39195,\n",
       "  19890,\n",
       "  18565,\n",
       "  19781,\n",
       "  1651,\n",
       "  5885,\n",
       "  23151,\n",
       "  43491,\n",
       "  11806,\n",
       "  19265,\n",
       "  25993,\n",
       "  40500,\n",
       "  15546,\n",
       "  44181,\n",
       "  45879,\n",
       "  8709,\n",
       "  11331,\n",
       "  24584,\n",
       "  6501,\n",
       "  3349,\n",
       "  22363,\n",
       "  47839,\n",
       "  31618,\n",
       "  1313,\n",
       "  35497,\n",
       "  1530,\n",
       "  17266,\n",
       "  17327,\n",
       "  13363,\n",
       "  16076,\n",
       "  46798,\n",
       "  4564,\n",
       "  4189,\n",
       "  22320,\n",
       "  19802,\n",
       "  15743,\n",
       "  30032,\n",
       "  10027,\n",
       "  19134,\n",
       "  28475,\n",
       "  39126,\n",
       "  40776,\n",
       "  28366,\n",
       "  48358,\n",
       "  25883,\n",
       "  20666,\n",
       "  29487,\n",
       "  2794,\n",
       "  28561,\n",
       "  31127,\n",
       "  40250,\n",
       "  30161,\n",
       "  6846,\n",
       "  874,\n",
       "  27068,\n",
       "  45804,\n",
       "  43625,\n",
       "  3115,\n",
       "  9778,\n",
       "  29222,\n",
       "  17587,\n",
       "  32403,\n",
       "  49627,\n",
       "  18694,\n",
       "  10453,\n",
       "  49417,\n",
       "  41162,\n",
       "  31137,\n",
       "  26049,\n",
       "  29756,\n",
       "  42682,\n",
       "  25109,\n",
       "  20424,\n",
       "  2564,\n",
       "  39887,\n",
       "  16947,\n",
       "  38230,\n",
       "  664,\n",
       "  11258,\n",
       "  39749,\n",
       "  3356,\n",
       "  46475,\n",
       "  45123,\n",
       "  19235,\n",
       "  31192,\n",
       "  29649,\n",
       "  44672,\n",
       "  42365,\n",
       "  23477,\n",
       "  45366,\n",
       "  2411,\n",
       "  34253,\n",
       "  49867,\n",
       "  2401,\n",
       "  36350,\n",
       "  24349,\n",
       "  42031,\n",
       "  44493,\n",
       "  17117,\n",
       "  42082,\n",
       "  18267,\n",
       "  33294,\n",
       "  8968,\n",
       "  21074,\n",
       "  31967,\n",
       "  36565,\n",
       "  10225,\n",
       "  9514,\n",
       "  36589,\n",
       "  5397,\n",
       "  47768,\n",
       "  45676,\n",
       "  43612,\n",
       "  4257,\n",
       "  3182,\n",
       "  15003,\n",
       "  47144,\n",
       "  36671,\n",
       "  14995,\n",
       "  22758,\n",
       "  49774,\n",
       "  7802,\n",
       "  19639,\n",
       "  4428,\n",
       "  42137,\n",
       "  47373,\n",
       "  5297,\n",
       "  32889,\n",
       "  43451,\n",
       "  15992,\n",
       "  32354,\n",
       "  17951,\n",
       "  4234,\n",
       "  5819,\n",
       "  5073,\n",
       "  48508,\n",
       "  21811,\n",
       "  30187,\n",
       "  23553,\n",
       "  28039,\n",
       "  15209,\n",
       "  5081,\n",
       "  14271,\n",
       "  9608,\n",
       "  30776,\n",
       "  23371,\n",
       "  18627,\n",
       "  28605,\n",
       "  4409,\n",
       "  18298,\n",
       "  9757,\n",
       "  31232,\n",
       "  45029,\n",
       "  11725,\n",
       "  49010,\n",
       "  41013,\n",
       "  33466,\n",
       "  33612,\n",
       "  12493,\n",
       "  48918,\n",
       "  35781,\n",
       "  2441,\n",
       "  47337,\n",
       "  40183,\n",
       "  17464,\n",
       "  3450,\n",
       "  40577,\n",
       "  31081,\n",
       "  635,\n",
       "  6151,\n",
       "  43938,\n",
       "  9330,\n",
       "  22675,\n",
       "  48515,\n",
       "  10856,\n",
       "  24447,\n",
       "  18392,\n",
       "  18359,\n",
       "  25299,\n",
       "  21722,\n",
       "  4553,\n",
       "  37811,\n",
       "  16780,\n",
       "  5278,\n",
       "  34596,\n",
       "  4485,\n",
       "  28955,\n",
       "  40664,\n",
       "  25922,\n",
       "  9383,\n",
       "  24588,\n",
       "  13433,\n",
       "  34124,\n",
       "  44910,\n",
       "  7026,\n",
       "  37924,\n",
       "  26647,\n",
       "  32589,\n",
       "  33402,\n",
       "  43207,\n",
       "  29796,\n",
       "  31110,\n",
       "  19353,\n",
       "  35171,\n",
       "  29646,\n",
       "  35007,\n",
       "  20869,\n",
       "  15643,\n",
       "  28439,\n",
       "  33582,\n",
       "  11343,\n",
       "  48108,\n",
       "  14628,\n",
       "  4307,\n",
       "  24293,\n",
       "  43595,\n",
       "  34571,\n",
       "  28986,\n",
       "  1964,\n",
       "  1145,\n",
       "  24197,\n",
       "  7545,\n",
       "  38639,\n",
       "  21636,\n",
       "  41957,\n",
       "  6643,\n",
       "  7632,\n",
       "  37222,\n",
       "  13862,\n",
       "  41880,\n",
       "  37084,\n",
       "  8117,\n",
       "  13930,\n",
       "  39108,\n",
       "  17139,\n",
       "  14451,\n",
       "  1201,\n",
       "  31573,\n",
       "  34033,\n",
       "  19855,\n",
       "  13687,\n",
       "  32925,\n",
       "  15359,\n",
       "  21938,\n",
       "  18742,\n",
       "  47332,\n",
       "  15998,\n",
       "  32068,\n",
       "  34103,\n",
       "  11077,\n",
       "  31829,\n",
       "  42076,\n",
       "  34254,\n",
       "  29921,\n",
       "  23669,\n",
       "  24363,\n",
       "  4301,\n",
       "  9504,\n",
       "  49004,\n",
       "  22176,\n",
       "  21168,\n",
       "  13170,\n",
       "  4581,\n",
       "  453,\n",
       "  31858,\n",
       "  2778,\n",
       "  37747,\n",
       "  7116,\n",
       "  10597,\n",
       "  41377,\n",
       "  19081,\n",
       "  1307,\n",
       "  29011,\n",
       "  18700,\n",
       "  31326,\n",
       "  19786,\n",
       "  10657,\n",
       "  19281,\n",
       "  4723,\n",
       "  29666,\n",
       "  491,\n",
       "  42783,\n",
       "  45543,\n",
       "  6536,\n",
       "  44549,\n",
       "  30824,\n",
       "  44517,\n",
       "  40180,\n",
       "  8021,\n",
       "  7040,\n",
       "  2546,\n",
       "  4480,\n",
       "  12746,\n",
       "  12522,\n",
       "  23929,\n",
       "  10627,\n",
       "  36310,\n",
       "  2449,\n",
       "  46582,\n",
       "  11288,\n",
       "  32288,\n",
       "  19004,\n",
       "  21777,\n",
       "  25003,\n",
       "  18318,\n",
       "  20271,\n",
       "  5895,\n",
       "  17818,\n",
       "  29496,\n",
       "  20724,\n",
       "  1511,\n",
       "  37974,\n",
       "  28223,\n",
       "  42573,\n",
       "  43645,\n",
       "  27249,\n",
       "  31488,\n",
       "  18801,\n",
       "  12922,\n",
       "  15268,\n",
       "  28292,\n",
       "  14175,\n",
       "  5673,\n",
       "  2753,\n",
       "  8481,\n",
       "  18831,\n",
       "  10632,\n",
       "  39917,\n",
       "  47617,\n",
       "  16476,\n",
       "  24547,\n",
       "  26794,\n",
       "  35695,\n",
       "  46209,\n",
       "  34705,\n",
       "  17481,\n",
       "  48765,\n",
       "  11168,\n",
       "  11441,\n",
       "  12926,\n",
       "  7224,\n",
       "  20363,\n",
       "  45592,\n",
       "  27624,\n",
       "  10451,\n",
       "  22615,\n",
       "  1916,\n",
       "  4268,\n",
       "  20990,\n",
       "  31943,\n",
       "  31711,\n",
       "  41233,\n",
       "  7220,\n",
       "  7092,\n",
       "  3077,\n",
       "  1298,\n",
       "  236,\n",
       "  32823,\n",
       "  40114,\n",
       "  9384,\n",
       "  44176,\n",
       "  33561,\n",
       "  6157,\n",
       "  24079,\n",
       "  37699,\n",
       "  7742,\n",
       "  28414,\n",
       "  49229,\n",
       "  7885,\n",
       "  32036,\n",
       "  7562,\n",
       "  42720,\n",
       "  43311,\n",
       "  24002,\n",
       "  8733,\n",
       "  17072,\n",
       "  36657,\n",
       "  32761,\n",
       "  47725,\n",
       "  48854,\n",
       "  40805,\n",
       "  24949,\n",
       "  1106,\n",
       "  23166,\n",
       "  8900,\n",
       "  41765,\n",
       "  38149,\n",
       "  8170,\n",
       "  3599,\n",
       "  39122,\n",
       "  28766,\n",
       "  1936,\n",
       "  49730,\n",
       "  44233,\n",
       "  35999,\n",
       "  3468,\n",
       "  48769,\n",
       "  21356,\n",
       "  46840,\n",
       "  4066,\n",
       "  ...],\n",
       " 'val_idx': [35592,\n",
       "  37476,\n",
       "  1757,\n",
       "  29610,\n",
       "  48912,\n",
       "  28994,\n",
       "  36458,\n",
       "  14631,\n",
       "  10937,\n",
       "  79,\n",
       "  33564,\n",
       "  20633,\n",
       "  28627,\n",
       "  19605,\n",
       "  20508,\n",
       "  22401,\n",
       "  2471,\n",
       "  29782,\n",
       "  49964,\n",
       "  21867,\n",
       "  30706,\n",
       "  21599,\n",
       "  33265,\n",
       "  39759,\n",
       "  40857,\n",
       "  47313,\n",
       "  18104,\n",
       "  15270,\n",
       "  17433,\n",
       "  27444,\n",
       "  37965,\n",
       "  37959,\n",
       "  32825,\n",
       "  35741,\n",
       "  34923,\n",
       "  29394,\n",
       "  43284,\n",
       "  13253,\n",
       "  27292,\n",
       "  11176,\n",
       "  16417,\n",
       "  33321,\n",
       "  42463,\n",
       "  2038,\n",
       "  11830,\n",
       "  41797,\n",
       "  34305,\n",
       "  32279,\n",
       "  33034,\n",
       "  17645,\n",
       "  4874,\n",
       "  39367,\n",
       "  33311,\n",
       "  46895,\n",
       "  24038,\n",
       "  33496,\n",
       "  17923,\n",
       "  3367,\n",
       "  10484,\n",
       "  32996,\n",
       "  49582,\n",
       "  36896,\n",
       "  23046,\n",
       "  42937,\n",
       "  37804,\n",
       "  37642,\n",
       "  43959,\n",
       "  31196,\n",
       "  45847,\n",
       "  19270,\n",
       "  13211,\n",
       "  8079,\n",
       "  39737,\n",
       "  37453,\n",
       "  20267,\n",
       "  49108,\n",
       "  33088,\n",
       "  28196,\n",
       "  30620,\n",
       "  45839,\n",
       "  11424,\n",
       "  19137,\n",
       "  10991,\n",
       "  13756,\n",
       "  21206,\n",
       "  9824,\n",
       "  19962,\n",
       "  27528,\n",
       "  43179,\n",
       "  37065,\n",
       "  20037,\n",
       "  29513,\n",
       "  38319,\n",
       "  29292,\n",
       "  42146,\n",
       "  15456,\n",
       "  49035,\n",
       "  28761,\n",
       "  32423,\n",
       "  30982,\n",
       "  15993,\n",
       "  33710,\n",
       "  32122,\n",
       "  36730,\n",
       "  5869,\n",
       "  25810,\n",
       "  16728,\n",
       "  2503,\n",
       "  34643,\n",
       "  40692,\n",
       "  32023,\n",
       "  46669,\n",
       "  3768,\n",
       "  45877,\n",
       "  19870,\n",
       "  20469,\n",
       "  37308,\n",
       "  30878,\n",
       "  48012,\n",
       "  11155,\n",
       "  44885,\n",
       "  11627,\n",
       "  32277,\n",
       "  24344,\n",
       "  36882,\n",
       "  19128,\n",
       "  32943,\n",
       "  647,\n",
       "  9706,\n",
       "  17894,\n",
       "  15935,\n",
       "  16958,\n",
       "  3756,\n",
       "  5341,\n",
       "  23643,\n",
       "  1226,\n",
       "  1342,\n",
       "  15483,\n",
       "  34174,\n",
       "  33837,\n",
       "  27366,\n",
       "  15869,\n",
       "  41267,\n",
       "  48227,\n",
       "  44502,\n",
       "  37029,\n",
       "  32999,\n",
       "  10570,\n",
       "  9012,\n",
       "  16900,\n",
       "  29319,\n",
       "  27440,\n",
       "  17169,\n",
       "  16582,\n",
       "  36373,\n",
       "  44322,\n",
       "  2653,\n",
       "  16834,\n",
       "  1108,\n",
       "  42108,\n",
       "  48670,\n",
       "  28827,\n",
       "  48361,\n",
       "  23740,\n",
       "  23255,\n",
       "  21262,\n",
       "  38782,\n",
       "  10367,\n",
       "  14708,\n",
       "  3309,\n",
       "  45505,\n",
       "  28757,\n",
       "  11060,\n",
       "  24741,\n",
       "  22984,\n",
       "  47210,\n",
       "  1304,\n",
       "  12029,\n",
       "  40826,\n",
       "  36794,\n",
       "  46468,\n",
       "  48212,\n",
       "  38437,\n",
       "  120,\n",
       "  23331,\n",
       "  11867,\n",
       "  5456,\n",
       "  23403,\n",
       "  5843,\n",
       "  44140,\n",
       "  9252,\n",
       "  46099,\n",
       "  49666,\n",
       "  40843,\n",
       "  32139,\n",
       "  20675,\n",
       "  34442,\n",
       "  48597,\n",
       "  21975,\n",
       "  34586,\n",
       "  12173,\n",
       "  8004,\n",
       "  16936,\n",
       "  11660,\n",
       "  31720,\n",
       "  45320,\n",
       "  11370,\n",
       "  10375,\n",
       "  15118,\n",
       "  25499,\n",
       "  49356,\n",
       "  8318,\n",
       "  48998,\n",
       "  26060,\n",
       "  30476,\n",
       "  33633,\n",
       "  36557,\n",
       "  24855,\n",
       "  1933,\n",
       "  32479,\n",
       "  39913,\n",
       "  16743,\n",
       "  30629,\n",
       "  18757,\n",
       "  29922,\n",
       "  36339,\n",
       "  34622,\n",
       "  31312,\n",
       "  12877,\n",
       "  34231,\n",
       "  18388,\n",
       "  2202,\n",
       "  18086,\n",
       "  31541,\n",
       "  48145,\n",
       "  2346,\n",
       "  15213,\n",
       "  26688,\n",
       "  46629,\n",
       "  43502,\n",
       "  41801,\n",
       "  18362,\n",
       "  26553,\n",
       "  27264,\n",
       "  19111,\n",
       "  13585,\n",
       "  8303,\n",
       "  25310,\n",
       "  18139,\n",
       "  23760,\n",
       "  38243,\n",
       "  32368,\n",
       "  32787,\n",
       "  32492,\n",
       "  21557,\n",
       "  25734,\n",
       "  19644,\n",
       "  25445,\n",
       "  44467,\n",
       "  6249,\n",
       "  36515,\n",
       "  17893,\n",
       "  41581,\n",
       "  2500,\n",
       "  29577,\n",
       "  30195,\n",
       "  6993,\n",
       "  32151,\n",
       "  23429,\n",
       "  44439,\n",
       "  47264,\n",
       "  7709,\n",
       "  34116,\n",
       "  25641,\n",
       "  16720,\n",
       "  49173,\n",
       "  7122,\n",
       "  45135,\n",
       "  27750,\n",
       "  27220,\n",
       "  37844,\n",
       "  40982,\n",
       "  8514,\n",
       "  35238,\n",
       "  1109,\n",
       "  38,\n",
       "  12154,\n",
       "  35786,\n",
       "  44101,\n",
       "  13982,\n",
       "  24766,\n",
       "  37336,\n",
       "  25701,\n",
       "  47336,\n",
       "  24257,\n",
       "  34037,\n",
       "  20967,\n",
       "  40634,\n",
       "  19329,\n",
       "  42296,\n",
       "  1427,\n",
       "  751,\n",
       "  10436,\n",
       "  24270,\n",
       "  14910,\n",
       "  2888,\n",
       "  37992,\n",
       "  18206,\n",
       "  37018,\n",
       "  27906,\n",
       "  22556,\n",
       "  1410,\n",
       "  45529,\n",
       "  48665,\n",
       "  15428,\n",
       "  14648,\n",
       "  47688,\n",
       "  17793,\n",
       "  11862,\n",
       "  33619,\n",
       "  23555,\n",
       "  17748,\n",
       "  20150,\n",
       "  48237,\n",
       "  38099,\n",
       "  24806,\n",
       "  20493,\n",
       "  8501,\n",
       "  3925,\n",
       "  31676,\n",
       "  25861,\n",
       "  20028,\n",
       "  14990,\n",
       "  2243,\n",
       "  5268,\n",
       "  36865,\n",
       "  17436,\n",
       "  32194,\n",
       "  31826,\n",
       "  22484,\n",
       "  29859,\n",
       "  8048,\n",
       "  11848,\n",
       "  12020,\n",
       "  17250,\n",
       "  233,\n",
       "  25425,\n",
       "  16876,\n",
       "  17273,\n",
       "  2647,\n",
       "  9943,\n",
       "  48747,\n",
       "  42849,\n",
       "  27877,\n",
       "  36420,\n",
       "  8032,\n",
       "  33452,\n",
       "  42960,\n",
       "  13998,\n",
       "  12559,\n",
       "  49898,\n",
       "  29088,\n",
       "  42487,\n",
       "  10666,\n",
       "  21644,\n",
       "  8624,\n",
       "  10892,\n",
       "  45264,\n",
       "  16527,\n",
       "  31188,\n",
       "  5852,\n",
       "  41813,\n",
       "  31700,\n",
       "  7494,\n",
       "  21072,\n",
       "  22523,\n",
       "  42471,\n",
       "  18866,\n",
       "  26499,\n",
       "  34769,\n",
       "  46800,\n",
       "  11199,\n",
       "  31670,\n",
       "  36682,\n",
       "  26396,\n",
       "  19900,\n",
       "  23767,\n",
       "  22066,\n",
       "  15223,\n",
       "  5717,\n",
       "  14085,\n",
       "  44772,\n",
       "  2465,\n",
       "  6693,\n",
       "  12570,\n",
       "  30609,\n",
       "  34075,\n",
       "  19085,\n",
       "  42841,\n",
       "  15368,\n",
       "  20844,\n",
       "  48885,\n",
       "  7560,\n",
       "  48676,\n",
       "  15911,\n",
       "  15224,\n",
       "  15094,\n",
       "  9913,\n",
       "  7584,\n",
       "  37799,\n",
       "  17028,\n",
       "  33142,\n",
       "  15061,\n",
       "  7147,\n",
       "  45195,\n",
       "  8256,\n",
       "  20708,\n",
       "  24364,\n",
       "  32633,\n",
       "  49149,\n",
       "  6978,\n",
       "  12018,\n",
       "  42402,\n",
       "  20087,\n",
       "  16632,\n",
       "  26560,\n",
       "  40968,\n",
       "  44091,\n",
       "  6670,\n",
       "  970,\n",
       "  46535,\n",
       "  21803,\n",
       "  39772,\n",
       "  11649,\n",
       "  43614,\n",
       "  43667,\n",
       "  12703,\n",
       "  10978,\n",
       "  40983,\n",
       "  7212,\n",
       "  31172,\n",
       "  47377,\n",
       "  45840,\n",
       "  18608,\n",
       "  3212,\n",
       "  19483,\n",
       "  34481,\n",
       "  40172,\n",
       "  48537,\n",
       "  6879,\n",
       "  17840,\n",
       "  13005,\n",
       "  39545,\n",
       "  13636,\n",
       "  27989,\n",
       "  46256,\n",
       "  46533,\n",
       "  31005,\n",
       "  4864,\n",
       "  41837,\n",
       "  2592,\n",
       "  46941,\n",
       "  3161,\n",
       "  48198,\n",
       "  43390,\n",
       "  2798,\n",
       "  12870,\n",
       "  18558,\n",
       "  30628,\n",
       "  38857,\n",
       "  38953,\n",
       "  14364,\n",
       "  14698,\n",
       "  10241,\n",
       "  27538,\n",
       "  21064,\n",
       "  642,\n",
       "  46539,\n",
       "  30698,\n",
       "  47252,\n",
       "  10207,\n",
       "  34968,\n",
       "  32489,\n",
       "  243,\n",
       "  43045,\n",
       "  12219,\n",
       "  9712,\n",
       "  25774,\n",
       "  13354,\n",
       "  40674,\n",
       "  36259,\n",
       "  9312,\n",
       "  37191,\n",
       "  16021,\n",
       "  22048,\n",
       "  1430,\n",
       "  2172,\n",
       "  44247,\n",
       "  30135,\n",
       "  11833,\n",
       "  7055,\n",
       "  38086,\n",
       "  12899,\n",
       "  32255,\n",
       "  18835,\n",
       "  22893,\n",
       "  34073,\n",
       "  15166,\n",
       "  26769,\n",
       "  30729,\n",
       "  30442,\n",
       "  22099,\n",
       "  46075,\n",
       "  14041,\n",
       "  6205,\n",
       "  43078,\n",
       "  10193,\n",
       "  9954,\n",
       "  9505,\n",
       "  6618,\n",
       "  21639,\n",
       "  3434,\n",
       "  2168,\n",
       "  8990,\n",
       "  34558,\n",
       "  19827,\n",
       "  13329,\n",
       "  26970,\n",
       "  20455,\n",
       "  36792,\n",
       "  17268,\n",
       "  24531,\n",
       "  37473,\n",
       "  12089,\n",
       "  3785,\n",
       "  16168,\n",
       "  21678,\n",
       "  23325,\n",
       "  44674,\n",
       "  26887,\n",
       "  6374,\n",
       "  14958,\n",
       "  40520,\n",
       "  32871,\n",
       "  33925,\n",
       "  17527,\n",
       "  19449,\n",
       "  32112,\n",
       "  44842,\n",
       "  46701,\n",
       "  10058,\n",
       "  31429,\n",
       "  30931,\n",
       "  38615,\n",
       "  14289,\n",
       "  31927,\n",
       "  8365,\n",
       "  40607,\n",
       "  39153,\n",
       "  16694,\n",
       "  20878,\n",
       "  10272,\n",
       "  24063,\n",
       "  39411,\n",
       "  48939,\n",
       "  4789,\n",
       "  22427,\n",
       "  28829,\n",
       "  37977,\n",
       "  32567,\n",
       "  27532,\n",
       "  2100,\n",
       "  47631,\n",
       "  31938,\n",
       "  17468,\n",
       "  19252,\n",
       "  20509,\n",
       "  37660,\n",
       "  32136,\n",
       "  13927,\n",
       "  10850,\n",
       "  34332,\n",
       "  22400,\n",
       "  844,\n",
       "  41642,\n",
       "  16811,\n",
       "  36217,\n",
       "  40632,\n",
       "  20335,\n",
       "  20127,\n",
       "  16837,\n",
       "  47224,\n",
       "  17467,\n",
       "  38907,\n",
       "  22287,\n",
       "  35107,\n",
       "  25623,\n",
       "  41176,\n",
       "  3828,\n",
       "  5246,\n",
       "  49216,\n",
       "  47545,\n",
       "  34897,\n",
       "  32523,\n",
       "  24536,\n",
       "  47864,\n",
       "  27261,\n",
       "  21699,\n",
       "  17195,\n",
       "  9645,\n",
       "  19647,\n",
       "  18343,\n",
       "  29864,\n",
       "  31937,\n",
       "  23107,\n",
       "  3603,\n",
       "  40060,\n",
       "  40041,\n",
       "  24401,\n",
       "  28390,\n",
       "  31461,\n",
       "  16428,\n",
       "  3176,\n",
       "  32673,\n",
       "  42172,\n",
       "  9695,\n",
       "  39678,\n",
       "  42256,\n",
       "  33123,\n",
       "  1860,\n",
       "  13154,\n",
       "  6641,\n",
       "  33026,\n",
       "  21353,\n",
       "  570,\n",
       "  38252,\n",
       "  1779,\n",
       "  1909,\n",
       "  18389,\n",
       "  7958,\n",
       "  5252,\n",
       "  5037,\n",
       "  13858,\n",
       "  47132,\n",
       "  46233,\n",
       "  32066,\n",
       "  29779,\n",
       "  35921,\n",
       "  13996,\n",
       "  41411,\n",
       "  40475,\n",
       "  4334,\n",
       "  35923,\n",
       "  11625,\n",
       "  9582,\n",
       "  10748,\n",
       "  18111,\n",
       "  34390,\n",
       "  12797,\n",
       "  11234,\n",
       "  8180,\n",
       "  31663,\n",
       "  27615,\n",
       "  13353,\n",
       "  7228,\n",
       "  2760,\n",
       "  12312,\n",
       "  43092,\n",
       "  44896,\n",
       "  6109,\n",
       "  49197,\n",
       "  6828,\n",
       "  9267,\n",
       "  35384,\n",
       "  42579,\n",
       "  45573,\n",
       "  21963,\n",
       "  30583,\n",
       "  39962,\n",
       "  49917,\n",
       "  24156,\n",
       "  49372,\n",
       "  12578,\n",
       "  968,\n",
       "  33776,\n",
       "  43096,\n",
       "  29976,\n",
       "  37548,\n",
       "  5612,\n",
       "  16431,\n",
       "  25752,\n",
       "  24503,\n",
       "  42315,\n",
       "  19313,\n",
       "  3124,\n",
       "  30504,\n",
       "  40651,\n",
       "  35644,\n",
       "  26315,\n",
       "  31078,\n",
       "  40950,\n",
       "  36164,\n",
       "  18524,\n",
       "  35529,\n",
       "  10935,\n",
       "  48103,\n",
       "  37171,\n",
       "  18281,\n",
       "  10995,\n",
       "  4103,\n",
       "  30010,\n",
       "  14487,\n",
       "  20443,\n",
       "  34182,\n",
       "  34537,\n",
       "  22208,\n",
       "  49946,\n",
       "  9108,\n",
       "  21779,\n",
       "  33841,\n",
       "  43677,\n",
       "  25874,\n",
       "  6010,\n",
       "  31166,\n",
       "  17742,\n",
       "  13598,\n",
       "  36855,\n",
       "  9053,\n",
       "  41751,\n",
       "  9631,\n",
       "  39340,\n",
       "  7616,\n",
       "  48925,\n",
       "  39051,\n",
       "  3412,\n",
       "  1669,\n",
       "  9579,\n",
       "  36332,\n",
       "  40981,\n",
       "  33556,\n",
       "  17205,\n",
       "  32497,\n",
       "  46035,\n",
       "  36773,\n",
       "  29266,\n",
       "  22537,\n",
       "  4056,\n",
       "  18279,\n",
       "  42826,\n",
       "  2759,\n",
       "  17553,\n",
       "  16800,\n",
       "  9058,\n",
       "  25524,\n",
       "  27347,\n",
       "  30968,\n",
       "  48293,\n",
       "  6726,\n",
       "  8640,\n",
       "  35260,\n",
       "  9753,\n",
       "  15271,\n",
       "  15723,\n",
       "  9427,\n",
       "  31348,\n",
       "  19040,\n",
       "  38486,\n",
       "  31903,\n",
       "  18583,\n",
       "  7038,\n",
       "  3343,\n",
       "  35231,\n",
       "  49265,\n",
       "  32045,\n",
       "  15298,\n",
       "  22106,\n",
       "  17531,\n",
       "  5026,\n",
       "  49584,\n",
       "  6309,\n",
       "  20501,\n",
       "  36544,\n",
       "  9091,\n",
       "  23032,\n",
       "  27689,\n",
       "  48582,\n",
       "  16602,\n",
       "  48615,\n",
       "  47055,\n",
       "  10177,\n",
       "  5004,\n",
       "  40160,\n",
       "  26936,\n",
       "  15921,\n",
       "  45178,\n",
       "  41103,\n",
       "  12930,\n",
       "  41035,\n",
       "  20682,\n",
       "  8154,\n",
       "  34276,\n",
       "  39548,\n",
       "  34423,\n",
       "  5316,\n",
       "  2297,\n",
       "  23747,\n",
       "  36103,\n",
       "  17604,\n",
       "  4431,\n",
       "  8730,\n",
       "  43564,\n",
       "  21796,\n",
       "  49374,\n",
       "  25184,\n",
       "  28927,\n",
       "  1545,\n",
       "  46653,\n",
       "  6169,\n",
       "  21972,\n",
       "  21933,\n",
       "  1559,\n",
       "  35169,\n",
       "  45734,\n",
       "  5228,\n",
       "  28722,\n",
       "  5669,\n",
       "  2806,\n",
       "  42198,\n",
       "  26691,\n",
       "  43824,\n",
       "  13373,\n",
       "  29093,\n",
       "  41948,\n",
       "  4365,\n",
       "  46655,\n",
       "  16680,\n",
       "  40562,\n",
       "  28373,\n",
       "  31269,\n",
       "  45696,\n",
       "  19879,\n",
       "  43407,\n",
       "  3172,\n",
       "  34894,\n",
       "  21625,\n",
       "  2989,\n",
       "  6853,\n",
       "  45930,\n",
       "  9249,\n",
       "  38396,\n",
       "  4636,\n",
       "  31694,\n",
       "  40936,\n",
       "  33671,\n",
       "  17910,\n",
       "  25847,\n",
       "  6403,\n",
       "  12192,\n",
       "  47213,\n",
       "  21701,\n",
       "  10346,\n",
       "  21579,\n",
       "  35180,\n",
       "  38483,\n",
       "  23943,\n",
       "  5871,\n",
       "  1582,\n",
       "  16202,\n",
       "  28732,\n",
       "  36583,\n",
       "  5758,\n",
       "  2774,\n",
       "  33838,\n",
       "  7438,\n",
       "  9268,\n",
       "  33195,\n",
       "  44021,\n",
       "  49447,\n",
       "  27275,\n",
       "  31122,\n",
       "  32004,\n",
       "  45812,\n",
       "  11388,\n",
       "  44746,\n",
       "  42955,\n",
       "  26103,\n",
       "  46043,\n",
       "  7104,\n",
       "  15366,\n",
       "  28102,\n",
       "  37897,\n",
       "  49843,\n",
       "  49632,\n",
       "  1953,\n",
       "  42884,\n",
       "  13725,\n",
       "  17216,\n",
       "  15914,\n",
       "  44020,\n",
       "  15881,\n",
       "  47428,\n",
       "  8378,\n",
       "  29439,\n",
       "  17649,\n",
       "  18034,\n",
       "  4069,\n",
       "  43347,\n",
       "  43900,\n",
       "  40062,\n",
       "  34886,\n",
       "  35658,\n",
       "  11832,\n",
       "  29933,\n",
       "  5666,\n",
       "  13559,\n",
       "  28178,\n",
       "  24495,\n",
       "  23354,\n",
       "  5520,\n",
       "  27294,\n",
       "  37887,\n",
       "  29927,\n",
       "  1618,\n",
       "  47777,\n",
       "  1206,\n",
       "  4612,\n",
       "  17242,\n",
       "  38545,\n",
       "  33113,\n",
       "  5814,\n",
       "  10275,\n",
       "  29777,\n",
       "  37540,\n",
       "  35578,\n",
       "  17155,\n",
       "  27964,\n",
       "  23260,\n",
       "  37663,\n",
       "  23351,\n",
       "  23991,\n",
       "  38020,\n",
       "  39964,\n",
       "  32530,\n",
       "  1396,\n",
       "  20703,\n",
       "  43775,\n",
       "  22784,\n",
       "  12963,\n",
       "  46145,\n",
       "  27336,\n",
       "  37693,\n",
       "  37024,\n",
       "  30289,\n",
       "  44565,\n",
       "  10472,\n",
       "  35790,\n",
       "  19955,\n",
       "  18341,\n",
       "  9602,\n",
       "  23667,\n",
       "  29609,\n",
       "  44596,\n",
       "  17412,\n",
       "  27412,\n",
       "  1725,\n",
       "  13508,\n",
       "  13576,\n",
       "  45716,\n",
       "  3189,\n",
       "  7354,\n",
       "  24059,\n",
       "  47644,\n",
       "  452,\n",
       "  16186,\n",
       "  28983,\n",
       "  34212,\n",
       "  25028,\n",
       "  6525,\n",
       "  888,\n",
       "  826,\n",
       "  17730,\n",
       "  6338,\n",
       "  34970,\n",
       "  22272,\n",
       "  1842,\n",
       "  48977,\n",
       "  38092,\n",
       "  1299,\n",
       "  5730,\n",
       "  32757,\n",
       "  6860,\n",
       "  22562,\n",
       "  17895,\n",
       "  35542,\n",
       "  529,\n",
       "  48090,\n",
       "  49556,\n",
       "  41730,\n",
       "  12755,\n",
       "  41949,\n",
       "  ...],\n",
       " 'train_sampler': <torch.utils.data.sampler.SubsetRandomSampler at 0x7f44dd3bbbd0>,\n",
       " 'val_sampler': <torch.utils.data.sampler.SubsetRandomSampler at 0x7f4470cbd390>,\n",
       " 'classes': ('plane',\n",
       "  'car',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'deer',\n",
       "  'dog',\n",
       "  'frog',\n",
       "  'horse',\n",
       "  'ship',\n",
       "  'truck')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter\n",
    "lr = 0.0012\n",
    "#epochs = 50\n",
    "#epochs = 20\n",
    "epochs = 30\n",
    "batch_size = 60\n",
    "weight_decay = 1.2e-3\n",
    "iteration = 0\n",
    "remaining_weight = 1\n",
    "prune_per = 0.2\n",
    "# number of iteration\n",
    "noi = 11\n",
    "\n",
    "switch = 0\n",
    "best_accu = []\n",
    "# 마지막 layer의 Pruning rate는 기존의 1/2\n",
    "# prune_per_ll = prune_per/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cp_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_train = dsets.MNIST(root='../MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms,\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root='../MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms,\n",
    "                        download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, prune function\n",
    "def train(model, dataloader, optimizer, criterion, cp_mask):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, label) in enumerate(dataloader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        # 0-weight 학습 방지\n",
    "        if cp_mask:\n",
    "            i = 0\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    p.grad.data *= cp_mask[i]\n",
    "                    i += 1\n",
    "        optimizer.step()\n",
    "        running_loss += loss / len(dataloader)\n",
    "    return running_loss\n",
    "\n",
    "def test(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            outputs = model(data)\n",
    "            #test_loss += F.nll_loss(outputs, label, reduction='sum').item() # sum up batch loss\n",
    "            loss = criterion(outputs, label)\n",
    "            predicted = outputs.data.max(1, keepdim=True)[1]\n",
    "            correct += predicted.eq(label.data.view_as(predicted)).sum().item()\n",
    "            \n",
    "            test_loss += loss / len(dataloader)\n",
    "        accuracy =  correct / len(dataloader)\n",
    "        # 로더 -> 배치 개수 로더.dataset -> 전체 길이, \n",
    "    return accuracy, test_loss\n",
    "\n",
    "# prune function\n",
    "# pruning mask 생성 -> mask 복사 -> init값 복사 -> prune 진행\n",
    "def weight_init(model1, model2, c_rate, f_rate, o_rate):\n",
    "    # prune mask 생성\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name = 'weight', amount = c_rate)\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # bottle neck 방지\n",
    "            if name != 'fc3':\n",
    "                prune.l1_unstructured(module, name = 'weight', amount = f_rate)\n",
    "                break\n",
    "            else:\n",
    "                prune.l1_unstructured(module, name = 'weight', amount = o_rate)\n",
    "                        \n",
    "    # mask 복사\n",
    "    cp_mask = []\n",
    "    for name, mask in model1.named_buffers():\n",
    "        cp_mask.append(mask)\n",
    "    \n",
    "    # init 값을 model에 복사\n",
    "    for name, p in model1.named_parameters():\n",
    "        if 'weight_orig' in name:\n",
    "            for name2, p2 in model2.named_parameters():\n",
    "                if name[0:len(name) - 5] in name2:\n",
    "                    p.data = copy.deepcopy(p2.data)\n",
    "                    break\n",
    "        if 'bias_orig' in name:\n",
    "            for name2, p2 in model2.named_parameters():\n",
    "                if name[0:len(name) - 5] in name2:\n",
    "                    p.data = copy.deepcopy(p2.data)\n",
    "                    break\n",
    "                    \n",
    "    # prune 진행\n",
    "    for name, module in model1.named_modules():\n",
    "        \n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.remove(module, name = 'weight')\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            prune.remove(module, name = 'weight')\n",
    "    # copy된 mask return\n",
    "    return cp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 83\n"
     ]
    }
   ],
   "source": [
    "print(len(param.train_loader), len(param.val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            predicted = torch.argmax(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            accuracy = (correct/total)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cu.Conv6().to(device)\n",
    "model_init = copy.deepcopy(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "#optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = 1.2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPS = 1e-6\n",
    "# number of weight\n",
    "a = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0)\n",
    "#b = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "b = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "\n",
    "now = (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_now(model):\n",
    "    fc1_1 = ((model.fc1.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc1_0 = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc1 = fc1_1 + fc1_0\n",
    "    fc1_p = fc1_0 / fc1_1\n",
    "    fc2_1 = ((model.fc2.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc2_0 = ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc2 = fc2_1 + fc2_0\n",
    "    fc3_1 = ((model.fc3.weight != 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc3_0 = ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0).item()\n",
    "    fc3 = fc3_1 + fc3_0\n",
    "    #print(fc1, fc2, fc3, fc1+fc2+fc3, fc1_1 + fc2_1 + fc3_1 ,fc1_0 + fc2_0 + fc3_0)\n",
    "    print(\"Remaining weight %.1f %%\" %(((fc1_1+fc2_1+fc3_1)/(fc1+fc2+fc3))*100))\n",
    "    print('total weight :',\n",
    "        '%d' % (fc1+fc2+fc3),\n",
    "         '(%d |' % (fc1_1+fc2_1+fc3_1),\n",
    "         '%d)' % (fc1_0+fc2_0+fc3_0)\n",
    "         )\n",
    "    print('fc1 :',\n",
    "        '%d' % fc1,\n",
    "         '(%d |' % fc1_1,\n",
    "         '%d)' % fc1_0\n",
    "         )\n",
    "    print('fc2 :',\n",
    "        '%d' % fc2,\n",
    "         '(%d |' % fc2_1,\n",
    "         '%d)' % fc2_0\n",
    "         )\n",
    "    print('fc3 :',\n",
    "        '%d' % fc3,\n",
    "         '(%d |' % fc3_1,\n",
    "         '%d)' % fc3_0\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_init(model, model_init, 1 - weight_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_init(model, model_init, 1 - weight_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model.fc3.weight_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.l1_unstructured(module, name = 'weight', amount = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # init 값 복사\n",
    "for name, p in model.named_parameters():\n",
    "     if 'weight_orig' in name:\n",
    "        for name2, p2 in model_init.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break\n",
    "    if 'bias_orig' in name:\n",
    "        for name2, p2 in modelinit.named_parameters():\n",
    "            if name[0:len(name) - 5] in name2:\n",
    "                p.data = copy.deepcopy(p2.data)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        prune.remove(module, name = 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model.fc3.weight[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(model_init.fc3.weight[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start!\n",
      "\n",
      "Remaining weight 100.0 %\n",
      "total weight : 1116672 (1116672 | 0)\n",
      "fc1 : 1048576 (1048576 | 0)\n",
      "fc2 : 65536 (65536 | 0)\n",
      "fc3 : 2560 (2560 | 0)\n",
      "tensor([ 7.6890e-03, -3.6649e-02,  5.9590e-02, -4.2926e-02,  2.7237e-02,\n",
      "         5.2710e-02, -5.4603e-02,  3.5584e-02,  2.7941e-02, -3.2613e-02,\n",
      "        -5.8250e-02, -4.6459e-02,  9.4622e-03,  4.9968e-02,  5.2741e-02,\n",
      "        -7.3652e-03, -4.9151e-02, -3.7955e-02,  1.2158e-03,  5.4745e-02,\n",
      "        -1.7738e-02, -4.9666e-02,  3.2432e-02,  2.1323e-02, -1.7187e-02,\n",
      "        -3.6458e-02,  5.1150e-02, -6.1049e-03, -1.0101e-02,  1.0226e-02,\n",
      "        -3.4342e-02,  9.4833e-04, -4.0037e-02, -2.6993e-02, -2.1734e-02,\n",
      "        -1.0343e-02,  4.8679e-02, -1.1301e-02, -4.4951e-02, -2.4664e-03,\n",
      "        -1.6751e-02,  4.2464e-02,  5.2488e-02, -8.3954e-03,  5.9923e-02,\n",
      "         5.4813e-02, -3.3796e-02,  4.9552e-02, -2.6248e-02,  3.5886e-02,\n",
      "        -3.0951e-02,  4.2183e-03, -3.6124e-02, -6.3934e-04, -3.2179e-02,\n",
      "        -4.8573e-02, -3.5609e-02, -3.6832e-03,  2.8826e-02,  2.1156e-03,\n",
      "         1.3734e-04, -4.0242e-02,  3.0561e-02,  3.5835e-02,  1.3900e-03,\n",
      "         5.0367e-02,  4.4298e-02,  5.2146e-02, -1.8378e-02, -2.0506e-02,\n",
      "        -4.2609e-02, -3.6456e-02, -3.8613e-02, -1.2653e-02,  3.1574e-02,\n",
      "         1.2124e-03, -5.7803e-02, -4.4135e-02,  2.6971e-02, -3.7627e-02,\n",
      "         3.4280e-02, -1.2124e-02, -3.1103e-02,  2.9689e-02,  6.3315e-03,\n",
      "        -4.4978e-02,  1.2964e-02, -4.9616e-04,  2.0574e-02,  3.0878e-02,\n",
      "        -3.7234e-02,  4.0831e-02,  5.1146e-02, -1.1536e-02, -1.3133e-02,\n",
      "        -5.0238e-02,  4.8414e-02, -2.7973e-02,  5.7297e-02,  4.1277e-03,\n",
      "        -3.0485e-02, -2.1339e-02, -3.3587e-03, -4.6966e-02, -4.7902e-02,\n",
      "         3.2706e-02,  6.7365e-03,  2.4687e-02,  4.1024e-02,  3.2961e-02,\n",
      "        -5.6521e-02,  2.4689e-02,  3.5997e-02, -6.1706e-02,  4.8570e-02,\n",
      "         6.0467e-02, -2.7125e-02,  4.0221e-02,  2.1056e-02,  8.9198e-04,\n",
      "        -5.7183e-02, -4.7279e-02,  2.2876e-02,  2.0316e-02, -6.0155e-02,\n",
      "        -3.7070e-02,  1.3705e-02, -6.7007e-03, -2.7594e-02,  5.3302e-02,\n",
      "         3.0736e-02,  1.7539e-02, -7.4909e-03, -3.7125e-02,  1.4840e-02,\n",
      "         4.5410e-02,  3.7304e-02, -5.8316e-02,  2.9167e-02,  3.5933e-02,\n",
      "         4.5516e-05,  4.3370e-02, -5.4465e-02, -5.8635e-02, -2.6638e-03,\n",
      "         1.2085e-02, -4.4353e-02,  1.7780e-02,  2.8165e-02,  2.3354e-02,\n",
      "        -4.3221e-02, -6.6973e-03,  2.6887e-02,  4.3619e-02, -3.1245e-02,\n",
      "        -1.0859e-02,  4.0054e-02, -3.5586e-02, -3.7115e-02,  5.9401e-03,\n",
      "        -2.2450e-03, -2.2020e-02, -4.6015e-02,  5.6977e-02, -3.6759e-02,\n",
      "        -1.6392e-02,  5.6549e-02,  2.9449e-02,  4.1007e-02,  5.2173e-02,\n",
      "         2.9320e-02, -3.1283e-02, -1.1905e-02,  1.3729e-02,  2.7350e-02,\n",
      "         3.3365e-02,  3.2488e-02,  5.8925e-02,  4.8815e-02, -1.5883e-02,\n",
      "         2.6175e-02, -7.1794e-04,  2.0912e-02,  3.8410e-02, -1.8847e-02,\n",
      "        -1.3168e-02,  4.9705e-02,  3.6469e-02,  3.8061e-02,  4.6797e-02,\n",
      "         4.9893e-02,  3.0479e-02,  3.2981e-03,  2.4908e-02,  6.8775e-03,\n",
      "         2.0704e-02,  3.0280e-02, -3.7123e-03,  4.9393e-02,  2.4270e-04,\n",
      "        -1.7000e-02,  4.3215e-02,  1.1996e-02, -1.8140e-02, -5.8204e-02,\n",
      "         5.4902e-02,  6.8356e-03, -5.1845e-02, -6.2011e-02, -9.7137e-03,\n",
      "        -1.5128e-02, -1.6150e-02, -4.1919e-02,  2.5920e-02, -1.2524e-02,\n",
      "        -3.9993e-02, -2.9169e-02,  3.7464e-02,  6.1591e-02, -8.6735e-03,\n",
      "         9.3563e-03, -2.3211e-02,  2.8340e-02,  2.3612e-02, -4.2650e-02,\n",
      "        -2.4926e-03, -2.6484e-02, -4.0729e-02, -5.5216e-02,  3.3929e-02,\n",
      "        -3.2489e-02,  5.5096e-02,  5.6050e-02,  2.9803e-02,  4.2099e-02,\n",
      "        -4.7161e-02, -5.6837e-02,  3.7843e-02, -5.3196e-02, -5.9665e-02,\n",
      "         2.9696e-02, -5.6538e-02,  2.7176e-02, -3.0918e-02, -4.0334e-02,\n",
      "        -6.0490e-02,  3.8251e-02,  4.6406e-02, -2.7976e-02,  1.2265e-02,\n",
      "         4.1669e-02, -4.0490e-02,  5.2583e-02,  9.0696e-03,  5.9778e-02,\n",
      "         6.0885e-02], device='cuda:1', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7fa3f4bc6c74405be62ab0c2754199e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0] (loss: x.xxxxx) (accu: 0.1000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(param.noi):\n",
    "    best_accu.append(0)\n",
    "    best_accu[i] = [0, 0, 0]\n",
    "    cp_mask = []\n",
    "    remaining_weight = param.remaining_weight_f\n",
    "    if i != 0:\n",
    "        # x1 = 1 * (1-0.2)\n",
    "        # x2 = 1 * (1-0.2) * (1-0.2)\n",
    "        # ...\n",
    "        # xn = 1 * (1-0.2) ** n -> 남은 weight\n",
    "        # pruning weight 1 - (1-0.2)**n\n",
    "        \n",
    "        # 필요한 값은 pruning weight \n",
    "        # c = conv f = fc o = output layer\n",
    "        param.remaining_weight_c = (1-param.prune_per_c) ** i\n",
    "        param.remaining_weight_f = (1-param.prune_per_f) ** i\n",
    "        param.remaining_weight_o = (1-param.prune_per_o) ** i\n",
    "        #remaining_weight = param.remaining_weight_f\n",
    "        #1- 남은 웨이트 -> prune 할 비율\n",
    "        # pruning 및 mask 복사\n",
    "        cp_mask = weight_init(model, model_init,\n",
    "                              1 - param.remaining_weight_c,\n",
    "                              1 - param.remaining_weight_f,\n",
    "                              1 - param.remaining_weight_o\n",
    "                             )\n",
    "        #switch = 1\n",
    "    optimizer = optim.Adam(model.parameters(), lr = param.lr, weight_decay = param.weight_decay)\n",
    "    print(\"Learning start!\\n\")\n",
    "    calc_now(model)\n",
    "    \n",
    "    print(model.fc3.weight[0])\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    #pw = ((model.fc1.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc2.weight == 0).sum(dim=1)).sum(dim=0) + ((model.fc3.weight == 0).sum(dim=1)).sum(dim=0)\n",
    "    #print('pruned weight (All | Pruned) %d |' % now,'%d' % pw)\n",
    "    #print(model.fc3.weight[0][0])\n",
    "    #print(model_init.fc3.weight[0][0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(param.epochs)):\n",
    "        # epoch가 0일때 정확도 계산\n",
    "        if epoch == 0:\n",
    "            accuracy, test_loss = test(model, param.test_loader, criterion)\n",
    "            visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([0]),\n",
    "                        str(round(remaining_weight*100, 1))\n",
    "                       )\n",
    "            print('[epoch : %d]' % (epoch),\n",
    "             '(loss: x.xxxxx)',\n",
    "             '(accu: %.4f)' % (accuracy)\n",
    "             )\n",
    "        # model training    \n",
    "        running_loss = train(model, param.train_loader, optimizer, criterion, cp_mask)\n",
    "        # val_set이 있을 경우 val_set을 통해 loss, accu를 구한다.\n",
    "        if param.valset == 'empty':\n",
    "            accuracy, test_loss = test(model, param.test_loader, criterion)\n",
    "        else:\n",
    "            accuracy, test_loss = test(model, param.val_loader, criterion)\n",
    "        \n",
    "        # visdom plot\n",
    "        visdom_plot(vis_plt, torch.Tensor([accuracy]), torch.Tensor([(epoch+1) * 1000]),\n",
    "                    str(round(remaining_weight*100, 1))\n",
    "                   )\n",
    "        \n",
    "        # best accuracy list (weight_remain, epoch, accuracy)\n",
    "        if best_accu[i][2] <= accuracy:\n",
    "            best_accu[i] = [remaining_weight, epoch, accuracy]\n",
    "        \n",
    "        print('[epoch : %d]' % (epoch+1),\n",
    "             '(r_loss: %.5f)' % (running_loss),\n",
    "             '(t_loss: %.5f)' % (test_loss),\n",
    "             '(accu: %.4f)' % (accuracy)\n",
    "             )\n",
    "    stop_time = timeit.default_timer()\n",
    "    #print(model.fc3.weight[0][0])\n",
    "    #print(model_init.fc3.weight[0][0])\n",
    "    \n",
    "    print(model.fc3.weight[0])\n",
    "    \n",
    "    print(\"Finish!\",\n",
    "          \"(Best accu: %.4f)\" % best_accu[i][2],\n",
    "          \"(Time taken(sec) : %.2f)\" % (stop_time - start_time),\n",
    "          \"\\n\\n\\n\\n\\n\\n\\n\")\n",
    "    #calc_now(model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[epoch : 0] (loss: x.xxxxx) (accu: 0.1053)\n",
    "[epoch : 1] (r_loss: 0.00008) (t_loss: -8.30549) (accu: 0.9617)\n",
    "[epoch : 2] (r_loss: 0.00012) (t_loss: -8.05022) (accu: 0.9668)\n",
    "[epoch : 3] (r_loss: 0.00021) (t_loss: -8.19537) (accu: 0.9714)\n",
    "[epoch : 4] (r_loss: 0.00009) (t_loss: -7.94015) (accu: 0.9688)\n",
    "[epoch : 5] (r_loss: 0.00006) (t_loss: -8.75366) (accu: 0.9603)\n",
    "\n",
    "\n",
    "1\n",
    "[epoch : 0] (loss: x.xxxxx) (accu: 0.1053)\n",
    "[epoch : 1] (loss: 0.00008) (accu: 0.9617)\n",
    "[epoch : 2] (loss: 0.00012) (accu: 0.9668)\n",
    "[epoch : 3] (loss: 0.00021) (accu: 0.9714)\n",
    "[epoch : 4] (loss: 0.00009) (accu: 0.9688)\n",
    "[epoch : 5] (loss: 0.00006) (accu: 0.9603)\n",
    "2\n",
    "[epoch : 0] (loss: x.xxxxx) (accu: 0.0980)\n",
    "[epoch : 1] (loss: 0.00002) (accu: 0.9651)\n",
    "[epoch : 2] (loss: 0.00004) (accu: 0.9611)\n",
    "[epoch : 3] (loss: 0.00003) (accu: 0.9703)\n",
    "[epoch : 4] (loss: 0.00007) (accu: 0.9706)\n",
    "[epoch : 5] (loss: 0.00002) (accu: 0.9663)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum accuracy per weight remaining\")\n",
    "for i in range(len(best_accu)):\n",
    "    print(\"Remaining weight %.1f %% \" % (best_accu[i][0] * 100),\n",
    "         \"Epoch %d\" % best_accu[i][1],\n",
    "         \"Accu %.4f %%\" % best_accu[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, p in model.named_parameters():\n",
    "    EPS = 1e-6\n",
    "    if 'weight' in name:\n",
    "        tensor = p.data.cpu().numpy()\n",
    "        grad_tensor = p.grad.data.cpu().numpy()\n",
    "        grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "        p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        print(p.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 숫자 60000\n",
    "배치 길이 60\n",
    "배치 개수 1000\n",
    "epoch = 50\n",
    "\n",
    "이터레이션 횟수 50000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
