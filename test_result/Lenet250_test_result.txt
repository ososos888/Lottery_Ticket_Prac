Namespace(batch_size=60, dataset='mnist', epochs=40, lr=0.0012, model_arch='Lenet250_75', prune_iters=19, prune_per_conv=1, prune_per_linear=0.2, prune_per_out=0.1, test_iters=3, test_type='test_accu', testname='Lenet200_test', validation_ratio=0, weight_decay=0)
Learning start!
------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :        215500 (215500 | 0)          100.00
fc1.weight   :        196000 (196000 | 0)          100.00
fc2.weight   :         18750 (18750 | 0)           100.00
fcout.weight :           750 (750 | 0)             100.00
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (1/19), Remaining weight : 100.0 %]
[epoch : 1] (l_loss: 0.22366) (t_loss: 0.12327) (accu: 0.9622)
[epoch : 2] (l_loss: 0.09525) (t_loss: 0.09339) (accu: 0.9723)
[epoch : 3] (l_loss: 0.06771) (t_loss: 0.10773) (accu: 0.9674)
[epoch : 4] (l_loss: 0.05493) (t_loss: 0.07612) (accu: 0.9778)
[epoch : 5] (l_loss: 0.04518) (t_loss: 0.07679) (accu: 0.9780)
[epoch : 6] (l_loss: 0.03857) (t_loss: 0.07891) (accu: 0.9776)
[epoch : 7] (l_loss: 0.03285) (t_loss: 0.09602) (accu: 0.9751)
[epoch : 8] (l_loss: 0.02851) (t_loss: 0.10225) (accu: 0.9750)
[epoch : 9] (l_loss: 0.02471) (t_loss: 0.09902) (accu: 0.9767)
[epoch : 10] (l_loss: 0.02413) (t_loss: 0.09448) (accu: 0.9778)
[epoch : 11] (l_loss: 0.02189) (t_loss: 0.12755) (accu: 0.9733)
[epoch : 12] (l_loss: 0.02100) (t_loss: 0.10082) (accu: 0.9787)
[epoch : 13] (l_loss: 0.01618) (t_loss: 0.10400) (accu: 0.9785)
[epoch : 14] (l_loss: 0.01823) (t_loss: 0.11268) (accu: 0.9780)
[epoch : 15] (l_loss: 0.01861) (t_loss: 0.12047) (accu: 0.9768)
[epoch : 16] (l_loss: 0.01832) (t_loss: 0.10609) (accu: 0.9802)
[epoch : 17] (l_loss: 0.01537) (t_loss: 0.10909) (accu: 0.9810)
[epoch : 18] (l_loss: 0.01496) (t_loss: 0.13236) (accu: 0.9763)
[epoch : 19] (l_loss: 0.01414) (t_loss: 0.13274) (accu: 0.9786)
[epoch : 20] (l_loss: 0.01496) (t_loss: 0.12805) (accu: 0.9792)
[epoch : 21] (l_loss: 0.01382) (t_loss: 0.12089) (accu: 0.9795)
[epoch : 22] (l_loss: 0.01254) (t_loss: 0.14156) (accu: 0.9785)
[epoch : 23] (l_loss: 0.01312) (t_loss: 0.12995) (accu: 0.9786)
[epoch : 24] (l_loss: 0.01271) (t_loss: 0.12795) (accu: 0.9799)
[epoch : 25] (l_loss: 0.01395) (t_loss: 0.12098) (accu: 0.9803)
[epoch : 26] (l_loss: 0.00999) (t_loss: 0.13640) (accu: 0.9777)
[epoch : 27] (l_loss: 0.01551) (t_loss: 0.12394) (accu: 0.9809)
[epoch : 28] (l_loss: 0.00656) (t_loss: 0.13501) (accu: 0.9821)
[epoch : 29] (l_loss: 0.01221) (t_loss: 0.12800) (accu: 0.9789)
[epoch : 30] (l_loss: 0.01585) (t_loss: 0.13425) (accu: 0.9807)
[epoch : 31] (l_loss: 0.01177) (t_loss: 0.15159) (accu: 0.9795)
[epoch : 32] (l_loss: 0.00851) (t_loss: 0.13389) (accu: 0.9807)
[epoch : 33] (l_loss: 0.01035) (t_loss: 0.16514) (accu: 0.9787)
[epoch : 34] (l_loss: 0.01048) (t_loss: 0.13901) (accu: 0.9815)
[epoch : 35] (l_loss: 0.00791) (t_loss: 0.17001) (accu: 0.9783)
[epoch : 36] (l_loss: 0.01102) (t_loss: 0.14524) (accu: 0.9805)
[epoch : 37] (l_loss: 0.00974) (t_loss: 0.17158) (accu: 0.9791)
[epoch : 38] (l_loss: 0.01028) (t_loss: 0.16638) (accu: 0.9807)
[epoch : 39] (l_loss: 0.00976) (t_loss: 0.18687) (accu: 0.9791)
[epoch : 40] (l_loss: 0.01218) (t_loss: 0.17578) (accu: 0.9790)
Finish! (Best accu: 0.9821) (Time taken(sec) : 670.54) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (172475 | 43025)         80.03
fc1.weight   :      196000 (156800 | 39200)         80.00
fc2.weight   :        18750 (15000 | 3750)          80.00
fcout.weight :           750 (675 | 75)             90.00
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (2/19), Remaining weight : 80.03 %]
[epoch : 1] (l_loss: 0.20415) (t_loss: 0.11650) (accu: 0.9646)
[epoch : 2] (l_loss: 0.08694) (t_loss: 0.09426) (accu: 0.9712)
[epoch : 3] (l_loss: 0.06036) (t_loss: 0.08237) (accu: 0.9735)
[epoch : 4] (l_loss: 0.04454) (t_loss: 0.10422) (accu: 0.9711)
[epoch : 5] (l_loss: 0.03825) (t_loss: 0.07140) (accu: 0.9787)
[epoch : 6] (l_loss: 0.02955) (t_loss: 0.08207) (accu: 0.9784)
[epoch : 7] (l_loss: 0.02568) (t_loss: 0.08036) (accu: 0.9783)
[epoch : 8] (l_loss: 0.02726) (t_loss: 0.08247) (accu: 0.9795)
[epoch : 9] (l_loss: 0.02122) (t_loss: 0.10481) (accu: 0.9744)
[epoch : 10] (l_loss: 0.02004) (t_loss: 0.10403) (accu: 0.9764)
[epoch : 11] (l_loss: 0.01864) (t_loss: 0.11199) (accu: 0.9744)
[epoch : 12] (l_loss: 0.01718) (t_loss: 0.09996) (accu: 0.9782)
[epoch : 13] (l_loss: 0.01643) (t_loss: 0.12556) (accu: 0.9757)
[epoch : 14] (l_loss: 0.01646) (t_loss: 0.10384) (accu: 0.9808)
[epoch : 15] (l_loss: 0.01337) (t_loss: 0.12965) (accu: 0.9757)
[epoch : 16] (l_loss: 0.01624) (t_loss: 0.11107) (accu: 0.9806)
[epoch : 17] (l_loss: 0.01009) (t_loss: 0.11583) (accu: 0.9784)
[epoch : 18] (l_loss: 0.01044) (t_loss: 0.12677) (accu: 0.9793)
[epoch : 19] (l_loss: 0.01447) (t_loss: 0.12749) (accu: 0.9787)
[epoch : 20] (l_loss: 0.01253) (t_loss: 0.12492) (accu: 0.9809)
[epoch : 21] (l_loss: 0.00892) (t_loss: 0.09923) (accu: 0.9832)
[epoch : 22] (l_loss: 0.01290) (t_loss: 0.14536) (accu: 0.9754)
[epoch : 23] (l_loss: 0.01136) (t_loss: 0.11904) (accu: 0.9789)
[epoch : 24] (l_loss: 0.00923) (t_loss: 0.12147) (accu: 0.9803)
[epoch : 25] (l_loss: 0.01212) (t_loss: 0.14703) (accu: 0.9761)
[epoch : 26] (l_loss: 0.00849) (t_loss: 0.12196) (accu: 0.9810)
[epoch : 27] (l_loss: 0.01243) (t_loss: 0.19229) (accu: 0.9732)
[epoch : 28] (l_loss: 0.01226) (t_loss: 0.13949) (accu: 0.9806)
[epoch : 29] (l_loss: 0.00818) (t_loss: 0.13977) (accu: 0.9806)
[epoch : 30] (l_loss: 0.00842) (t_loss: 0.14376) (accu: 0.9812)
[epoch : 31] (l_loss: 0.00853) (t_loss: 0.17708) (accu: 0.9774)
[epoch : 32] (l_loss: 0.01021) (t_loss: 0.16111) (accu: 0.9799)
[epoch : 33] (l_loss: 0.00854) (t_loss: 0.19272) (accu: 0.9749)
[epoch : 34] (l_loss: 0.01015) (t_loss: 0.14981) (accu: 0.9804)
[epoch : 35] (l_loss: 0.00621) (t_loss: 0.15970) (accu: 0.9812)
[epoch : 36] (l_loss: 0.01406) (t_loss: 0.17205) (accu: 0.9792)
[epoch : 37] (l_loss: 0.00652) (t_loss: 0.15345) (accu: 0.9798)
[epoch : 38] (l_loss: 0.00595) (t_loss: 0.16215) (accu: 0.9818)
[epoch : 39] (l_loss: 0.00852) (t_loss: 0.15296) (accu: 0.9804)
[epoch : 40] (l_loss: 0.00995) (t_loss: 0.18594) (accu: 0.9775)
Finish! (Best accu: 0.9832) (Time taken(sec) : 684.60) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (138048 | 77452)         64.06
fc1.weight   :      196000 (125440 | 70560)         64.00
fc2.weight   :        18750 (12000 | 6750)          64.00
fcout.weight :          750 (608 | 142)             81.07
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (3/19), Remaining weight : 64.06 %]
[epoch : 1] (l_loss: 0.19950) (t_loss: 0.10086) (accu: 0.9695)
[epoch : 2] (l_loss: 0.07807) (t_loss: 0.08234) (accu: 0.9741)
[epoch : 3] (l_loss: 0.05351) (t_loss: 0.08365) (accu: 0.9743)
[epoch : 4] (l_loss: 0.04023) (t_loss: 0.07222) (accu: 0.9795)
[epoch : 5] (l_loss: 0.03365) (t_loss: 0.07230) (accu: 0.9784)
[epoch : 6] (l_loss: 0.02639) (t_loss: 0.08720) (accu: 0.9773)
[epoch : 7] (l_loss: 0.02226) (t_loss: 0.08476) (accu: 0.9778)
[epoch : 8] (l_loss: 0.02088) (t_loss: 0.08007) (accu: 0.9795)
[epoch : 9] (l_loss: 0.01914) (t_loss: 0.09694) (accu: 0.9774)
[epoch : 10] (l_loss: 0.01448) (t_loss: 0.09391) (accu: 0.9781)
[epoch : 11] (l_loss: 0.01848) (t_loss: 0.09396) (accu: 0.9804)
[epoch : 12] (l_loss: 0.01600) (t_loss: 0.09223) (accu: 0.9787)
[epoch : 13] (l_loss: 0.01191) (t_loss: 0.09582) (accu: 0.9799)
[epoch : 14] (l_loss: 0.00937) (t_loss: 0.12412) (accu: 0.9781)
[epoch : 15] (l_loss: 0.01526) (t_loss: 0.11008) (accu: 0.9789)
[epoch : 16] (l_loss: 0.00986) (t_loss: 0.11174) (accu: 0.9801)
[epoch : 17] (l_loss: 0.01314) (t_loss: 0.12799) (accu: 0.9791)
[epoch : 18] (l_loss: 0.01132) (t_loss: 0.11404) (accu: 0.9810)
[epoch : 19] (l_loss: 0.01159) (t_loss: 0.13651) (accu: 0.9790)
[epoch : 20] (l_loss: 0.01058) (t_loss: 0.13219) (accu: 0.9788)
[epoch : 21] (l_loss: 0.01043) (t_loss: 0.13210) (accu: 0.9802)
[epoch : 22] (l_loss: 0.01015) (t_loss: 0.12565) (accu: 0.9808)
[epoch : 23] (l_loss: 0.00971) (t_loss: 0.14737) (accu: 0.9794)
[epoch : 24] (l_loss: 0.00796) (t_loss: 0.13038) (accu: 0.9816)
[epoch : 25] (l_loss: 0.00937) (t_loss: 0.12824) (accu: 0.9816)
[epoch : 26] (l_loss: 0.00927) (t_loss: 0.14879) (accu: 0.9787)
[epoch : 27] (l_loss: 0.01085) (t_loss: 0.14532) (accu: 0.9795)
[epoch : 28] (l_loss: 0.00661) (t_loss: 0.15884) (accu: 0.9793)
[epoch : 29] (l_loss: 0.00978) (t_loss: 0.15904) (accu: 0.9804)
[epoch : 30] (l_loss: 0.00915) (t_loss: 0.13464) (accu: 0.9808)
[epoch : 31] (l_loss: 0.00833) (t_loss: 0.16743) (accu: 0.9796)
[epoch : 32] (l_loss: 0.00867) (t_loss: 0.18040) (accu: 0.9786)
[epoch : 33] (l_loss: 0.00611) (t_loss: 0.16887) (accu: 0.9796)
[epoch : 34] (l_loss: 0.00933) (t_loss: 0.17459) (accu: 0.9803)
[epoch : 35] (l_loss: 0.00707) (t_loss: 0.18892) (accu: 0.9789)
[epoch : 36] (l_loss: 0.00743) (t_loss: 0.15885) (accu: 0.9806)
[epoch : 37] (l_loss: 0.00997) (t_loss: 0.18554) (accu: 0.9782)
[epoch : 38] (l_loss: 0.00563) (t_loss: 0.16237) (accu: 0.9801)
[epoch : 39] (l_loss: 0.00743) (t_loss: 0.17784) (accu: 0.9793)
[epoch : 40] (l_loss: 0.00942) (t_loss: 0.14996) (accu: 0.9803)
Finish! (Best accu: 0.9816) (Time taken(sec) : 713.95) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (110499 | 105001)        51.28
fc1.weight   :      196000 (100352 | 95648)         51.20
fc2.weight   :        18750 (9600 | 9150)           51.20
fcout.weight :          750 (547 | 203)             72.93
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (4/19), Remaining weight : 51.28 %]
[epoch : 1] (l_loss: 0.19481) (t_loss: 0.09858) (accu: 0.9694)
[epoch : 2] (l_loss: 0.07003) (t_loss: 0.07116) (accu: 0.9786)
[epoch : 3] (l_loss: 0.04730) (t_loss: 0.07258) (accu: 0.9773)
[epoch : 4] (l_loss: 0.03196) (t_loss: 0.08221) (accu: 0.9751)
[epoch : 5] (l_loss: 0.02728) (t_loss: 0.07907) (accu: 0.9782)
[epoch : 6] (l_loss: 0.02202) (t_loss: 0.08092) (accu: 0.9782)
[epoch : 7] (l_loss: 0.01883) (t_loss: 0.07761) (accu: 0.9796)
[epoch : 8] (l_loss: 0.01595) (t_loss: 0.09219) (accu: 0.9763)
[epoch : 9] (l_loss: 0.01704) (t_loss: 0.09925) (accu: 0.9778)
[epoch : 10] (l_loss: 0.01420) (t_loss: 0.09362) (accu: 0.9792)
[epoch : 11] (l_loss: 0.01304) (t_loss: 0.10610) (accu: 0.9765)
[epoch : 12] (l_loss: 0.01076) (t_loss: 0.10592) (accu: 0.9797)
[epoch : 13] (l_loss: 0.01062) (t_loss: 0.10930) (accu: 0.9783)
[epoch : 14] (l_loss: 0.01006) (t_loss: 0.10445) (accu: 0.9809)
[epoch : 15] (l_loss: 0.01121) (t_loss: 0.12314) (accu: 0.9782)
[epoch : 16] (l_loss: 0.01036) (t_loss: 0.10109) (accu: 0.9805)
[epoch : 17] (l_loss: 0.01004) (t_loss: 0.11731) (accu: 0.9791)
[epoch : 18] (l_loss: 0.00807) (t_loss: 0.12308) (accu: 0.9775)
[epoch : 19] (l_loss: 0.01099) (t_loss: 0.11864) (accu: 0.9800)
[epoch : 20] (l_loss: 0.00672) (t_loss: 0.12641) (accu: 0.9809)
[epoch : 21] (l_loss: 0.00564) (t_loss: 0.13430) (accu: 0.9785)
[epoch : 22] (l_loss: 0.00806) (t_loss: 0.14226) (accu: 0.9788)
[epoch : 23] (l_loss: 0.00962) (t_loss: 0.13808) (accu: 0.9783)
[epoch : 24] (l_loss: 0.01009) (t_loss: 0.13379) (accu: 0.9809)
[epoch : 25] (l_loss: 0.00684) (t_loss: 0.13747) (accu: 0.9804)
[epoch : 26] (l_loss: 0.00594) (t_loss: 0.15148) (accu: 0.9776)
[epoch : 27] (l_loss: 0.00809) (t_loss: 0.16306) (accu: 0.9782)
[epoch : 28] (l_loss: 0.00957) (t_loss: 0.15504) (accu: 0.9795)
[epoch : 29] (l_loss: 0.00702) (t_loss: 0.15464) (accu: 0.9804)
[epoch : 30] (l_loss: 0.00565) (t_loss: 0.15570) (accu: 0.9785)
[epoch : 31] (l_loss: 0.00651) (t_loss: 0.13752) (accu: 0.9805)
[epoch : 32] (l_loss: 0.00512) (t_loss: 0.16248) (accu: 0.9805)
[epoch : 33] (l_loss: 0.00898) (t_loss: 0.15957) (accu: 0.9791)
[epoch : 34] (l_loss: 0.00481) (t_loss: 0.15080) (accu: 0.9808)
[epoch : 35] (l_loss: 0.00764) (t_loss: 0.16467) (accu: 0.9813)
[epoch : 36] (l_loss: 0.00713) (t_loss: 0.16918) (accu: 0.9796)
[epoch : 37] (l_loss: 0.00566) (t_loss: 0.16806) (accu: 0.9805)
[epoch : 38] (l_loss: 0.00715) (t_loss: 0.16905) (accu: 0.9804)
[epoch : 39] (l_loss: 0.00512) (t_loss: 0.15573) (accu: 0.9806)
[epoch : 40] (l_loss: 0.00486) (t_loss: 0.19273) (accu: 0.9795)
Finish! (Best accu: 0.9813) (Time taken(sec) : 721.75) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (88454 | 127046)         41.05
fc1.weight   :      196000 (80282 | 115718)         40.96
fc2.weight   :        18750 (7680 | 11070)          40.96
fcout.weight :          750 (492 | 258)             65.60
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (5/19), Remaining weight : 41.05 %]
[epoch : 1] (l_loss: 0.18769) (t_loss: 0.09493) (accu: 0.9701)
[epoch : 2] (l_loss: 0.06355) (t_loss: 0.08676) (accu: 0.9726)
[epoch : 3] (l_loss: 0.04021) (t_loss: 0.07511) (accu: 0.9768)
[epoch : 4] (l_loss: 0.02972) (t_loss: 0.06951) (accu: 0.9801)
[epoch : 5] (l_loss: 0.02294) (t_loss: 0.09824) (accu: 0.9758)
[epoch : 6] (l_loss: 0.01789) (t_loss: 0.07653) (accu: 0.9797)
[epoch : 7] (l_loss: 0.01704) (t_loss: 0.07769) (accu: 0.9807)
[epoch : 8] (l_loss: 0.01249) (t_loss: 0.09306) (accu: 0.9775)
[epoch : 9] (l_loss: 0.01349) (t_loss: 0.12092) (accu: 0.9731)
[epoch : 10] (l_loss: 0.01141) (t_loss: 0.09353) (accu: 0.9795)
[epoch : 11] (l_loss: 0.00869) (t_loss: 0.09735) (accu: 0.9809)
[epoch : 12] (l_loss: 0.00960) (t_loss: 0.10847) (accu: 0.9794)
[epoch : 13] (l_loss: 0.00992) (t_loss: 0.10514) (accu: 0.9807)
[epoch : 14] (l_loss: 0.00850) (t_loss: 0.11918) (accu: 0.9777)
[epoch : 15] (l_loss: 0.00729) (t_loss: 0.11535) (accu: 0.9791)
[epoch : 16] (l_loss: 0.00894) (t_loss: 0.13210) (accu: 0.9771)
[epoch : 17] (l_loss: 0.00591) (t_loss: 0.13349) (accu: 0.9777)
[epoch : 18] (l_loss: 0.00873) (t_loss: 0.14820) (accu: 0.9767)
[epoch : 19] (l_loss: 0.01004) (t_loss: 0.11679) (accu: 0.9809)
[epoch : 20] (l_loss: 0.00648) (t_loss: 0.13376) (accu: 0.9782)
[epoch : 21] (l_loss: 0.00591) (t_loss: 0.15106) (accu: 0.9800)
[epoch : 22] (l_loss: 0.00981) (t_loss: 0.12651) (accu: 0.9802)
[epoch : 23] (l_loss: 0.00551) (t_loss: 0.13831) (accu: 0.9805)
[epoch : 24] (l_loss: 0.00554) (t_loss: 0.13988) (accu: 0.9799)
[epoch : 25] (l_loss: 0.00775) (t_loss: 0.15152) (accu: 0.9774)
[epoch : 26] (l_loss: 0.00775) (t_loss: 0.14476) (accu: 0.9798)
[epoch : 27] (l_loss: 0.00517) (t_loss: 0.14438) (accu: 0.9815)
[epoch : 28] (l_loss: 0.00530) (t_loss: 0.17280) (accu: 0.9761)
[epoch : 29] (l_loss: 0.00632) (t_loss: 0.14645) (accu: 0.9795)
[epoch : 30] (l_loss: 0.00581) (t_loss: 0.14744) (accu: 0.9819)
[epoch : 31] (l_loss: 0.00589) (t_loss: 0.15035) (accu: 0.9806)
[epoch : 32] (l_loss: 0.00625) (t_loss: 0.17408) (accu: 0.9788)
[epoch : 33] (l_loss: 0.00393) (t_loss: 0.18096) (accu: 0.9760)
[epoch : 34] (l_loss: 0.00758) (t_loss: 0.15327) (accu: 0.9814)
[epoch : 35] (l_loss: 0.00377) (t_loss: 0.16301) (accu: 0.9813)
[epoch : 36] (l_loss: 0.00465) (t_loss: 0.17986) (accu: 0.9800)
[epoch : 37] (l_loss: 0.00608) (t_loss: 0.18118) (accu: 0.9794)
[epoch : 38] (l_loss: 0.00884) (t_loss: 0.16602) (accu: 0.9804)
[epoch : 39] (l_loss: 0.00552) (t_loss: 0.16472) (accu: 0.9799)
[epoch : 40] (l_loss: 0.00424) (t_loss: 0.17744) (accu: 0.9806)
Finish! (Best accu: 0.9819) (Time taken(sec) : 720.79) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (70812 | 144688)         32.86
fc1.weight   :      196000 (64225 | 131775)         32.77
fc2.weight   :        18750 (6144 | 12606)          32.77
fcout.weight :          750 (443 | 307)             59.07
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (6/19), Remaining weight : 32.86 %]
[epoch : 1] (l_loss: 0.18194) (t_loss: 0.08350) (accu: 0.9736)
[epoch : 2] (l_loss: 0.05563) (t_loss: 0.06408) (accu: 0.9797)
[epoch : 3] (l_loss: 0.03473) (t_loss: 0.06864) (accu: 0.9782)
[epoch : 4] (l_loss: 0.02398) (t_loss: 0.06899) (accu: 0.9804)
[epoch : 5] (l_loss: 0.01692) (t_loss: 0.07153) (accu: 0.9810)
[epoch : 6] (l_loss: 0.01600) (t_loss: 0.07033) (accu: 0.9807)
[epoch : 7] (l_loss: 0.01020) (t_loss: 0.08819) (accu: 0.9797)
[epoch : 8] (l_loss: 0.01241) (t_loss: 0.08720) (accu: 0.9800)
[epoch : 9] (l_loss: 0.00839) (t_loss: 0.09260) (accu: 0.9802)
[epoch : 10] (l_loss: 0.00840) (t_loss: 0.10553) (accu: 0.9774)
[epoch : 11] (l_loss: 0.00958) (t_loss: 0.09674) (accu: 0.9810)
[epoch : 12] (l_loss: 0.00918) (t_loss: 0.10963) (accu: 0.9796)
[epoch : 13] (l_loss: 0.00632) (t_loss: 0.10907) (accu: 0.9813)
[epoch : 14] (l_loss: 0.00585) (t_loss: 0.10283) (accu: 0.9808)
[epoch : 15] (l_loss: 0.00795) (t_loss: 0.11228) (accu: 0.9812)
[epoch : 16] (l_loss: 0.00647) (t_loss: 0.11078) (accu: 0.9826)
[epoch : 17] (l_loss: 0.00535) (t_loss: 0.13148) (accu: 0.9791)
[epoch : 18] (l_loss: 0.00682) (t_loss: 0.11930) (accu: 0.9809)
[epoch : 19] (l_loss: 0.00409) (t_loss: 0.12135) (accu: 0.9810)
[epoch : 20] (l_loss: 0.00752) (t_loss: 0.13029) (accu: 0.9814)
[epoch : 21] (l_loss: 0.00420) (t_loss: 0.11197) (accu: 0.9829)
[epoch : 22] (l_loss: 0.00631) (t_loss: 0.14344) (accu: 0.9797)
[epoch : 23] (l_loss: 0.00542) (t_loss: 0.13415) (accu: 0.9798)
[epoch : 24] (l_loss: 0.00405) (t_loss: 0.13734) (accu: 0.9809)
[epoch : 25] (l_loss: 0.00714) (t_loss: 0.13599) (accu: 0.9819)
[epoch : 26] (l_loss: 0.00486) (t_loss: 0.13043) (accu: 0.9824)
[epoch : 27] (l_loss: 0.00420) (t_loss: 0.13700) (accu: 0.9812)
[epoch : 28] (l_loss: 0.00450) (t_loss: 0.15146) (accu: 0.9819)
[epoch : 29] (l_loss: 0.00289) (t_loss: 0.16660) (accu: 0.9805)
[epoch : 30] (l_loss: 0.00818) (t_loss: 0.16145) (accu: 0.9785)
[epoch : 31] (l_loss: 0.00458) (t_loss: 0.15235) (accu: 0.9809)
[epoch : 32] (l_loss: 0.00432) (t_loss: 0.16205) (accu: 0.9807)
[epoch : 33] (l_loss: 0.00652) (t_loss: 0.15670) (accu: 0.9804)
[epoch : 34] (l_loss: 0.00210) (t_loss: 0.13838) (accu: 0.9819)
[epoch : 35] (l_loss: 0.00732) (t_loss: 0.19849) (accu: 0.9762)
[epoch : 36] (l_loss: 0.00533) (t_loss: 0.18653) (accu: 0.9785)
[epoch : 37] (l_loss: 0.00449) (t_loss: 0.16947) (accu: 0.9811)
[epoch : 38] (l_loss: 0.00245) (t_loss: 0.16919) (accu: 0.9804)
[epoch : 39] (l_loss: 0.00588) (t_loss: 0.16030) (accu: 0.9824)
[epoch : 40] (l_loss: 0.00391) (t_loss: 0.22075) (accu: 0.9773)
Finish! (Best accu: 0.9829) (Time taken(sec) : 731.58) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (56694 | 158806)         26.31
fc1.weight   :      196000 (51380 | 144620)         26.21
fc2.weight   :        18750 (4915 | 13835)          26.21
fcout.weight :          750 (399 | 351)             53.20
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (7/19), Remaining weight : 26.31 %]
[epoch : 1] (l_loss: 0.18269) (t_loss: 0.08157) (accu: 0.9747)
[epoch : 2] (l_loss: 0.05325) (t_loss: 0.07201) (accu: 0.9784)
[epoch : 3] (l_loss: 0.03252) (t_loss: 0.06462) (accu: 0.9809)
[epoch : 4] (l_loss: 0.02069) (t_loss: 0.07009) (accu: 0.9805)
[epoch : 5] (l_loss: 0.01553) (t_loss: 0.06921) (accu: 0.9823)
[epoch : 6] (l_loss: 0.01222) (t_loss: 0.07113) (accu: 0.9806)
[epoch : 7] (l_loss: 0.01016) (t_loss: 0.08264) (accu: 0.9802)
[epoch : 8] (l_loss: 0.01058) (t_loss: 0.09705) (accu: 0.9772)
[epoch : 9] (l_loss: 0.00929) (t_loss: 0.09155) (accu: 0.9815)
[epoch : 10] (l_loss: 0.00573) (t_loss: 0.10068) (accu: 0.9794)
[epoch : 11] (l_loss: 0.00830) (t_loss: 0.10327) (accu: 0.9793)
[epoch : 12] (l_loss: 0.00694) (t_loss: 0.09465) (accu: 0.9804)
[epoch : 13] (l_loss: 0.00529) (t_loss: 0.10123) (accu: 0.9804)
[epoch : 14] (l_loss: 0.00864) (t_loss: 0.10137) (accu: 0.9804)
[epoch : 15] (l_loss: 0.00501) (t_loss: 0.10444) (accu: 0.9813)
[epoch : 16] (l_loss: 0.00395) (t_loss: 0.11153) (accu: 0.9801)
[epoch : 17] (l_loss: 0.00810) (t_loss: 0.13221) (accu: 0.9785)
[epoch : 18] (l_loss: 0.00532) (t_loss: 0.12326) (accu: 0.9803)
[epoch : 19] (l_loss: 0.00318) (t_loss: 0.11761) (accu: 0.9801)
[epoch : 20] (l_loss: 0.00418) (t_loss: 0.12092) (accu: 0.9792)
[epoch : 21] (l_loss: 0.00691) (t_loss: 0.12954) (accu: 0.9812)
[epoch : 22] (l_loss: 0.00543) (t_loss: 0.12637) (accu: 0.9817)
[epoch : 23] (l_loss: 0.00319) (t_loss: 0.12204) (accu: 0.9809)
[epoch : 24] (l_loss: 0.00384) (t_loss: 0.13744) (accu: 0.9802)
[epoch : 25] (l_loss: 0.00467) (t_loss: 0.13861) (accu: 0.9806)
[epoch : 26] (l_loss: 0.00484) (t_loss: 0.14367) (accu: 0.9804)
[epoch : 27] (l_loss: 0.00451) (t_loss: 0.12985) (accu: 0.9821)
[epoch : 28] (l_loss: 0.00352) (t_loss: 0.13914) (accu: 0.9824)
[epoch : 29] (l_loss: 0.00406) (t_loss: 0.13526) (accu: 0.9811)
[epoch : 30] (l_loss: 0.00437) (t_loss: 0.14151) (accu: 0.9821)
[epoch : 31] (l_loss: 0.00253) (t_loss: 0.14568) (accu: 0.9814)
[epoch : 32] (l_loss: 0.00487) (t_loss: 0.15561) (accu: 0.9821)
[epoch : 33] (l_loss: 0.00308) (t_loss: 0.17295) (accu: 0.9784)
[epoch : 34] (l_loss: 0.00567) (t_loss: 0.14902) (accu: 0.9812)
[epoch : 35] (l_loss: 0.00290) (t_loss: 0.15206) (accu: 0.9833)
[epoch : 36] (l_loss: 0.00351) (t_loss: 0.16621) (accu: 0.9810)
[epoch : 37] (l_loss: 0.00487) (t_loss: 0.16228) (accu: 0.9815)
[epoch : 38] (l_loss: 0.00331) (t_loss: 0.16751) (accu: 0.9810)
[epoch : 39] (l_loss: 0.00419) (t_loss: 0.15900) (accu: 0.9810)
[epoch : 40] (l_loss: 0.00192) (t_loss: 0.16730) (accu: 0.9816)
Finish! (Best accu: 0.9833) (Time taken(sec) : 723.52) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (45395 | 170105)         21.06
fc1.weight   :      196000 (41104 | 154896)         20.97
fc2.weight   :        18750 (3932 | 14818)          20.97
fcout.weight :          750 (359 | 391)             47.87
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (8/19), Remaining weight : 21.06 %]
[epoch : 1] (l_loss: 0.17838) (t_loss: 0.08287) (accu: 0.9735)
[epoch : 2] (l_loss: 0.04775) (t_loss: 0.06435) (accu: 0.9796)
[epoch : 3] (l_loss: 0.02776) (t_loss: 0.06712) (accu: 0.9803)
[epoch : 4] (l_loss: 0.01698) (t_loss: 0.07327) (accu: 0.9798)
[epoch : 5] (l_loss: 0.01174) (t_loss: 0.07281) (accu: 0.9801)
[epoch : 6] (l_loss: 0.00979) (t_loss: 0.07982) (accu: 0.9812)
[epoch : 7] (l_loss: 0.00828) (t_loss: 0.07825) (accu: 0.9800)
[epoch : 8] (l_loss: 0.00466) (t_loss: 0.10693) (accu: 0.9770)
[epoch : 9] (l_loss: 0.00765) (t_loss: 0.09074) (accu: 0.9790)
[epoch : 10] (l_loss: 0.00619) (t_loss: 0.09899) (accu: 0.9778)
[epoch : 11] (l_loss: 0.00548) (t_loss: 0.09280) (accu: 0.9807)
[epoch : 12] (l_loss: 0.00437) (t_loss: 0.10079) (accu: 0.9807)
[epoch : 13] (l_loss: 0.00559) (t_loss: 0.09930) (accu: 0.9812)
[epoch : 14] (l_loss: 0.00507) (t_loss: 0.09651) (accu: 0.9810)
[epoch : 15] (l_loss: 0.00476) (t_loss: 0.09682) (accu: 0.9817)
[epoch : 16] (l_loss: 0.00184) (t_loss: 0.11763) (accu: 0.9810)
[epoch : 17] (l_loss: 0.00602) (t_loss: 0.11192) (accu: 0.9809)
[epoch : 18] (l_loss: 0.00271) (t_loss: 0.12506) (accu: 0.9810)
[epoch : 19] (l_loss: 0.00569) (t_loss: 0.14212) (accu: 0.9790)
[epoch : 20] (l_loss: 0.00366) (t_loss: 0.11760) (accu: 0.9824)
[epoch : 21] (l_loss: 0.00480) (t_loss: 0.13616) (accu: 0.9792)
[epoch : 22] (l_loss: 0.00419) (t_loss: 0.14555) (accu: 0.9773)
[epoch : 23] (l_loss: 0.00294) (t_loss: 0.13767) (accu: 0.9816)
[epoch : 24] (l_loss: 0.00225) (t_loss: 0.14651) (accu: 0.9802)
[epoch : 25] (l_loss: 0.00435) (t_loss: 0.14430) (accu: 0.9795)
[epoch : 26] (l_loss: 0.00428) (t_loss: 0.15249) (accu: 0.9786)
[epoch : 27] (l_loss: 0.00325) (t_loss: 0.14377) (accu: 0.9823)
[epoch : 28] (l_loss: 0.00525) (t_loss: 0.15122) (accu: 0.9787)
[epoch : 29] (l_loss: 0.00232) (t_loss: 0.15253) (accu: 0.9807)
[epoch : 30] (l_loss: 0.00276) (t_loss: 0.13857) (accu: 0.9822)
[epoch : 31] (l_loss: 0.00223) (t_loss: 0.17526) (accu: 0.9777)
[epoch : 32] (l_loss: 0.00470) (t_loss: 0.15476) (accu: 0.9808)
[epoch : 33] (l_loss: 0.00274) (t_loss: 0.17749) (accu: 0.9800)
[epoch : 34] (l_loss: 0.00346) (t_loss: 0.15490) (accu: 0.9817)
[epoch : 35] (l_loss: 0.00159) (t_loss: 0.16107) (accu: 0.9814)
[epoch : 36] (l_loss: 0.00341) (t_loss: 0.16272) (accu: 0.9810)
[epoch : 37] (l_loss: 0.00326) (t_loss: 0.16486) (accu: 0.9812)
[epoch : 38] (l_loss: 0.00300) (t_loss: 0.14930) (accu: 0.9831)
[epoch : 39] (l_loss: 0.00204) (t_loss: 0.15867) (accu: 0.9831)
[epoch : 40] (l_loss: 0.00277) (t_loss: 0.16949) (accu: 0.9799)
Finish! (Best accu: 0.9831) (Time taken(sec) : 730.36) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (36352 | 179148)         16.87
fc1.weight   :      196000 (32883 | 163117)         16.78
fc2.weight   :        18750 (3146 | 15604)          16.78
fcout.weight :          750 (323 | 427)             43.07
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (9/19), Remaining weight : 16.87 %]
[epoch : 1] (l_loss: 0.18282) (t_loss: 0.07920) (accu: 0.9766)
[epoch : 2] (l_loss: 0.04719) (t_loss: 0.06357) (accu: 0.9789)
[epoch : 3] (l_loss: 0.02606) (t_loss: 0.05936) (accu: 0.9825)
[epoch : 4] (l_loss: 0.01568) (t_loss: 0.06132) (accu: 0.9808)
[epoch : 5] (l_loss: 0.01083) (t_loss: 0.06672) (accu: 0.9823)
[epoch : 6] (l_loss: 0.00793) (t_loss: 0.07994) (accu: 0.9806)
[epoch : 7] (l_loss: 0.00763) (t_loss: 0.07304) (accu: 0.9817)
[epoch : 8] (l_loss: 0.00543) (t_loss: 0.07538) (accu: 0.9819)
[epoch : 9] (l_loss: 0.00403) (t_loss: 0.08454) (accu: 0.9818)
[epoch : 10] (l_loss: 0.00597) (t_loss: 0.09022) (accu: 0.9820)
[epoch : 11] (l_loss: 0.00310) (t_loss: 0.09223) (accu: 0.9816)
[epoch : 12] (l_loss: 0.00655) (t_loss: 0.09132) (accu: 0.9806)
[epoch : 13] (l_loss: 0.00334) (t_loss: 0.09083) (accu: 0.9834)
[epoch : 14] (l_loss: 0.00303) (t_loss: 0.09824) (accu: 0.9818)
[epoch : 15] (l_loss: 0.00273) (t_loss: 0.10284) (accu: 0.9799)
[epoch : 16] (l_loss: 0.00414) (t_loss: 0.10334) (accu: 0.9816)
[epoch : 17] (l_loss: 0.00476) (t_loss: 0.10564) (accu: 0.9814)
[epoch : 18] (l_loss: 0.00192) (t_loss: 0.11278) (accu: 0.9816)
[epoch : 19] (l_loss: 0.00495) (t_loss: 0.12228) (accu: 0.9809)
[epoch : 20] (l_loss: 0.00270) (t_loss: 0.10778) (accu: 0.9810)
[epoch : 21] (l_loss: 0.00226) (t_loss: 0.11325) (accu: 0.9800)
[epoch : 22] (l_loss: 0.00326) (t_loss: 0.12340) (accu: 0.9802)
[epoch : 23] (l_loss: 0.00236) (t_loss: 0.11758) (accu: 0.9819)
[epoch : 24] (l_loss: 0.00174) (t_loss: 0.11600) (accu: 0.9827)
[epoch : 25] (l_loss: 0.00436) (t_loss: 0.13967) (accu: 0.9793)
[epoch : 26] (l_loss: 0.00212) (t_loss: 0.11657) (accu: 0.9823)
[epoch : 27] (l_loss: 0.00209) (t_loss: 0.12627) (accu: 0.9820)
[epoch : 28] (l_loss: 0.00324) (t_loss: 0.12024) (accu: 0.9828)
[epoch : 29] (l_loss: 0.00328) (t_loss: 0.12754) (accu: 0.9832)
[epoch : 30] (l_loss: 0.00139) (t_loss: 0.13080) (accu: 0.9835)
[epoch : 31] (l_loss: 0.00246) (t_loss: 0.13782) (accu: 0.9817)
[epoch : 32] (l_loss: 0.00365) (t_loss: 0.13284) (accu: 0.9814)
[epoch : 33] (l_loss: 0.00180) (t_loss: 0.14543) (accu: 0.9811)
[epoch : 34] (l_loss: 0.00253) (t_loss: 0.15587) (accu: 0.9802)
[epoch : 35] (l_loss: 0.00350) (t_loss: 0.15313) (accu: 0.9819)
[epoch : 36] (l_loss: 0.00154) (t_loss: 0.15663) (accu: 0.9814)
[epoch : 37] (l_loss: 0.00164) (t_loss: 0.16069) (accu: 0.9820)
[epoch : 38] (l_loss: 0.00128) (t_loss: 0.16671) (accu: 0.9810)
[epoch : 39] (l_loss: 0.00356) (t_loss: 0.18114) (accu: 0.9790)
[epoch : 40] (l_loss: 0.00280) (t_loss: 0.15429) (accu: 0.9818)
Finish! (Best accu: 0.9835) (Time taken(sec) : 736.69) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (29115 | 186385)         13.51
fc1.weight   :      196000 (26307 | 169693)         13.42
fc2.weight   :        18750 (2517 | 16233)          13.42
fcout.weight :          750 (291 | 459)             38.80
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (10/19), Remaining weight : 13.51 %]
[epoch : 1] (l_loss: 0.19218) (t_loss: 0.07360) (accu: 0.9780)
[epoch : 2] (l_loss: 0.04475) (t_loss: 0.06702) (accu: 0.9789)
[epoch : 3] (l_loss: 0.02420) (t_loss: 0.06266) (accu: 0.9808)
[epoch : 4] (l_loss: 0.01459) (t_loss: 0.06381) (accu: 0.9819)
[epoch : 5] (l_loss: 0.00834) (t_loss: 0.06962) (accu: 0.9813)
[epoch : 6] (l_loss: 0.00648) (t_loss: 0.06793) (accu: 0.9812)
[epoch : 7] (l_loss: 0.00531) (t_loss: 0.06863) (accu: 0.9827)
[epoch : 8] (l_loss: 0.00364) (t_loss: 0.08019) (accu: 0.9818)
[epoch : 9] (l_loss: 0.00564) (t_loss: 0.08428) (accu: 0.9801)
[epoch : 10] (l_loss: 0.00385) (t_loss: 0.08397) (accu: 0.9830)
[epoch : 11] (l_loss: 0.00181) (t_loss: 0.09747) (accu: 0.9792)
[epoch : 12] (l_loss: 0.00458) (t_loss: 0.09091) (accu: 0.9815)
[epoch : 13] (l_loss: 0.00436) (t_loss: 0.08960) (accu: 0.9826)
[epoch : 14] (l_loss: 0.00201) (t_loss: 0.09229) (accu: 0.9838)
[epoch : 15] (l_loss: 0.00024) (t_loss: 0.09124) (accu: 0.9848)
[epoch : 16] (l_loss: 0.00012) (t_loss: 0.09268) (accu: 0.9849)
[epoch : 17] (l_loss: 0.00767) (t_loss: 0.11813) (accu: 0.9796)
[epoch : 18] (l_loss: 0.00260) (t_loss: 0.10660) (accu: 0.9824)
[epoch : 19] (l_loss: 0.00239) (t_loss: 0.10759) (accu: 0.9831)
[epoch : 20] (l_loss: 0.00128) (t_loss: 0.12421) (accu: 0.9825)
[epoch : 21] (l_loss: 0.00465) (t_loss: 0.11956) (accu: 0.9816)
[epoch : 22] (l_loss: 0.00202) (t_loss: 0.12158) (accu: 0.9806)
[epoch : 23] (l_loss: 0.00191) (t_loss: 0.12612) (accu: 0.9819)
[epoch : 24] (l_loss: 0.00104) (t_loss: 0.12142) (accu: 0.9820)
[epoch : 25] (l_loss: 0.00449) (t_loss: 0.14413) (accu: 0.9798)
[epoch : 26] (l_loss: 0.00256) (t_loss: 0.12687) (accu: 0.9826)
[epoch : 27] (l_loss: 0.00216) (t_loss: 0.14743) (accu: 0.9810)
[epoch : 28] (l_loss: 0.00273) (t_loss: 0.13209) (accu: 0.9814)
[epoch : 29] (l_loss: 0.00232) (t_loss: 0.14005) (accu: 0.9827)
[epoch : 30] (l_loss: 0.00065) (t_loss: 0.12995) (accu: 0.9825)
[epoch : 31] (l_loss: 0.00247) (t_loss: 0.14974) (accu: 0.9782)
[epoch : 32] (l_loss: 0.00072) (t_loss: 0.13536) (accu: 0.9826)
[epoch : 33] (l_loss: 0.00439) (t_loss: 0.14762) (accu: 0.9820)
[epoch : 34] (l_loss: 0.00209) (t_loss: 0.13548) (accu: 0.9821)
[epoch : 35] (l_loss: 0.00023) (t_loss: 0.14317) (accu: 0.9825)
[epoch : 36] (l_loss: 0.00004) (t_loss: 0.13136) (accu: 0.9837)
[epoch : 37] (l_loss: 0.00001) (t_loss: 0.13220) (accu: 0.9839)
[epoch : 38] (l_loss: 0.00001) (t_loss: 0.13297) (accu: 0.9838)
[epoch : 39] (l_loss: 0.00001) (t_loss: 0.13414) (accu: 0.9840)
[epoch : 40] (l_loss: 0.00000) (t_loss: 0.13496) (accu: 0.9840)
Finish! (Best accu: 0.9849) (Time taken(sec) : 731.82) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (23320 | 192180)         10.82
fc1.weight   :      196000 (21045 | 174955)         10.74
fc2.weight   :        18750 (2013 | 16737)          10.74
fcout.weight :          750 (262 | 488)             34.93
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (11/19), Remaining weight : 10.82 %]
[epoch : 1] (l_loss: 0.19903) (t_loss: 0.07986) (accu: 0.9757)
[epoch : 2] (l_loss: 0.04522) (t_loss: 0.05843) (accu: 0.9811)
[epoch : 3] (l_loss: 0.02319) (t_loss: 0.05832) (accu: 0.9821)
[epoch : 4] (l_loss: 0.01375) (t_loss: 0.06340) (accu: 0.9816)
[epoch : 5] (l_loss: 0.00823) (t_loss: 0.06302) (accu: 0.9825)
[epoch : 6] (l_loss: 0.00566) (t_loss: 0.06586) (accu: 0.9836)
[epoch : 7] (l_loss: 0.00502) (t_loss: 0.07881) (accu: 0.9819)
[epoch : 8] (l_loss: 0.00391) (t_loss: 0.08069) (accu: 0.9816)
[epoch : 9] (l_loss: 0.00311) (t_loss: 0.08460) (accu: 0.9822)
[epoch : 10] (l_loss: 0.00258) (t_loss: 0.09139) (accu: 0.9826)
[epoch : 11] (l_loss: 0.00411) (t_loss: 0.08702) (accu: 0.9829)
[epoch : 12] (l_loss: 0.00098) (t_loss: 0.09341) (accu: 0.9827)
[epoch : 13] (l_loss: 0.00334) (t_loss: 0.10350) (accu: 0.9806)
[epoch : 14] (l_loss: 0.00226) (t_loss: 0.09724) (accu: 0.9818)
[epoch : 15] (l_loss: 0.00124) (t_loss: 0.09392) (accu: 0.9814)
[epoch : 16] (l_loss: 0.00479) (t_loss: 0.10318) (accu: 0.9831)
[epoch : 17] (l_loss: 0.00068) (t_loss: 0.09487) (accu: 0.9835)
[epoch : 18] (l_loss: 0.00020) (t_loss: 0.09938) (accu: 0.9840)
[epoch : 19] (l_loss: 0.00009) (t_loss: 0.10168) (accu: 0.9835)
[epoch : 20] (l_loss: 0.00005) (t_loss: 0.09986) (accu: 0.9843)
[epoch : 21] (l_loss: 0.00003) (t_loss: 0.10120) (accu: 0.9843)
[epoch : 22] (l_loss: 0.00002) (t_loss: 0.10484) (accu: 0.9846)
[epoch : 23] (l_loss: 0.00002) (t_loss: 0.10816) (accu: 0.9841)
[epoch : 24] (l_loss: 0.00527) (t_loss: 0.15889) (accu: 0.9764)
[epoch : 25] (l_loss: 0.00627) (t_loss: 0.12127) (accu: 0.9828)
[epoch : 26] (l_loss: 0.00089) (t_loss: 0.12163) (accu: 0.9832)
[epoch : 27] (l_loss: 0.00063) (t_loss: 0.11764) (accu: 0.9829)
[epoch : 28] (l_loss: 0.00007) (t_loss: 0.11402) (accu: 0.9842)
[epoch : 29] (l_loss: 0.00004) (t_loss: 0.11500) (accu: 0.9842)
[epoch : 30] (l_loss: 0.00002) (t_loss: 0.11623) (accu: 0.9842)
[epoch : 31] (l_loss: 0.00001) (t_loss: 0.11844) (accu: 0.9844)
[epoch : 32] (l_loss: 0.00001) (t_loss: 0.12041) (accu: 0.9841)
[epoch : 33] (l_loss: 0.00001) (t_loss: 0.12251) (accu: 0.9840)
[epoch : 34] (l_loss: 0.00078) (t_loss: 0.18659) (accu: 0.9773)
[epoch : 35] (l_loss: 0.01133) (t_loss: 0.15108) (accu: 0.9815)
[epoch : 36] (l_loss: 0.00082) (t_loss: 0.13952) (accu: 0.9833)
[epoch : 37] (l_loss: 0.00011) (t_loss: 0.13750) (accu: 0.9829)
[epoch : 38] (l_loss: 0.00003) (t_loss: 0.13802) (accu: 0.9831)
[epoch : 39] (l_loss: 0.00002) (t_loss: 0.13845) (accu: 0.9835)
[epoch : 40] (l_loss: 0.00001) (t_loss: 0.13925) (accu: 0.9834)
Finish! (Best accu: 0.9846) (Time taken(sec) : 740.31) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (18682 | 196818)          8.67
fc1.weight   :      196000 (16836 | 179164)          8.59
fc2.weight   :        18750 (1611 | 17139)           8.59
fcout.weight :          750 (235 | 515)             31.33
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (12/19), Remaining weight : 8.67 %]
[epoch : 1] (l_loss: 0.21790) (t_loss: 0.07924) (accu: 0.9766)
[epoch : 2] (l_loss: 0.04793) (t_loss: 0.06184) (accu: 0.9811)
[epoch : 3] (l_loss: 0.02585) (t_loss: 0.05925) (accu: 0.9812)
[epoch : 4] (l_loss: 0.01519) (t_loss: 0.06417) (accu: 0.9814)
[epoch : 5] (l_loss: 0.00956) (t_loss: 0.05992) (accu: 0.9835)
[epoch : 6] (l_loss: 0.00610) (t_loss: 0.07220) (accu: 0.9809)
[epoch : 7] (l_loss: 0.00460) (t_loss: 0.07693) (accu: 0.9821)
[epoch : 8] (l_loss: 0.00380) (t_loss: 0.08255) (accu: 0.9807)
[epoch : 9] (l_loss: 0.00213) (t_loss: 0.07863) (accu: 0.9821)
[epoch : 10] (l_loss: 0.00192) (t_loss: 0.10277) (accu: 0.9792)
[epoch : 11] (l_loss: 0.00486) (t_loss: 0.08851) (accu: 0.9814)
[epoch : 12] (l_loss: 0.00096) (t_loss: 0.09495) (accu: 0.9827)
[epoch : 13] (l_loss: 0.00065) (t_loss: 0.08773) (accu: 0.9827)
[epoch : 14] (l_loss: 0.00187) (t_loss: 0.12417) (accu: 0.9784)
[epoch : 15] (l_loss: 0.00470) (t_loss: 0.09794) (accu: 0.9833)
[epoch : 16] (l_loss: 0.00096) (t_loss: 0.09757) (accu: 0.9843)
[epoch : 17] (l_loss: 0.00076) (t_loss: 0.10636) (accu: 0.9811)
[epoch : 18] (l_loss: 0.00480) (t_loss: 0.10494) (accu: 0.9824)
[epoch : 19] (l_loss: 0.00094) (t_loss: 0.10260) (accu: 0.9824)
[epoch : 20] (l_loss: 0.00024) (t_loss: 0.10150) (accu: 0.9837)
[epoch : 21] (l_loss: 0.00007) (t_loss: 0.10265) (accu: 0.9840)
[epoch : 22] (l_loss: 0.00004) (t_loss: 0.10369) (accu: 0.9842)
[epoch : 23] (l_loss: 0.00003) (t_loss: 0.10547) (accu: 0.9842)
[epoch : 24] (l_loss: 0.00003) (t_loss: 0.10806) (accu: 0.9841)
[epoch : 25] (l_loss: 0.00572) (t_loss: 0.13159) (accu: 0.9815)
[epoch : 26] (l_loss: 0.00319) (t_loss: 0.12467) (accu: 0.9825)
[epoch : 27] (l_loss: 0.00083) (t_loss: 0.12818) (accu: 0.9822)
[epoch : 28] (l_loss: 0.00011) (t_loss: 0.12430) (accu: 0.9834)
[epoch : 29] (l_loss: 0.00005) (t_loss: 0.12521) (accu: 0.9832)
[epoch : 30] (l_loss: 0.00003) (t_loss: 0.12643) (accu: 0.9830)
[epoch : 31] (l_loss: 0.00002) (t_loss: 0.12741) (accu: 0.9835)
[epoch : 32] (l_loss: 0.00001) (t_loss: 0.12858) (accu: 0.9834)
[epoch : 33] (l_loss: 0.00001) (t_loss: 0.13096) (accu: 0.9833)
[epoch : 34] (l_loss: 0.00001) (t_loss: 0.13182) (accu: 0.9831)
[epoch : 35] (l_loss: 0.00001) (t_loss: 0.13519) (accu: 0.9838)
[epoch : 36] (l_loss: 0.00785) (t_loss: 0.14130) (accu: 0.9815)
[epoch : 37] (l_loss: 0.00163) (t_loss: 0.13811) (accu: 0.9829)
[epoch : 38] (l_loss: 0.00119) (t_loss: 0.13353) (accu: 0.9833)
[epoch : 39] (l_loss: 0.00105) (t_loss: 0.15233) (accu: 0.9810)
[epoch : 40] (l_loss: 0.00152) (t_loss: 0.14380) (accu: 0.9823)
Finish! (Best accu: 0.9843) (Time taken(sec) : 734.10) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (14969 | 200531)          6.95
fc1.weight   :      196000 (13469 | 182531)          6.87
fc2.weight   :        18750 (1288 | 17462)           6.87
fcout.weight :          750 (212 | 538)             28.27
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (13/19), Remaining weight : 6.95 %]
[epoch : 1] (l_loss: 0.24406) (t_loss: 0.08823) (accu: 0.9730)
[epoch : 2] (l_loss: 0.05496) (t_loss: 0.06566) (accu: 0.9802)
[epoch : 3] (l_loss: 0.03028) (t_loss: 0.06076) (accu: 0.9807)
[epoch : 4] (l_loss: 0.01834) (t_loss: 0.06013) (accu: 0.9825)
[epoch : 5] (l_loss: 0.01149) (t_loss: 0.05922) (accu: 0.9827)
[epoch : 6] (l_loss: 0.00780) (t_loss: 0.06605) (accu: 0.9813)
[epoch : 7] (l_loss: 0.00535) (t_loss: 0.07124) (accu: 0.9814)
[epoch : 8] (l_loss: 0.00397) (t_loss: 0.07366) (accu: 0.9821)
[epoch : 9] (l_loss: 0.00292) (t_loss: 0.08069) (accu: 0.9803)
[epoch : 10] (l_loss: 0.00348) (t_loss: 0.08152) (accu: 0.9808)
[epoch : 11] (l_loss: 0.00136) (t_loss: 0.08382) (accu: 0.9818)
[epoch : 12] (l_loss: 0.00177) (t_loss: 0.09287) (accu: 0.9811)
[epoch : 13] (l_loss: 0.00400) (t_loss: 0.09392) (accu: 0.9820)
[epoch : 14] (l_loss: 0.00125) (t_loss: 0.09066) (accu: 0.9826)
[epoch : 15] (l_loss: 0.00098) (t_loss: 0.09148) (accu: 0.9825)
[epoch : 16] (l_loss: 0.00195) (t_loss: 0.10478) (accu: 0.9809)
[epoch : 17] (l_loss: 0.00179) (t_loss: 0.10703) (accu: 0.9808)
[epoch : 18] (l_loss: 0.00183) (t_loss: 0.10637) (accu: 0.9808)
[epoch : 19] (l_loss: 0.00163) (t_loss: 0.10496) (accu: 0.9814)
[epoch : 20] (l_loss: 0.00063) (t_loss: 0.10112) (accu: 0.9825)
[epoch : 21] (l_loss: 0.00012) (t_loss: 0.10018) (accu: 0.9832)
[epoch : 22] (l_loss: 0.00006) (t_loss: 0.10090) (accu: 0.9835)
[epoch : 23] (l_loss: 0.00004) (t_loss: 0.10343) (accu: 0.9827)
[epoch : 24] (l_loss: 0.00003) (t_loss: 0.10570) (accu: 0.9832)
[epoch : 25] (l_loss: 0.00003) (t_loss: 0.10826) (accu: 0.9831)
[epoch : 26] (l_loss: 0.00275) (t_loss: 0.13755) (accu: 0.9792)
[epoch : 27] (l_loss: 0.00403) (t_loss: 0.12820) (accu: 0.9805)
[epoch : 28] (l_loss: 0.00095) (t_loss: 0.12417) (accu: 0.9823)
[epoch : 29] (l_loss: 0.00017) (t_loss: 0.11821) (accu: 0.9832)
[epoch : 30] (l_loss: 0.00013) (t_loss: 0.12198) (accu: 0.9828)
[epoch : 31] (l_loss: 0.00304) (t_loss: 0.14319) (accu: 0.9815)
[epoch : 32] (l_loss: 0.00255) (t_loss: 0.14236) (accu: 0.9800)
[epoch : 33] (l_loss: 0.00102) (t_loss: 0.14690) (accu: 0.9799)
[epoch : 34] (l_loss: 0.00025) (t_loss: 0.13089) (accu: 0.9838)
[epoch : 35] (l_loss: 0.00004) (t_loss: 0.12796) (accu: 0.9836)
[epoch : 36] (l_loss: 0.00002) (t_loss: 0.12789) (accu: 0.9839)
[epoch : 37] (l_loss: 0.00002) (t_loss: 0.12898) (accu: 0.9840)
[epoch : 38] (l_loss: 0.00001) (t_loss: 0.12982) (accu: 0.9841)
[epoch : 39] (l_loss: 0.00001) (t_loss: 0.13080) (accu: 0.9841)
[epoch : 40] (l_loss: 0.00001) (t_loss: 0.13307) (accu: 0.9840)
Finish! (Best accu: 0.9841) (Time taken(sec) : 741.23) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (11997 | 203503)          5.57
fc1.weight   :      196000 (10775 | 185225)          5.50
fc2.weight   :        18750 (1031 | 17719)           5.50
fcout.weight :          750 (191 | 559)             25.47
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (14/19), Remaining weight : 5.57 %]
[epoch : 1] (l_loss: 0.27301) (t_loss: 0.09466) (accu: 0.9717)
[epoch : 2] (l_loss: 0.06004) (t_loss: 0.06674) (accu: 0.9791)
[epoch : 3] (l_loss: 0.03457) (t_loss: 0.06499) (accu: 0.9799)
[epoch : 4] (l_loss: 0.02223) (t_loss: 0.06248) (accu: 0.9806)
[epoch : 5] (l_loss: 0.01476) (t_loss: 0.06247) (accu: 0.9819)
[epoch : 6] (l_loss: 0.00982) (t_loss: 0.06495) (accu: 0.9810)
[epoch : 7] (l_loss: 0.00674) (t_loss: 0.07112) (accu: 0.9804)
[epoch : 8] (l_loss: 0.00444) (t_loss: 0.07916) (accu: 0.9800)
[epoch : 9] (l_loss: 0.00374) (t_loss: 0.07937) (accu: 0.9822)
[epoch : 10] (l_loss: 0.00239) (t_loss: 0.09716) (accu: 0.9788)
[epoch : 11] (l_loss: 0.00228) (t_loss: 0.09054) (accu: 0.9807)
[epoch : 12] (l_loss: 0.00164) (t_loss: 0.12403) (accu: 0.9759)
[epoch : 13] (l_loss: 0.00377) (t_loss: 0.10347) (accu: 0.9802)
[epoch : 14] (l_loss: 0.00150) (t_loss: 0.10362) (accu: 0.9817)
[epoch : 15] (l_loss: 0.00045) (t_loss: 0.10104) (accu: 0.9812)
[epoch : 16] (l_loss: 0.00023) (t_loss: 0.10290) (accu: 0.9813)
[epoch : 17] (l_loss: 0.00019) (t_loss: 0.10818) (accu: 0.9813)
[epoch : 18] (l_loss: 0.00337) (t_loss: 0.12553) (accu: 0.9793)
[epoch : 19] (l_loss: 0.00284) (t_loss: 0.10943) (accu: 0.9811)
[epoch : 20] (l_loss: 0.00042) (t_loss: 0.10814) (accu: 0.9815)
[epoch : 21] (l_loss: 0.00014) (t_loss: 0.10921) (accu: 0.9823)
[epoch : 22] (l_loss: 0.00009) (t_loss: 0.11116) (accu: 0.9817)
[epoch : 23] (l_loss: 0.00007) (t_loss: 0.11325) (accu: 0.9820)
[epoch : 24] (l_loss: 0.00006) (t_loss: 0.11599) (accu: 0.9826)
[epoch : 25] (l_loss: 0.00006) (t_loss: 0.12482) (accu: 0.9818)
[epoch : 26] (l_loss: 0.00808) (t_loss: 0.12843) (accu: 0.9813)
[epoch : 27] (l_loss: 0.00071) (t_loss: 0.12839) (accu: 0.9811)
[epoch : 28] (l_loss: 0.00015) (t_loss: 0.12894) (accu: 0.9822)
[epoch : 29] (l_loss: 0.00007) (t_loss: 0.12801) (accu: 0.9823)
[epoch : 30] (l_loss: 0.00005) (t_loss: 0.12915) (accu: 0.9820)
[epoch : 31] (l_loss: 0.00004) (t_loss: 0.13000) (accu: 0.9818)
[epoch : 32] (l_loss: 0.00003) (t_loss: 0.13184) (accu: 0.9823)
[epoch : 33] (l_loss: 0.00002) (t_loss: 0.13186) (accu: 0.9824)
[epoch : 34] (l_loss: 0.00365) (t_loss: 0.16057) (accu: 0.9799)
[epoch : 35] (l_loss: 0.00313) (t_loss: 0.15387) (accu: 0.9801)
[epoch : 36] (l_loss: 0.00056) (t_loss: 0.14527) (accu: 0.9811)
[epoch : 37] (l_loss: 0.00015) (t_loss: 0.14067) (accu: 0.9827)
[epoch : 38] (l_loss: 0.00005) (t_loss: 0.14086) (accu: 0.9824)
[epoch : 39] (l_loss: 0.00002) (t_loss: 0.14114) (accu: 0.9822)
[epoch : 40] (l_loss: 0.00002) (t_loss: 0.14203) (accu: 0.9821)
Finish! (Best accu: 0.9827) (Time taken(sec) : 739.13) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (9617 | 205883)          4.46
fc1.weight   :       196000 (8620 | 187380)          4.40
fc2.weight   :        18750 (825 | 17925)            4.40
fcout.weight :          750 (172 | 578)             22.93
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (15/19), Remaining weight : 4.46 %]
[epoch : 1] (l_loss: 0.31386) (t_loss: 0.10195) (accu: 0.9707)
[epoch : 2] (l_loss: 0.06950) (t_loss: 0.07642) (accu: 0.9770)
[epoch : 3] (l_loss: 0.04168) (t_loss: 0.06737) (accu: 0.9795)
[epoch : 4] (l_loss: 0.02743) (t_loss: 0.06552) (accu: 0.9796)
[epoch : 5] (l_loss: 0.01920) (t_loss: 0.06480) (accu: 0.9797)
[epoch : 6] (l_loss: 0.01301) (t_loss: 0.06915) (accu: 0.9796)
[epoch : 7] (l_loss: 0.00954) (t_loss: 0.07063) (accu: 0.9797)
[epoch : 8] (l_loss: 0.00655) (t_loss: 0.07636) (accu: 0.9784)
[epoch : 9] (l_loss: 0.00479) (t_loss: 0.08498) (accu: 0.9782)
[epoch : 10] (l_loss: 0.00350) (t_loss: 0.08978) (accu: 0.9788)
[epoch : 11] (l_loss: 0.00262) (t_loss: 0.09254) (accu: 0.9788)
[epoch : 12] (l_loss: 0.00254) (t_loss: 0.09727) (accu: 0.9785)
[epoch : 13] (l_loss: 0.00238) (t_loss: 0.10708) (accu: 0.9787)
[epoch : 14] (l_loss: 0.00262) (t_loss: 0.10344) (accu: 0.9788)
[epoch : 15] (l_loss: 0.00116) (t_loss: 0.10838) (accu: 0.9795)
[epoch : 16] (l_loss: 0.00146) (t_loss: 0.10920) (accu: 0.9792)
[epoch : 17] (l_loss: 0.00055) (t_loss: 0.11015) (accu: 0.9798)
[epoch : 18] (l_loss: 0.00043) (t_loss: 0.13444) (accu: 0.9784)
[epoch : 19] (l_loss: 0.00468) (t_loss: 0.12780) (accu: 0.9776)
[epoch : 20] (l_loss: 0.00068) (t_loss: 0.12433) (accu: 0.9790)
[epoch : 21] (l_loss: 0.00023) (t_loss: 0.12315) (accu: 0.9794)
[epoch : 22] (l_loss: 0.00015) (t_loss: 0.12555) (accu: 0.9793)
[epoch : 23] (l_loss: 0.00143) (t_loss: 0.16510) (accu: 0.9768)
[epoch : 24] (l_loss: 0.00353) (t_loss: 0.13476) (accu: 0.9791)
[epoch : 25] (l_loss: 0.00062) (t_loss: 0.13608) (accu: 0.9790)
[epoch : 26] (l_loss: 0.00019) (t_loss: 0.13102) (accu: 0.9792)
[epoch : 27] (l_loss: 0.00010) (t_loss: 0.13223) (accu: 0.9799)
[epoch : 28] (l_loss: 0.00007) (t_loss: 0.13352) (accu: 0.9795)
[epoch : 29] (l_loss: 0.00006) (t_loss: 0.13472) (accu: 0.9802)
[epoch : 30] (l_loss: 0.00045) (t_loss: 0.16237) (accu: 0.9782)
[epoch : 31] (l_loss: 0.00570) (t_loss: 0.14549) (accu: 0.9798)
[epoch : 32] (l_loss: 0.00040) (t_loss: 0.14352) (accu: 0.9800)
[epoch : 33] (l_loss: 0.00011) (t_loss: 0.14412) (accu: 0.9803)
[epoch : 34] (l_loss: 0.00006) (t_loss: 0.14465) (accu: 0.9797)
[epoch : 35] (l_loss: 0.00005) (t_loss: 0.14595) (accu: 0.9797)
[epoch : 36] (l_loss: 0.00004) (t_loss: 0.14726) (accu: 0.9798)
[epoch : 37] (l_loss: 0.00003) (t_loss: 0.14895) (accu: 0.9796)
[epoch : 38] (l_loss: 0.00033) (t_loss: 0.17927) (accu: 0.9767)
[epoch : 39] (l_loss: 0.00506) (t_loss: 0.15551) (accu: 0.9799)
[epoch : 40] (l_loss: 0.00047) (t_loss: 0.15174) (accu: 0.9797)
Finish! (Best accu: 0.9803) (Time taken(sec) : 748.45) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (7710 | 207790)          3.58
fc1.weight   :       196000 (6896 | 189104)          3.52
fc2.weight   :        18750 (660 | 18090)            3.52
fcout.weight :          750 (154 | 596)             20.53
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (16/19), Remaining weight : 3.58 %]
[epoch : 1] (l_loss: 0.35866) (t_loss: 0.11039) (accu: 0.9684)
[epoch : 2] (l_loss: 0.07827) (t_loss: 0.08173) (accu: 0.9738)
[epoch : 3] (l_loss: 0.04903) (t_loss: 0.07361) (accu: 0.9765)
[epoch : 4] (l_loss: 0.03367) (t_loss: 0.06970) (accu: 0.9783)
[epoch : 5] (l_loss: 0.02363) (t_loss: 0.07464) (accu: 0.9785)
[epoch : 6] (l_loss: 0.01701) (t_loss: 0.07449) (accu: 0.9781)
[epoch : 7] (l_loss: 0.01211) (t_loss: 0.07594) (accu: 0.9791)
[epoch : 8] (l_loss: 0.00928) (t_loss: 0.08503) (accu: 0.9760)
[epoch : 9] (l_loss: 0.00689) (t_loss: 0.08260) (accu: 0.9785)
[epoch : 10] (l_loss: 0.00515) (t_loss: 0.09362) (accu: 0.9769)
[epoch : 11] (l_loss: 0.00396) (t_loss: 0.09795) (accu: 0.9774)
[epoch : 12] (l_loss: 0.00312) (t_loss: 0.09922) (accu: 0.9778)
[epoch : 13] (l_loss: 0.00252) (t_loss: 0.10996) (accu: 0.9776)
[epoch : 14] (l_loss: 0.00263) (t_loss: 0.10894) (accu: 0.9777)
[epoch : 15] (l_loss: 0.00149) (t_loss: 0.11431) (accu: 0.9775)
[epoch : 16] (l_loss: 0.00114) (t_loss: 0.11480) (accu: 0.9787)
[epoch : 17] (l_loss: 0.00232) (t_loss: 0.12688) (accu: 0.9780)
[epoch : 18] (l_loss: 0.00204) (t_loss: 0.12442) (accu: 0.9777)
[epoch : 19] (l_loss: 0.00075) (t_loss: 0.12524) (accu: 0.9777)
[epoch : 20] (l_loss: 0.00071) (t_loss: 0.13615) (accu: 0.9773)
[epoch : 21] (l_loss: 0.00264) (t_loss: 0.13295) (accu: 0.9779)
[epoch : 22] (l_loss: 0.00066) (t_loss: 0.13389) (accu: 0.9785)
[epoch : 23] (l_loss: 0.00028) (t_loss: 0.13287) (accu: 0.9792)
[epoch : 24] (l_loss: 0.00017) (t_loss: 0.13479) (accu: 0.9788)
[epoch : 25] (l_loss: 0.00013) (t_loss: 0.13818) (accu: 0.9787)
[epoch : 26] (l_loss: 0.00330) (t_loss: 0.16689) (accu: 0.9770)
[epoch : 27] (l_loss: 0.00184) (t_loss: 0.15165) (accu: 0.9786)
[epoch : 28] (l_loss: 0.00030) (t_loss: 0.14817) (accu: 0.9795)
[epoch : 29] (l_loss: 0.00012) (t_loss: 0.14785) (accu: 0.9794)
[epoch : 30] (l_loss: 0.00009) (t_loss: 0.14849) (accu: 0.9794)
[epoch : 31] (l_loss: 0.00008) (t_loss: 0.14958) (accu: 0.9789)
[epoch : 32] (l_loss: 0.00007) (t_loss: 0.15214) (accu: 0.9786)
[epoch : 33] (l_loss: 0.00359) (t_loss: 0.15863) (accu: 0.9787)
[epoch : 34] (l_loss: 0.00094) (t_loss: 0.16794) (accu: 0.9780)
[epoch : 35] (l_loss: 0.00021) (t_loss: 0.16329) (accu: 0.9788)
[epoch : 36] (l_loss: 0.00008) (t_loss: 0.16114) (accu: 0.9788)
[epoch : 37] (l_loss: 0.00005) (t_loss: 0.16313) (accu: 0.9791)
[epoch : 38] (l_loss: 0.00004) (t_loss: 0.16477) (accu: 0.9792)
[epoch : 39] (l_loss: 0.00004) (t_loss: 0.16609) (accu: 0.9793)
[epoch : 40] (l_loss: 0.00020) (t_loss: 0.21740) (accu: 0.9743)
Finish! (Best accu: 0.9795) (Time taken(sec) : 751.41) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (6184 | 209316)          2.87
fc1.weight   :       196000 (5517 | 190483)          2.81
fc2.weight   :        18750 (528 | 18222)            2.82
fcout.weight :          750 (139 | 611)             18.53
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (17/19), Remaining weight : 2.87 %]
[epoch : 1] (l_loss: 0.41063) (t_loss: 0.13054) (accu: 0.9623)
[epoch : 2] (l_loss: 0.09638) (t_loss: 0.09558) (accu: 0.9704)
[epoch : 3] (l_loss: 0.06495) (t_loss: 0.08221) (accu: 0.9758)
[epoch : 4] (l_loss: 0.04855) (t_loss: 0.08080) (accu: 0.9762)
[epoch : 5] (l_loss: 0.03809) (t_loss: 0.07920) (accu: 0.9767)
[epoch : 6] (l_loss: 0.03040) (t_loss: 0.08052) (accu: 0.9767)
[epoch : 7] (l_loss: 0.02462) (t_loss: 0.08043) (accu: 0.9776)
[epoch : 8] (l_loss: 0.02005) (t_loss: 0.08312) (accu: 0.9771)
[epoch : 9] (l_loss: 0.01666) (t_loss: 0.08589) (accu: 0.9783)
[epoch : 10] (l_loss: 0.01362) (t_loss: 0.08681) (accu: 0.9777)
[epoch : 11] (l_loss: 0.01173) (t_loss: 0.09625) (accu: 0.9766)
[epoch : 12] (l_loss: 0.00994) (t_loss: 0.09989) (accu: 0.9756)
[epoch : 13] (l_loss: 0.00799) (t_loss: 0.09875) (accu: 0.9775)
[epoch : 14] (l_loss: 0.00691) (t_loss: 0.10410) (accu: 0.9769)
[epoch : 15] (l_loss: 0.00575) (t_loss: 0.10804) (accu: 0.9777)
[epoch : 16] (l_loss: 0.00517) (t_loss: 0.11544) (accu: 0.9755)
[epoch : 17] (l_loss: 0.00458) (t_loss: 0.11943) (accu: 0.9755)
[epoch : 18] (l_loss: 0.00424) (t_loss: 0.12209) (accu: 0.9769)
[epoch : 19] (l_loss: 0.00338) (t_loss: 0.12959) (accu: 0.9763)
[epoch : 20] (l_loss: 0.00323) (t_loss: 0.13232) (accu: 0.9754)
[epoch : 21] (l_loss: 0.00231) (t_loss: 0.13664) (accu: 0.9766)
[epoch : 22] (l_loss: 0.00200) (t_loss: 0.14366) (accu: 0.9756)
[epoch : 23] (l_loss: 0.00243) (t_loss: 0.15269) (accu: 0.9764)
[epoch : 24] (l_loss: 0.00184) (t_loss: 0.14585) (accu: 0.9770)
[epoch : 25] (l_loss: 0.00193) (t_loss: 0.14950) (accu: 0.9765)
[epoch : 26] (l_loss: 0.00113) (t_loss: 0.15292) (accu: 0.9760)
[epoch : 27] (l_loss: 0.00188) (t_loss: 0.15741) (accu: 0.9766)
[epoch : 28] (l_loss: 0.00190) (t_loss: 0.16258) (accu: 0.9766)
[epoch : 29] (l_loss: 0.00168) (t_loss: 0.16748) (accu: 0.9751)
[epoch : 30] (l_loss: 0.00166) (t_loss: 0.16635) (accu: 0.9764)
[epoch : 31] (l_loss: 0.00159) (t_loss: 0.16644) (accu: 0.9767)
[epoch : 32] (l_loss: 0.00045) (t_loss: 0.16795) (accu: 0.9767)
[epoch : 33] (l_loss: 0.00033) (t_loss: 0.16788) (accu: 0.9771)
[epoch : 34] (l_loss: 0.00316) (t_loss: 0.17644) (accu: 0.9766)
[epoch : 35] (l_loss: 0.00130) (t_loss: 0.18273) (accu: 0.9762)
[epoch : 36] (l_loss: 0.00063) (t_loss: 0.18736) (accu: 0.9770)
[epoch : 37] (l_loss: 0.00036) (t_loss: 0.18376) (accu: 0.9768)
[epoch : 38] (l_loss: 0.00024) (t_loss: 0.18632) (accu: 0.9770)
[epoch : 39] (l_loss: 0.00017) (t_loss: 0.19230) (accu: 0.9763)
[epoch : 40] (l_loss: 0.00243) (t_loss: 0.21913) (accu: 0.9741)
Finish! (Best accu: 0.9783) (Time taken(sec) : 749.55) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (4961 | 210539)          2.30
fc1.weight   :       196000 (4414 | 191586)          2.25
fc2.weight   :        18750 (422 | 18328)            2.25
fcout.weight :          750 (125 | 625)             16.67
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (18/19), Remaining weight : 2.3 %]
[epoch : 1] (l_loss: 0.47518) (t_loss: 0.14844) (accu: 0.9584)
[epoch : 2] (l_loss: 0.11463) (t_loss: 0.10750) (accu: 0.9686)
[epoch : 3] (l_loss: 0.07963) (t_loss: 0.09150) (accu: 0.9730)
[epoch : 4] (l_loss: 0.06211) (t_loss: 0.08506) (accu: 0.9751)
[epoch : 5] (l_loss: 0.05038) (t_loss: 0.08271) (accu: 0.9749)
[epoch : 6] (l_loss: 0.04222) (t_loss: 0.08539) (accu: 0.9750)
[epoch : 7] (l_loss: 0.03603) (t_loss: 0.08415) (accu: 0.9753)
[epoch : 8] (l_loss: 0.03111) (t_loss: 0.08989) (accu: 0.9742)
[epoch : 9] (l_loss: 0.02721) (t_loss: 0.09051) (accu: 0.9744)
[epoch : 10] (l_loss: 0.02367) (t_loss: 0.08993) (accu: 0.9752)
[epoch : 11] (l_loss: 0.02067) (t_loss: 0.09696) (accu: 0.9740)
[epoch : 12] (l_loss: 0.01847) (t_loss: 0.09826) (accu: 0.9748)
[epoch : 13] (l_loss: 0.01614) (t_loss: 0.09696) (accu: 0.9758)
[epoch : 14] (l_loss: 0.01410) (t_loss: 0.10391) (accu: 0.9755)
[epoch : 15] (l_loss: 0.01263) (t_loss: 0.10561) (accu: 0.9761)
[epoch : 16] (l_loss: 0.01119) (t_loss: 0.11011) (accu: 0.9748)
[epoch : 17] (l_loss: 0.01040) (t_loss: 0.11559) (accu: 0.9757)
[epoch : 18] (l_loss: 0.00925) (t_loss: 0.12382) (accu: 0.9747)
[epoch : 19] (l_loss: 0.00840) (t_loss: 0.12340) (accu: 0.9749)
[epoch : 20] (l_loss: 0.00757) (t_loss: 0.12716) (accu: 0.9757)
[epoch : 21] (l_loss: 0.00701) (t_loss: 0.12848) (accu: 0.9754)
[epoch : 22] (l_loss: 0.00619) (t_loss: 0.13820) (accu: 0.9750)
[epoch : 23] (l_loss: 0.00583) (t_loss: 0.13825) (accu: 0.9746)
[epoch : 24] (l_loss: 0.00498) (t_loss: 0.14230) (accu: 0.9747)
[epoch : 25] (l_loss: 0.00478) (t_loss: 0.14743) (accu: 0.9753)
[epoch : 26] (l_loss: 0.00464) (t_loss: 0.14875) (accu: 0.9745)
[epoch : 27] (l_loss: 0.00400) (t_loss: 0.14988) (accu: 0.9752)
[epoch : 28] (l_loss: 0.00390) (t_loss: 0.15844) (accu: 0.9736)
[epoch : 29] (l_loss: 0.00334) (t_loss: 0.16220) (accu: 0.9739)
[epoch : 30] (l_loss: 0.00321) (t_loss: 0.16260) (accu: 0.9744)
[epoch : 31] (l_loss: 0.00314) (t_loss: 0.16473) (accu: 0.9743)
[epoch : 32] (l_loss: 0.00308) (t_loss: 0.16691) (accu: 0.9750)
[epoch : 33] (l_loss: 0.00246) (t_loss: 0.17182) (accu: 0.9741)
[epoch : 34] (l_loss: 0.00267) (t_loss: 0.18111) (accu: 0.9728)
[epoch : 35] (l_loss: 0.00255) (t_loss: 0.17800) (accu: 0.9739)
[epoch : 36] (l_loss: 0.00208) (t_loss: 0.18393) (accu: 0.9736)
[epoch : 37] (l_loss: 0.00187) (t_loss: 0.19847) (accu: 0.9737)
[epoch : 38] (l_loss: 0.00212) (t_loss: 0.18604) (accu: 0.9739)
[epoch : 39] (l_loss: 0.00174) (t_loss: 0.19932) (accu: 0.9732)
[epoch : 40] (l_loss: 0.00224) (t_loss: 0.19725) (accu: 0.9740)
Finish! (Best accu: 0.9761) (Time taken(sec) : 753.51) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (3982 | 211518)          1.85
fc1.weight   :       196000 (3531 | 192469)          1.80
fc2.weight   :        18750 (338 | 18412)            1.80
fcout.weight :          750 (113 | 637)             15.07
------------------------------------------------------------
Learning start! [Test_Iter : (1/3), Prune_iter : (19/19), Remaining weight : 1.85 %]
[epoch : 1] (l_loss: 0.52432) (t_loss: 0.16367) (accu: 0.9523)
[epoch : 2] (l_loss: 0.12845) (t_loss: 0.11920) (accu: 0.9641)
[epoch : 3] (l_loss: 0.09086) (t_loss: 0.10102) (accu: 0.9708)
[epoch : 4] (l_loss: 0.07140) (t_loss: 0.09504) (accu: 0.9716)
[epoch : 5] (l_loss: 0.05918) (t_loss: 0.09179) (accu: 0.9726)
[epoch : 6] (l_loss: 0.05001) (t_loss: 0.09052) (accu: 0.9726)
[epoch : 7] (l_loss: 0.04292) (t_loss: 0.08760) (accu: 0.9746)
[epoch : 8] (l_loss: 0.03794) (t_loss: 0.09036) (accu: 0.9738)
[epoch : 9] (l_loss: 0.03307) (t_loss: 0.08838) (accu: 0.9740)
[epoch : 10] (l_loss: 0.02930) (t_loss: 0.09032) (accu: 0.9751)
[epoch : 11] (l_loss: 0.02611) (t_loss: 0.09244) (accu: 0.9750)
[epoch : 12] (l_loss: 0.02378) (t_loss: 0.09466) (accu: 0.9748)
[epoch : 13] (l_loss: 0.02143) (t_loss: 0.09865) (accu: 0.9744)
[epoch : 14] (l_loss: 0.01962) (t_loss: 0.10260) (accu: 0.9738)
[epoch : 15] (l_loss: 0.01792) (t_loss: 0.09989) (accu: 0.9746)
[epoch : 16] (l_loss: 0.01632) (t_loss: 0.10498) (accu: 0.9753)
[epoch : 17] (l_loss: 0.01527) (t_loss: 0.10881) (accu: 0.9750)
[epoch : 18] (l_loss: 0.01403) (t_loss: 0.11283) (accu: 0.9750)
[epoch : 19] (l_loss: 0.01291) (t_loss: 0.11624) (accu: 0.9751)
[epoch : 20] (l_loss: 0.01212) (t_loss: 0.12177) (accu: 0.9735)
[epoch : 21] (l_loss: 0.01088) (t_loss: 0.11838) (accu: 0.9748)
[epoch : 22] (l_loss: 0.01048) (t_loss: 0.12695) (accu: 0.9729)
[epoch : 23] (l_loss: 0.00950) (t_loss: 0.12850) (accu: 0.9737)
[epoch : 24] (l_loss: 0.00886) (t_loss: 0.13148) (accu: 0.9739)
[epoch : 25] (l_loss: 0.00825) (t_loss: 0.13229) (accu: 0.9746)
[epoch : 26] (l_loss: 0.00789) (t_loss: 0.14360) (accu: 0.9737)
[epoch : 27] (l_loss: 0.00727) (t_loss: 0.14146) (accu: 0.9735)
[epoch : 28] (l_loss: 0.00692) (t_loss: 0.14352) (accu: 0.9745)
[epoch : 29] (l_loss: 0.00643) (t_loss: 0.14677) (accu: 0.9729)
[epoch : 30] (l_loss: 0.00570) (t_loss: 0.14546) (accu: 0.9737)
[epoch : 31] (l_loss: 0.00582) (t_loss: 0.15049) (accu: 0.9747)
[epoch : 32] (l_loss: 0.00550) (t_loss: 0.15364) (accu: 0.9739)
[epoch : 33] (l_loss: 0.00482) (t_loss: 0.16139) (accu: 0.9730)
[epoch : 34] (l_loss: 0.00461) (t_loss: 0.16187) (accu: 0.9735)
[epoch : 35] (l_loss: 0.00436) (t_loss: 0.16401) (accu: 0.9739)
[epoch : 36] (l_loss: 0.00440) (t_loss: 0.17121) (accu: 0.9741)
[epoch : 37] (l_loss: 0.00435) (t_loss: 0.17602) (accu: 0.9731)
[epoch : 38] (l_loss: 0.00380) (t_loss: 0.17592) (accu: 0.9732)
[epoch : 39] (l_loss: 0.00355) (t_loss: 0.18392) (accu: 0.9733)
[epoch : 40] (l_loss: 0.00372) (t_loss: 0.18642) (accu: 0.9731)
Finish! (Best accu: 0.9753) (Time taken(sec) : 750.57) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :        215500 (215500 | 0)          100.00
fc1.weight   :        196000 (196000 | 0)          100.00
fc2.weight   :         18750 (18750 | 0)           100.00
fcout.weight :           750 (750 | 0)             100.00
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (1/19), Remaining weight : 100.0 %]
[epoch : 1] (l_loss: 0.22263) (t_loss: 0.11174) (accu: 0.9655)
[epoch : 2] (l_loss: 0.09229) (t_loss: 0.08969) (accu: 0.9704)
[epoch : 3] (l_loss: 0.06641) (t_loss: 0.08392) (accu: 0.9752)
[epoch : 4] (l_loss: 0.05127) (t_loss: 0.08742) (accu: 0.9745)
[epoch : 5] (l_loss: 0.04276) (t_loss: 0.09263) (accu: 0.9739)
[epoch : 6] (l_loss: 0.03786) (t_loss: 0.10061) (accu: 0.9738)
[epoch : 7] (l_loss: 0.03277) (t_loss: 0.07412) (accu: 0.9800)
[epoch : 8] (l_loss: 0.02701) (t_loss: 0.11548) (accu: 0.9721)
[epoch : 9] (l_loss: 0.02639) (t_loss: 0.11186) (accu: 0.9736)
[epoch : 10] (l_loss: 0.02246) (t_loss: 0.09009) (accu: 0.9776)
[epoch : 11] (l_loss: 0.02196) (t_loss: 0.11107) (accu: 0.9767)
[epoch : 12] (l_loss: 0.02242) (t_loss: 0.10124) (accu: 0.9778)
[epoch : 13] (l_loss: 0.01882) (t_loss: 0.10202) (accu: 0.9775)
[epoch : 14] (l_loss: 0.01727) (t_loss: 0.12194) (accu: 0.9785)
[epoch : 15] (l_loss: 0.01680) (t_loss: 0.10805) (accu: 0.9790)
[epoch : 16] (l_loss: 0.01861) (t_loss: 0.11709) (accu: 0.9787)
[epoch : 17] (l_loss: 0.01543) (t_loss: 0.11645) (accu: 0.9791)
[epoch : 18] (l_loss: 0.01243) (t_loss: 0.14580) (accu: 0.9747)
[epoch : 19] (l_loss: 0.01452) (t_loss: 0.11325) (accu: 0.9804)
[epoch : 20] (l_loss: 0.01299) (t_loss: 0.12306) (accu: 0.9789)
[epoch : 21] (l_loss: 0.01369) (t_loss: 0.12134) (accu: 0.9814)
[epoch : 22] (l_loss: 0.01305) (t_loss: 0.13288) (accu: 0.9804)
[epoch : 23] (l_loss: 0.01154) (t_loss: 0.15510) (accu: 0.9777)
[epoch : 24] (l_loss: 0.01734) (t_loss: 0.13782) (accu: 0.9796)
[epoch : 25] (l_loss: 0.01099) (t_loss: 0.16493) (accu: 0.9785)
[epoch : 26] (l_loss: 0.01248) (t_loss: 0.14888) (accu: 0.9800)
[epoch : 27] (l_loss: 0.01361) (t_loss: 0.13791) (accu: 0.9796)
[epoch : 28] (l_loss: 0.01219) (t_loss: 0.12630) (accu: 0.9816)
[epoch : 29] (l_loss: 0.01132) (t_loss: 0.13242) (accu: 0.9818)
[epoch : 30] (l_loss: 0.00986) (t_loss: 0.15335) (accu: 0.9812)
[epoch : 31] (l_loss: 0.01117) (t_loss: 0.17032) (accu: 0.9770)
[epoch : 32] (l_loss: 0.01299) (t_loss: 0.16819) (accu: 0.9778)
[epoch : 33] (l_loss: 0.01079) (t_loss: 0.16224) (accu: 0.9794)
[epoch : 34] (l_loss: 0.01073) (t_loss: 0.17039) (accu: 0.9777)
[epoch : 35] (l_loss: 0.00981) (t_loss: 0.14722) (accu: 0.9833)
[epoch : 36] (l_loss: 0.00766) (t_loss: 0.16678) (accu: 0.9802)
[epoch : 37] (l_loss: 0.01141) (t_loss: 0.15713) (accu: 0.9816)
[epoch : 38] (l_loss: 0.01016) (t_loss: 0.15066) (accu: 0.9802)
[epoch : 39] (l_loss: 0.00879) (t_loss: 0.16000) (accu: 0.9810)
[epoch : 40] (l_loss: 0.01377) (t_loss: 0.19516) (accu: 0.9783)
Finish! (Best accu: 0.9833) (Time taken(sec) : 685.36) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (172475 | 43025)         80.03
fc1.weight   :      196000 (156800 | 39200)         80.00
fc2.weight   :        18750 (15000 | 3750)          80.00
fcout.weight :           750 (675 | 75)             90.00
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (2/19), Remaining weight : 80.03 %]
[epoch : 1] (l_loss: 0.21006) (t_loss: 0.10375) (accu: 0.9669)
[epoch : 2] (l_loss: 0.08474) (t_loss: 0.08694) (accu: 0.9727)
[epoch : 3] (l_loss: 0.05718) (t_loss: 0.08493) (accu: 0.9744)
[epoch : 4] (l_loss: 0.04724) (t_loss: 0.07776) (accu: 0.9765)
[epoch : 5] (l_loss: 0.03700) (t_loss: 0.10003) (accu: 0.9710)
[epoch : 6] (l_loss: 0.02970) (t_loss: 0.08421) (accu: 0.9765)
[epoch : 7] (l_loss: 0.02784) (t_loss: 0.09515) (accu: 0.9776)
[epoch : 8] (l_loss: 0.02549) (t_loss: 0.09887) (accu: 0.9739)
[epoch : 9] (l_loss: 0.02337) (t_loss: 0.10153) (accu: 0.9778)
[epoch : 10] (l_loss: 0.02034) (t_loss: 0.08580) (accu: 0.9790)
[epoch : 11] (l_loss: 0.02036) (t_loss: 0.10257) (accu: 0.9770)
[epoch : 12] (l_loss: 0.01528) (t_loss: 0.10649) (accu: 0.9770)
[epoch : 13] (l_loss: 0.01636) (t_loss: 0.08716) (accu: 0.9813)
[epoch : 14] (l_loss: 0.01660) (t_loss: 0.10372) (accu: 0.9784)
[epoch : 15] (l_loss: 0.01463) (t_loss: 0.08762) (accu: 0.9811)
[epoch : 16] (l_loss: 0.01383) (t_loss: 0.11292) (accu: 0.9775)
[epoch : 17] (l_loss: 0.01245) (t_loss: 0.10228) (accu: 0.9802)
[epoch : 18] (l_loss: 0.01357) (t_loss: 0.10651) (accu: 0.9790)
[epoch : 19] (l_loss: 0.01035) (t_loss: 0.10779) (accu: 0.9812)
[epoch : 20] (l_loss: 0.01460) (t_loss: 0.10562) (accu: 0.9804)
[epoch : 21] (l_loss: 0.01072) (t_loss: 0.13101) (accu: 0.9764)
[epoch : 22] (l_loss: 0.01181) (t_loss: 0.12725) (accu: 0.9795)
[epoch : 23] (l_loss: 0.01151) (t_loss: 0.14068) (accu: 0.9776)
[epoch : 24] (l_loss: 0.01079) (t_loss: 0.12237) (accu: 0.9796)
[epoch : 25] (l_loss: 0.00991) (t_loss: 0.13585) (accu: 0.9809)
[epoch : 26] (l_loss: 0.00880) (t_loss: 0.14075) (accu: 0.9784)
[epoch : 27] (l_loss: 0.01133) (t_loss: 0.12886) (accu: 0.9815)
[epoch : 28] (l_loss: 0.00810) (t_loss: 0.17092) (accu: 0.9765)
[epoch : 29] (l_loss: 0.01169) (t_loss: 0.14057) (accu: 0.9800)
[epoch : 30] (l_loss: 0.01201) (t_loss: 0.13994) (accu: 0.9799)
[epoch : 31] (l_loss: 0.00569) (t_loss: 0.12294) (accu: 0.9841)
[epoch : 32] (l_loss: 0.00912) (t_loss: 0.16340) (accu: 0.9782)
[epoch : 33] (l_loss: 0.01190) (t_loss: 0.15802) (accu: 0.9784)
[epoch : 34] (l_loss: 0.00683) (t_loss: 0.14491) (accu: 0.9817)
[epoch : 35] (l_loss: 0.01004) (t_loss: 0.17759) (accu: 0.9776)
[epoch : 36] (l_loss: 0.01014) (t_loss: 0.15521) (accu: 0.9803)
[epoch : 37] (l_loss: 0.00594) (t_loss: 0.15846) (accu: 0.9794)
[epoch : 38] (l_loss: 0.00904) (t_loss: 0.18394) (accu: 0.9795)
[epoch : 39] (l_loss: 0.00794) (t_loss: 0.15107) (accu: 0.9821)
[epoch : 40] (l_loss: 0.00921) (t_loss: 0.20015) (accu: 0.9762)
Finish! (Best accu: 0.9841) (Time taken(sec) : 696.44) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (138048 | 77452)         64.06
fc1.weight   :      196000 (125440 | 70560)         64.00
fc2.weight   :        18750 (12000 | 6750)          64.00
fcout.weight :          750 (608 | 142)             81.07
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (3/19), Remaining weight : 64.06 %]
[epoch : 1] (l_loss: 0.19936) (t_loss: 0.10710) (accu: 0.9661)
[epoch : 2] (l_loss: 0.07590) (t_loss: 0.08162) (accu: 0.9728)
[epoch : 3] (l_loss: 0.05303) (t_loss: 0.07885) (accu: 0.9767)
[epoch : 4] (l_loss: 0.03999) (t_loss: 0.07292) (accu: 0.9776)
[epoch : 5] (l_loss: 0.03160) (t_loss: 0.08181) (accu: 0.9780)
[epoch : 6] (l_loss: 0.02688) (t_loss: 0.08514) (accu: 0.9783)
[epoch : 7] (l_loss: 0.02453) (t_loss: 0.08263) (accu: 0.9776)
[epoch : 8] (l_loss: 0.02077) (t_loss: 0.09347) (accu: 0.9767)
[epoch : 9] (l_loss: 0.01715) (t_loss: 0.09714) (accu: 0.9756)
[epoch : 10] (l_loss: 0.02019) (t_loss: 0.10463) (accu: 0.9757)
[epoch : 11] (l_loss: 0.01401) (t_loss: 0.09515) (accu: 0.9796)
[epoch : 12] (l_loss: 0.01578) (t_loss: 0.09856) (accu: 0.9781)
[epoch : 13] (l_loss: 0.01258) (t_loss: 0.10698) (accu: 0.9785)
[epoch : 14] (l_loss: 0.01488) (t_loss: 0.11435) (accu: 0.9776)
[epoch : 15] (l_loss: 0.01157) (t_loss: 0.11575) (accu: 0.9778)
[epoch : 16] (l_loss: 0.01375) (t_loss: 0.09968) (accu: 0.9803)
[epoch : 17] (l_loss: 0.00979) (t_loss: 0.12572) (accu: 0.9766)
[epoch : 18] (l_loss: 0.01140) (t_loss: 0.10589) (accu: 0.9800)
[epoch : 19] (l_loss: 0.00957) (t_loss: 0.12025) (accu: 0.9809)
[epoch : 20] (l_loss: 0.01091) (t_loss: 0.10445) (accu: 0.9816)
[epoch : 21] (l_loss: 0.01318) (t_loss: 0.14323) (accu: 0.9766)
[epoch : 22] (l_loss: 0.00963) (t_loss: 0.12016) (accu: 0.9819)
[epoch : 23] (l_loss: 0.00847) (t_loss: 0.12662) (accu: 0.9787)
[epoch : 24] (l_loss: 0.00813) (t_loss: 0.11895) (accu: 0.9825)
[epoch : 25] (l_loss: 0.01056) (t_loss: 0.13555) (accu: 0.9786)
[epoch : 26] (l_loss: 0.00943) (t_loss: 0.14569) (accu: 0.9796)
[epoch : 27] (l_loss: 0.00838) (t_loss: 0.13456) (accu: 0.9791)
[epoch : 28] (l_loss: 0.00802) (t_loss: 0.15004) (accu: 0.9780)
[epoch : 29] (l_loss: 0.00985) (t_loss: 0.15182) (accu: 0.9797)
[epoch : 30] (l_loss: 0.00853) (t_loss: 0.13938) (accu: 0.9801)
[epoch : 31] (l_loss: 0.00527) (t_loss: 0.13999) (accu: 0.9808)
[epoch : 32] (l_loss: 0.01072) (t_loss: 0.16004) (accu: 0.9798)
[epoch : 33] (l_loss: 0.00806) (t_loss: 0.15155) (accu: 0.9793)
[epoch : 34] (l_loss: 0.00501) (t_loss: 0.18208) (accu: 0.9764)
[epoch : 35] (l_loss: 0.01002) (t_loss: 0.15614) (accu: 0.9793)
[epoch : 36] (l_loss: 0.00669) (t_loss: 0.17288) (accu: 0.9768)
[epoch : 37] (l_loss: 0.00601) (t_loss: 0.18013) (accu: 0.9793)
[epoch : 38] (l_loss: 0.01001) (t_loss: 0.17083) (accu: 0.9797)
[epoch : 39] (l_loss: 0.00790) (t_loss: 0.15508) (accu: 0.9815)
[epoch : 40] (l_loss: 0.00703) (t_loss: 0.17704) (accu: 0.9802)
Finish! (Best accu: 0.9825) (Time taken(sec) : 692.55) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (110499 | 105001)        51.28
fc1.weight   :      196000 (100352 | 95648)         51.20
fc2.weight   :        18750 (9600 | 9150)           51.20
fcout.weight :          750 (547 | 203)             72.93
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (4/19), Remaining weight : 51.28 %]
[epoch : 1] (l_loss: 0.19849) (t_loss: 0.09722) (accu: 0.9697)
[epoch : 2] (l_loss: 0.07108) (t_loss: 0.07289) (accu: 0.9782)
[epoch : 3] (l_loss: 0.04485) (t_loss: 0.09040) (accu: 0.9744)
[epoch : 4] (l_loss: 0.03515) (t_loss: 0.07016) (accu: 0.9777)
[epoch : 5] (l_loss: 0.02743) (t_loss: 0.07309) (accu: 0.9809)
[epoch : 6] (l_loss: 0.02017) (t_loss: 0.08207) (accu: 0.9794)
[epoch : 7] (l_loss: 0.01978) (t_loss: 0.08993) (accu: 0.9779)
[epoch : 8] (l_loss: 0.01703) (t_loss: 0.10419) (accu: 0.9756)
[epoch : 9] (l_loss: 0.01645) (t_loss: 0.08081) (accu: 0.9796)
[epoch : 10] (l_loss: 0.01436) (t_loss: 0.09283) (accu: 0.9785)
[epoch : 11] (l_loss: 0.01162) (t_loss: 0.08885) (accu: 0.9813)
[epoch : 12] (l_loss: 0.01192) (t_loss: 0.09710) (accu: 0.9783)
[epoch : 13] (l_loss: 0.01182) (t_loss: 0.09348) (accu: 0.9819)
[epoch : 14] (l_loss: 0.01387) (t_loss: 0.10066) (accu: 0.9785)
[epoch : 15] (l_loss: 0.00958) (t_loss: 0.09463) (accu: 0.9821)
[epoch : 16] (l_loss: 0.01073) (t_loss: 0.12218) (accu: 0.9784)
[epoch : 17] (l_loss: 0.00974) (t_loss: 0.12095) (accu: 0.9793)
[epoch : 18] (l_loss: 0.00904) (t_loss: 0.12611) (accu: 0.9792)
[epoch : 19] (l_loss: 0.00707) (t_loss: 0.11943) (accu: 0.9814)
[epoch : 20] (l_loss: 0.00855) (t_loss: 0.12400) (accu: 0.9779)
[epoch : 21] (l_loss: 0.00861) (t_loss: 0.13542) (accu: 0.9778)
[epoch : 22] (l_loss: 0.00806) (t_loss: 0.14307) (accu: 0.9784)
[epoch : 23] (l_loss: 0.00788) (t_loss: 0.12723) (accu: 0.9791)
[epoch : 24] (l_loss: 0.00516) (t_loss: 0.12160) (accu: 0.9822)
[epoch : 25] (l_loss: 0.00998) (t_loss: 0.13198) (accu: 0.9806)
[epoch : 26] (l_loss: 0.00837) (t_loss: 0.12978) (accu: 0.9830)
[epoch : 27] (l_loss: 0.00406) (t_loss: 0.15127) (accu: 0.9786)
[epoch : 28] (l_loss: 0.00837) (t_loss: 0.15304) (accu: 0.9800)
[epoch : 29] (l_loss: 0.00879) (t_loss: 0.13482) (accu: 0.9806)
[epoch : 30] (l_loss: 0.00764) (t_loss: 0.17701) (accu: 0.9790)
[epoch : 31] (l_loss: 0.00944) (t_loss: 0.15452) (accu: 0.9803)
[epoch : 32] (l_loss: 0.00581) (t_loss: 0.15284) (accu: 0.9816)
[epoch : 33] (l_loss: 0.00526) (t_loss: 0.18258) (accu: 0.9780)
[epoch : 34] (l_loss: 0.00787) (t_loss: 0.15116) (accu: 0.9824)
[epoch : 35] (l_loss: 0.00649) (t_loss: 0.15759) (accu: 0.9807)
[epoch : 36] (l_loss: 0.00704) (t_loss: 0.18008) (accu: 0.9790)
[epoch : 37] (l_loss: 0.00606) (t_loss: 0.18093) (accu: 0.9779)
[epoch : 38] (l_loss: 0.00637) (t_loss: 0.18069) (accu: 0.9804)
[epoch : 39] (l_loss: 0.00699) (t_loss: 0.20530) (accu: 0.9789)
[epoch : 40] (l_loss: 0.00753) (t_loss: 0.15902) (accu: 0.9826)
Finish! (Best accu: 0.9830) (Time taken(sec) : 707.51) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (88454 | 127046)         41.05
fc1.weight   :      196000 (80282 | 115718)         40.96
fc2.weight   :        18750 (7680 | 11070)          40.96
fcout.weight :          750 (492 | 258)             65.60
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (5/19), Remaining weight : 41.05 %]
[epoch : 1] (l_loss: 0.18844) (t_loss: 0.08534) (accu: 0.9740)
[epoch : 2] (l_loss: 0.05951) (t_loss: 0.07637) (accu: 0.9754)
[epoch : 3] (l_loss: 0.03894) (t_loss: 0.07038) (accu: 0.9781)
[epoch : 4] (l_loss: 0.02803) (t_loss: 0.07294) (accu: 0.9796)
[epoch : 5] (l_loss: 0.02086) (t_loss: 0.06546) (accu: 0.9807)
[epoch : 6] (l_loss: 0.01731) (t_loss: 0.06580) (accu: 0.9829)
[epoch : 7] (l_loss: 0.01288) (t_loss: 0.07531) (accu: 0.9801)
[epoch : 8] (l_loss: 0.01415) (t_loss: 0.07503) (accu: 0.9819)
[epoch : 9] (l_loss: 0.01323) (t_loss: 0.09299) (accu: 0.9788)
[epoch : 10] (l_loss: 0.01076) (t_loss: 0.07773) (accu: 0.9814)
[epoch : 11] (l_loss: 0.01015) (t_loss: 0.10504) (accu: 0.9780)
[epoch : 12] (l_loss: 0.01129) (t_loss: 0.09088) (accu: 0.9810)
[epoch : 13] (l_loss: 0.00727) (t_loss: 0.08501) (accu: 0.9822)
[epoch : 14] (l_loss: 0.00891) (t_loss: 0.11535) (accu: 0.9784)
[epoch : 15] (l_loss: 0.00883) (t_loss: 0.10553) (accu: 0.9806)
[epoch : 16] (l_loss: 0.00787) (t_loss: 0.10986) (accu: 0.9811)
[epoch : 17] (l_loss: 0.00859) (t_loss: 0.11550) (accu: 0.9795)
[epoch : 18] (l_loss: 0.00652) (t_loss: 0.10975) (accu: 0.9806)
[epoch : 19] (l_loss: 0.00737) (t_loss: 0.09731) (accu: 0.9824)
[epoch : 20] (l_loss: 0.00659) (t_loss: 0.13790) (accu: 0.9775)
[epoch : 21] (l_loss: 0.00856) (t_loss: 0.10548) (accu: 0.9827)
[epoch : 22] (l_loss: 0.00571) (t_loss: 0.13162) (accu: 0.9800)
[epoch : 23] (l_loss: 0.00774) (t_loss: 0.11623) (accu: 0.9823)
[epoch : 24] (l_loss: 0.00615) (t_loss: 0.12535) (accu: 0.9811)
[epoch : 25] (l_loss: 0.00588) (t_loss: 0.11822) (accu: 0.9823)
[epoch : 26] (l_loss: 0.00470) (t_loss: 0.14297) (accu: 0.9783)
[epoch : 27] (l_loss: 0.00602) (t_loss: 0.12987) (accu: 0.9818)
[epoch : 28] (l_loss: 0.00773) (t_loss: 0.14206) (accu: 0.9812)
[epoch : 29] (l_loss: 0.00478) (t_loss: 0.13711) (accu: 0.9819)
[epoch : 30] (l_loss: 0.00614) (t_loss: 0.14300) (accu: 0.9808)
[epoch : 31] (l_loss: 0.00389) (t_loss: 0.14307) (accu: 0.9812)
[epoch : 32] (l_loss: 0.00684) (t_loss: 0.13706) (accu: 0.9822)
[epoch : 33] (l_loss: 0.00632) (t_loss: 0.13575) (accu: 0.9820)
[epoch : 34] (l_loss: 0.00476) (t_loss: 0.14388) (accu: 0.9807)
[epoch : 35] (l_loss: 0.00585) (t_loss: 0.14850) (accu: 0.9831)
[epoch : 36] (l_loss: 0.00555) (t_loss: 0.15209) (accu: 0.9816)
[epoch : 37] (l_loss: 0.00615) (t_loss: 0.17495) (accu: 0.9803)
[epoch : 38] (l_loss: 0.00344) (t_loss: 0.16738) (accu: 0.9818)
[epoch : 39] (l_loss: 0.00609) (t_loss: 0.17613) (accu: 0.9796)
[epoch : 40] (l_loss: 0.00414) (t_loss: 0.15358) (accu: 0.9839)
Finish! (Best accu: 0.9839) (Time taken(sec) : 713.68) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (70812 | 144688)         32.86
fc1.weight   :      196000 (64225 | 131775)         32.77
fc2.weight   :        18750 (6144 | 12606)          32.77
fcout.weight :          750 (443 | 307)             59.07
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (6/19), Remaining weight : 32.86 %]
[epoch : 1] (l_loss: 0.18216) (t_loss: 0.08145) (accu: 0.9741)
[epoch : 2] (l_loss: 0.05485) (t_loss: 0.06433) (accu: 0.9797)
[epoch : 3] (l_loss: 0.03310) (t_loss: 0.06359) (accu: 0.9795)
[epoch : 4] (l_loss: 0.02256) (t_loss: 0.06925) (accu: 0.9800)
[epoch : 5] (l_loss: 0.01617) (t_loss: 0.06766) (accu: 0.9806)
[epoch : 6] (l_loss: 0.01333) (t_loss: 0.07484) (accu: 0.9806)
[epoch : 7] (l_loss: 0.01330) (t_loss: 0.09016) (accu: 0.9791)
[epoch : 8] (l_loss: 0.00910) (t_loss: 0.07988) (accu: 0.9802)
[epoch : 9] (l_loss: 0.00842) (t_loss: 0.07667) (accu: 0.9831)
[epoch : 10] (l_loss: 0.00882) (t_loss: 0.08130) (accu: 0.9817)
[epoch : 11] (l_loss: 0.00894) (t_loss: 0.08805) (accu: 0.9816)
[epoch : 12] (l_loss: 0.00662) (t_loss: 0.10024) (accu: 0.9810)
[epoch : 13] (l_loss: 0.00730) (t_loss: 0.10636) (accu: 0.9784)
[epoch : 14] (l_loss: 0.00709) (t_loss: 0.10551) (accu: 0.9815)
[epoch : 15] (l_loss: 0.00910) (t_loss: 0.10513) (accu: 0.9806)
[epoch : 16] (l_loss: 0.00478) (t_loss: 0.09888) (accu: 0.9816)
[epoch : 17] (l_loss: 0.00410) (t_loss: 0.11060) (accu: 0.9813)
[epoch : 18] (l_loss: 0.00918) (t_loss: 0.11906) (accu: 0.9800)
[epoch : 19] (l_loss: 0.00646) (t_loss: 0.11174) (accu: 0.9816)
[epoch : 20] (l_loss: 0.00382) (t_loss: 0.12715) (accu: 0.9783)
[epoch : 21] (l_loss: 0.00526) (t_loss: 0.12261) (accu: 0.9809)
[epoch : 22] (l_loss: 0.00681) (t_loss: 0.12263) (accu: 0.9811)
[epoch : 23] (l_loss: 0.00265) (t_loss: 0.11805) (accu: 0.9826)
[epoch : 24] (l_loss: 0.00437) (t_loss: 0.13130) (accu: 0.9809)
[epoch : 25] (l_loss: 0.00654) (t_loss: 0.16564) (accu: 0.9786)
[epoch : 26] (l_loss: 0.00685) (t_loss: 0.12772) (accu: 0.9815)
[epoch : 27] (l_loss: 0.00292) (t_loss: 0.13358) (accu: 0.9815)
[epoch : 28] (l_loss: 0.00550) (t_loss: 0.15560) (accu: 0.9790)
[epoch : 29] (l_loss: 0.00659) (t_loss: 0.14895) (accu: 0.9806)
[epoch : 30] (l_loss: 0.00291) (t_loss: 0.16371) (accu: 0.9793)
[epoch : 31] (l_loss: 0.00382) (t_loss: 0.15971) (accu: 0.9794)
[epoch : 32] (l_loss: 0.00740) (t_loss: 0.15634) (accu: 0.9818)
[epoch : 33] (l_loss: 0.00569) (t_loss: 0.14072) (accu: 0.9807)
[epoch : 34] (l_loss: 0.00495) (t_loss: 0.17398) (accu: 0.9800)
[epoch : 35] (l_loss: 0.00417) (t_loss: 0.15040) (accu: 0.9810)
[epoch : 36] (l_loss: 0.00339) (t_loss: 0.17019) (accu: 0.9799)
[epoch : 37] (l_loss: 0.00429) (t_loss: 0.16103) (accu: 0.9810)
[epoch : 38] (l_loss: 0.00338) (t_loss: 0.16040) (accu: 0.9815)
[epoch : 39] (l_loss: 0.00615) (t_loss: 0.16609) (accu: 0.9814)
[epoch : 40] (l_loss: 0.00279) (t_loss: 0.17113) (accu: 0.9801)
Finish! (Best accu: 0.9831) (Time taken(sec) : 721.65) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (56694 | 158806)         26.31
fc1.weight   :      196000 (51380 | 144620)         26.21
fc2.weight   :        18750 (4915 | 13835)          26.21
fcout.weight :          750 (399 | 351)             53.20
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (7/19), Remaining weight : 26.31 %]
[epoch : 1] (l_loss: 0.18026) (t_loss: 0.07732) (accu: 0.9754)
[epoch : 2] (l_loss: 0.04908) (t_loss: 0.06893) (accu: 0.9782)
[epoch : 3] (l_loss: 0.02837) (t_loss: 0.06309) (accu: 0.9808)
[epoch : 4] (l_loss: 0.01791) (t_loss: 0.06850) (accu: 0.9807)
[epoch : 5] (l_loss: 0.01407) (t_loss: 0.06813) (accu: 0.9823)
[epoch : 6] (l_loss: 0.01103) (t_loss: 0.07412) (accu: 0.9815)
[epoch : 7] (l_loss: 0.00929) (t_loss: 0.07880) (accu: 0.9802)
[epoch : 8] (l_loss: 0.00768) (t_loss: 0.08885) (accu: 0.9801)
[epoch : 9] (l_loss: 0.00812) (t_loss: 0.09539) (accu: 0.9798)
[epoch : 10] (l_loss: 0.00603) (t_loss: 0.10674) (accu: 0.9782)
[epoch : 11] (l_loss: 0.00568) (t_loss: 0.11061) (accu: 0.9786)
[epoch : 12] (l_loss: 0.00593) (t_loss: 0.09564) (accu: 0.9821)
[epoch : 13] (l_loss: 0.00569) (t_loss: 0.11474) (accu: 0.9801)
[epoch : 14] (l_loss: 0.00468) (t_loss: 0.11368) (accu: 0.9809)
[epoch : 15] (l_loss: 0.00489) (t_loss: 0.11850) (accu: 0.9800)
[epoch : 16] (l_loss: 0.00664) (t_loss: 0.11388) (accu: 0.9814)
[epoch : 17] (l_loss: 0.00367) (t_loss: 0.13923) (accu: 0.9793)
[epoch : 18] (l_loss: 0.00454) (t_loss: 0.11759) (accu: 0.9804)
[epoch : 19] (l_loss: 0.00513) (t_loss: 0.12299) (accu: 0.9808)
[epoch : 20] (l_loss: 0.00528) (t_loss: 0.14941) (accu: 0.9791)
[epoch : 21] (l_loss: 0.00498) (t_loss: 0.12233) (accu: 0.9828)
[epoch : 22] (l_loss: 0.00537) (t_loss: 0.12136) (accu: 0.9830)
[epoch : 23] (l_loss: 0.00318) (t_loss: 0.14121) (accu: 0.9808)
[epoch : 24] (l_loss: 0.00474) (t_loss: 0.13809) (accu: 0.9798)
[epoch : 25] (l_loss: 0.00416) (t_loss: 0.13782) (accu: 0.9810)
[epoch : 26] (l_loss: 0.00407) (t_loss: 0.15980) (accu: 0.9791)
[epoch : 27] (l_loss: 0.00442) (t_loss: 0.14696) (accu: 0.9794)
[epoch : 28] (l_loss: 0.00261) (t_loss: 0.13820) (accu: 0.9832)
[epoch : 29] (l_loss: 0.00229) (t_loss: 0.13965) (accu: 0.9803)
[epoch : 30] (l_loss: 0.00582) (t_loss: 0.15006) (accu: 0.9820)
[epoch : 31] (l_loss: 0.00296) (t_loss: 0.14392) (accu: 0.9819)
[epoch : 32] (l_loss: 0.00283) (t_loss: 0.15153) (accu: 0.9805)
[epoch : 33] (l_loss: 0.00524) (t_loss: 0.14660) (accu: 0.9816)
[epoch : 34] (l_loss: 0.00468) (t_loss: 0.14058) (accu: 0.9829)
[epoch : 35] (l_loss: 0.00384) (t_loss: 0.15550) (accu: 0.9815)
[epoch : 36] (l_loss: 0.00260) (t_loss: 0.16067) (accu: 0.9790)
[epoch : 37] (l_loss: 0.00288) (t_loss: 0.16334) (accu: 0.9810)
[epoch : 38] (l_loss: 0.00234) (t_loss: 0.16995) (accu: 0.9817)
[epoch : 39] (l_loss: 0.00610) (t_loss: 0.14992) (accu: 0.9817)
[epoch : 40] (l_loss: 0.00336) (t_loss: 0.16419) (accu: 0.9819)
Finish! (Best accu: 0.9832) (Time taken(sec) : 726.48) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (45395 | 170105)         21.06
fc1.weight   :      196000 (41104 | 154896)         20.97
fc2.weight   :        18750 (3932 | 14818)          20.97
fcout.weight :          750 (359 | 391)             47.87
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (8/19), Remaining weight : 21.06 %]
[epoch : 1] (l_loss: 0.17974) (t_loss: 0.07214) (accu: 0.9777)
[epoch : 2] (l_loss: 0.04538) (t_loss: 0.06491) (accu: 0.9788)
[epoch : 3] (l_loss: 0.02501) (t_loss: 0.05777) (accu: 0.9805)
[epoch : 4] (l_loss: 0.01567) (t_loss: 0.07060) (accu: 0.9804)
[epoch : 5] (l_loss: 0.01073) (t_loss: 0.07110) (accu: 0.9815)
[epoch : 6] (l_loss: 0.00990) (t_loss: 0.08088) (accu: 0.9801)
[epoch : 7] (l_loss: 0.00664) (t_loss: 0.08332) (accu: 0.9788)
[epoch : 8] (l_loss: 0.00742) (t_loss: 0.07976) (accu: 0.9816)
[epoch : 9] (l_loss: 0.00561) (t_loss: 0.09684) (accu: 0.9797)
[epoch : 10] (l_loss: 0.00619) (t_loss: 0.08653) (accu: 0.9808)
[epoch : 11] (l_loss: 0.00393) (t_loss: 0.09409) (accu: 0.9796)
[epoch : 12] (l_loss: 0.00565) (t_loss: 0.08992) (accu: 0.9825)
[epoch : 13] (l_loss: 0.00278) (t_loss: 0.09557) (accu: 0.9832)
[epoch : 14] (l_loss: 0.00452) (t_loss: 0.10098) (accu: 0.9809)
[epoch : 15] (l_loss: 0.00563) (t_loss: 0.09731) (accu: 0.9821)
[epoch : 16] (l_loss: 0.00302) (t_loss: 0.10756) (accu: 0.9815)
[epoch : 17] (l_loss: 0.00346) (t_loss: 0.11456) (accu: 0.9812)
[epoch : 18] (l_loss: 0.00432) (t_loss: 0.13420) (accu: 0.9797)
[epoch : 19] (l_loss: 0.00308) (t_loss: 0.12189) (accu: 0.9815)
[epoch : 20] (l_loss: 0.00405) (t_loss: 0.11871) (accu: 0.9817)
[epoch : 21] (l_loss: 0.00383) (t_loss: 0.14799) (accu: 0.9781)
[epoch : 22] (l_loss: 0.00439) (t_loss: 0.12540) (accu: 0.9812)
[epoch : 23] (l_loss: 0.00422) (t_loss: 0.12929) (accu: 0.9809)
[epoch : 24] (l_loss: 0.00297) (t_loss: 0.14169) (accu: 0.9796)
[epoch : 25] (l_loss: 0.00150) (t_loss: 0.14062) (accu: 0.9805)
[epoch : 26] (l_loss: 0.00500) (t_loss: 0.13315) (accu: 0.9822)
[epoch : 27] (l_loss: 0.00239) (t_loss: 0.13886) (accu: 0.9816)
[epoch : 28] (l_loss: 0.00282) (t_loss: 0.15178) (accu: 0.9813)
[epoch : 29] (l_loss: 0.00325) (t_loss: 0.14795) (accu: 0.9823)
[epoch : 30] (l_loss: 0.00373) (t_loss: 0.14307) (accu: 0.9805)
[epoch : 31] (l_loss: 0.00404) (t_loss: 0.15106) (accu: 0.9802)
[epoch : 32] (l_loss: 0.00178) (t_loss: 0.16517) (accu: 0.9803)
[epoch : 33] (l_loss: 0.00362) (t_loss: 0.15561) (accu: 0.9813)
[epoch : 34] (l_loss: 0.00338) (t_loss: 0.15863) (accu: 0.9812)
[epoch : 35] (l_loss: 0.00380) (t_loss: 0.15480) (accu: 0.9812)
[epoch : 36] (l_loss: 0.00277) (t_loss: 0.14374) (accu: 0.9830)
[epoch : 37] (l_loss: 0.00175) (t_loss: 0.15859) (accu: 0.9807)
[epoch : 38] (l_loss: 0.00060) (t_loss: 0.14909) (accu: 0.9827)
[epoch : 39] (l_loss: 0.00520) (t_loss: 0.18938) (accu: 0.9792)
[epoch : 40] (l_loss: 0.00325) (t_loss: 0.16882) (accu: 0.9814)
Finish! (Best accu: 0.9832) (Time taken(sec) : 722.48) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (36352 | 179148)         16.87
fc1.weight   :      196000 (32883 | 163117)         16.78
fc2.weight   :        18750 (3146 | 15604)          16.78
fcout.weight :          750 (323 | 427)             43.07
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (9/19), Remaining weight : 16.87 %]
[epoch : 1] (l_loss: 0.18393) (t_loss: 0.07370) (accu: 0.9779)
[epoch : 2] (l_loss: 0.04350) (t_loss: 0.06191) (accu: 0.9812)
[epoch : 3] (l_loss: 0.02292) (t_loss: 0.05858) (accu: 0.9814)
[epoch : 4] (l_loss: 0.01339) (t_loss: 0.06644) (accu: 0.9799)
[epoch : 5] (l_loss: 0.00805) (t_loss: 0.08148) (accu: 0.9785)
[epoch : 6] (l_loss: 0.00753) (t_loss: 0.06936) (accu: 0.9836)
[epoch : 7] (l_loss: 0.00611) (t_loss: 0.08190) (accu: 0.9813)
[epoch : 8] (l_loss: 0.00620) (t_loss: 0.08469) (accu: 0.9823)
[epoch : 9] (l_loss: 0.00361) (t_loss: 0.08712) (accu: 0.9816)
[epoch : 10] (l_loss: 0.00504) (t_loss: 0.09764) (accu: 0.9812)
[epoch : 11] (l_loss: 0.00360) (t_loss: 0.09288) (accu: 0.9811)
[epoch : 12] (l_loss: 0.00346) (t_loss: 0.10015) (accu: 0.9807)
[epoch : 13] (l_loss: 0.00353) (t_loss: 0.10308) (accu: 0.9821)
[epoch : 14] (l_loss: 0.00421) (t_loss: 0.11781) (accu: 0.9795)
[epoch : 15] (l_loss: 0.00334) (t_loss: 0.11163) (accu: 0.9821)
[epoch : 16] (l_loss: 0.00218) (t_loss: 0.11903) (accu: 0.9812)
[epoch : 17] (l_loss: 0.00473) (t_loss: 0.11095) (accu: 0.9826)
[epoch : 18] (l_loss: 0.00226) (t_loss: 0.12459) (accu: 0.9811)
[epoch : 19] (l_loss: 0.00259) (t_loss: 0.11355) (accu: 0.9827)
[epoch : 20] (l_loss: 0.00264) (t_loss: 0.12987) (accu: 0.9793)
[epoch : 21] (l_loss: 0.00303) (t_loss: 0.14872) (accu: 0.9795)
[epoch : 22] (l_loss: 0.00379) (t_loss: 0.13937) (accu: 0.9806)
[epoch : 23] (l_loss: 0.00306) (t_loss: 0.12696) (accu: 0.9825)
[epoch : 24] (l_loss: 0.00032) (t_loss: 0.12832) (accu: 0.9830)
[epoch : 25] (l_loss: 0.00006) (t_loss: 0.12793) (accu: 0.9838)
[epoch : 26] (l_loss: 0.00711) (t_loss: 0.13696) (accu: 0.9822)
[epoch : 27] (l_loss: 0.00331) (t_loss: 0.14759) (accu: 0.9808)
[epoch : 28] (l_loss: 0.00278) (t_loss: 0.16705) (accu: 0.9807)
[epoch : 29] (l_loss: 0.00219) (t_loss: 0.15299) (accu: 0.9812)
[epoch : 30] (l_loss: 0.00135) (t_loss: 0.16166) (accu: 0.9807)
[epoch : 31] (l_loss: 0.00286) (t_loss: 0.14849) (accu: 0.9817)
[epoch : 32] (l_loss: 0.00126) (t_loss: 0.15389) (accu: 0.9808)
[epoch : 33] (l_loss: 0.00242) (t_loss: 0.16103) (accu: 0.9813)
[epoch : 34] (l_loss: 0.00568) (t_loss: 0.14731) (accu: 0.9820)
[epoch : 35] (l_loss: 0.00217) (t_loss: 0.14882) (accu: 0.9843)
[epoch : 36] (l_loss: 0.00006) (t_loss: 0.14335) (accu: 0.9848)
[epoch : 37] (l_loss: 0.00001) (t_loss: 0.14285) (accu: 0.9847)
[epoch : 38] (l_loss: 0.00001) (t_loss: 0.14288) (accu: 0.9844)
[epoch : 39] (l_loss: 0.00001) (t_loss: 0.14317) (accu: 0.9845)
[epoch : 40] (l_loss: 0.00000) (t_loss: 0.14356) (accu: 0.9848)
Finish! (Best accu: 0.9848) (Time taken(sec) : 716.50) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (29115 | 186385)         13.51
fc1.weight   :      196000 (26307 | 169693)         13.42
fc2.weight   :        18750 (2517 | 16233)          13.42
fcout.weight :          750 (291 | 459)             38.80
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (10/19), Remaining weight : 13.51 %]
[epoch : 1] (l_loss: 0.18856) (t_loss: 0.07266) (accu: 0.9776)
[epoch : 2] (l_loss: 0.04136) (t_loss: 0.05898) (accu: 0.9815)
[epoch : 3] (l_loss: 0.02124) (t_loss: 0.06109) (accu: 0.9818)
[epoch : 4] (l_loss: 0.01237) (t_loss: 0.06102) (accu: 0.9832)
[epoch : 5] (l_loss: 0.00768) (t_loss: 0.07151) (accu: 0.9823)
[epoch : 6] (l_loss: 0.00574) (t_loss: 0.07260) (accu: 0.9819)
[epoch : 7] (l_loss: 0.00531) (t_loss: 0.08564) (accu: 0.9807)
[epoch : 8] (l_loss: 0.00441) (t_loss: 0.07962) (accu: 0.9818)
[epoch : 9] (l_loss: 0.00340) (t_loss: 0.09395) (accu: 0.9820)
[epoch : 10] (l_loss: 0.00449) (t_loss: 0.09064) (accu: 0.9815)
[epoch : 11] (l_loss: 0.00421) (t_loss: 0.09016) (accu: 0.9823)
[epoch : 12] (l_loss: 0.00278) (t_loss: 0.09384) (accu: 0.9824)
[epoch : 13] (l_loss: 0.00382) (t_loss: 0.10559) (accu: 0.9805)
[epoch : 14] (l_loss: 0.00370) (t_loss: 0.10579) (accu: 0.9809)
[epoch : 15] (l_loss: 0.00117) (t_loss: 0.11029) (accu: 0.9817)
[epoch : 16] (l_loss: 0.00172) (t_loss: 0.11403) (accu: 0.9814)
[epoch : 17] (l_loss: 0.00594) (t_loss: 0.11826) (accu: 0.9812)
[epoch : 18] (l_loss: 0.00153) (t_loss: 0.11370) (accu: 0.9828)
[epoch : 19] (l_loss: 0.00113) (t_loss: 0.12105) (accu: 0.9816)
[epoch : 20] (l_loss: 0.00187) (t_loss: 0.13434) (accu: 0.9812)
[epoch : 21] (l_loss: 0.00510) (t_loss: 0.12882) (accu: 0.9812)
[epoch : 22] (l_loss: 0.00087) (t_loss: 0.11444) (accu: 0.9829)
[epoch : 23] (l_loss: 0.00019) (t_loss: 0.12102) (accu: 0.9830)
[epoch : 24] (l_loss: 0.00003) (t_loss: 0.12121) (accu: 0.9829)
[epoch : 25] (l_loss: 0.00002) (t_loss: 0.12248) (accu: 0.9828)
[epoch : 26] (l_loss: 0.00001) (t_loss: 0.12276) (accu: 0.9832)
[epoch : 27] (l_loss: 0.00001) (t_loss: 0.12361) (accu: 0.9836)
[epoch : 28] (l_loss: 0.00001) (t_loss: 0.12530) (accu: 0.9835)
[epoch : 29] (l_loss: 0.00001) (t_loss: 0.12825) (accu: 0.9830)
[epoch : 30] (l_loss: 0.00739) (t_loss: 0.17551) (accu: 0.9777)
[epoch : 31] (l_loss: 0.00475) (t_loss: 0.15526) (accu: 0.9813)
[epoch : 32] (l_loss: 0.00172) (t_loss: 0.16707) (accu: 0.9817)
[epoch : 33] (l_loss: 0.00131) (t_loss: 0.15272) (accu: 0.9817)
[epoch : 34] (l_loss: 0.00236) (t_loss: 0.18083) (accu: 0.9782)
[epoch : 35] (l_loss: 0.00398) (t_loss: 0.14547) (accu: 0.9827)
[epoch : 36] (l_loss: 0.00230) (t_loss: 0.17180) (accu: 0.9799)
[epoch : 37] (l_loss: 0.00126) (t_loss: 0.15020) (accu: 0.9824)
[epoch : 38] (l_loss: 0.00117) (t_loss: 0.17195) (accu: 0.9798)
[epoch : 39] (l_loss: 0.00353) (t_loss: 0.15905) (accu: 0.9804)
[epoch : 40] (l_loss: 0.00112) (t_loss: 0.15935) (accu: 0.9810)
Finish! (Best accu: 0.9836) (Time taken(sec) : 727.27) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (23320 | 192180)         10.82
fc1.weight   :      196000 (21045 | 174955)         10.74
fc2.weight   :        18750 (2013 | 16737)          10.74
fcout.weight :          750 (262 | 488)             34.93
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (11/19), Remaining weight : 10.82 %]
[epoch : 1] (l_loss: 0.20393) (t_loss: 0.07560) (accu: 0.9774)
[epoch : 2] (l_loss: 0.04334) (t_loss: 0.05863) (accu: 0.9809)
[epoch : 3] (l_loss: 0.02227) (t_loss: 0.06162) (accu: 0.9811)
[epoch : 4] (l_loss: 0.01305) (t_loss: 0.06199) (accu: 0.9823)
[epoch : 5] (l_loss: 0.00825) (t_loss: 0.06525) (accu: 0.9828)
[epoch : 6] (l_loss: 0.00554) (t_loss: 0.07783) (accu: 0.9814)
[epoch : 7] (l_loss: 0.00421) (t_loss: 0.07677) (accu: 0.9833)
[epoch : 8] (l_loss: 0.00384) (t_loss: 0.08217) (accu: 0.9811)
[epoch : 9] (l_loss: 0.00366) (t_loss: 0.09051) (accu: 0.9817)
[epoch : 10] (l_loss: 0.00344) (t_loss: 0.10360) (accu: 0.9792)
[epoch : 11] (l_loss: 0.00254) (t_loss: 0.09262) (accu: 0.9820)
[epoch : 12] (l_loss: 0.00041) (t_loss: 0.09192) (accu: 0.9837)
[epoch : 13] (l_loss: 0.00289) (t_loss: 0.12629) (accu: 0.9769)
[epoch : 14] (l_loss: 0.00474) (t_loss: 0.10686) (accu: 0.9818)
[epoch : 15] (l_loss: 0.00057) (t_loss: 0.10873) (accu: 0.9808)
[epoch : 16] (l_loss: 0.00021) (t_loss: 0.09899) (accu: 0.9830)
[epoch : 17] (l_loss: 0.00008) (t_loss: 0.10061) (accu: 0.9831)
[epoch : 18] (l_loss: 0.00005) (t_loss: 0.10371) (accu: 0.9833)
[epoch : 19] (l_loss: 0.00004) (t_loss: 0.10488) (accu: 0.9837)
[epoch : 20] (l_loss: 0.00003) (t_loss: 0.10803) (accu: 0.9838)
[epoch : 21] (l_loss: 0.00002) (t_loss: 0.11427) (accu: 0.9837)
[epoch : 22] (l_loss: 0.01129) (t_loss: 0.12175) (accu: 0.9817)
[epoch : 23] (l_loss: 0.00206) (t_loss: 0.12486) (accu: 0.9815)
[epoch : 24] (l_loss: 0.00123) (t_loss: 0.12884) (accu: 0.9818)
[epoch : 25] (l_loss: 0.00215) (t_loss: 0.14285) (accu: 0.9803)
[epoch : 26] (l_loss: 0.00170) (t_loss: 0.12936) (accu: 0.9802)
[epoch : 27] (l_loss: 0.00141) (t_loss: 0.13910) (accu: 0.9806)
[epoch : 28] (l_loss: 0.00368) (t_loss: 0.14525) (accu: 0.9801)
[epoch : 29] (l_loss: 0.00089) (t_loss: 0.13423) (accu: 0.9822)
[epoch : 30] (l_loss: 0.00034) (t_loss: 0.13361) (accu: 0.9824)
[epoch : 31] (l_loss: 0.00005) (t_loss: 0.13175) (accu: 0.9820)
[epoch : 32] (l_loss: 0.00002) (t_loss: 0.13276) (accu: 0.9821)
[epoch : 33] (l_loss: 0.00001) (t_loss: 0.13354) (accu: 0.9829)
[epoch : 34] (l_loss: 0.00001) (t_loss: 0.13523) (accu: 0.9829)
[epoch : 35] (l_loss: 0.00001) (t_loss: 0.13640) (accu: 0.9829)
[epoch : 36] (l_loss: 0.00000) (t_loss: 0.13831) (accu: 0.9825)
[epoch : 37] (l_loss: 0.00000) (t_loss: 0.14139) (accu: 0.9836)
[epoch : 38] (l_loss: 0.00000) (t_loss: 0.14416) (accu: 0.9832)
[epoch : 39] (l_loss: 0.00000) (t_loss: 0.14613) (accu: 0.9831)
[epoch : 40] (l_loss: 0.00000) (t_loss: 0.15025) (accu: 0.9829)
Finish! (Best accu: 0.9838) (Time taken(sec) : 741.12) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (18682 | 196818)          8.67
fc1.weight   :      196000 (16836 | 179164)          8.59
fc2.weight   :        18750 (1611 | 17139)           8.59
fcout.weight :          750 (235 | 515)             31.33
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (12/19), Remaining weight : 8.67 %]
[epoch : 1] (l_loss: 0.22011) (t_loss: 0.07742) (accu: 0.9768)
[epoch : 2] (l_loss: 0.04607) (t_loss: 0.06276) (accu: 0.9814)
[epoch : 3] (l_loss: 0.02440) (t_loss: 0.05857) (accu: 0.9816)
[epoch : 4] (l_loss: 0.01382) (t_loss: 0.06215) (accu: 0.9817)
[epoch : 5] (l_loss: 0.00855) (t_loss: 0.06580) (accu: 0.9821)
[epoch : 6] (l_loss: 0.00565) (t_loss: 0.07038) (accu: 0.9814)
[epoch : 7] (l_loss: 0.00350) (t_loss: 0.07267) (accu: 0.9827)
[epoch : 8] (l_loss: 0.00271) (t_loss: 0.09041) (accu: 0.9787)
[epoch : 9] (l_loss: 0.00259) (t_loss: 0.08155) (accu: 0.9821)
[epoch : 10] (l_loss: 0.00261) (t_loss: 0.09852) (accu: 0.9797)
[epoch : 11] (l_loss: 0.00235) (t_loss: 0.08846) (accu: 0.9827)
[epoch : 12] (l_loss: 0.00060) (t_loss: 0.09397) (accu: 0.9828)
[epoch : 13] (l_loss: 0.00481) (t_loss: 0.10440) (accu: 0.9803)
[epoch : 14] (l_loss: 0.00165) (t_loss: 0.10213) (accu: 0.9812)
[epoch : 15] (l_loss: 0.00211) (t_loss: 0.11545) (accu: 0.9809)
[epoch : 16] (l_loss: 0.00209) (t_loss: 0.13196) (accu: 0.9787)
[epoch : 17] (l_loss: 0.00205) (t_loss: 0.11631) (accu: 0.9817)
[epoch : 18] (l_loss: 0.00028) (t_loss: 0.11272) (accu: 0.9820)
[epoch : 19] (l_loss: 0.00010) (t_loss: 0.11416) (accu: 0.9827)
[epoch : 20] (l_loss: 0.00005) (t_loss: 0.11291) (accu: 0.9827)
[epoch : 21] (l_loss: 0.00003) (t_loss: 0.11447) (accu: 0.9823)
[epoch : 22] (l_loss: 0.00002) (t_loss: 0.11931) (accu: 0.9827)
[epoch : 23] (l_loss: 0.00002) (t_loss: 0.12370) (accu: 0.9824)
[epoch : 24] (l_loss: 0.00224) (t_loss: 0.17736) (accu: 0.9757)
[epoch : 25] (l_loss: 0.00559) (t_loss: 0.14622) (accu: 0.9810)
[epoch : 26] (l_loss: 0.00051) (t_loss: 0.13438) (accu: 0.9814)
[epoch : 27] (l_loss: 0.00031) (t_loss: 0.13360) (accu: 0.9816)
[epoch : 28] (l_loss: 0.00227) (t_loss: 0.17150) (accu: 0.9778)
[epoch : 29] (l_loss: 0.00305) (t_loss: 0.15043) (accu: 0.9800)
[epoch : 30] (l_loss: 0.00146) (t_loss: 0.14473) (accu: 0.9812)
[epoch : 31] (l_loss: 0.00019) (t_loss: 0.14150) (accu: 0.9811)
[epoch : 32] (l_loss: 0.00003) (t_loss: 0.14120) (accu: 0.9816)
[epoch : 33] (l_loss: 0.00002) (t_loss: 0.14057) (accu: 0.9819)
[epoch : 34] (l_loss: 0.00001) (t_loss: 0.14088) (accu: 0.9820)
[epoch : 35] (l_loss: 0.00001) (t_loss: 0.14163) (accu: 0.9821)
[epoch : 36] (l_loss: 0.00001) (t_loss: 0.14199) (accu: 0.9826)
[epoch : 37] (l_loss: 0.00001) (t_loss: 0.14233) (accu: 0.9825)
[epoch : 38] (l_loss: 0.00000) (t_loss: 0.14554) (accu: 0.9824)
[epoch : 39] (l_loss: 0.00000) (t_loss: 0.14854) (accu: 0.9825)
[epoch : 40] (l_loss: 0.00000) (t_loss: 0.15188) (accu: 0.9826)
Finish! (Best accu: 0.9828) (Time taken(sec) : 729.01) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (14969 | 200531)          6.95
fc1.weight   :      196000 (13469 | 182531)          6.87
fc2.weight   :        18750 (1288 | 17462)           6.87
fcout.weight :          750 (212 | 538)             28.27
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (13/19), Remaining weight : 6.95 %]
[epoch : 1] (l_loss: 0.23864) (t_loss: 0.08391) (accu: 0.9754)
[epoch : 2] (l_loss: 0.05164) (t_loss: 0.06313) (accu: 0.9806)
[epoch : 3] (l_loss: 0.02899) (t_loss: 0.06348) (accu: 0.9814)
[epoch : 4] (l_loss: 0.01745) (t_loss: 0.06080) (accu: 0.9825)
[epoch : 5] (l_loss: 0.01149) (t_loss: 0.06758) (accu: 0.9808)
[epoch : 6] (l_loss: 0.00738) (t_loss: 0.06848) (accu: 0.9823)
[epoch : 7] (l_loss: 0.00484) (t_loss: 0.07391) (accu: 0.9816)
[epoch : 8] (l_loss: 0.00450) (t_loss: 0.08219) (accu: 0.9807)
[epoch : 9] (l_loss: 0.00308) (t_loss: 0.09322) (accu: 0.9791)
[epoch : 10] (l_loss: 0.00247) (t_loss: 0.09263) (accu: 0.9808)
[epoch : 11] (l_loss: 0.00216) (t_loss: 0.09362) (accu: 0.9814)
[epoch : 12] (l_loss: 0.00307) (t_loss: 0.09214) (accu: 0.9828)
[epoch : 13] (l_loss: 0.00121) (t_loss: 0.09441) (accu: 0.9830)
[epoch : 14] (l_loss: 0.00225) (t_loss: 0.11438) (accu: 0.9792)
[epoch : 15] (l_loss: 0.00287) (t_loss: 0.10013) (accu: 0.9830)
[epoch : 16] (l_loss: 0.00032) (t_loss: 0.09999) (accu: 0.9831)
[epoch : 17] (l_loss: 0.00014) (t_loss: 0.10299) (accu: 0.9828)
[epoch : 18] (l_loss: 0.00010) (t_loss: 0.10497) (accu: 0.9827)
[epoch : 19] (l_loss: 0.00007) (t_loss: 0.10826) (accu: 0.9828)
[epoch : 20] (l_loss: 0.00424) (t_loss: 0.12120) (accu: 0.9815)
[epoch : 21] (l_loss: 0.00348) (t_loss: 0.11811) (accu: 0.9818)
[epoch : 22] (l_loss: 0.00048) (t_loss: 0.11903) (accu: 0.9819)
[epoch : 23] (l_loss: 0.00016) (t_loss: 0.11962) (accu: 0.9819)
[epoch : 24] (l_loss: 0.00007) (t_loss: 0.11810) (accu: 0.9820)
[epoch : 25] (l_loss: 0.00004) (t_loss: 0.12053) (accu: 0.9824)
[epoch : 26] (l_loss: 0.00003) (t_loss: 0.12165) (accu: 0.9826)
[epoch : 27] (l_loss: 0.00003) (t_loss: 0.12337) (accu: 0.9825)
[epoch : 28] (l_loss: 0.00002) (t_loss: 0.12921) (accu: 0.9818)
[epoch : 29] (l_loss: 0.00815) (t_loss: 0.14326) (accu: 0.9807)
[epoch : 30] (l_loss: 0.00108) (t_loss: 0.12912) (accu: 0.9819)
[epoch : 31] (l_loss: 0.00040) (t_loss: 0.13216) (accu: 0.9827)
[epoch : 32] (l_loss: 0.00006) (t_loss: 0.13045) (accu: 0.9821)
[epoch : 33] (l_loss: 0.00003) (t_loss: 0.13135) (accu: 0.9823)
[epoch : 34] (l_loss: 0.00002) (t_loss: 0.13350) (accu: 0.9820)
[epoch : 35] (l_loss: 0.00002) (t_loss: 0.13496) (accu: 0.9822)
[epoch : 36] (l_loss: 0.00001) (t_loss: 0.13751) (accu: 0.9828)
[epoch : 37] (l_loss: 0.00001) (t_loss: 0.13942) (accu: 0.9827)
[epoch : 38] (l_loss: 0.00661) (t_loss: 0.17091) (accu: 0.9808)
[epoch : 39] (l_loss: 0.00221) (t_loss: 0.16931) (accu: 0.9788)
[epoch : 40] (l_loss: 0.00131) (t_loss: 0.15800) (accu: 0.9806)
Finish! (Best accu: 0.9831) (Time taken(sec) : 735.70) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (11997 | 203503)          5.57
fc1.weight   :      196000 (10775 | 185225)          5.50
fc2.weight   :        18750 (1031 | 17719)           5.50
fcout.weight :          750 (191 | 559)             25.47
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (14/19), Remaining weight : 5.57 %]
[epoch : 1] (l_loss: 0.27865) (t_loss: 0.08852) (accu: 0.9740)
[epoch : 2] (l_loss: 0.05726) (t_loss: 0.06367) (accu: 0.9811)
[epoch : 3] (l_loss: 0.03285) (t_loss: 0.06186) (accu: 0.9811)
[epoch : 4] (l_loss: 0.02075) (t_loss: 0.06194) (accu: 0.9815)
[epoch : 5] (l_loss: 0.01289) (t_loss: 0.06414) (accu: 0.9812)
[epoch : 6] (l_loss: 0.00881) (t_loss: 0.06517) (accu: 0.9820)
[epoch : 7] (l_loss: 0.00556) (t_loss: 0.07200) (accu: 0.9814)
[epoch : 8] (l_loss: 0.00410) (t_loss: 0.07922) (accu: 0.9799)
[epoch : 9] (l_loss: 0.00291) (t_loss: 0.07924) (accu: 0.9806)
[epoch : 10] (l_loss: 0.00323) (t_loss: 0.09956) (accu: 0.9785)
[epoch : 11] (l_loss: 0.00250) (t_loss: 0.09015) (accu: 0.9801)
[epoch : 12] (l_loss: 0.00091) (t_loss: 0.08802) (accu: 0.9817)
[epoch : 13] (l_loss: 0.00066) (t_loss: 0.10088) (accu: 0.9803)
[epoch : 14] (l_loss: 0.00362) (t_loss: 0.10853) (accu: 0.9814)
[epoch : 15] (l_loss: 0.00155) (t_loss: 0.10593) (accu: 0.9812)
[epoch : 16] (l_loss: 0.00038) (t_loss: 0.10445) (accu: 0.9812)
[epoch : 17] (l_loss: 0.00019) (t_loss: 0.10605) (accu: 0.9813)
[epoch : 18] (l_loss: 0.00012) (t_loss: 0.10784) (accu: 0.9817)
[epoch : 19] (l_loss: 0.00009) (t_loss: 0.11370) (accu: 0.9816)
[epoch : 20] (l_loss: 0.00260) (t_loss: 0.16409) (accu: 0.9764)
[epoch : 21] (l_loss: 0.00364) (t_loss: 0.12257) (accu: 0.9811)
[epoch : 22] (l_loss: 0.00060) (t_loss: 0.12063) (accu: 0.9822)
[epoch : 23] (l_loss: 0.00048) (t_loss: 0.13349) (accu: 0.9805)
[epoch : 24] (l_loss: 0.00070) (t_loss: 0.13249) (accu: 0.9793)
[epoch : 25] (l_loss: 0.00017) (t_loss: 0.12707) (accu: 0.9818)
[epoch : 26] (l_loss: 0.00005) (t_loss: 0.12666) (accu: 0.9814)
[epoch : 27] (l_loss: 0.00003) (t_loss: 0.12929) (accu: 0.9816)
[epoch : 28] (l_loss: 0.00003) (t_loss: 0.13084) (accu: 0.9817)
[epoch : 29] (l_loss: 0.00113) (t_loss: 0.18077) (accu: 0.9769)
[epoch : 30] (l_loss: 0.00587) (t_loss: 0.14476) (accu: 0.9806)
[epoch : 31] (l_loss: 0.00085) (t_loss: 0.14010) (accu: 0.9815)
[epoch : 32] (l_loss: 0.00027) (t_loss: 0.14161) (accu: 0.9810)
[epoch : 33] (l_loss: 0.00006) (t_loss: 0.13984) (accu: 0.9817)
[epoch : 34] (l_loss: 0.00003) (t_loss: 0.14023) (accu: 0.9814)
[epoch : 35] (l_loss: 0.00003) (t_loss: 0.14032) (accu: 0.9815)
[epoch : 36] (l_loss: 0.00002) (t_loss: 0.14144) (accu: 0.9819)
[epoch : 37] (l_loss: 0.00002) (t_loss: 0.14284) (accu: 0.9819)
[epoch : 38] (l_loss: 0.00001) (t_loss: 0.14515) (accu: 0.9819)
[epoch : 39] (l_loss: 0.00001) (t_loss: 0.14639) (accu: 0.9820)
[epoch : 40] (l_loss: 0.00001) (t_loss: 0.15162) (accu: 0.9817)
Finish! (Best accu: 0.9822) (Time taken(sec) : 739.52) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (9617 | 205883)          4.46
fc1.weight   :       196000 (8620 | 187380)          4.40
fc2.weight   :        18750 (825 | 17925)            4.40
fcout.weight :          750 (172 | 578)             22.93
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (15/19), Remaining weight : 4.46 %]
[epoch : 1] (l_loss: 0.31702) (t_loss: 0.10128) (accu: 0.9726)
[epoch : 2] (l_loss: 0.07000) (t_loss: 0.07133) (accu: 0.9775)
[epoch : 3] (l_loss: 0.04247) (t_loss: 0.06406) (accu: 0.9793)
[epoch : 4] (l_loss: 0.02848) (t_loss: 0.06254) (accu: 0.9803)
[epoch : 5] (l_loss: 0.01921) (t_loss: 0.07402) (accu: 0.9777)
[epoch : 6] (l_loss: 0.01408) (t_loss: 0.07041) (accu: 0.9804)
[epoch : 7] (l_loss: 0.00957) (t_loss: 0.07545) (accu: 0.9796)
[epoch : 8] (l_loss: 0.00722) (t_loss: 0.07892) (accu: 0.9795)
[epoch : 9] (l_loss: 0.00534) (t_loss: 0.08072) (accu: 0.9804)
[epoch : 10] (l_loss: 0.00393) (t_loss: 0.08619) (accu: 0.9803)
[epoch : 11] (l_loss: 0.00274) (t_loss: 0.09325) (accu: 0.9797)
[epoch : 12] (l_loss: 0.00242) (t_loss: 0.09810) (accu: 0.9792)
[epoch : 13] (l_loss: 0.00302) (t_loss: 0.09830) (accu: 0.9804)
[epoch : 14] (l_loss: 0.00197) (t_loss: 0.10129) (accu: 0.9795)
[epoch : 15] (l_loss: 0.00144) (t_loss: 0.10402) (accu: 0.9800)
[epoch : 16] (l_loss: 0.00111) (t_loss: 0.10571) (accu: 0.9805)
[epoch : 17] (l_loss: 0.00120) (t_loss: 0.11813) (accu: 0.9785)
[epoch : 18] (l_loss: 0.00226) (t_loss: 0.11939) (accu: 0.9781)
[epoch : 19] (l_loss: 0.00104) (t_loss: 0.11617) (accu: 0.9794)
[epoch : 20] (l_loss: 0.00046) (t_loss: 0.11873) (accu: 0.9800)
[epoch : 21] (l_loss: 0.00024) (t_loss: 0.12055) (accu: 0.9800)
[epoch : 22] (l_loss: 0.00012) (t_loss: 0.12153) (accu: 0.9803)
[epoch : 23] (l_loss: 0.00011) (t_loss: 0.14644) (accu: 0.9782)
[epoch : 24] (l_loss: 0.00628) (t_loss: 0.13676) (accu: 0.9803)
[epoch : 25] (l_loss: 0.00067) (t_loss: 0.13534) (accu: 0.9800)
[epoch : 26] (l_loss: 0.00022) (t_loss: 0.13355) (accu: 0.9796)
[epoch : 27] (l_loss: 0.00009) (t_loss: 0.13376) (accu: 0.9798)
[epoch : 28] (l_loss: 0.00007) (t_loss: 0.13529) (accu: 0.9803)
[epoch : 29] (l_loss: 0.00005) (t_loss: 0.13894) (accu: 0.9806)
[epoch : 30] (l_loss: 0.00005) (t_loss: 0.14328) (accu: 0.9802)
[epoch : 31] (l_loss: 0.00528) (t_loss: 0.15512) (accu: 0.9784)
[epoch : 32] (l_loss: 0.00078) (t_loss: 0.15227) (accu: 0.9793)
[epoch : 33] (l_loss: 0.00018) (t_loss: 0.15158) (accu: 0.9802)
[epoch : 34] (l_loss: 0.00007) (t_loss: 0.15078) (accu: 0.9811)
[epoch : 35] (l_loss: 0.00005) (t_loss: 0.15105) (accu: 0.9807)
[epoch : 36] (l_loss: 0.00004) (t_loss: 0.15105) (accu: 0.9807)
[epoch : 37] (l_loss: 0.00003) (t_loss: 0.15320) (accu: 0.9800)
[epoch : 38] (l_loss: 0.00002) (t_loss: 0.16140) (accu: 0.9800)
[epoch : 39] (l_loss: 0.00631) (t_loss: 0.17643) (accu: 0.9790)
[epoch : 40] (l_loss: 0.00077) (t_loss: 0.16870) (accu: 0.9795)
Finish! (Best accu: 0.9811) (Time taken(sec) : 745.10) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (7710 | 207790)          3.58
fc1.weight   :       196000 (6896 | 189104)          3.52
fc2.weight   :        18750 (660 | 18090)            3.52
fcout.weight :          750 (154 | 596)             20.53
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (16/19), Remaining weight : 3.58 %]
[epoch : 1] (l_loss: 0.37103) (t_loss: 0.11853) (accu: 0.9648)
[epoch : 2] (l_loss: 0.08424) (t_loss: 0.08060) (accu: 0.9751)
[epoch : 3] (l_loss: 0.05124) (t_loss: 0.06907) (accu: 0.9787)
[epoch : 4] (l_loss: 0.03531) (t_loss: 0.06986) (accu: 0.9787)
[epoch : 5] (l_loss: 0.02529) (t_loss: 0.07130) (accu: 0.9781)
[epoch : 6] (l_loss: 0.01857) (t_loss: 0.07403) (accu: 0.9778)
[epoch : 7] (l_loss: 0.01407) (t_loss: 0.07316) (accu: 0.9788)
[epoch : 8] (l_loss: 0.01037) (t_loss: 0.07990) (accu: 0.9781)
[epoch : 9] (l_loss: 0.00780) (t_loss: 0.08255) (accu: 0.9787)
[epoch : 10] (l_loss: 0.00606) (t_loss: 0.08519) (accu: 0.9794)
[epoch : 11] (l_loss: 0.00481) (t_loss: 0.08893) (accu: 0.9796)
[epoch : 12] (l_loss: 0.00419) (t_loss: 0.09333) (accu: 0.9788)
[epoch : 13] (l_loss: 0.00301) (t_loss: 0.10076) (accu: 0.9785)
[epoch : 14] (l_loss: 0.00294) (t_loss: 0.10400) (accu: 0.9801)
[epoch : 15] (l_loss: 0.00257) (t_loss: 0.10960) (accu: 0.9786)
[epoch : 16] (l_loss: 0.00131) (t_loss: 0.10485) (accu: 0.9790)
[epoch : 17] (l_loss: 0.00225) (t_loss: 0.11706) (accu: 0.9787)
[epoch : 18] (l_loss: 0.00198) (t_loss: 0.11863) (accu: 0.9793)
[epoch : 19] (l_loss: 0.00132) (t_loss: 0.12259) (accu: 0.9794)
[epoch : 20] (l_loss: 0.00142) (t_loss: 0.12019) (accu: 0.9792)
[epoch : 21] (l_loss: 0.00123) (t_loss: 0.14072) (accu: 0.9773)
[epoch : 22] (l_loss: 0.00182) (t_loss: 0.12982) (accu: 0.9800)
[epoch : 23] (l_loss: 0.00214) (t_loss: 0.12818) (accu: 0.9798)
[epoch : 24] (l_loss: 0.00061) (t_loss: 0.12804) (accu: 0.9800)
[epoch : 25] (l_loss: 0.00025) (t_loss: 0.13063) (accu: 0.9795)
[epoch : 26] (l_loss: 0.00016) (t_loss: 0.12970) (accu: 0.9803)
[epoch : 27] (l_loss: 0.00291) (t_loss: 0.14337) (accu: 0.9793)
[epoch : 28] (l_loss: 0.00214) (t_loss: 0.13850) (accu: 0.9799)
[epoch : 29] (l_loss: 0.00046) (t_loss: 0.13430) (accu: 0.9802)
[epoch : 30] (l_loss: 0.00017) (t_loss: 0.13730) (accu: 0.9798)
[epoch : 31] (l_loss: 0.00012) (t_loss: 0.13750) (accu: 0.9805)
[epoch : 32] (l_loss: 0.00010) (t_loss: 0.14353) (accu: 0.9804)
[epoch : 33] (l_loss: 0.00037) (t_loss: 0.16523) (accu: 0.9765)
[epoch : 34] (l_loss: 0.00421) (t_loss: 0.15641) (accu: 0.9795)
[epoch : 35] (l_loss: 0.00061) (t_loss: 0.15815) (accu: 0.9791)
[epoch : 36] (l_loss: 0.00038) (t_loss: 0.15586) (accu: 0.9785)
[epoch : 37] (l_loss: 0.00030) (t_loss: 0.16234) (accu: 0.9790)
[epoch : 38] (l_loss: 0.00166) (t_loss: 0.17682) (accu: 0.9785)
[epoch : 39] (l_loss: 0.00150) (t_loss: 0.16861) (accu: 0.9786)
[epoch : 40] (l_loss: 0.00022) (t_loss: 0.16253) (accu: 0.9796)
Finish! (Best accu: 0.9805) (Time taken(sec) : 739.81) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (6184 | 209316)          2.87
fc1.weight   :       196000 (5517 | 190483)          2.81
fc2.weight   :        18750 (528 | 18222)            2.82
fcout.weight :          750 (139 | 611)             18.53
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (17/19), Remaining weight : 2.87 %]
[epoch : 1] (l_loss: 0.40967) (t_loss: 0.12749) (accu: 0.9641)
[epoch : 2] (l_loss: 0.09499) (t_loss: 0.08803) (accu: 0.9726)
[epoch : 3] (l_loss: 0.06180) (t_loss: 0.07671) (accu: 0.9769)
[epoch : 4] (l_loss: 0.04462) (t_loss: 0.07087) (accu: 0.9771)
[epoch : 5] (l_loss: 0.03384) (t_loss: 0.07065) (accu: 0.9783)
[epoch : 6] (l_loss: 0.02705) (t_loss: 0.06874) (accu: 0.9798)
[epoch : 7] (l_loss: 0.02138) (t_loss: 0.07072) (accu: 0.9807)
[epoch : 8] (l_loss: 0.01730) (t_loss: 0.07579) (accu: 0.9797)
[epoch : 9] (l_loss: 0.01416) (t_loss: 0.07900) (accu: 0.9783)
[epoch : 10] (l_loss: 0.01149) (t_loss: 0.08335) (accu: 0.9792)
[epoch : 11] (l_loss: 0.00959) (t_loss: 0.08673) (accu: 0.9784)
[epoch : 12] (l_loss: 0.00800) (t_loss: 0.09060) (accu: 0.9784)
[epoch : 13] (l_loss: 0.00673) (t_loss: 0.09169) (accu: 0.9787)
[epoch : 14] (l_loss: 0.00566) (t_loss: 0.09612) (accu: 0.9795)
[epoch : 15] (l_loss: 0.00508) (t_loss: 0.10416) (accu: 0.9770)
[epoch : 16] (l_loss: 0.00398) (t_loss: 0.10277) (accu: 0.9785)
[epoch : 17] (l_loss: 0.00378) (t_loss: 0.10617) (accu: 0.9788)
[epoch : 18] (l_loss: 0.00324) (t_loss: 0.11218) (accu: 0.9788)
[epoch : 19] (l_loss: 0.00288) (t_loss: 0.12358) (accu: 0.9781)
[epoch : 20] (l_loss: 0.00239) (t_loss: 0.12211) (accu: 0.9780)
[epoch : 21] (l_loss: 0.00245) (t_loss: 0.12182) (accu: 0.9784)
[epoch : 22] (l_loss: 0.00228) (t_loss: 0.13212) (accu: 0.9771)
[epoch : 23] (l_loss: 0.00149) (t_loss: 0.13099) (accu: 0.9784)
[epoch : 24] (l_loss: 0.00151) (t_loss: 0.13391) (accu: 0.9785)
[epoch : 25] (l_loss: 0.00184) (t_loss: 0.13515) (accu: 0.9784)
[epoch : 26] (l_loss: 0.00162) (t_loss: 0.13672) (accu: 0.9787)
[epoch : 27] (l_loss: 0.00098) (t_loss: 0.14047) (accu: 0.9784)
[epoch : 28] (l_loss: 0.00106) (t_loss: 0.15031) (accu: 0.9775)
[epoch : 29] (l_loss: 0.00276) (t_loss: 0.14631) (accu: 0.9778)
[epoch : 30] (l_loss: 0.00092) (t_loss: 0.15104) (accu: 0.9786)
[epoch : 31] (l_loss: 0.00077) (t_loss: 0.15140) (accu: 0.9778)
[epoch : 32] (l_loss: 0.00223) (t_loss: 0.15330) (accu: 0.9785)
[epoch : 33] (l_loss: 0.00060) (t_loss: 0.15296) (accu: 0.9790)
[epoch : 34] (l_loss: 0.00028) (t_loss: 0.15474) (accu: 0.9794)
[epoch : 35] (l_loss: 0.00017) (t_loss: 0.15700) (accu: 0.9794)
[epoch : 36] (l_loss: 0.00193) (t_loss: 0.19323) (accu: 0.9741)
[epoch : 37] (l_loss: 0.00307) (t_loss: 0.17553) (accu: 0.9781)
[epoch : 38] (l_loss: 0.00057) (t_loss: 0.16481) (accu: 0.9791)
[epoch : 39] (l_loss: 0.00019) (t_loss: 0.16505) (accu: 0.9791)
[epoch : 40] (l_loss: 0.00013) (t_loss: 0.16627) (accu: 0.9788)
Finish! (Best accu: 0.9807) (Time taken(sec) : 746.70) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (4961 | 210539)          2.30
fc1.weight   :       196000 (4414 | 191586)          2.25
fc2.weight   :        18750 (422 | 18328)            2.25
fcout.weight :          750 (125 | 625)             16.67
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (18/19), Remaining weight : 2.3 %]
[epoch : 1] (l_loss: 0.44797) (t_loss: 0.13905) (accu: 0.9594)
[epoch : 2] (l_loss: 0.10992) (t_loss: 0.10034) (accu: 0.9711)
[epoch : 3] (l_loss: 0.07486) (t_loss: 0.08368) (accu: 0.9745)
[epoch : 4] (l_loss: 0.05764) (t_loss: 0.08021) (accu: 0.9747)
[epoch : 5] (l_loss: 0.04589) (t_loss: 0.07759) (accu: 0.9757)
[epoch : 6] (l_loss: 0.03793) (t_loss: 0.07706) (accu: 0.9767)
[epoch : 7] (l_loss: 0.03190) (t_loss: 0.07659) (accu: 0.9762)
[epoch : 8] (l_loss: 0.02697) (t_loss: 0.07945) (accu: 0.9757)
[epoch : 9] (l_loss: 0.02300) (t_loss: 0.08065) (accu: 0.9766)
[epoch : 10] (l_loss: 0.02025) (t_loss: 0.08393) (accu: 0.9766)
[epoch : 11] (l_loss: 0.01719) (t_loss: 0.08738) (accu: 0.9766)
[epoch : 12] (l_loss: 0.01512) (t_loss: 0.09273) (accu: 0.9757)
[epoch : 13] (l_loss: 0.01342) (t_loss: 0.09561) (accu: 0.9745)
[epoch : 14] (l_loss: 0.01187) (t_loss: 0.10226) (accu: 0.9752)
[epoch : 15] (l_loss: 0.01097) (t_loss: 0.10213) (accu: 0.9759)
[epoch : 16] (l_loss: 0.00934) (t_loss: 0.10619) (accu: 0.9758)
[epoch : 17] (l_loss: 0.00850) (t_loss: 0.11070) (accu: 0.9755)
[epoch : 18] (l_loss: 0.00748) (t_loss: 0.11420) (accu: 0.9764)
[epoch : 19] (l_loss: 0.00665) (t_loss: 0.11483) (accu: 0.9757)
[epoch : 20] (l_loss: 0.00616) (t_loss: 0.12528) (accu: 0.9756)
[epoch : 21] (l_loss: 0.00592) (t_loss: 0.12954) (accu: 0.9758)
[epoch : 22] (l_loss: 0.00480) (t_loss: 0.13201) (accu: 0.9753)
[epoch : 23] (l_loss: 0.00435) (t_loss: 0.12985) (accu: 0.9766)
[epoch : 24] (l_loss: 0.00433) (t_loss: 0.14061) (accu: 0.9744)
[epoch : 25] (l_loss: 0.00381) (t_loss: 0.14725) (accu: 0.9764)
[epoch : 26] (l_loss: 0.00339) (t_loss: 0.14655) (accu: 0.9758)
[epoch : 27] (l_loss: 0.00331) (t_loss: 0.15916) (accu: 0.9747)
[epoch : 28] (l_loss: 0.00342) (t_loss: 0.15508) (accu: 0.9756)
[epoch : 29] (l_loss: 0.00284) (t_loss: 0.15678) (accu: 0.9764)
[epoch : 30] (l_loss: 0.00224) (t_loss: 0.15551) (accu: 0.9766)
[epoch : 31] (l_loss: 0.00277) (t_loss: 0.17123) (accu: 0.9754)
[epoch : 32] (l_loss: 0.00337) (t_loss: 0.16991) (accu: 0.9749)
[epoch : 33] (l_loss: 0.00172) (t_loss: 0.17037) (accu: 0.9760)
[epoch : 34] (l_loss: 0.00131) (t_loss: 0.17555) (accu: 0.9761)
[epoch : 35] (l_loss: 0.00319) (t_loss: 0.18581) (accu: 0.9752)
[epoch : 36] (l_loss: 0.00188) (t_loss: 0.18254) (accu: 0.9753)
[epoch : 37] (l_loss: 0.00150) (t_loss: 0.18266) (accu: 0.9763)
[epoch : 38] (l_loss: 0.00205) (t_loss: 0.19043) (accu: 0.9757)
[epoch : 39] (l_loss: 0.00280) (t_loss: 0.18969) (accu: 0.9755)
[epoch : 40] (l_loss: 0.00093) (t_loss: 0.18864) (accu: 0.9769)
Finish! (Best accu: 0.9769) (Time taken(sec) : 742.47) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (3982 | 211518)          1.85
fc1.weight   :       196000 (3531 | 192469)          1.80
fc2.weight   :        18750 (338 | 18412)            1.80
fcout.weight :          750 (113 | 637)             15.07
------------------------------------------------------------
Learning start! [Test_Iter : (2/3), Prune_iter : (19/19), Remaining weight : 1.85 %]
[epoch : 1] (l_loss: 0.50930) (t_loss: 0.15542) (accu: 0.9549)
[epoch : 2] (l_loss: 0.12614) (t_loss: 0.11017) (accu: 0.9670)
[epoch : 3] (l_loss: 0.08959) (t_loss: 0.09398) (accu: 0.9733)
[epoch : 4] (l_loss: 0.07087) (t_loss: 0.08721) (accu: 0.9742)
[epoch : 5] (l_loss: 0.05848) (t_loss: 0.08478) (accu: 0.9744)
[epoch : 6] (l_loss: 0.05008) (t_loss: 0.08470) (accu: 0.9747)
[epoch : 7] (l_loss: 0.04336) (t_loss: 0.08365) (accu: 0.9740)
[epoch : 8] (l_loss: 0.03835) (t_loss: 0.08164) (accu: 0.9758)
[epoch : 9] (l_loss: 0.03388) (t_loss: 0.08757) (accu: 0.9753)
[epoch : 10] (l_loss: 0.03075) (t_loss: 0.08654) (accu: 0.9760)
[epoch : 11] (l_loss: 0.02807) (t_loss: 0.09098) (accu: 0.9753)
[epoch : 12] (l_loss: 0.02508) (t_loss: 0.09208) (accu: 0.9748)
[epoch : 13] (l_loss: 0.02335) (t_loss: 0.09489) (accu: 0.9744)
[epoch : 14] (l_loss: 0.02133) (t_loss: 0.10103) (accu: 0.9739)
[epoch : 15] (l_loss: 0.01989) (t_loss: 0.10271) (accu: 0.9746)
[epoch : 16] (l_loss: 0.01870) (t_loss: 0.10321) (accu: 0.9748)
[epoch : 17] (l_loss: 0.01724) (t_loss: 0.10723) (accu: 0.9731)
[epoch : 18] (l_loss: 0.01622) (t_loss: 0.10922) (accu: 0.9744)
[epoch : 19] (l_loss: 0.01492) (t_loss: 0.11407) (accu: 0.9743)
[epoch : 20] (l_loss: 0.01396) (t_loss: 0.11993) (accu: 0.9732)
[epoch : 21] (l_loss: 0.01315) (t_loss: 0.11896) (accu: 0.9746)
[epoch : 22] (l_loss: 0.01262) (t_loss: 0.12210) (accu: 0.9739)
[epoch : 23] (l_loss: 0.01160) (t_loss: 0.12789) (accu: 0.9749)
[epoch : 24] (l_loss: 0.01089) (t_loss: 0.13278) (accu: 0.9740)
[epoch : 25] (l_loss: 0.01033) (t_loss: 0.13357) (accu: 0.9744)
[epoch : 26] (l_loss: 0.00950) (t_loss: 0.13693) (accu: 0.9736)
[epoch : 27] (l_loss: 0.00878) (t_loss: 0.14318) (accu: 0.9742)
[epoch : 28] (l_loss: 0.00883) (t_loss: 0.15038) (accu: 0.9730)
[epoch : 29] (l_loss: 0.00817) (t_loss: 0.14671) (accu: 0.9729)
[epoch : 30] (l_loss: 0.00754) (t_loss: 0.14884) (accu: 0.9729)
[epoch : 31] (l_loss: 0.00702) (t_loss: 0.15810) (accu: 0.9726)
[epoch : 32] (l_loss: 0.00673) (t_loss: 0.15759) (accu: 0.9743)
[epoch : 33] (l_loss: 0.00601) (t_loss: 0.15844) (accu: 0.9739)
[epoch : 34] (l_loss: 0.00611) (t_loss: 0.16184) (accu: 0.9734)
[epoch : 35] (l_loss: 0.00532) (t_loss: 0.16631) (accu: 0.9727)
[epoch : 36] (l_loss: 0.00522) (t_loss: 0.17032) (accu: 0.9735)
[epoch : 37] (l_loss: 0.00494) (t_loss: 0.17929) (accu: 0.9726)
[epoch : 38] (l_loss: 0.00464) (t_loss: 0.17965) (accu: 0.9734)
[epoch : 39] (l_loss: 0.00463) (t_loss: 0.18019) (accu: 0.9725)
[epoch : 40] (l_loss: 0.00428) (t_loss: 0.18838) (accu: 0.9730)
Finish! (Best accu: 0.9760) (Time taken(sec) : 751.52) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :        215500 (215500 | 0)          100.00
fc1.weight   :        196000 (196000 | 0)          100.00
fc2.weight   :         18750 (18750 | 0)           100.00
fcout.weight :           750 (750 | 0)             100.00
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (1/19), Remaining weight : 100.0 %]
[epoch : 1] (l_loss: 0.22324) (t_loss: 0.13821) (accu: 0.9557)
[epoch : 2] (l_loss: 0.09791) (t_loss: 0.08544) (accu: 0.9730)
[epoch : 3] (l_loss: 0.06686) (t_loss: 0.09253) (accu: 0.9727)
[epoch : 4] (l_loss: 0.05352) (t_loss: 0.08050) (accu: 0.9763)
[epoch : 5] (l_loss: 0.04435) (t_loss: 0.10674) (accu: 0.9688)
[epoch : 6] (l_loss: 0.03914) (t_loss: 0.09521) (accu: 0.9755)
[epoch : 7] (l_loss: 0.03381) (t_loss: 0.09423) (accu: 0.9748)
[epoch : 8] (l_loss: 0.02680) (t_loss: 0.08733) (accu: 0.9782)
[epoch : 9] (l_loss: 0.02632) (t_loss: 0.08719) (accu: 0.9782)
[epoch : 10] (l_loss: 0.02447) (t_loss: 0.11311) (accu: 0.9764)
[epoch : 11] (l_loss: 0.01810) (t_loss: 0.09596) (accu: 0.9786)
[epoch : 12] (l_loss: 0.02129) (t_loss: 0.10451) (accu: 0.9780)
[epoch : 13] (l_loss: 0.02241) (t_loss: 0.10543) (accu: 0.9782)
[epoch : 14] (l_loss: 0.01622) (t_loss: 0.11338) (accu: 0.9792)
[epoch : 15] (l_loss: 0.01918) (t_loss: 0.10559) (accu: 0.9799)
[epoch : 16] (l_loss: 0.01531) (t_loss: 0.11767) (accu: 0.9788)
[epoch : 17] (l_loss: 0.02061) (t_loss: 0.10214) (accu: 0.9807)
[epoch : 18] (l_loss: 0.01088) (t_loss: 0.10318) (accu: 0.9807)
[epoch : 19] (l_loss: 0.01670) (t_loss: 0.10592) (accu: 0.9798)
[epoch : 20] (l_loss: 0.01009) (t_loss: 0.12971) (accu: 0.9797)
[epoch : 21] (l_loss: 0.01727) (t_loss: 0.10438) (accu: 0.9813)
[epoch : 22] (l_loss: 0.01276) (t_loss: 0.14933) (accu: 0.9779)
[epoch : 23] (l_loss: 0.01260) (t_loss: 0.11944) (accu: 0.9820)
[epoch : 24] (l_loss: 0.01217) (t_loss: 0.12800) (accu: 0.9807)
[epoch : 25] (l_loss: 0.01268) (t_loss: 0.11689) (accu: 0.9826)
[epoch : 26] (l_loss: 0.01149) (t_loss: 0.13627) (accu: 0.9805)
[epoch : 27] (l_loss: 0.01129) (t_loss: 0.13722) (accu: 0.9801)
[epoch : 28] (l_loss: 0.01288) (t_loss: 0.13506) (accu: 0.9814)
[epoch : 29] (l_loss: 0.01280) (t_loss: 0.12926) (accu: 0.9820)
[epoch : 30] (l_loss: 0.00615) (t_loss: 0.14559) (accu: 0.9802)
[epoch : 31] (l_loss: 0.01022) (t_loss: 0.13849) (accu: 0.9810)
[epoch : 32] (l_loss: 0.01376) (t_loss: 0.15789) (accu: 0.9800)
[epoch : 33] (l_loss: 0.01266) (t_loss: 0.16149) (accu: 0.9795)
[epoch : 34] (l_loss: 0.00965) (t_loss: 0.16456) (accu: 0.9792)
[epoch : 35] (l_loss: 0.00859) (t_loss: 0.17738) (accu: 0.9802)
[epoch : 36] (l_loss: 0.00932) (t_loss: 0.16629) (accu: 0.9808)
[epoch : 37] (l_loss: 0.01119) (t_loss: 0.15251) (accu: 0.9808)
[epoch : 38] (l_loss: 0.01138) (t_loss: 0.16087) (accu: 0.9800)
[epoch : 39] (l_loss: 0.00783) (t_loss: 0.19893) (accu: 0.9780)
[epoch : 40] (l_loss: 0.01138) (t_loss: 0.16162) (accu: 0.9810)
Finish! (Best accu: 0.9826) (Time taken(sec) : 685.11) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (172475 | 43025)         80.03
fc1.weight   :      196000 (156800 | 39200)         80.00
fc2.weight   :        18750 (15000 | 3750)          80.00
fcout.weight :           750 (675 | 75)             90.00
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (2/19), Remaining weight : 80.03 %]
[epoch : 1] (l_loss: 0.20892) (t_loss: 0.11062) (accu: 0.9662)
[epoch : 2] (l_loss: 0.08426) (t_loss: 0.08251) (accu: 0.9753)
[epoch : 3] (l_loss: 0.06011) (t_loss: 0.08630) (accu: 0.9739)
[epoch : 4] (l_loss: 0.04514) (t_loss: 0.09086) (accu: 0.9729)
[epoch : 5] (l_loss: 0.03687) (t_loss: 0.08799) (accu: 0.9741)
[epoch : 6] (l_loss: 0.03007) (t_loss: 0.07815) (accu: 0.9792)
[epoch : 7] (l_loss: 0.02780) (t_loss: 0.08090) (accu: 0.9787)
[epoch : 8] (l_loss: 0.02369) (t_loss: 0.08905) (accu: 0.9782)
[epoch : 9] (l_loss: 0.02113) (t_loss: 0.08185) (accu: 0.9791)
[epoch : 10] (l_loss: 0.02073) (t_loss: 0.09152) (accu: 0.9793)
[epoch : 11] (l_loss: 0.01849) (t_loss: 0.10059) (accu: 0.9781)
[epoch : 12] (l_loss: 0.01706) (t_loss: 0.10074) (accu: 0.9799)
[epoch : 13] (l_loss: 0.01543) (t_loss: 0.09495) (accu: 0.9802)
[epoch : 14] (l_loss: 0.01343) (t_loss: 0.09545) (accu: 0.9812)
[epoch : 15] (l_loss: 0.01670) (t_loss: 0.10386) (accu: 0.9803)
[epoch : 16] (l_loss: 0.01312) (t_loss: 0.09632) (accu: 0.9813)
[epoch : 17] (l_loss: 0.01335) (t_loss: 0.13099) (accu: 0.9790)
[epoch : 18] (l_loss: 0.01241) (t_loss: 0.10750) (accu: 0.9822)
[epoch : 19] (l_loss: 0.01276) (t_loss: 0.10142) (accu: 0.9808)
[epoch : 20] (l_loss: 0.01322) (t_loss: 0.12871) (accu: 0.9770)
[epoch : 21] (l_loss: 0.00772) (t_loss: 0.11820) (accu: 0.9798)
[epoch : 22] (l_loss: 0.01303) (t_loss: 0.12795) (accu: 0.9798)
[epoch : 23] (l_loss: 0.00943) (t_loss: 0.12821) (accu: 0.9803)
[epoch : 24] (l_loss: 0.01127) (t_loss: 0.12216) (accu: 0.9811)
[epoch : 25] (l_loss: 0.01368) (t_loss: 0.17230) (accu: 0.9754)
[epoch : 26] (l_loss: 0.01124) (t_loss: 0.13677) (accu: 0.9796)
[epoch : 27] (l_loss: 0.00835) (t_loss: 0.12093) (accu: 0.9814)
[epoch : 28] (l_loss: 0.00825) (t_loss: 0.13191) (accu: 0.9821)
[epoch : 29] (l_loss: 0.01161) (t_loss: 0.15423) (accu: 0.9784)
[epoch : 30] (l_loss: 0.00974) (t_loss: 0.14729) (accu: 0.9809)
[epoch : 31] (l_loss: 0.00777) (t_loss: 0.14114) (accu: 0.9816)
[epoch : 32] (l_loss: 0.01208) (t_loss: 0.18944) (accu: 0.9785)
[epoch : 33] (l_loss: 0.00833) (t_loss: 0.16355) (accu: 0.9825)
[epoch : 34] (l_loss: 0.01098) (t_loss: 0.17370) (accu: 0.9790)
[epoch : 35] (l_loss: 0.01120) (t_loss: 0.16372) (accu: 0.9814)
[epoch : 36] (l_loss: 0.00730) (t_loss: 0.15659) (accu: 0.9819)
[epoch : 37] (l_loss: 0.00781) (t_loss: 0.16969) (accu: 0.9806)
[epoch : 38] (l_loss: 0.00851) (t_loss: 0.14403) (accu: 0.9825)
[epoch : 39] (l_loss: 0.01096) (t_loss: 0.15310) (accu: 0.9806)
[epoch : 40] (l_loss: 0.01059) (t_loss: 0.15000) (accu: 0.9832)
Finish! (Best accu: 0.9832) (Time taken(sec) : 682.23) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (138048 | 77452)         64.06
fc1.weight   :      196000 (125440 | 70560)         64.00
fc2.weight   :        18750 (12000 | 6750)          64.00
fcout.weight :          750 (608 | 142)             81.07
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (3/19), Remaining weight : 64.06 %]
[epoch : 1] (l_loss: 0.20107) (t_loss: 0.10005) (accu: 0.9683)
[epoch : 2] (l_loss: 0.07891) (t_loss: 0.06826) (accu: 0.9773)
[epoch : 3] (l_loss: 0.05263) (t_loss: 0.07566) (accu: 0.9776)
[epoch : 4] (l_loss: 0.03920) (t_loss: 0.07813) (accu: 0.9753)
[epoch : 5] (l_loss: 0.03265) (t_loss: 0.07355) (accu: 0.9788)
[epoch : 6] (l_loss: 0.02559) (t_loss: 0.07428) (accu: 0.9805)
[epoch : 7] (l_loss: 0.02392) (t_loss: 0.08633) (accu: 0.9765)
[epoch : 8] (l_loss: 0.02059) (t_loss: 0.07887) (accu: 0.9815)
[epoch : 9] (l_loss: 0.01989) (t_loss: 0.09976) (accu: 0.9753)
[epoch : 10] (l_loss: 0.01735) (t_loss: 0.09513) (accu: 0.9788)
[epoch : 11] (l_loss: 0.01526) (t_loss: 0.10179) (accu: 0.9798)
[epoch : 12] (l_loss: 0.01314) (t_loss: 0.10533) (accu: 0.9779)
[epoch : 13] (l_loss: 0.01560) (t_loss: 0.08474) (accu: 0.9824)
[epoch : 14] (l_loss: 0.01056) (t_loss: 0.10217) (accu: 0.9810)
[epoch : 15] (l_loss: 0.01319) (t_loss: 0.13265) (accu: 0.9777)
[epoch : 16] (l_loss: 0.01158) (t_loss: 0.10813) (accu: 0.9811)
[epoch : 17] (l_loss: 0.01232) (t_loss: 0.10988) (accu: 0.9792)
[epoch : 18] (l_loss: 0.01187) (t_loss: 0.11370) (accu: 0.9813)
[epoch : 19] (l_loss: 0.01024) (t_loss: 0.11456) (accu: 0.9807)
[epoch : 20] (l_loss: 0.00877) (t_loss: 0.12687) (accu: 0.9784)
[epoch : 21] (l_loss: 0.00986) (t_loss: 0.11631) (accu: 0.9827)
[epoch : 22] (l_loss: 0.01042) (t_loss: 0.13185) (accu: 0.9802)
[epoch : 23] (l_loss: 0.01172) (t_loss: 0.11739) (accu: 0.9816)
[epoch : 24] (l_loss: 0.00896) (t_loss: 0.14179) (accu: 0.9800)
[epoch : 25] (l_loss: 0.00913) (t_loss: 0.14809) (accu: 0.9788)
[epoch : 26] (l_loss: 0.00879) (t_loss: 0.16921) (accu: 0.9764)
[epoch : 27] (l_loss: 0.01039) (t_loss: 0.14731) (accu: 0.9794)
[epoch : 28] (l_loss: 0.00793) (t_loss: 0.13314) (accu: 0.9827)
[epoch : 29] (l_loss: 0.00582) (t_loss: 0.14270) (accu: 0.9823)
[epoch : 30] (l_loss: 0.01100) (t_loss: 0.13750) (accu: 0.9805)
[epoch : 31] (l_loss: 0.00735) (t_loss: 0.13729) (accu: 0.9818)
[epoch : 32] (l_loss: 0.00700) (t_loss: 0.13988) (accu: 0.9833)
[epoch : 33] (l_loss: 0.01035) (t_loss: 0.19598) (accu: 0.9791)
[epoch : 34] (l_loss: 0.00701) (t_loss: 0.16165) (accu: 0.9807)
[epoch : 35] (l_loss: 0.00311) (t_loss: 0.14646) (accu: 0.9822)
[epoch : 36] (l_loss: 0.01255) (t_loss: 0.17339) (accu: 0.9784)
[epoch : 37] (l_loss: 0.00845) (t_loss: 0.17491) (accu: 0.9779)
[epoch : 38] (l_loss: 0.00539) (t_loss: 0.14680) (accu: 0.9825)
[epoch : 39] (l_loss: 0.00681) (t_loss: 0.16459) (accu: 0.9809)
[epoch : 40] (l_loss: 0.00802) (t_loss: 0.17170) (accu: 0.9795)
Finish! (Best accu: 0.9833) (Time taken(sec) : 693.20) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (110499 | 105001)        51.28
fc1.weight   :      196000 (100352 | 95648)         51.20
fc2.weight   :        18750 (9600 | 9150)           51.20
fcout.weight :          750 (547 | 203)             72.93
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (4/19), Remaining weight : 51.28 %]
[epoch : 1] (l_loss: 0.19595) (t_loss: 0.09713) (accu: 0.9709)
[epoch : 2] (l_loss: 0.07140) (t_loss: 0.07543) (accu: 0.9770)
[epoch : 3] (l_loss: 0.04953) (t_loss: 0.07281) (accu: 0.9779)
[epoch : 4] (l_loss: 0.03510) (t_loss: 0.07730) (accu: 0.9772)
[epoch : 5] (l_loss: 0.02859) (t_loss: 0.07923) (accu: 0.9791)
[epoch : 6] (l_loss: 0.02268) (t_loss: 0.08810) (accu: 0.9777)
[epoch : 7] (l_loss: 0.02066) (t_loss: 0.08672) (accu: 0.9790)
[epoch : 8] (l_loss: 0.01865) (t_loss: 0.09311) (accu: 0.9771)
[epoch : 9] (l_loss: 0.01540) (t_loss: 0.08893) (accu: 0.9797)
[epoch : 10] (l_loss: 0.01599) (t_loss: 0.09596) (accu: 0.9779)
[epoch : 11] (l_loss: 0.01074) (t_loss: 0.08793) (accu: 0.9820)
[epoch : 12] (l_loss: 0.01259) (t_loss: 0.10810) (accu: 0.9805)
[epoch : 13] (l_loss: 0.01149) (t_loss: 0.11175) (accu: 0.9808)
[epoch : 14] (l_loss: 0.00943) (t_loss: 0.12225) (accu: 0.9770)
[epoch : 15] (l_loss: 0.01492) (t_loss: 0.11644) (accu: 0.9799)
[epoch : 16] (l_loss: 0.00716) (t_loss: 0.10934) (accu: 0.9806)
[epoch : 17] (l_loss: 0.00845) (t_loss: 0.10927) (accu: 0.9798)
[epoch : 18] (l_loss: 0.01142) (t_loss: 0.13245) (accu: 0.9787)
[epoch : 19] (l_loss: 0.00850) (t_loss: 0.12801) (accu: 0.9801)
[epoch : 20] (l_loss: 0.00856) (t_loss: 0.17588) (accu: 0.9743)
[epoch : 21] (l_loss: 0.00896) (t_loss: 0.15383) (accu: 0.9765)
[epoch : 22] (l_loss: 0.00926) (t_loss: 0.13708) (accu: 0.9803)
[epoch : 23] (l_loss: 0.00802) (t_loss: 0.13089) (accu: 0.9811)
[epoch : 24] (l_loss: 0.00769) (t_loss: 0.13792) (accu: 0.9808)
[epoch : 25] (l_loss: 0.00774) (t_loss: 0.14720) (accu: 0.9798)
[epoch : 26] (l_loss: 0.00953) (t_loss: 0.13482) (accu: 0.9822)
[epoch : 27] (l_loss: 0.00636) (t_loss: 0.13182) (accu: 0.9825)
[epoch : 28] (l_loss: 0.01107) (t_loss: 0.13369) (accu: 0.9816)
[epoch : 29] (l_loss: 0.00610) (t_loss: 0.12798) (accu: 0.9821)
[epoch : 30] (l_loss: 0.00761) (t_loss: 0.14028) (accu: 0.9816)
[epoch : 31] (l_loss: 0.00457) (t_loss: 0.15887) (accu: 0.9778)
[epoch : 32] (l_loss: 0.00756) (t_loss: 0.17097) (accu: 0.9796)
[epoch : 33] (l_loss: 0.00633) (t_loss: 0.15134) (accu: 0.9799)
[epoch : 34] (l_loss: 0.00741) (t_loss: 0.14547) (accu: 0.9817)
[epoch : 35] (l_loss: 0.00647) (t_loss: 0.17417) (accu: 0.9791)
[epoch : 36] (l_loss: 0.00709) (t_loss: 0.14989) (accu: 0.9830)
[epoch : 37] (l_loss: 0.00793) (t_loss: 0.16366) (accu: 0.9802)
[epoch : 38] (l_loss: 0.00517) (t_loss: 0.18573) (accu: 0.9793)
[epoch : 39] (l_loss: 0.00722) (t_loss: 0.15679) (accu: 0.9816)
[epoch : 40] (l_loss: 0.00608) (t_loss: 0.14623) (accu: 0.9830)
Finish! (Best accu: 0.9830) (Time taken(sec) : 708.43) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (88454 | 127046)         41.05
fc1.weight   :      196000 (80282 | 115718)         40.96
fc2.weight   :        18750 (7680 | 11070)          40.96
fcout.weight :          750 (492 | 258)             65.60
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (5/19), Remaining weight : 41.05 %]
[epoch : 1] (l_loss: 0.19362) (t_loss: 0.08783) (accu: 0.9745)
[epoch : 2] (l_loss: 0.06755) (t_loss: 0.07198) (accu: 0.9764)
[epoch : 3] (l_loss: 0.04369) (t_loss: 0.07768) (accu: 0.9750)
[epoch : 4] (l_loss: 0.03180) (t_loss: 0.06725) (accu: 0.9789)
[epoch : 5] (l_loss: 0.02374) (t_loss: 0.08854) (accu: 0.9766)
[epoch : 6] (l_loss: 0.02035) (t_loss: 0.07190) (accu: 0.9819)
[epoch : 7] (l_loss: 0.01620) (t_loss: 0.08641) (accu: 0.9778)
[epoch : 8] (l_loss: 0.01292) (t_loss: 0.07728) (accu: 0.9814)
[epoch : 9] (l_loss: 0.01357) (t_loss: 0.08941) (accu: 0.9795)
[epoch : 10] (l_loss: 0.01208) (t_loss: 0.09831) (accu: 0.9791)
[epoch : 11] (l_loss: 0.01286) (t_loss: 0.08661) (accu: 0.9816)
[epoch : 12] (l_loss: 0.00535) (t_loss: 0.09445) (accu: 0.9827)
[epoch : 13] (l_loss: 0.01471) (t_loss: 0.09285) (accu: 0.9809)
[epoch : 14] (l_loss: 0.00823) (t_loss: 0.10263) (accu: 0.9791)
[epoch : 15] (l_loss: 0.00889) (t_loss: 0.10208) (accu: 0.9794)
[epoch : 16] (l_loss: 0.00674) (t_loss: 0.10773) (accu: 0.9795)
[epoch : 17] (l_loss: 0.01092) (t_loss: 0.11257) (accu: 0.9794)
[epoch : 18] (l_loss: 0.00618) (t_loss: 0.12452) (accu: 0.9777)
[epoch : 19] (l_loss: 0.00834) (t_loss: 0.11332) (accu: 0.9801)
[epoch : 20] (l_loss: 0.00602) (t_loss: 0.13712) (accu: 0.9779)
[epoch : 21] (l_loss: 0.00809) (t_loss: 0.10836) (accu: 0.9813)
[epoch : 22] (l_loss: 0.00698) (t_loss: 0.12583) (accu: 0.9800)
[epoch : 23] (l_loss: 0.00734) (t_loss: 0.10765) (accu: 0.9829)
[epoch : 24] (l_loss: 0.00546) (t_loss: 0.12490) (accu: 0.9807)
[epoch : 25] (l_loss: 0.00610) (t_loss: 0.12530) (accu: 0.9820)
[epoch : 26] (l_loss: 0.00819) (t_loss: 0.15730) (accu: 0.9777)
[epoch : 27] (l_loss: 0.00465) (t_loss: 0.13511) (accu: 0.9813)
[epoch : 28] (l_loss: 0.00890) (t_loss: 0.14113) (accu: 0.9773)
[epoch : 29] (l_loss: 0.00585) (t_loss: 0.13919) (accu: 0.9801)
[epoch : 30] (l_loss: 0.00313) (t_loss: 0.12023) (accu: 0.9819)
[epoch : 31] (l_loss: 0.00616) (t_loss: 0.15760) (accu: 0.9769)
[epoch : 32] (l_loss: 0.00876) (t_loss: 0.13647) (accu: 0.9807)
[epoch : 33] (l_loss: 0.00426) (t_loss: 0.15926) (accu: 0.9810)
[epoch : 34] (l_loss: 0.00935) (t_loss: 0.13645) (accu: 0.9814)
[epoch : 35] (l_loss: 0.00325) (t_loss: 0.13786) (accu: 0.9802)
[epoch : 36] (l_loss: 0.00702) (t_loss: 0.18736) (accu: 0.9781)
[epoch : 37] (l_loss: 0.00486) (t_loss: 0.14420) (accu: 0.9833)
[epoch : 38] (l_loss: 0.00171) (t_loss: 0.15543) (accu: 0.9801)
[epoch : 39] (l_loss: 0.01268) (t_loss: 0.15931) (accu: 0.9801)
[epoch : 40] (l_loss: 0.00356) (t_loss: 0.15436) (accu: 0.9795)
Finish! (Best accu: 0.9833) (Time taken(sec) : 711.83) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (70812 | 144688)         32.86
fc1.weight   :      196000 (64225 | 131775)         32.77
fc2.weight   :        18750 (6144 | 12606)          32.77
fcout.weight :          750 (443 | 307)             59.07
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (6/19), Remaining weight : 32.86 %]
[epoch : 1] (l_loss: 0.18831) (t_loss: 0.08583) (accu: 0.9729)
[epoch : 2] (l_loss: 0.06125) (t_loss: 0.07488) (accu: 0.9754)
[epoch : 3] (l_loss: 0.03754) (t_loss: 0.07404) (accu: 0.9770)
[epoch : 4] (l_loss: 0.02569) (t_loss: 0.06529) (accu: 0.9814)
[epoch : 5] (l_loss: 0.01981) (t_loss: 0.07153) (accu: 0.9785)
[epoch : 6] (l_loss: 0.01641) (t_loss: 0.08402) (accu: 0.9778)
[epoch : 7] (l_loss: 0.01311) (t_loss: 0.07871) (accu: 0.9796)
[epoch : 8] (l_loss: 0.01014) (t_loss: 0.08946) (accu: 0.9790)
[epoch : 9] (l_loss: 0.01197) (t_loss: 0.08414) (accu: 0.9800)
[epoch : 10] (l_loss: 0.00848) (t_loss: 0.08083) (accu: 0.9816)
[epoch : 11] (l_loss: 0.00957) (t_loss: 0.09868) (accu: 0.9792)
[epoch : 12] (l_loss: 0.00850) (t_loss: 0.10808) (accu: 0.9779)
[epoch : 13] (l_loss: 0.00811) (t_loss: 0.10056) (accu: 0.9805)
[epoch : 14] (l_loss: 0.00560) (t_loss: 0.08687) (accu: 0.9825)
[epoch : 15] (l_loss: 0.00871) (t_loss: 0.10480) (accu: 0.9800)
[epoch : 16] (l_loss: 0.00699) (t_loss: 0.12035) (accu: 0.9786)
[epoch : 17] (l_loss: 0.00582) (t_loss: 0.11443) (accu: 0.9790)
[epoch : 18] (l_loss: 0.00918) (t_loss: 0.11206) (accu: 0.9786)
[epoch : 19] (l_loss: 0.00641) (t_loss: 0.11400) (accu: 0.9793)
[epoch : 20] (l_loss: 0.00507) (t_loss: 0.11419) (accu: 0.9810)
[epoch : 21] (l_loss: 0.00652) (t_loss: 0.11238) (accu: 0.9806)
[epoch : 22] (l_loss: 0.00411) (t_loss: 0.11172) (accu: 0.9806)
[epoch : 23] (l_loss: 0.00602) (t_loss: 0.12979) (accu: 0.9799)
[epoch : 24] (l_loss: 0.00721) (t_loss: 0.12584) (accu: 0.9799)
[epoch : 25] (l_loss: 0.00427) (t_loss: 0.11850) (accu: 0.9808)
[epoch : 26] (l_loss: 0.00286) (t_loss: 0.11967) (accu: 0.9809)
[epoch : 27] (l_loss: 0.00709) (t_loss: 0.12137) (accu: 0.9807)
[epoch : 28] (l_loss: 0.00360) (t_loss: 0.12203) (accu: 0.9823)
[epoch : 29] (l_loss: 0.00458) (t_loss: 0.13390) (accu: 0.9819)
[epoch : 30] (l_loss: 0.00690) (t_loss: 0.14508) (accu: 0.9785)
[epoch : 31] (l_loss: 0.00410) (t_loss: 0.11874) (accu: 0.9826)
[epoch : 32] (l_loss: 0.00456) (t_loss: 0.14675) (accu: 0.9791)
[epoch : 33] (l_loss: 0.00513) (t_loss: 0.13080) (accu: 0.9825)
[epoch : 34] (l_loss: 0.00208) (t_loss: 0.13341) (accu: 0.9819)
[epoch : 35] (l_loss: 0.00425) (t_loss: 0.16970) (accu: 0.9800)
[epoch : 36] (l_loss: 0.00504) (t_loss: 0.15498) (accu: 0.9790)
[epoch : 37] (l_loss: 0.00423) (t_loss: 0.15120) (accu: 0.9818)
[epoch : 38] (l_loss: 0.00449) (t_loss: 0.14158) (accu: 0.9821)
[epoch : 39] (l_loss: 0.00558) (t_loss: 0.14830) (accu: 0.9826)
[epoch : 40] (l_loss: 0.00444) (t_loss: 0.15311) (accu: 0.9802)
Finish! (Best accu: 0.9826) (Time taken(sec) : 717.33) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (56694 | 158806)         26.31
fc1.weight   :      196000 (51380 | 144620)         26.21
fc2.weight   :        18750 (4915 | 13835)          26.21
fcout.weight :          750 (399 | 351)             53.20
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (7/19), Remaining weight : 26.31 %]
[epoch : 1] (l_loss: 0.18347) (t_loss: 0.08358) (accu: 0.9745)
[epoch : 2] (l_loss: 0.05408) (t_loss: 0.07092) (accu: 0.9776)
[epoch : 3] (l_loss: 0.03234) (t_loss: 0.06203) (accu: 0.9804)
[epoch : 4] (l_loss: 0.02151) (t_loss: 0.06991) (accu: 0.9793)
[epoch : 5] (l_loss: 0.01479) (t_loss: 0.06419) (accu: 0.9811)
[epoch : 6] (l_loss: 0.01128) (t_loss: 0.07881) (accu: 0.9787)
[epoch : 7] (l_loss: 0.01081) (t_loss: 0.11222) (accu: 0.9745)
[epoch : 8] (l_loss: 0.00954) (t_loss: 0.09197) (accu: 0.9791)
[epoch : 9] (l_loss: 0.00838) (t_loss: 0.09014) (accu: 0.9795)
[epoch : 10] (l_loss: 0.00734) (t_loss: 0.09222) (accu: 0.9817)
[epoch : 11] (l_loss: 0.00632) (t_loss: 0.09298) (accu: 0.9804)
[epoch : 12] (l_loss: 0.00811) (t_loss: 0.09407) (accu: 0.9800)
[epoch : 13] (l_loss: 0.00556) (t_loss: 0.11073) (accu: 0.9789)
[epoch : 14] (l_loss: 0.00549) (t_loss: 0.10070) (accu: 0.9813)
[epoch : 15] (l_loss: 0.00806) (t_loss: 0.11597) (accu: 0.9781)
[epoch : 16] (l_loss: 0.00325) (t_loss: 0.10804) (accu: 0.9812)
[epoch : 17] (l_loss: 0.00545) (t_loss: 0.12299) (accu: 0.9769)
[epoch : 18] (l_loss: 0.00486) (t_loss: 0.12290) (accu: 0.9784)
[epoch : 19] (l_loss: 0.00669) (t_loss: 0.10483) (accu: 0.9794)
[epoch : 20] (l_loss: 0.00518) (t_loss: 0.12810) (accu: 0.9780)
[epoch : 21] (l_loss: 0.00370) (t_loss: 0.12929) (accu: 0.9798)
[epoch : 22] (l_loss: 0.00421) (t_loss: 0.12050) (accu: 0.9809)
[epoch : 23] (l_loss: 0.00396) (t_loss: 0.14250) (accu: 0.9774)
[epoch : 24] (l_loss: 0.00443) (t_loss: 0.12204) (accu: 0.9811)
[epoch : 25] (l_loss: 0.00595) (t_loss: 0.12593) (accu: 0.9809)
[epoch : 26] (l_loss: 0.00225) (t_loss: 0.12359) (accu: 0.9809)
[epoch : 27] (l_loss: 0.00452) (t_loss: 0.14271) (accu: 0.9794)
[epoch : 28] (l_loss: 0.00217) (t_loss: 0.14027) (accu: 0.9808)
[epoch : 29] (l_loss: 0.00663) (t_loss: 0.15627) (accu: 0.9794)
[epoch : 30] (l_loss: 0.00422) (t_loss: 0.13820) (accu: 0.9810)
[epoch : 31] (l_loss: 0.00274) (t_loss: 0.14260) (accu: 0.9815)
[epoch : 32] (l_loss: 0.00230) (t_loss: 0.12524) (accu: 0.9845)
[epoch : 33] (l_loss: 0.00525) (t_loss: 0.16413) (accu: 0.9801)
[epoch : 34] (l_loss: 0.00498) (t_loss: 0.15656) (accu: 0.9806)
[epoch : 35] (l_loss: 0.00446) (t_loss: 0.15280) (accu: 0.9810)
[epoch : 36] (l_loss: 0.00256) (t_loss: 0.16062) (accu: 0.9809)
[epoch : 37] (l_loss: 0.00517) (t_loss: 0.16323) (accu: 0.9801)
[epoch : 38] (l_loss: 0.00264) (t_loss: 0.15044) (accu: 0.9819)
[epoch : 39] (l_loss: 0.00259) (t_loss: 0.15744) (accu: 0.9811)
[epoch : 40] (l_loss: 0.00548) (t_loss: 0.16005) (accu: 0.9810)
Finish! (Best accu: 0.9845) (Time taken(sec) : 720.27) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (45395 | 170105)         21.06
fc1.weight   :      196000 (41104 | 154896)         20.97
fc2.weight   :        18750 (3932 | 14818)          20.97
fcout.weight :          750 (359 | 391)             47.87
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (8/19), Remaining weight : 21.06 %]
[epoch : 1] (l_loss: 0.17965) (t_loss: 0.07777) (accu: 0.9752)
[epoch : 2] (l_loss: 0.04955) (t_loss: 0.05943) (accu: 0.9810)
[epoch : 3] (l_loss: 0.02794) (t_loss: 0.06865) (accu: 0.9786)
[epoch : 4] (l_loss: 0.01887) (t_loss: 0.06589) (accu: 0.9809)
[epoch : 5] (l_loss: 0.01269) (t_loss: 0.06978) (accu: 0.9809)
[epoch : 6] (l_loss: 0.01029) (t_loss: 0.07179) (accu: 0.9816)
[epoch : 7] (l_loss: 0.00720) (t_loss: 0.07608) (accu: 0.9808)
[epoch : 8] (l_loss: 0.00707) (t_loss: 0.08487) (accu: 0.9801)
[epoch : 9] (l_loss: 0.00666) (t_loss: 0.08786) (accu: 0.9810)
[epoch : 10] (l_loss: 0.00593) (t_loss: 0.08887) (accu: 0.9811)
[epoch : 11] (l_loss: 0.00534) (t_loss: 0.08142) (accu: 0.9821)
[epoch : 12] (l_loss: 0.00515) (t_loss: 0.10693) (accu: 0.9793)
[epoch : 13] (l_loss: 0.00413) (t_loss: 0.10251) (accu: 0.9809)
[epoch : 14] (l_loss: 0.00436) (t_loss: 0.10730) (accu: 0.9794)
[epoch : 15] (l_loss: 0.00593) (t_loss: 0.10496) (accu: 0.9800)
[epoch : 16] (l_loss: 0.00383) (t_loss: 0.11315) (accu: 0.9808)
[epoch : 17] (l_loss: 0.00367) (t_loss: 0.11193) (accu: 0.9806)
[epoch : 18] (l_loss: 0.00441) (t_loss: 0.13247) (accu: 0.9772)
[epoch : 19] (l_loss: 0.00375) (t_loss: 0.11404) (accu: 0.9812)
[epoch : 20] (l_loss: 0.00452) (t_loss: 0.11554) (accu: 0.9820)
[epoch : 21] (l_loss: 0.00395) (t_loss: 0.12699) (accu: 0.9798)
[epoch : 22] (l_loss: 0.00204) (t_loss: 0.11491) (accu: 0.9823)
[epoch : 23] (l_loss: 0.00500) (t_loss: 0.12440) (accu: 0.9801)
[epoch : 24] (l_loss: 0.00341) (t_loss: 0.13477) (accu: 0.9799)
[epoch : 25] (l_loss: 0.00334) (t_loss: 0.12868) (accu: 0.9815)
[epoch : 26] (l_loss: 0.00423) (t_loss: 0.11750) (accu: 0.9832)
[epoch : 27] (l_loss: 0.00289) (t_loss: 0.11609) (accu: 0.9821)
[epoch : 28] (l_loss: 0.00243) (t_loss: 0.15877) (accu: 0.9779)
[epoch : 29] (l_loss: 0.00469) (t_loss: 0.13729) (accu: 0.9801)
[epoch : 30] (l_loss: 0.00262) (t_loss: 0.13412) (accu: 0.9817)
[epoch : 31] (l_loss: 0.00247) (t_loss: 0.14652) (accu: 0.9804)
[epoch : 32] (l_loss: 0.00288) (t_loss: 0.13916) (accu: 0.9827)
[epoch : 33] (l_loss: 0.00347) (t_loss: 0.17252) (accu: 0.9794)
[epoch : 34] (l_loss: 0.00339) (t_loss: 0.13909) (accu: 0.9821)
[epoch : 35] (l_loss: 0.00383) (t_loss: 0.13857) (accu: 0.9816)
[epoch : 36] (l_loss: 0.00134) (t_loss: 0.13972) (accu: 0.9829)
[epoch : 37] (l_loss: 0.00366) (t_loss: 0.15760) (accu: 0.9807)
[epoch : 38] (l_loss: 0.00442) (t_loss: 0.14610) (accu: 0.9816)
[epoch : 39] (l_loss: 0.00271) (t_loss: 0.14542) (accu: 0.9824)
[epoch : 40] (l_loss: 0.00139) (t_loss: 0.14845) (accu: 0.9808)
Finish! (Best accu: 0.9832) (Time taken(sec) : 731.43) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (36352 | 179148)         16.87
fc1.weight   :      196000 (32883 | 163117)         16.78
fc2.weight   :        18750 (3146 | 15604)          16.78
fcout.weight :          750 (323 | 427)             43.07
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (9/19), Remaining weight : 16.87 %]
[epoch : 1] (l_loss: 0.18681) (t_loss: 0.07206) (accu: 0.9776)
[epoch : 2] (l_loss: 0.04707) (t_loss: 0.06524) (accu: 0.9786)
[epoch : 3] (l_loss: 0.02730) (t_loss: 0.05656) (accu: 0.9827)
[epoch : 4] (l_loss: 0.01589) (t_loss: 0.06319) (accu: 0.9818)
[epoch : 5] (l_loss: 0.01159) (t_loss: 0.06200) (accu: 0.9830)
[epoch : 6] (l_loss: 0.00760) (t_loss: 0.07693) (accu: 0.9792)
[epoch : 7] (l_loss: 0.00646) (t_loss: 0.07238) (accu: 0.9822)
[epoch : 8] (l_loss: 0.00590) (t_loss: 0.07708) (accu: 0.9812)
[epoch : 9] (l_loss: 0.00512) (t_loss: 0.08751) (accu: 0.9800)
[epoch : 10] (l_loss: 0.00463) (t_loss: 0.09407) (accu: 0.9790)
[epoch : 11] (l_loss: 0.00399) (t_loss: 0.08884) (accu: 0.9819)
[epoch : 12] (l_loss: 0.00403) (t_loss: 0.09185) (accu: 0.9834)
[epoch : 13] (l_loss: 0.00460) (t_loss: 0.09236) (accu: 0.9814)
[epoch : 14] (l_loss: 0.00279) (t_loss: 0.09379) (accu: 0.9824)
[epoch : 15] (l_loss: 0.00430) (t_loss: 0.09619) (accu: 0.9812)
[epoch : 16] (l_loss: 0.00349) (t_loss: 0.10298) (accu: 0.9808)
[epoch : 17] (l_loss: 0.00244) (t_loss: 0.08964) (accu: 0.9827)
[epoch : 18] (l_loss: 0.00315) (t_loss: 0.10408) (accu: 0.9830)
[epoch : 19] (l_loss: 0.00635) (t_loss: 0.09965) (accu: 0.9821)
[epoch : 20] (l_loss: 0.00146) (t_loss: 0.09849) (accu: 0.9821)
[epoch : 21] (l_loss: 0.00037) (t_loss: 0.11126) (accu: 0.9819)
[epoch : 22] (l_loss: 0.00590) (t_loss: 0.10786) (accu: 0.9823)
[epoch : 23] (l_loss: 0.00243) (t_loss: 0.11706) (accu: 0.9817)
[epoch : 24] (l_loss: 0.00140) (t_loss: 0.11892) (accu: 0.9822)
[epoch : 25] (l_loss: 0.00439) (t_loss: 0.11352) (accu: 0.9821)
[epoch : 26] (l_loss: 0.00183) (t_loss: 0.12338) (accu: 0.9822)
[epoch : 27] (l_loss: 0.00134) (t_loss: 0.13231) (accu: 0.9818)
[epoch : 28] (l_loss: 0.00126) (t_loss: 0.13023) (accu: 0.9811)
[epoch : 29] (l_loss: 0.00607) (t_loss: 0.13496) (accu: 0.9811)
[epoch : 30] (l_loss: 0.00286) (t_loss: 0.14534) (accu: 0.9795)
[epoch : 31] (l_loss: 0.00189) (t_loss: 0.13627) (accu: 0.9811)
[epoch : 32] (l_loss: 0.00189) (t_loss: 0.13019) (accu: 0.9809)
[epoch : 33] (l_loss: 0.00228) (t_loss: 0.13161) (accu: 0.9817)
[epoch : 34] (l_loss: 0.00209) (t_loss: 0.13994) (accu: 0.9813)
[epoch : 35] (l_loss: 0.00333) (t_loss: 0.12458) (accu: 0.9829)
[epoch : 36] (l_loss: 0.00119) (t_loss: 0.12764) (accu: 0.9826)
[epoch : 37] (l_loss: 0.00241) (t_loss: 0.16470) (accu: 0.9806)
[epoch : 38] (l_loss: 0.00086) (t_loss: 0.13638) (accu: 0.9827)
[epoch : 39] (l_loss: 0.00098) (t_loss: 0.15175) (accu: 0.9816)
[epoch : 40] (l_loss: 0.00517) (t_loss: 0.14637) (accu: 0.9831)
Finish! (Best accu: 0.9834) (Time taken(sec) : 731.15) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (29115 | 186385)         13.51
fc1.weight   :      196000 (26307 | 169693)         13.42
fc2.weight   :        18750 (2517 | 16233)          13.42
fcout.weight :          750 (291 | 459)             38.80
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (10/19), Remaining weight : 13.51 %]
[epoch : 1] (l_loss: 0.19364) (t_loss: 0.07603) (accu: 0.9769)
[epoch : 2] (l_loss: 0.04696) (t_loss: 0.05904) (accu: 0.9816)
[epoch : 3] (l_loss: 0.02566) (t_loss: 0.05609) (accu: 0.9832)
[epoch : 4] (l_loss: 0.01601) (t_loss: 0.05846) (accu: 0.9829)
[epoch : 5] (l_loss: 0.00977) (t_loss: 0.06956) (accu: 0.9805)
[epoch : 6] (l_loss: 0.00699) (t_loss: 0.07258) (accu: 0.9833)
[epoch : 7] (l_loss: 0.00676) (t_loss: 0.06902) (accu: 0.9835)
[epoch : 8] (l_loss: 0.00420) (t_loss: 0.07596) (accu: 0.9818)
[epoch : 9] (l_loss: 0.00393) (t_loss: 0.08110) (accu: 0.9815)
[epoch : 10] (l_loss: 0.00588) (t_loss: 0.08568) (accu: 0.9813)
[epoch : 11] (l_loss: 0.00275) (t_loss: 0.08025) (accu: 0.9835)
[epoch : 12] (l_loss: 0.00076) (t_loss: 0.08309) (accu: 0.9831)
[epoch : 13] (l_loss: 0.00669) (t_loss: 0.09123) (accu: 0.9828)
[epoch : 14] (l_loss: 0.00236) (t_loss: 0.08526) (accu: 0.9823)
[epoch : 15] (l_loss: 0.00095) (t_loss: 0.09188) (accu: 0.9829)
[epoch : 16] (l_loss: 0.00231) (t_loss: 0.10691) (accu: 0.9807)
[epoch : 17] (l_loss: 0.00488) (t_loss: 0.10416) (accu: 0.9813)
[epoch : 18] (l_loss: 0.00144) (t_loss: 0.10506) (accu: 0.9813)
[epoch : 19] (l_loss: 0.00244) (t_loss: 0.11224) (accu: 0.9805)
[epoch : 20] (l_loss: 0.00364) (t_loss: 0.11581) (accu: 0.9814)
[epoch : 21] (l_loss: 0.00146) (t_loss: 0.11356) (accu: 0.9828)
[epoch : 22] (l_loss: 0.00300) (t_loss: 0.11172) (accu: 0.9812)
[epoch : 23] (l_loss: 0.00179) (t_loss: 0.11354) (accu: 0.9818)
[epoch : 24] (l_loss: 0.00163) (t_loss: 0.12867) (accu: 0.9820)
[epoch : 25] (l_loss: 0.00314) (t_loss: 0.13447) (accu: 0.9794)
[epoch : 26] (l_loss: 0.00252) (t_loss: 0.12466) (accu: 0.9829)
[epoch : 27] (l_loss: 0.00123) (t_loss: 0.14509) (accu: 0.9799)
[epoch : 28] (l_loss: 0.00300) (t_loss: 0.13201) (accu: 0.9811)
[epoch : 29] (l_loss: 0.00338) (t_loss: 0.12711) (accu: 0.9817)
[epoch : 30] (l_loss: 0.00049) (t_loss: 0.11972) (accu: 0.9829)
[epoch : 31] (l_loss: 0.00028) (t_loss: 0.13004) (accu: 0.9809)
[epoch : 32] (l_loss: 0.00421) (t_loss: 0.14080) (accu: 0.9798)
[epoch : 33] (l_loss: 0.00180) (t_loss: 0.13842) (accu: 0.9809)
[epoch : 34] (l_loss: 0.00298) (t_loss: 0.12953) (accu: 0.9825)
[epoch : 35] (l_loss: 0.00118) (t_loss: 0.13301) (accu: 0.9816)
[epoch : 36] (l_loss: 0.00068) (t_loss: 0.12751) (accu: 0.9828)
[epoch : 37] (l_loss: 0.00007) (t_loss: 0.12796) (accu: 0.9825)
[epoch : 38] (l_loss: 0.00001) (t_loss: 0.12736) (accu: 0.9826)
[epoch : 39] (l_loss: 0.00001) (t_loss: 0.12704) (accu: 0.9828)
[epoch : 40] (l_loss: 0.00001) (t_loss: 0.12796) (accu: 0.9829)
Finish! (Best accu: 0.9835) (Time taken(sec) : 725.46) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (23320 | 192180)         10.82
fc1.weight   :      196000 (21045 | 174955)         10.74
fc2.weight   :        18750 (2013 | 16737)          10.74
fcout.weight :          750 (262 | 488)             34.93
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (11/19), Remaining weight : 10.82 %]
[epoch : 1] (l_loss: 0.20326) (t_loss: 0.07410) (accu: 0.9778)
[epoch : 2] (l_loss: 0.04815) (t_loss: 0.06652) (accu: 0.9801)
[epoch : 3] (l_loss: 0.02620) (t_loss: 0.05619) (accu: 0.9821)
[epoch : 4] (l_loss: 0.01571) (t_loss: 0.05922) (accu: 0.9821)
[epoch : 5] (l_loss: 0.01038) (t_loss: 0.05917) (accu: 0.9832)
[epoch : 6] (l_loss: 0.00575) (t_loss: 0.06353) (accu: 0.9823)
[epoch : 7] (l_loss: 0.00420) (t_loss: 0.07336) (accu: 0.9814)
[epoch : 8] (l_loss: 0.00463) (t_loss: 0.07745) (accu: 0.9813)
[epoch : 9] (l_loss: 0.00475) (t_loss: 0.08018) (accu: 0.9809)
[epoch : 10] (l_loss: 0.00153) (t_loss: 0.08180) (accu: 0.9829)
[epoch : 11] (l_loss: 0.00091) (t_loss: 0.08806) (accu: 0.9811)
[epoch : 12] (l_loss: 0.00541) (t_loss: 0.08440) (accu: 0.9820)
[epoch : 13] (l_loss: 0.00240) (t_loss: 0.08511) (accu: 0.9813)
[epoch : 14] (l_loss: 0.00080) (t_loss: 0.10138) (accu: 0.9794)
[epoch : 15] (l_loss: 0.00472) (t_loss: 0.11496) (accu: 0.9795)
[epoch : 16] (l_loss: 0.00292) (t_loss: 0.10711) (accu: 0.9793)
[epoch : 17] (l_loss: 0.00033) (t_loss: 0.09271) (accu: 0.9821)
[epoch : 18] (l_loss: 0.00014) (t_loss: 0.09438) (accu: 0.9828)
[epoch : 19] (l_loss: 0.00006) (t_loss: 0.09562) (accu: 0.9829)
[epoch : 20] (l_loss: 0.00004) (t_loss: 0.09483) (accu: 0.9833)
[epoch : 21] (l_loss: 0.00041) (t_loss: 0.16824) (accu: 0.9729)
[epoch : 22] (l_loss: 0.00985) (t_loss: 0.12146) (accu: 0.9787)
[epoch : 23] (l_loss: 0.00095) (t_loss: 0.11733) (accu: 0.9800)
[epoch : 24] (l_loss: 0.00027) (t_loss: 0.10366) (accu: 0.9829)
[epoch : 25] (l_loss: 0.00007) (t_loss: 0.10456) (accu: 0.9825)
[epoch : 26] (l_loss: 0.00004) (t_loss: 0.10560) (accu: 0.9830)
[epoch : 27] (l_loss: 0.00003) (t_loss: 0.10652) (accu: 0.9829)
[epoch : 28] (l_loss: 0.00002) (t_loss: 0.10736) (accu: 0.9835)
[epoch : 29] (l_loss: 0.00002) (t_loss: 0.10800) (accu: 0.9832)
[epoch : 30] (l_loss: 0.00774) (t_loss: 0.12891) (accu: 0.9795)
[epoch : 31] (l_loss: 0.00265) (t_loss: 0.12077) (accu: 0.9810)
[epoch : 32] (l_loss: 0.00077) (t_loss: 0.12317) (accu: 0.9810)
[epoch : 33] (l_loss: 0.00012) (t_loss: 0.11941) (accu: 0.9816)
[epoch : 34] (l_loss: 0.00004) (t_loss: 0.11688) (accu: 0.9820)
[epoch : 35] (l_loss: 0.00002) (t_loss: 0.11782) (accu: 0.9820)
[epoch : 36] (l_loss: 0.00002) (t_loss: 0.11818) (accu: 0.9821)
[epoch : 37] (l_loss: 0.00001) (t_loss: 0.11887) (accu: 0.9822)
[epoch : 38] (l_loss: 0.00001) (t_loss: 0.12080) (accu: 0.9827)
[epoch : 39] (l_loss: 0.00001) (t_loss: 0.12259) (accu: 0.9828)
[epoch : 40] (l_loss: 0.00000) (t_loss: 0.12441) (accu: 0.9825)
Finish! (Best accu: 0.9835) (Time taken(sec) : 722.72) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (18682 | 196818)          8.67
fc1.weight   :      196000 (16836 | 179164)          8.59
fc2.weight   :        18750 (1611 | 17139)           8.59
fcout.weight :          750 (235 | 515)             31.33
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (12/19), Remaining weight : 8.67 %]
[epoch : 1] (l_loss: 0.21856) (t_loss: 0.07738) (accu: 0.9775)
[epoch : 2] (l_loss: 0.04930) (t_loss: 0.06459) (accu: 0.9791)
[epoch : 3] (l_loss: 0.02735) (t_loss: 0.05879) (accu: 0.9821)
[epoch : 4] (l_loss: 0.01610) (t_loss: 0.05776) (accu: 0.9811)
[epoch : 5] (l_loss: 0.01047) (t_loss: 0.06137) (accu: 0.9818)
[epoch : 6] (l_loss: 0.00675) (t_loss: 0.06774) (accu: 0.9805)
[epoch : 7] (l_loss: 0.00493) (t_loss: 0.07473) (accu: 0.9800)
[epoch : 8] (l_loss: 0.00326) (t_loss: 0.07494) (accu: 0.9805)
[epoch : 9] (l_loss: 0.00288) (t_loss: 0.08027) (accu: 0.9800)
[epoch : 10] (l_loss: 0.00312) (t_loss: 0.08212) (accu: 0.9824)
[epoch : 11] (l_loss: 0.00314) (t_loss: 0.09442) (accu: 0.9787)
[epoch : 12] (l_loss: 0.00148) (t_loss: 0.08749) (accu: 0.9817)
[epoch : 13] (l_loss: 0.00051) (t_loss: 0.08873) (accu: 0.9815)
[epoch : 14] (l_loss: 0.00485) (t_loss: 0.10125) (accu: 0.9798)
[epoch : 15] (l_loss: 0.00189) (t_loss: 0.10245) (accu: 0.9806)
[epoch : 16] (l_loss: 0.00069) (t_loss: 0.09321) (accu: 0.9824)
[epoch : 17] (l_loss: 0.00013) (t_loss: 0.09451) (accu: 0.9828)
[epoch : 18] (l_loss: 0.00007) (t_loss: 0.09596) (accu: 0.9827)
[epoch : 19] (l_loss: 0.00005) (t_loss: 0.09703) (accu: 0.9832)
[epoch : 20] (l_loss: 0.00004) (t_loss: 0.10044) (accu: 0.9826)
[epoch : 21] (l_loss: 0.00003) (t_loss: 0.10262) (accu: 0.9828)
[epoch : 22] (l_loss: 0.00878) (t_loss: 0.12471) (accu: 0.9797)
[epoch : 23] (l_loss: 0.00122) (t_loss: 0.12531) (accu: 0.9796)
[epoch : 24] (l_loss: 0.00054) (t_loss: 0.11393) (accu: 0.9815)
[epoch : 25] (l_loss: 0.00010) (t_loss: 0.11301) (accu: 0.9820)
[epoch : 26] (l_loss: 0.00004) (t_loss: 0.11298) (accu: 0.9822)
[epoch : 27] (l_loss: 0.00003) (t_loss: 0.11259) (accu: 0.9823)
[epoch : 28] (l_loss: 0.00002) (t_loss: 0.11378) (accu: 0.9826)
[epoch : 29] (l_loss: 0.00580) (t_loss: 0.17097) (accu: 0.9780)
[epoch : 30] (l_loss: 0.00375) (t_loss: 0.12661) (accu: 0.9803)
[epoch : 31] (l_loss: 0.00074) (t_loss: 0.12655) (accu: 0.9814)
[epoch : 32] (l_loss: 0.00043) (t_loss: 0.13074) (accu: 0.9808)
[epoch : 33] (l_loss: 0.00343) (t_loss: 0.14104) (accu: 0.9804)
[epoch : 34] (l_loss: 0.00169) (t_loss: 0.11925) (accu: 0.9826)
[epoch : 35] (l_loss: 0.00084) (t_loss: 0.14284) (accu: 0.9799)
[epoch : 36] (l_loss: 0.00160) (t_loss: 0.12980) (accu: 0.9814)
[epoch : 37] (l_loss: 0.00271) (t_loss: 0.13066) (accu: 0.9812)
[epoch : 38] (l_loss: 0.00121) (t_loss: 0.15251) (accu: 0.9789)
[epoch : 39] (l_loss: 0.00210) (t_loss: 0.13097) (accu: 0.9814)
[epoch : 40] (l_loss: 0.00092) (t_loss: 0.12866) (accu: 0.9821)
Finish! (Best accu: 0.9832) (Time taken(sec) : 747.79) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (14969 | 200531)          6.95
fc1.weight   :      196000 (13469 | 182531)          6.87
fc2.weight   :        18750 (1288 | 17462)           6.87
fcout.weight :          750 (212 | 538)             28.27
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (13/19), Remaining weight : 6.95 %]
[epoch : 1] (l_loss: 0.24090) (t_loss: 0.07913) (accu: 0.9758)
[epoch : 2] (l_loss: 0.05275) (t_loss: 0.06123) (accu: 0.9812)
[epoch : 3] (l_loss: 0.03099) (t_loss: 0.05761) (accu: 0.9812)
[epoch : 4] (l_loss: 0.01907) (t_loss: 0.05859) (accu: 0.9816)
[epoch : 5] (l_loss: 0.01228) (t_loss: 0.06020) (accu: 0.9821)
[epoch : 6] (l_loss: 0.00797) (t_loss: 0.06288) (accu: 0.9814)
[epoch : 7] (l_loss: 0.00513) (t_loss: 0.06768) (accu: 0.9811)
[epoch : 8] (l_loss: 0.00416) (t_loss: 0.07360) (accu: 0.9807)
[epoch : 9] (l_loss: 0.00338) (t_loss: 0.07557) (accu: 0.9802)
[epoch : 10] (l_loss: 0.00319) (t_loss: 0.08551) (accu: 0.9794)
[epoch : 11] (l_loss: 0.00185) (t_loss: 0.08408) (accu: 0.9806)
[epoch : 12] (l_loss: 0.00216) (t_loss: 0.08859) (accu: 0.9796)
[epoch : 13] (l_loss: 0.00188) (t_loss: 0.07813) (accu: 0.9822)
[epoch : 14] (l_loss: 0.00149) (t_loss: 0.09487) (accu: 0.9804)
[epoch : 15] (l_loss: 0.00212) (t_loss: 0.08970) (accu: 0.9801)
[epoch : 16] (l_loss: 0.00040) (t_loss: 0.10407) (accu: 0.9788)
[epoch : 17] (l_loss: 0.00317) (t_loss: 0.10741) (accu: 0.9801)
[epoch : 18] (l_loss: 0.00138) (t_loss: 0.09555) (accu: 0.9815)
[epoch : 19] (l_loss: 0.00053) (t_loss: 0.10155) (accu: 0.9805)
[epoch : 20] (l_loss: 0.00016) (t_loss: 0.09758) (accu: 0.9806)
[epoch : 21] (l_loss: 0.00007) (t_loss: 0.09749) (accu: 0.9811)
[epoch : 22] (l_loss: 0.00005) (t_loss: 0.09822) (accu: 0.9811)
[epoch : 23] (l_loss: 0.00004) (t_loss: 0.09933) (accu: 0.9809)
[epoch : 24] (l_loss: 0.00003) (t_loss: 0.10245) (accu: 0.9821)
[epoch : 25] (l_loss: 0.00768) (t_loss: 0.11887) (accu: 0.9813)
[epoch : 26] (l_loss: 0.00122) (t_loss: 0.11332) (accu: 0.9813)
[epoch : 27] (l_loss: 0.00057) (t_loss: 0.10906) (accu: 0.9815)
[epoch : 28] (l_loss: 0.00013) (t_loss: 0.10715) (accu: 0.9812)
[epoch : 29] (l_loss: 0.00004) (t_loss: 0.10751) (accu: 0.9809)
[epoch : 30] (l_loss: 0.00003) (t_loss: 0.10829) (accu: 0.9810)
[epoch : 31] (l_loss: 0.00002) (t_loss: 0.10922) (accu: 0.9813)
[epoch : 32] (l_loss: 0.00002) (t_loss: 0.11053) (accu: 0.9813)
[epoch : 33] (l_loss: 0.00677) (t_loss: 0.13406) (accu: 0.9799)
[epoch : 34] (l_loss: 0.00182) (t_loss: 0.12509) (accu: 0.9813)
[epoch : 35] (l_loss: 0.00038) (t_loss: 0.12399) (accu: 0.9809)
[epoch : 36] (l_loss: 0.00008) (t_loss: 0.11761) (accu: 0.9823)
[epoch : 37] (l_loss: 0.00003) (t_loss: 0.11985) (accu: 0.9820)
[epoch : 38] (l_loss: 0.00002) (t_loss: 0.11993) (accu: 0.9820)
[epoch : 39] (l_loss: 0.00002) (t_loss: 0.12013) (accu: 0.9822)
[epoch : 40] (l_loss: 0.00001) (t_loss: 0.12160) (accu: 0.9822)
Finish! (Best accu: 0.9823) (Time taken(sec) : 752.41) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :      215500 (11997 | 203503)          5.57
fc1.weight   :      196000 (10775 | 185225)          5.50
fc2.weight   :        18750 (1031 | 17719)           5.50
fcout.weight :          750 (191 | 559)             25.47
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (14/19), Remaining weight : 5.57 %]
[epoch : 1] (l_loss: 0.27439) (t_loss: 0.08976) (accu: 0.9711)
[epoch : 2] (l_loss: 0.06054) (t_loss: 0.06646) (accu: 0.9787)
[epoch : 3] (l_loss: 0.03655) (t_loss: 0.06049) (accu: 0.9804)
[epoch : 4] (l_loss: 0.02379) (t_loss: 0.06069) (accu: 0.9814)
[epoch : 5] (l_loss: 0.01665) (t_loss: 0.07030) (accu: 0.9793)
[epoch : 6] (l_loss: 0.01140) (t_loss: 0.06228) (accu: 0.9816)
[epoch : 7] (l_loss: 0.00782) (t_loss: 0.07083) (accu: 0.9808)
[epoch : 8] (l_loss: 0.00549) (t_loss: 0.06924) (accu: 0.9811)
[epoch : 9] (l_loss: 0.00371) (t_loss: 0.07767) (accu: 0.9791)
[epoch : 10] (l_loss: 0.00326) (t_loss: 0.07868) (accu: 0.9801)
[epoch : 11] (l_loss: 0.00229) (t_loss: 0.08422) (accu: 0.9810)
[epoch : 12] (l_loss: 0.00207) (t_loss: 0.09029) (accu: 0.9801)
[epoch : 13] (l_loss: 0.00269) (t_loss: 0.09023) (accu: 0.9810)
[epoch : 14] (l_loss: 0.00109) (t_loss: 0.08713) (accu: 0.9815)
[epoch : 15] (l_loss: 0.00039) (t_loss: 0.09096) (accu: 0.9824)
[epoch : 16] (l_loss: 0.00270) (t_loss: 0.11199) (accu: 0.9780)
[epoch : 17] (l_loss: 0.00376) (t_loss: 0.10241) (accu: 0.9806)
[epoch : 18] (l_loss: 0.00081) (t_loss: 0.09307) (accu: 0.9819)
[epoch : 19] (l_loss: 0.00023) (t_loss: 0.09825) (accu: 0.9820)
[epoch : 20] (l_loss: 0.00013) (t_loss: 0.09734) (accu: 0.9823)
[epoch : 21] (l_loss: 0.00010) (t_loss: 0.10303) (accu: 0.9822)
[epoch : 22] (l_loss: 0.00034) (t_loss: 0.12610) (accu: 0.9777)
[epoch : 23] (l_loss: 0.00570) (t_loss: 0.11126) (accu: 0.9803)
[epoch : 24] (l_loss: 0.00049) (t_loss: 0.11252) (accu: 0.9812)
[epoch : 25] (l_loss: 0.00014) (t_loss: 0.10933) (accu: 0.9815)
[epoch : 26] (l_loss: 0.00008) (t_loss: 0.10975) (accu: 0.9819)
[epoch : 27] (l_loss: 0.00006) (t_loss: 0.11050) (accu: 0.9817)
[epoch : 28] (l_loss: 0.00005) (t_loss: 0.11147) (accu: 0.9817)
[epoch : 29] (l_loss: 0.00004) (t_loss: 0.11514) (accu: 0.9818)
[epoch : 30] (l_loss: 0.00149) (t_loss: 0.18223) (accu: 0.9743)
[epoch : 31] (l_loss: 0.00599) (t_loss: 0.13143) (accu: 0.9799)
[epoch : 32] (l_loss: 0.00064) (t_loss: 0.13049) (accu: 0.9800)
[epoch : 33] (l_loss: 0.00016) (t_loss: 0.12527) (accu: 0.9812)
[epoch : 34] (l_loss: 0.00006) (t_loss: 0.12201) (accu: 0.9814)
[epoch : 35] (l_loss: 0.00004) (t_loss: 0.12227) (accu: 0.9816)
[epoch : 36] (l_loss: 0.00003) (t_loss: 0.12289) (accu: 0.9818)
[epoch : 37] (l_loss: 0.00002) (t_loss: 0.12321) (accu: 0.9821)
[epoch : 38] (l_loss: 0.00002) (t_loss: 0.12541) (accu: 0.9823)
[epoch : 39] (l_loss: 0.00055) (t_loss: 0.17516) (accu: 0.9761)
[epoch : 40] (l_loss: 0.00631) (t_loss: 0.14488) (accu: 0.9804)
Finish! (Best accu: 0.9824) (Time taken(sec) : 749.76) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (9617 | 205883)          4.46
fc1.weight   :       196000 (8620 | 187380)          4.40
fc2.weight   :        18750 (825 | 17925)            4.40
fcout.weight :          750 (172 | 578)             22.93
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (15/19), Remaining weight : 4.46 %]
[epoch : 1] (l_loss: 0.30741) (t_loss: 0.09584) (accu: 0.9718)
[epoch : 2] (l_loss: 0.06701) (t_loss: 0.07056) (accu: 0.9778)
[epoch : 3] (l_loss: 0.04123) (t_loss: 0.06736) (accu: 0.9794)
[epoch : 4] (l_loss: 0.02767) (t_loss: 0.06107) (accu: 0.9805)
[epoch : 5] (l_loss: 0.01889) (t_loss: 0.06411) (accu: 0.9811)
[epoch : 6] (l_loss: 0.01373) (t_loss: 0.06766) (accu: 0.9815)
[epoch : 7] (l_loss: 0.00983) (t_loss: 0.07186) (accu: 0.9812)
[epoch : 8] (l_loss: 0.00666) (t_loss: 0.06901) (accu: 0.9813)
[epoch : 9] (l_loss: 0.00526) (t_loss: 0.07496) (accu: 0.9815)
[epoch : 10] (l_loss: 0.00380) (t_loss: 0.08402) (accu: 0.9805)
[epoch : 11] (l_loss: 0.00266) (t_loss: 0.08865) (accu: 0.9811)
[epoch : 12] (l_loss: 0.00221) (t_loss: 0.08687) (accu: 0.9815)
[epoch : 13] (l_loss: 0.00187) (t_loss: 0.09005) (accu: 0.9814)
[epoch : 14] (l_loss: 0.00255) (t_loss: 0.09813) (accu: 0.9796)
[epoch : 15] (l_loss: 0.00133) (t_loss: 0.09457) (accu: 0.9816)
[epoch : 16] (l_loss: 0.00064) (t_loss: 0.09810) (accu: 0.9822)
[epoch : 17] (l_loss: 0.00044) (t_loss: 0.10061) (accu: 0.9817)
[epoch : 18] (l_loss: 0.00071) (t_loss: 0.14566) (accu: 0.9747)
[epoch : 19] (l_loss: 0.00441) (t_loss: 0.10878) (accu: 0.9814)
[epoch : 20] (l_loss: 0.00040) (t_loss: 0.10898) (accu: 0.9813)
[epoch : 21] (l_loss: 0.00016) (t_loss: 0.10898) (accu: 0.9818)
[epoch : 22] (l_loss: 0.00012) (t_loss: 0.11215) (accu: 0.9814)
[epoch : 23] (l_loss: 0.00010) (t_loss: 0.11261) (accu: 0.9817)
[epoch : 24] (l_loss: 0.00008) (t_loss: 0.11700) (accu: 0.9822)
[epoch : 25] (l_loss: 0.00429) (t_loss: 0.14593) (accu: 0.9778)
[epoch : 26] (l_loss: 0.00208) (t_loss: 0.13844) (accu: 0.9788)
[epoch : 27] (l_loss: 0.00070) (t_loss: 0.12721) (accu: 0.9813)
[epoch : 28] (l_loss: 0.00057) (t_loss: 0.12959) (accu: 0.9804)
[epoch : 29] (l_loss: 0.00046) (t_loss: 0.13469) (accu: 0.9805)
[epoch : 30] (l_loss: 0.00200) (t_loss: 0.13974) (accu: 0.9804)
[epoch : 31] (l_loss: 0.00136) (t_loss: 0.14432) (accu: 0.9798)
[epoch : 32] (l_loss: 0.00034) (t_loss: 0.13299) (accu: 0.9811)
[epoch : 33] (l_loss: 0.00009) (t_loss: 0.13158) (accu: 0.9818)
[epoch : 34] (l_loss: 0.00004) (t_loss: 0.13251) (accu: 0.9821)
[epoch : 35] (l_loss: 0.00003) (t_loss: 0.13330) (accu: 0.9821)
[epoch : 36] (l_loss: 0.00002) (t_loss: 0.13394) (accu: 0.9821)
[epoch : 37] (l_loss: 0.00002) (t_loss: 0.13600) (accu: 0.9813)
[epoch : 38] (l_loss: 0.00453) (t_loss: 0.17598) (accu: 0.9780)
[epoch : 39] (l_loss: 0.00206) (t_loss: 0.15591) (accu: 0.9799)
[epoch : 40] (l_loss: 0.00024) (t_loss: 0.15186) (accu: 0.9801)
Finish! (Best accu: 0.9822) (Time taken(sec) : 731.81) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (7710 | 207790)          3.58
fc1.weight   :       196000 (6896 | 189104)          3.52
fc2.weight   :        18750 (660 | 18090)            3.52
fcout.weight :          750 (154 | 596)             20.53
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (16/19), Remaining weight : 3.58 %]
[epoch : 1] (l_loss: 0.34825) (t_loss: 0.11153) (accu: 0.9674)
[epoch : 2] (l_loss: 0.07704) (t_loss: 0.07672) (accu: 0.9768)
[epoch : 3] (l_loss: 0.04881) (t_loss: 0.06751) (accu: 0.9788)
[epoch : 4] (l_loss: 0.03370) (t_loss: 0.06694) (accu: 0.9807)
[epoch : 5] (l_loss: 0.02510) (t_loss: 0.06577) (accu: 0.9818)
[epoch : 6] (l_loss: 0.01846) (t_loss: 0.06952) (accu: 0.9818)
[epoch : 7] (l_loss: 0.01418) (t_loss: 0.07188) (accu: 0.9811)
[epoch : 8] (l_loss: 0.01082) (t_loss: 0.07465) (accu: 0.9799)
[epoch : 9] (l_loss: 0.00809) (t_loss: 0.08218) (accu: 0.9809)
[epoch : 10] (l_loss: 0.00612) (t_loss: 0.08272) (accu: 0.9816)
[epoch : 11] (l_loss: 0.00495) (t_loss: 0.08918) (accu: 0.9802)
[epoch : 12] (l_loss: 0.00373) (t_loss: 0.09087) (accu: 0.9807)
[epoch : 13] (l_loss: 0.00331) (t_loss: 0.09462) (accu: 0.9807)
[epoch : 14] (l_loss: 0.00264) (t_loss: 0.09909) (accu: 0.9801)
[epoch : 15] (l_loss: 0.00232) (t_loss: 0.10902) (accu: 0.9798)
[epoch : 16] (l_loss: 0.00217) (t_loss: 0.10745) (accu: 0.9804)
[epoch : 17] (l_loss: 0.00160) (t_loss: 0.11459) (accu: 0.9803)
[epoch : 18] (l_loss: 0.00281) (t_loss: 0.12823) (accu: 0.9796)
[epoch : 19] (l_loss: 0.00187) (t_loss: 0.11887) (accu: 0.9798)
[epoch : 20] (l_loss: 0.00060) (t_loss: 0.11864) (accu: 0.9811)
[epoch : 21] (l_loss: 0.00031) (t_loss: 0.12142) (accu: 0.9809)
[epoch : 22] (l_loss: 0.00025) (t_loss: 0.12406) (accu: 0.9807)
[epoch : 23] (l_loss: 0.00437) (t_loss: 0.13541) (accu: 0.9800)
[epoch : 24] (l_loss: 0.00107) (t_loss: 0.12994) (accu: 0.9798)
[epoch : 25] (l_loss: 0.00030) (t_loss: 0.12907) (accu: 0.9814)
[epoch : 26] (l_loss: 0.00021) (t_loss: 0.13339) (accu: 0.9806)
[epoch : 27] (l_loss: 0.00013) (t_loss: 0.13327) (accu: 0.9812)
[epoch : 28] (l_loss: 0.00209) (t_loss: 0.16591) (accu: 0.9759)
[epoch : 29] (l_loss: 0.00394) (t_loss: 0.15201) (accu: 0.9784)
[epoch : 30] (l_loss: 0.00053) (t_loss: 0.14085) (accu: 0.9801)
[epoch : 31] (l_loss: 0.00014) (t_loss: 0.14137) (accu: 0.9805)
[epoch : 32] (l_loss: 0.00010) (t_loss: 0.14214) (accu: 0.9802)
[epoch : 33] (l_loss: 0.00008) (t_loss: 0.14474) (accu: 0.9810)
[epoch : 34] (l_loss: 0.00007) (t_loss: 0.14490) (accu: 0.9813)
[epoch : 35] (l_loss: 0.00265) (t_loss: 0.16841) (accu: 0.9787)
[epoch : 36] (l_loss: 0.00309) (t_loss: 0.16428) (accu: 0.9801)
[epoch : 37] (l_loss: 0.00056) (t_loss: 0.15839) (accu: 0.9812)
[epoch : 38] (l_loss: 0.00029) (t_loss: 0.16364) (accu: 0.9798)
[epoch : 39] (l_loss: 0.00009) (t_loss: 0.16130) (accu: 0.9807)
[epoch : 40] (l_loss: 0.00005) (t_loss: 0.16166) (accu: 0.9807)
Finish! (Best accu: 0.9818) (Time taken(sec) : 727.38) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (6184 | 209316)          2.87
fc1.weight   :       196000 (5517 | 190483)          2.81
fc2.weight   :        18750 (528 | 18222)            2.82
fcout.weight :          750 (139 | 611)             18.53
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (17/19), Remaining weight : 2.87 %]
[epoch : 1] (l_loss: 0.40427) (t_loss: 0.13155) (accu: 0.9615)
[epoch : 2] (l_loss: 0.09530) (t_loss: 0.08935) (accu: 0.9718)
[epoch : 3] (l_loss: 0.06255) (t_loss: 0.07837) (accu: 0.9757)
[epoch : 4] (l_loss: 0.04646) (t_loss: 0.07205) (accu: 0.9789)
[epoch : 5] (l_loss: 0.03611) (t_loss: 0.07412) (accu: 0.9776)
[epoch : 6] (l_loss: 0.02855) (t_loss: 0.07164) (accu: 0.9789)
[epoch : 7] (l_loss: 0.02376) (t_loss: 0.07459) (accu: 0.9781)
[epoch : 8] (l_loss: 0.01922) (t_loss: 0.07628) (accu: 0.9785)
[epoch : 9] (l_loss: 0.01604) (t_loss: 0.07746) (accu: 0.9798)
[epoch : 10] (l_loss: 0.01309) (t_loss: 0.08005) (accu: 0.9780)
[epoch : 11] (l_loss: 0.01084) (t_loss: 0.08026) (accu: 0.9793)
[epoch : 12] (l_loss: 0.00911) (t_loss: 0.08525) (accu: 0.9792)
[epoch : 13] (l_loss: 0.00806) (t_loss: 0.08970) (accu: 0.9786)
[epoch : 14] (l_loss: 0.00643) (t_loss: 0.09564) (accu: 0.9787)
[epoch : 15] (l_loss: 0.00525) (t_loss: 0.09935) (accu: 0.9777)
[epoch : 16] (l_loss: 0.00455) (t_loss: 0.09843) (accu: 0.9787)
[epoch : 17] (l_loss: 0.00398) (t_loss: 0.10298) (accu: 0.9778)
[epoch : 18] (l_loss: 0.00342) (t_loss: 0.10373) (accu: 0.9799)
[epoch : 19] (l_loss: 0.00255) (t_loss: 0.11625) (accu: 0.9774)
[epoch : 20] (l_loss: 0.00228) (t_loss: 0.12012) (accu: 0.9765)
[epoch : 21] (l_loss: 0.00231) (t_loss: 0.12331) (accu: 0.9783)
[epoch : 22] (l_loss: 0.00210) (t_loss: 0.12849) (accu: 0.9786)
[epoch : 23] (l_loss: 0.00145) (t_loss: 0.12686) (accu: 0.9795)
[epoch : 24] (l_loss: 0.00177) (t_loss: 0.13204) (accu: 0.9782)
[epoch : 25] (l_loss: 0.00184) (t_loss: 0.13524) (accu: 0.9783)
[epoch : 26] (l_loss: 0.00175) (t_loss: 0.14286) (accu: 0.9782)
[epoch : 27] (l_loss: 0.00139) (t_loss: 0.14100) (accu: 0.9782)
[epoch : 28] (l_loss: 0.00075) (t_loss: 0.14342) (accu: 0.9781)
[epoch : 29] (l_loss: 0.00118) (t_loss: 0.15848) (accu: 0.9774)
[epoch : 30] (l_loss: 0.00319) (t_loss: 0.15817) (accu: 0.9760)
[epoch : 31] (l_loss: 0.00062) (t_loss: 0.15370) (accu: 0.9784)
[epoch : 32] (l_loss: 0.00026) (t_loss: 0.15223) (accu: 0.9788)
[epoch : 33] (l_loss: 0.00018) (t_loss: 0.15493) (accu: 0.9786)
[epoch : 34] (l_loss: 0.00019) (t_loss: 0.16122) (accu: 0.9778)
[epoch : 35] (l_loss: 0.00468) (t_loss: 0.17851) (accu: 0.9767)
[epoch : 36] (l_loss: 0.00082) (t_loss: 0.16657) (accu: 0.9778)
[epoch : 37] (l_loss: 0.00025) (t_loss: 0.16659) (accu: 0.9784)
[epoch : 38] (l_loss: 0.00015) (t_loss: 0.16716) (accu: 0.9778)
[epoch : 39] (l_loss: 0.00012) (t_loss: 0.16711) (accu: 0.9784)
[epoch : 40] (l_loss: 0.00011) (t_loss: 0.16959) (accu: 0.9781)
Finish! (Best accu: 0.9799) (Time taken(sec) : 746.98) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (4961 | 210539)          2.30
fc1.weight   :       196000 (4414 | 191586)          2.25
fc2.weight   :        18750 (422 | 18328)            2.25
fcout.weight :          750 (125 | 625)             16.67
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (18/19), Remaining weight : 2.3 %]
[epoch : 1] (l_loss: 0.47496) (t_loss: 0.15170) (accu: 0.9561)
[epoch : 2] (l_loss: 0.11752) (t_loss: 0.10517) (accu: 0.9684)
[epoch : 3] (l_loss: 0.07767) (t_loss: 0.08825) (accu: 0.9742)
[epoch : 4] (l_loss: 0.05825) (t_loss: 0.08045) (accu: 0.9762)
[epoch : 5] (l_loss: 0.04648) (t_loss: 0.08030) (accu: 0.9772)
[epoch : 6] (l_loss: 0.03869) (t_loss: 0.08233) (accu: 0.9761)
[epoch : 7] (l_loss: 0.03299) (t_loss: 0.07921) (accu: 0.9782)
[epoch : 8] (l_loss: 0.02898) (t_loss: 0.07761) (accu: 0.9775)
[epoch : 9] (l_loss: 0.02493) (t_loss: 0.08285) (accu: 0.9760)
[epoch : 10] (l_loss: 0.02184) (t_loss: 0.08556) (accu: 0.9764)
[epoch : 11] (l_loss: 0.01939) (t_loss: 0.08514) (accu: 0.9776)
[epoch : 12] (l_loss: 0.01710) (t_loss: 0.08909) (accu: 0.9766)
[epoch : 13] (l_loss: 0.01510) (t_loss: 0.09027) (accu: 0.9765)
[epoch : 14] (l_loss: 0.01353) (t_loss: 0.09494) (accu: 0.9777)
[epoch : 15] (l_loss: 0.01186) (t_loss: 0.09340) (accu: 0.9772)
[epoch : 16] (l_loss: 0.01101) (t_loss: 0.09732) (accu: 0.9771)
[epoch : 17] (l_loss: 0.00965) (t_loss: 0.10283) (accu: 0.9767)
[epoch : 18] (l_loss: 0.00849) (t_loss: 0.10391) (accu: 0.9778)
[epoch : 19] (l_loss: 0.00762) (t_loss: 0.10924) (accu: 0.9776)
[epoch : 20] (l_loss: 0.00698) (t_loss: 0.11112) (accu: 0.9765)
[epoch : 21] (l_loss: 0.00625) (t_loss: 0.11657) (accu: 0.9758)
[epoch : 22] (l_loss: 0.00586) (t_loss: 0.11744) (accu: 0.9763)
[epoch : 23] (l_loss: 0.00502) (t_loss: 0.12653) (accu: 0.9754)
[epoch : 24] (l_loss: 0.00452) (t_loss: 0.12902) (accu: 0.9760)
[epoch : 25] (l_loss: 0.00420) (t_loss: 0.12944) (accu: 0.9775)
[epoch : 26] (l_loss: 0.00420) (t_loss: 0.14026) (accu: 0.9754)
[epoch : 27] (l_loss: 0.00370) (t_loss: 0.13759) (accu: 0.9762)
[epoch : 28] (l_loss: 0.00296) (t_loss: 0.14171) (accu: 0.9762)
[epoch : 29] (l_loss: 0.00343) (t_loss: 0.14610) (accu: 0.9753)
[epoch : 30] (l_loss: 0.00294) (t_loss: 0.14463) (accu: 0.9767)
[epoch : 31] (l_loss: 0.00243) (t_loss: 0.14812) (accu: 0.9763)
[epoch : 32] (l_loss: 0.00260) (t_loss: 0.15493) (accu: 0.9757)
[epoch : 33] (l_loss: 0.00237) (t_loss: 0.15537) (accu: 0.9772)
[epoch : 34] (l_loss: 0.00226) (t_loss: 0.16526) (accu: 0.9762)
[epoch : 35] (l_loss: 0.00260) (t_loss: 0.16980) (accu: 0.9757)
[epoch : 36] (l_loss: 0.00161) (t_loss: 0.16452) (accu: 0.9752)
[epoch : 37] (l_loss: 0.00133) (t_loss: 0.16495) (accu: 0.9772)
[epoch : 38] (l_loss: 0.00211) (t_loss: 0.17789) (accu: 0.9747)
[epoch : 39] (l_loss: 0.00254) (t_loss: 0.17408) (accu: 0.9759)
[epoch : 40] (l_loss: 0.00174) (t_loss: 0.17658) (accu: 0.9752)
Finish! (Best accu: 0.9782) (Time taken(sec) : 751.98) 


------------------------------------------------------------
   Layer                     Weight                Ratio(%)
all.weight   :       215500 (3982 | 211518)          1.85
fc1.weight   :       196000 (3531 | 192469)          1.80
fc2.weight   :        18750 (338 | 18412)            1.80
fcout.weight :          750 (113 | 637)             15.07
------------------------------------------------------------
Learning start! [Test_Iter : (3/3), Prune_iter : (19/19), Remaining weight : 1.85 %]
[epoch : 1] (l_loss: 0.54466) (t_loss: 0.17291) (accu: 0.9465)
[epoch : 2] (l_loss: 0.13795) (t_loss: 0.12035) (accu: 0.9629)
[epoch : 3] (l_loss: 0.09657) (t_loss: 0.10148) (accu: 0.9682)
[epoch : 4] (l_loss: 0.07610) (t_loss: 0.09343) (accu: 0.9713)
[epoch : 5] (l_loss: 0.06440) (t_loss: 0.08681) (accu: 0.9730)
[epoch : 6] (l_loss: 0.05632) (t_loss: 0.08929) (accu: 0.9727)
[epoch : 7] (l_loss: 0.04926) (t_loss: 0.08686) (accu: 0.9734)
[epoch : 8] (l_loss: 0.04404) (t_loss: 0.08992) (accu: 0.9733)
[epoch : 9] (l_loss: 0.03998) (t_loss: 0.08635) (accu: 0.9740)
[epoch : 10] (l_loss: 0.03681) (t_loss: 0.08943) (accu: 0.9737)
[epoch : 11] (l_loss: 0.03381) (t_loss: 0.08970) (accu: 0.9743)
[epoch : 12] (l_loss: 0.03157) (t_loss: 0.09089) (accu: 0.9744)
[epoch : 13] (l_loss: 0.02925) (t_loss: 0.09521) (accu: 0.9739)
[epoch : 14] (l_loss: 0.02763) (t_loss: 0.09501) (accu: 0.9738)
[epoch : 15] (l_loss: 0.02550) (t_loss: 0.09653) (accu: 0.9729)
[epoch : 16] (l_loss: 0.02464) (t_loss: 0.09919) (accu: 0.9737)
[epoch : 17] (l_loss: 0.02286) (t_loss: 0.10111) (accu: 0.9730)
[epoch : 18] (l_loss: 0.02178) (t_loss: 0.10392) (accu: 0.9728)
[epoch : 19] (l_loss: 0.02080) (t_loss: 0.10707) (accu: 0.9738)
[epoch : 20] (l_loss: 0.01962) (t_loss: 0.10605) (accu: 0.9732)
[epoch : 21] (l_loss: 0.01850) (t_loss: 0.11317) (accu: 0.9714)
[epoch : 22] (l_loss: 0.01784) (t_loss: 0.11366) (accu: 0.9727)
[epoch : 23] (l_loss: 0.01692) (t_loss: 0.11940) (accu: 0.9725)
[epoch : 24] (l_loss: 0.01656) (t_loss: 0.12003) (accu: 0.9730)
[epoch : 25] (l_loss: 0.01593) (t_loss: 0.11905) (accu: 0.9735)
[epoch : 26] (l_loss: 0.01475) (t_loss: 0.12428) (accu: 0.9732)
[epoch : 27] (l_loss: 0.01446) (t_loss: 0.12071) (accu: 0.9732)
[epoch : 28] (l_loss: 0.01344) (t_loss: 0.12970) (accu: 0.9724)
[epoch : 29] (l_loss: 0.01283) (t_loss: 0.12853) (accu: 0.9725)
[epoch : 30] (l_loss: 0.01221) (t_loss: 0.12877) (accu: 0.9726)
[epoch : 31] (l_loss: 0.01169) (t_loss: 0.13948) (accu: 0.9715)
[epoch : 32] (l_loss: 0.01131) (t_loss: 0.13680) (accu: 0.9728)
[epoch : 33] (l_loss: 0.01069) (t_loss: 0.13957) (accu: 0.9732)
[epoch : 34] (l_loss: 0.01024) (t_loss: 0.14237) (accu: 0.9727)
[epoch : 35] (l_loss: 0.00958) (t_loss: 0.14695) (accu: 0.9732)
[epoch : 36] (l_loss: 0.00939) (t_loss: 0.14130) (accu: 0.9736)
[epoch : 37] (l_loss: 0.00917) (t_loss: 0.15375) (accu: 0.9720)
[epoch : 38] (l_loss: 0.00861) (t_loss: 0.14939) (accu: 0.9737)
[epoch : 39] (l_loss: 0.00838) (t_loss: 0.15987) (accu: 0.9718)
[epoch : 40] (l_loss: 0.00822) (t_loss: 0.15713) (accu: 0.9733)
Finish! (Best accu: 0.9744) (Time taken(sec) : 751.02) 


