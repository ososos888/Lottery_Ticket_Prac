{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  2\n",
      "Current cuda device  1\n",
      "GeForce RTX 2080 Ti\n",
      "cpu와 cuda 중 다음 기기로 학습함: cuda:1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(777)\n",
    "torch.cuda.manual_seed_all(777)\n",
    "\n",
    "GPU_NUM = 1 # 사용 할 GPU Num 설정\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서로 다른 2개의 model 생성\n",
    "model1 = LeNet().to(device)\n",
    "model2 = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[-0.2787, -0.0059, -0.0645],\n",
      "          [-0.0761,  0.2542,  0.2541],\n",
      "          [ 0.1495,  0.0022,  0.2166]]],\n",
      "\n",
      "\n",
      "        [[[-0.1577, -0.1258,  0.0632],\n",
      "          [-0.2605,  0.0809,  0.1567],\n",
      "          [ 0.3265,  0.2777, -0.1169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2477,  0.2583,  0.2690],\n",
      "          [-0.1864, -0.0669, -0.1780],\n",
      "          [ 0.2941,  0.2786,  0.2635]]],\n",
      "\n",
      "\n",
      "        [[[-0.0440, -0.2318, -0.1231],\n",
      "          [-0.0819,  0.0778,  0.0237],\n",
      "          [ 0.3314, -0.0815,  0.3027]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2188,  0.0973,  0.0363],\n",
      "          [-0.0865, -0.2869, -0.0754],\n",
      "          [ 0.1529,  0.2711, -0.3294]]],\n",
      "\n",
      "\n",
      "        [[[-0.3166, -0.0336, -0.1902],\n",
      "          [-0.0712,  0.0088,  0.3326],\n",
      "          [-0.2331, -0.1208,  0.2693]]]], device='cuda:1', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.1990,  0.2356, -0.2919,  0.1017,  0.3330,  0.0286], device='cuda:1',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module1 = model1.conv1\n",
    "print(list(module1.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[-0.0514, -0.2635,  0.2106],\n",
      "          [-0.1219,  0.2052,  0.0304],\n",
      "          [ 0.3253, -0.0604,  0.1738]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2386, -0.0527,  0.1259],\n",
      "          [-0.0564, -0.2797,  0.0983],\n",
      "          [ 0.0872, -0.0875, -0.1945]]],\n",
      "\n",
      "\n",
      "        [[[-0.3241,  0.2657, -0.0745],\n",
      "          [ 0.1609, -0.2248, -0.1198],\n",
      "          [-0.2865, -0.2915, -0.1375]]],\n",
      "\n",
      "\n",
      "        [[[-0.3062,  0.2593, -0.2413],\n",
      "          [-0.1232,  0.1282,  0.2384],\n",
      "          [-0.2139, -0.1481, -0.2750]]],\n",
      "\n",
      "\n",
      "        [[[-0.3030, -0.1592,  0.2061],\n",
      "          [-0.1907, -0.0852,  0.2517],\n",
      "          [ 0.1138,  0.2115, -0.0989]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3036,  0.1325,  0.1421],\n",
      "          [ 0.2825,  0.0858, -0.3250],\n",
      "          [-0.0609,  0.3233, -0.2708]]]], device='cuda:1', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.1596, -0.2679, -0.2416,  0.1971, -0.1939,  0.2151], device='cuda:1',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module2 = model2.conv1\n",
    "print(list(module2.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model1 conv1에 대하여 random pruning 진행\n",
    "prune.random_unstructured(module1, name='weight', amount=0.3)\n",
    "prune.random_unstructured(module1, name='bias', amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 1., 0.],\n",
      "          [0., 1., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [0., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]]], device='cuda:1')), ('bias_mask', tensor([1., 1., 1., 0., 0., 1.], device='cuda:1'))]\n"
     ]
    }
   ],
   "source": [
    "# mask 확인\n",
    "print(list(module1.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2787, -0.0059, -0.0000],\n",
      "          [-0.0000,  0.2542,  0.2541],\n",
      "          [ 0.1495,  0.0022,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1577, -0.1258,  0.0632],\n",
      "          [-0.2605,  0.0809,  0.1567],\n",
      "          [ 0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2477,  0.2583,  0.0000],\n",
      "          [-0.1864, -0.0000, -0.1780],\n",
      "          [ 0.2941,  0.2786,  0.2635]]],\n",
      "\n",
      "\n",
      "        [[[-0.0440, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0778,  0.0237],\n",
      "          [ 0.3314, -0.0815,  0.3027]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2188,  0.0973,  0.0363],\n",
      "          [-0.0865, -0.0000, -0.0754],\n",
      "          [ 0.1529,  0.2711, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.1902],\n",
      "          [-0.0712,  0.0088,  0.3326],\n",
      "          [-0.2331, -0.0000,  0.2693]]]], device='cuda:1',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# mask에 따라 pruning된 parameter 확인\n",
    "print(module1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1990,  0.2356, -0.2919,  0.0000,  0.0000,  0.0286], device='cuda:1',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model1.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight_orig', 'bias_orig', 'weight_mask', 'bias_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(module1.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Conv2d' object has no attribute 'bias_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-74f778f91cfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Conv2d' object has no attribute 'bias_mask'"
     ]
    }
   ],
   "source": [
    "print(model2.conv1.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooBarPruningMethod(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'structured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        mask.view(-1)[::2] = 0\n",
    "        return mask\n",
    "    \n",
    "def foobar_unstructured(module, name):\n",
    "    \"\"\"Prunes tensor corresponding to parameter called `name` in `module`\n",
    "    by removing every other entry in the tensors.\n",
    "    Modifies module in place (and also return the modified module)\n",
    "    by:\n",
    "    1) adding a named buffer called `name+'_mask'` corresponding to the\n",
    "    binary mask applied to the parameter `name` by the pruning method.\n",
    "    The parameter `name` is replaced by its pruned version, while the\n",
    "    original (unpruned) parameter is stored in a new parameter named\n",
    "    `name+'_orig'`.\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): module containing the tensor to prune\n",
    "        name (string): parameter name within `module` on which pruning\n",
    "                will act.\n",
    "\n",
    "    Returns:\n",
    "        module (nn.Module): modified (i.e. pruned) version of the input\n",
    "            module\n",
    "\n",
    "    Examples:\n",
    "        >>> m = nn.Linear(3, 4)\n",
    "        >>> foobar_unstructured(m, name='bias')\n",
    "    \"\"\"\n",
    "    FooBarPruningMethod.apply(module, name)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1.], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "foobar_unstructured(model2.conv1, name='bias')\n",
    "print(model2.conv1.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.conv1.bias_mask = model1.conv1.bias_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 0., 0., 1.], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(model2.conv1.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module1.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight', 'bias_orig', 'bias_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(module2.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.2679, -0.0000,  0.1971, -0.0000,  0.2151], device='cuda:1',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module2.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "module2.bias = module1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1990,  0.2356, -0.2919,  0.0000,  0.0000,  0.0286], device='cuda:1',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1990,  0.2356, -0.2919,  0.0000,  0.0000,  0.0286], device='cuda:1',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(2, <__main__.FooBarPruningMethod object at 0x7f3b91e98810>)])\n"
     ]
    }
   ],
   "source": [
    "print(module2._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1990,  0.2356, -0.2919,  0.0000,  0.0000,  0.0286], device='cuda:1',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foobar_unstructured(model2.conv1, name='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model2.conv1.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module2.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.conv1.weight_mask = model1.conv1.weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model2.conv1.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model2.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
